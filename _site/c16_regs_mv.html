<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="M. en C. Arturo Bell Enríquez García" />


<title>Regresiones Lineales Múltiples</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
#rmd-source-code {
  display: none;
}
</style>





<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Bioestadística con R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Clases
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Biología como Ciencia de Datos</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c1_Intro_R.html">Introducción a R</a>
        </li>
        <li>
          <a href="c2_ggplot2.html">ggplot2</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Herramientas Básicas</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c3_probabilidad.html">Probabilidad</a>
        </li>
        <li>
          <a href="c4_muestreo.html">Teoría del Muestreo</a>
        </li>
        <li>
          <a href="c5_descriptiva.html">Estadística Descriptiva</a>
        </li>
        <li>
          <a href="c6_ph0.html">Pruebas de hipótesis</a>
        </li>
        <li>
          <a href="c7_param.html">Técnicas Paramétricas</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Relaciones Lineales</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c8_rls.html">Modelo Lineal Simple</a>
        </li>
        <li>
          <a href="c9_glm.html">Modelos Lineales Generalizados</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">No Paramétrico y No Lineal</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c10_no_par.html">Técnicas No Paramétricas</a>
        </li>
        <li>
          <a href="c11_no_lineal.html">Modelos No Lineales</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Técnicas Multivariadas</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c11_intro_mv.html">Introducción</a>
        </li>
        <li>
          <a href="c12_no_sup.html">No supervisadas</a>
        </li>
        <li>
          <a href="c13_comps_mv.html">Comparaciones Multivariadas</a>
        </li>
        <li>
          <a href="c14_clasificacion.html">Clasificaciones</a>
        </li>
        <li>
          <a href="c15_regs_mv.html">Regresiones Múltiples</a>
        </li>
      </ul>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Regresiones Lineales Múltiples</h1>
<h4 class="author">M. en C. Arturo Bell Enríquez García</h4>

</div>


<p><strong><a href="https://youtu.be/Kb8CwFgC9Zs">VIDEO</a></strong></p>
<div id="funciones-personalizadas" class="section level2">
<h2>Funciones personalizadas</h2>
<pre class="r"><code># Tema personalizado
blank_theme &lt;- function(aspect.ratio = 1/1.61){
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank(),
        axis.line = element_blank(),
        aspect.ratio = aspect.ratio,
        axis.ticks = element_blank(),
        text = element_text(colour = &quot;gray50&quot;), # Eliminar
        legend.position = &quot;none&quot;
        )
}</code></pre>
</div>
<div id="regresión-lineal-múltiple" class="section level2">
<h2>Regresión Lineal Múltiple</h2>
<p>Para esta sección utilizaremos los datos de la base <code>crime.csv</code>. El objetivo será predecir la tasa de crimenes/poblacion a partir de otras 88 variables:</p>
<p>La variable que nos interesa predecir es el la columna <code>ViolentCrimesPerPop</code>). Apliquemos un modelo de regresión lineal múltiple incluyendo todas las variables, sin dividir los datos en entrenamiento-prueba y sin escalarlos. Tampoco filtraremos los datos para evitar una fuga de información:</p>
<pre class="r"><code>dr.df &lt;- read.csv(&quot;data/crime.csv&quot;)[,-c(1)]
head(dr.df)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["population"],"name":[1],"type":["int"],"align":["right"]},{"label":["householdsize"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["agePct12t21"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["agePct12t29"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["agePct16t24"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["agePct65up"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["numbUrban"],"name":[7],"type":["int"],"align":["right"]},{"label":["pctUrban"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["medIncome"],"name":[9],"type":["int"],"align":["right"]},{"label":["pctWWage"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["pctWFarmSelf"],"name":[11],"type":["dbl"],"align":["right"]},{"label":["pctWInvInc"],"name":[12],"type":["dbl"],"align":["right"]},{"label":["pctWSocSec"],"name":[13],"type":["dbl"],"align":["right"]},{"label":["pctWPubAsst"],"name":[14],"type":["dbl"],"align":["right"]},{"label":["pctWRetire"],"name":[15],"type":["dbl"],"align":["right"]},{"label":["medFamInc"],"name":[16],"type":["int"],"align":["right"]},{"label":["perCapInc"],"name":[17],"type":["int"],"align":["right"]},{"label":["NumUnderPov"],"name":[18],"type":["int"],"align":["right"]},{"label":["PctPopUnderPov"],"name":[19],"type":["dbl"],"align":["right"]},{"label":["PctLess9thGrade"],"name":[20],"type":["dbl"],"align":["right"]},{"label":["PctNotHSGrad"],"name":[21],"type":["dbl"],"align":["right"]},{"label":["PctBSorMore"],"name":[22],"type":["dbl"],"align":["right"]},{"label":["PctUnemployed"],"name":[23],"type":["dbl"],"align":["right"]},{"label":["PctEmploy"],"name":[24],"type":["dbl"],"align":["right"]},{"label":["PctEmplManu"],"name":[25],"type":["dbl"],"align":["right"]},{"label":["PctEmplProfServ"],"name":[26],"type":["dbl"],"align":["right"]},{"label":["PctOccupManu"],"name":[27],"type":["dbl"],"align":["right"]},{"label":["PctOccupMgmtProf"],"name":[28],"type":["dbl"],"align":["right"]},{"label":["MalePctDivorce"],"name":[29],"type":["dbl"],"align":["right"]},{"label":["MalePctNevMarr"],"name":[30],"type":["dbl"],"align":["right"]},{"label":["FemalePctDiv"],"name":[31],"type":["dbl"],"align":["right"]},{"label":["TotalPctDiv"],"name":[32],"type":["dbl"],"align":["right"]},{"label":["PersPerFam"],"name":[33],"type":["dbl"],"align":["right"]},{"label":["PctFam2Par"],"name":[34],"type":["dbl"],"align":["right"]},{"label":["PctKids2Par"],"name":[35],"type":["dbl"],"align":["right"]},{"label":["PctYoungKids2Par"],"name":[36],"type":["dbl"],"align":["right"]},{"label":["PctTeen2Par"],"name":[37],"type":["dbl"],"align":["right"]},{"label":["PctWorkMomYoungKids"],"name":[38],"type":["dbl"],"align":["right"]},{"label":["PctWorkMom"],"name":[39],"type":["dbl"],"align":["right"]},{"label":["NumKidsBornNeverMar"],"name":[40],"type":["int"],"align":["right"]},{"label":["PctKidsBornNeverMar"],"name":[41],"type":["dbl"],"align":["right"]},{"label":["NumImmig"],"name":[42],"type":["int"],"align":["right"]},{"label":["PctImmigRecent"],"name":[43],"type":["dbl"],"align":["right"]},{"label":["PctImmigRec5"],"name":[44],"type":["dbl"],"align":["right"]},{"label":["PctImmigRec8"],"name":[45],"type":["dbl"],"align":["right"]},{"label":["PctImmigRec10"],"name":[46],"type":["dbl"],"align":["right"]},{"label":["PctRecentImmig"],"name":[47],"type":["dbl"],"align":["right"]},{"label":["PctRecImmig5"],"name":[48],"type":["dbl"],"align":["right"]},{"label":["PctRecImmig8"],"name":[49],"type":["dbl"],"align":["right"]},{"label":["PctRecImmig10"],"name":[50],"type":["dbl"],"align":["right"]},{"label":["PctSpeakEnglOnly"],"name":[51],"type":["dbl"],"align":["right"]},{"label":["PctNotSpeakEnglWell"],"name":[52],"type":["dbl"],"align":["right"]},{"label":["PctLargHouseFam"],"name":[53],"type":["dbl"],"align":["right"]},{"label":["PctLargHouseOccup"],"name":[54],"type":["dbl"],"align":["right"]},{"label":["PersPerOccupHous"],"name":[55],"type":["dbl"],"align":["right"]},{"label":["PersPerOwnOccHous"],"name":[56],"type":["dbl"],"align":["right"]},{"label":["PersPerRentOccHous"],"name":[57],"type":["dbl"],"align":["right"]},{"label":["PctPersOwnOccup"],"name":[58],"type":["dbl"],"align":["right"]},{"label":["PctPersDenseHous"],"name":[59],"type":["dbl"],"align":["right"]},{"label":["PctHousLess3BR"],"name":[60],"type":["dbl"],"align":["right"]},{"label":["MedNumBR"],"name":[61],"type":["int"],"align":["right"]},{"label":["HousVacant"],"name":[62],"type":["int"],"align":["right"]},{"label":["PctHousOccup"],"name":[63],"type":["dbl"],"align":["right"]},{"label":["PctHousOwnOcc"],"name":[64],"type":["dbl"],"align":["right"]},{"label":["PctVacantBoarded"],"name":[65],"type":["dbl"],"align":["right"]},{"label":["PctVacMore6Mos"],"name":[66],"type":["dbl"],"align":["right"]},{"label":["MedYrHousBuilt"],"name":[67],"type":["int"],"align":["right"]},{"label":["PctHousNoPhone"],"name":[68],"type":["dbl"],"align":["right"]},{"label":["PctWOFullPlumb"],"name":[69],"type":["dbl"],"align":["right"]},{"label":["OwnOccLowQuart"],"name":[70],"type":["int"],"align":["right"]},{"label":["OwnOccMedVal"],"name":[71],"type":["int"],"align":["right"]},{"label":["OwnOccHiQuart"],"name":[72],"type":["int"],"align":["right"]},{"label":["OwnOccQrange"],"name":[73],"type":["int"],"align":["right"]},{"label":["RentLowQ"],"name":[74],"type":["int"],"align":["right"]},{"label":["RentMedian"],"name":[75],"type":["int"],"align":["right"]},{"label":["RentHighQ"],"name":[76],"type":["int"],"align":["right"]},{"label":["RentQrange"],"name":[77],"type":["int"],"align":["right"]},{"label":["MedRent"],"name":[78],"type":["int"],"align":["right"]},{"label":["MedRentPctHousInc"],"name":[79],"type":["dbl"],"align":["right"]},{"label":["MedOwnCostPctInc"],"name":[80],"type":["dbl"],"align":["right"]},{"label":["MedOwnCostPctIncNoMtg"],"name":[81],"type":["dbl"],"align":["right"]},{"label":["NumInShelters"],"name":[82],"type":["int"],"align":["right"]},{"label":["NumStreet"],"name":[83],"type":["int"],"align":["right"]},{"label":["PctForeignBorn"],"name":[84],"type":["dbl"],"align":["right"]},{"label":["PctBornSameState"],"name":[85],"type":["dbl"],"align":["right"]},{"label":["PctSameHouse85"],"name":[86],"type":["dbl"],"align":["right"]},{"label":["PctSameCity85"],"name":[87],"type":["dbl"],"align":["right"]},{"label":["PctSameState85"],"name":[88],"type":["dbl"],"align":["right"]},{"label":["ViolentCrimesPerPop"],"name":[89],"type":["dbl"],"align":["right"]}],"data":[{"1":"11980","2":"3.10","3":"12.47","4":"21.44","5":"10.93","6":"11.33","7":"11980","8":"100","9":"75122","10":"89.24","11":"1.55","12":"70.20","13":"23.62","14":"1.03","15":"18.39","16":"79584","17":"29711","18":"227","19":"1.96","20":"5.81","21":"9.90","22":"48.18","23":"2.70","24":"64.55","25":"14.65","26":"28.82","27":"5.49","28":"50.73","29":"3.67","30":"26.38","31":"5.22","32":"4.47","33":"3.22","34":"91.43","35":"90.17","36":"95.78","37":"95.81","38":"44.56","39":"58.88","40":"31","41":"0.36","42":"1277","43":"8.69","44":"13.00","45":"20.99","46":"30.93","47":"0.93","48":"1.39","49":"2.24","50":"3.30","51":"85.68","52":"1.37","53":"4.81","54":"4.17","55":"2.99","56":"3.00","57":"2.84","58":"91.46","59":"0.39","60":"11.06","61":"3","62":"64","63":"98.37","64":"91.01","65":"3.12","66":"37.50","67":"1959","68":"0.00","69":"0.28","70":"215900","71":"262600","72":"326900","73":"111000","74":"685","75":"1001","76":"1001","77":"316","78":"1001","79":"23.8","80":"21.1","81":"14.0","82":"11","83":"0","84":"10.66","85":"53.72","86":"65.29","87":"78.09","88":"89.14","89":"41.02","_rn_":"1"},{"1":"23123","2":"2.82","3":"11.01","4":"21.30","5":"10.48","6":"17.18","7":"23123","8":"100","9":"47917","10":"78.99","11":"1.11","12":"64.11","13":"35.50","14":"2.75","15":"22.85","16":"55323","17":"20148","18":"885","19":"3.98","20":"5.61","21":"13.72","22":"29.89","23":"2.43","24":"61.96","25":"12.26","26":"29.28","27":"6.39","28":"37.64","29":"4.23","30":"27.99","31":"6.45","32":"5.42","33":"3.11","34":"86.91","35":"85.33","36":"96.82","37":"86.46","38":"51.14","39":"62.43","40":"43","41":"0.24","42":"1920","43":"5.21","44":"8.65","45":"13.33","46":"22.50","47":"0.43","48":"0.72","49":"1.11","50":"1.87","51":"87.79","52":"1.81","53":"4.25","54":"3.34","55":"2.70","56":"2.83","57":"1.96","58":"89.03","59":"1.01","60":"23.60","61":"3","62":"240","63":"97.15","64":"84.88","65":"0.00","66":"18.33","67":"1958","68":"0.31","69":"0.14","70":"136300","71":"164200","72":"199900","73":"63600","74":"467","75":"560","76":"672","77":"205","78":"627","79":"27.6","80":"20.7","81":"12.5","82":"0","83":"0","84":"8.30","85":"77.17","86":"71.27","87":"90.22","88":"96.12","89":"127.56","_rn_":"2"},{"1":"29344","2":"2.43","3":"11.36","4":"25.88","5":"11.01","6":"10.28","7":"29344","8":"100","9":"35669","10":"82.00","11":"1.15","12":"55.73","13":"22.25","14":"2.94","15":"14.56","16":"42112","17":"16946","18":"1389","19":"4.75","20":"2.80","21":"9.09","22":"30.13","23":"4.01","24":"69.80","25":"15.95","26":"21.52","27":"8.79","28":"32.48","29":"10.10","30":"25.78","31":"14.76","32":"12.55","33":"2.95","34":"78.54","35":"78.85","36":"92.37","37":"75.72","38":"66.08","39":"74.19","40":"164","41":"0.88","42":"1468","43":"16.42","44":"23.98","45":"32.08","46":"35.63","47":"0.82","48":"1.20","49":"1.61","50":"1.78","51":"93.11","52":"1.14","53":"2.97","54":"2.05","55":"2.42","56":"2.69","57":"2.06","58":"64.18","59":"2.03","60":"47.46","61":"3","62":"544","63":"95.68","64":"57.79","65":"0.92","66":"7.54","67":"1976","68":"1.55","69":"0.12","70":"74700","71":"90400","72":"112000","73":"37300","74":"370","75":"428","76":"520","77":"150","78":"484","79":"24.1","80":"21.7","81":"11.6","82":"16","83":"0","84":"5.00","85":"44.77","86":"36.60","87":"61.26","88":"82.85","89":"218.59","_rn_":"3"},{"1":"16656","2":"2.40","3":"12.55","4":"25.20","5":"12.19","6":"17.57","7":"0","8":"0","9":"20580","10":"68.15","11":"0.24","12":"38.95","13":"39.48","14":"11.71","15":"18.33","16":"26501","17":"10810","18":"2831","19":"17.23","20":"11.05","21":"33.68","22":"10.81","23":"9.86","24":"54.74","25":"31.22","26":"27.43","27":"26.76","28":"22.71","29":"10.98","30":"28.15","31":"14.47","32":"12.91","33":"2.98","34":"64.02","35":"62.36","36":"65.38","37":"67.43","38":"59.59","39":"70.27","40":"561","41":"3.84","42":"339","43":"13.86","44":"13.86","45":"15.34","46":"15.34","47":"0.28","48":"0.28","49":"0.31","50":"0.31","51":"94.98","52":"0.56","53":"3.93","54":"2.56","55":"2.37","56":"2.51","57":"2.20","58":"58.18","59":"1.21","60":"45.66","61":"3","62":"669","63":"91.19","64":"54.89","65":"2.54","66":"57.85","67":"1939","68":"7.00","69":"0.87","70":"36400","71":"49600","72":"66500","73":"30100","74":"195","75":"250","76":"309","77":"114","78":"333","79":"28.7","80":"20.6","81":"14.5","82":"0","83":"0","84":"2.04","85":"88.71","86":"56.70","87":"90.17","88":"96.24","89":"306.64","_rn_":"4"},{"1":"140494","2":"2.45","3":"18.09","4":"32.89","5":"20.04","6":"13.26","7":"140494","8":"100","9":"21577","10":"75.78","11":"1.00","12":"41.15","13":"29.31","14":"7.12","15":"14.09","16":"27705","17":"11878","18":"23223","19":"17.78","20":"8.76","21":"23.03","22":"20.66","23":"5.72","24":"59.02","25":"14.31","26":"26.83","27":"14.72","28":"23.42","29":"11.40","30":"33.32","31":"14.46","32":"13.04","33":"2.89","34":"71.94","35":"69.79","36":"79.76","37":"75.33","38":"62.96","39":"70.52","40":"1511","41":"1.58","42":"2091","43":"21.33","44":"30.56","45":"38.02","46":"45.48","47":"0.32","48":"0.45","49":"0.57","50":"0.68","51":"96.87","52":"0.60","53":"3.08","54":"1.92","55":"2.28","56":"2.37","57":"2.16","58":"57.81","59":"2.11","60":"53.19","61":"2","62":"5119","63":"91.81","64":"55.50","65":"2.09","66":"26.22","67":"1966","68":"6.13","69":"0.31","70":"37700","71":"53900","72":"73100","73":"35400","74":"215","75":"280","76":"349","77":"134","78":"340","79":"26.4","80":"17.3","81":"11.7","82":"327","83":"4","84":"1.49","85":"64.35","86":"42.29","87":"70.61","88":"85.66","89":"442.95","_rn_":"5"},{"1":"28700","2":"2.60","3":"11.17","4":"27.41","5":"12.76","6":"14.42","7":"28700","8":"100","9":"42805","10":"79.47","11":"0.39","12":"47.70","13":"30.23","14":"5.41","15":"17.23","16":"50394","17":"18193","18":"1126","19":"4.01","20":"4.49","21":"13.89","22":"27.01","23":"4.85","24":"65.42","25":"14.02","26":"27.17","27":"8.50","28":"32.78","29":"5.97","30":"36.05","31":"9.06","32":"7.64","33":"3.14","34":"79.53","35":"79.76","36":"92.05","37":"77.12","38":"65.16","39":"72.81","40":"263","41":"1.18","42":"2637","43":"11.38","44":"16.27","45":"23.93","46":"27.76","47":"1.05","48":"1.49","49":"2.20","50":"2.55","51":"89.98","52":"0.60","53":"5.08","54":"3.46","55":"2.55","56":"2.89","57":"2.09","58":"64.62","59":"1.47","60":"47.35","61":"3","62":"566","63":"95.11","64":"56.96","65":"1.41","66":"34.45","67":"1956","68":"0.69","69":"0.28","70":"155100","71":"179000","72":"215500","73":"60400","74":"463","75":"669","76":"824","77":"361","78":"736","79":"24.4","80":"20.8","81":"12.5","82":"0","83":"0","84":"9.19","85":"77.30","86":"63.45","87":"82.23","88":"93.53","89":"226.63","_rn_":"6"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>dr.lm &lt;- lm(ViolentCrimesPerPop~., data = dr.df)
summary(dr.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = ViolentCrimesPerPop ~ ., data = dr.df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1776.25  -184.04   -36.85   126.83  2194.09 
## 
## Coefficients: (2 not defined because of singularities)
##                         Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           -1.195e+03  3.295e+03  -0.363 0.716842    
## population             2.324e-04  2.049e-03   0.113 0.909703    
## householdsize         -7.569e+01  1.161e+02  -0.652 0.514556    
## agePct12t21            8.262e+00  1.279e+01   0.646 0.518346    
## agePct12t29           -3.394e+01  1.265e+01  -2.684 0.007344 ** 
## agePct16t24            1.250e+01  1.832e+01   0.682 0.495175    
## agePct65up            -1.119e+01  1.094e+01  -1.023 0.306440    
## numbUrban             -7.223e-04  2.023e-03  -0.357 0.721118    
## pctUrban               1.245e+00  4.790e-01   2.598 0.009436 ** 
## medIncome             -1.430e-02  7.156e-03  -1.998 0.045806 *  
## pctWWage              -9.557e+00  5.869e+00  -1.628 0.103596    
## pctWFarmSelf           2.328e+01  1.577e+01   1.476 0.139992    
## pctWInvInc            -6.764e+00  2.495e+00  -2.711 0.006771 ** 
## pctWSocSec             7.969e+00  5.907e+00   1.349 0.177469    
## pctWPubAsst            7.796e+00  5.838e+00   1.336 0.181861    
## pctWRetire            -9.214e+00  3.761e+00  -2.450 0.014395 *  
## medFamInc              9.378e-03  6.899e-03   1.359 0.174165    
## perCapInc              8.988e-04  7.623e-03   0.118 0.906152    
## NumUnderPov            2.705e-05  2.451e-03   0.011 0.991196    
## PctPopUnderPov        -6.144e+00  4.830e+00  -1.272 0.203515    
## PctLess9thGrade       -1.551e+01  6.320e+00  -2.454 0.014224 *  
## PctNotHSGrad           5.368e+00  4.856e+00   1.105 0.269148    
## PctBSorMore            2.611e+00  3.528e+00   0.740 0.459310    
## PctUnemployed         -1.734e+00  8.005e+00  -0.217 0.828581    
## PctEmploy              9.473e+00  4.809e+00   1.970 0.048991 *  
## PctEmplManu           -3.843e+00  2.133e+00  -1.802 0.071766 .  
## PctEmplProfServ       -3.164e-01  2.939e+00  -0.108 0.914297    
## PctOccupManu           1.303e+00  4.631e+00   0.281 0.778521    
## PctOccupMgmtProf       5.127e+00  4.664e+00   1.099 0.271738    
## MalePctDivorce         1.522e+02  6.854e+01   2.220 0.026545 *  
## MalePctNevMarr         8.419e+00  4.851e+00   1.735 0.082826 .  
## FemalePctDiv           9.881e+01  7.178e+01   1.376 0.168838    
## TotalPctDiv           -2.388e+02  1.391e+02  -1.717 0.086211 .  
## PersPerFam            -1.409e+02  3.512e+02  -0.401 0.688213    
## PctFam2Par             1.025e+01  8.784e+00   1.167 0.243302    
## PctKids2Par           -2.718e+01  6.971e+00  -3.899 9.99e-05 ***
## PctYoungKids2Par       2.794e+00  2.394e+00   1.167 0.243347    
## PctTeen2Par            3.471e-01  2.206e+00   0.157 0.874962    
## PctWorkMomYoungKids    3.659e+00  2.772e+00   1.320 0.186938    
## PctWorkMom            -9.343e+00  4.011e+00  -2.330 0.019934 *  
## NumKidsBornNeverMar   -5.637e-03  4.186e-03  -1.347 0.178236    
## PctKidsBornNeverMar    5.992e+01  9.252e+00   6.476 1.19e-10 ***
## NumImmig               1.029e-03  6.746e-04   1.525 0.127400    
## PctImmigRecent         2.153e+00  2.427e+00   0.887 0.375132    
## PctImmigRec5          -7.823e-01  3.071e+00  -0.255 0.798944    
## PctImmigRec8          -1.118e+00  3.000e+00  -0.373 0.709366    
## PctImmigRec10          1.574e+00  1.941e+00   0.811 0.417541    
## PctRecentImmig        -1.221e+01  4.962e+01  -0.246 0.805635    
## PctRecImmig5          -2.038e+01  6.021e+01  -0.339 0.734999    
## PctRecImmig8           1.590e+01  5.660e+01   0.281 0.778799    
## PctRecImmig10         -1.628e+01  3.339e+01  -0.487 0.626032    
## PctSpeakEnglOnly       1.257e+00  2.282e+00   0.551 0.581825    
## PctNotSpeakEnglWell   -2.051e+01  9.371e+00  -2.189 0.028740 *  
## PctLargHouseFam        1.952e+01  3.179e+01   0.614 0.539258    
## PctLargHouseOccup     -4.263e+01  3.462e+01  -1.232 0.218279    
## PersPerOccupHous       4.037e+02  4.203e+02   0.960 0.336949    
## PersPerOwnOccHous      3.591e+02  2.801e+02   1.282 0.199951    
## PersPerRentOccHous    -3.337e+02  1.157e+02  -2.883 0.003981 ** 
## PctPersOwnOccup       -4.662e+01  1.710e+01  -2.726 0.006470 ** 
## PctPersDenseHous       2.175e+01  6.714e+00   3.240 0.001216 ** 
## PctHousLess3BR         2.723e+00  2.058e+00   1.323 0.185976    
## MedNumBR               3.528e+01  2.662e+01   1.325 0.185226    
## HousVacant             2.096e-02  6.107e-03   3.432 0.000611 ***
## PctHousOccup          -1.933e+00  2.654e+00  -0.728 0.466650    
## PctHousOwnOcc          4.273e+01  1.714e+01   2.493 0.012761 *  
## PctVacantBoarded       1.413e+01  3.611e+00   3.914 9.41e-05 ***
## PctVacMore6Mos        -2.027e+00  9.147e-01  -2.216 0.026785 *  
## MedYrHousBuilt         1.840e+00  1.559e+00   1.180 0.238222    
## PctHousNoPhone         2.863e+00  5.658e+00   0.506 0.612853    
## PctWOFullPlumb        -5.755e+00  2.581e+01  -0.223 0.823578    
## OwnOccLowQuart         5.157e-05  1.316e-03   0.039 0.968733    
## OwnOccMedVal           2.811e-04  1.555e-03   0.181 0.856587    
## OwnOccHiQuart         -6.922e-04  6.662e-04  -1.039 0.298916    
## OwnOccQrange                  NA         NA      NA       NA    
## RentLowQ              -6.198e-01  2.612e-01  -2.373 0.017732 *  
## RentMedian            -2.455e-01  4.906e-01  -0.500 0.616889    
## RentHighQ             -2.857e-01  2.836e-01  -1.008 0.313822    
## RentQrange                    NA         NA      NA       NA    
## MedRent                1.192e+00  4.267e-01   2.792 0.005285 ** 
## MedRentPctHousInc     -2.590e+00  5.227e+00  -0.496 0.620222    
## MedOwnCostPctInc      -1.100e+00  5.934e+00  -0.185 0.852896    
## MedOwnCostPctIncNoMtg -2.819e+01  8.839e+00  -3.189 0.001450 ** 
## NumInShelters          7.886e-02  5.928e-02   1.330 0.183602    
## NumStreet             -3.028e-02  1.427e-01  -0.212 0.832056    
## PctForeignBorn         1.934e+01  6.651e+00   2.908 0.003681 ** 
## PctBornSameState       8.863e-01  1.353e+00   0.655 0.512569    
## PctSameHouse85         1.302e+00  2.646e+00   0.492 0.622713    
## PctSameCity85          1.212e+00  1.995e+00   0.607 0.543621    
## PctSameState85        -2.109e+00  3.135e+00  -0.673 0.501232    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 363 on 1907 degrees of freedom
## Multiple R-squared:  0.6665, Adjusted R-squared:  0.6514 
## F-statistic: 44.31 on 86 and 1907 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>summary(dr.df$RentQrange)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##     0.0   139.0   173.0   200.3   241.0   803.0</code></pre>
<p>Veamos qué pasa ahora si aplicamos este mismo modelo realizando la división entrenamiento-prueba.</p>
<div id="evaluación-el-problema-del-exceso-de-dimensionalidad-y-el-sobreajuste" class="section level4">
<h4>Evaluación, el PROBLEMA del exceso de dimensionalidad y el sobreajuste:</h4>
<p>Para realizar la división utilizaremos la función <code>sample.split()</code> de librería caTools:</p>
<pre class="r"><code>library(caret)
library(caTools)
set.seed(1111)
sample &lt;- sample.split(dr.df$ViolentCrimesPerPop, SplitRatio = .75)
train &lt;- subset(dr.df, sample == TRUE)
test &lt;- subset(dr.df, sample == FALSE)</code></pre>
<p>Ajustemos el modelo de entrenamiento:</p>
<pre class="r"><code>train.dr.lm &lt;- lm(ViolentCrimesPerPop~., data = train)
summary(train.dr.lm)$r.squared*100</code></pre>
<pre><code>## [1] 67.85562</code></pre>
<p>Evaluemos el desempeño en los datos de prueba.</p>
<pre class="r"><code>pred &lt;- predict.lm(train.dr.lm, test[,1:88]) </code></pre>
<pre><code>## Warning in predict.lm(train.dr.lm, test[, 1:88]): prediction from a rank-
## deficient fit may be misleading</code></pre>
<pre class="r"><code>R2(pred, test$ViolentCrimesPerPop)*100</code></pre>
<pre><code>## [1] 60.2964</code></pre>
<p>De estos resultados vemos que el modelo está sobreajustado, ya que el <span class="math inline">\(R^2\)</span> del modelo de prueba menor al de entrenamiento. Tomando esto en consideración, 1) escalemos los datos y b) apliquemos los modelos regularizados.</p>
<p>Para hacer las cosas más organizadas, primero dividamos ambos sets de datos en dos objetos: uno con las variables independientes y otro con la variable dependiente:</p>
<pre class="r"><code>X_train &lt;- train[,1:88]
y_train &lt;- train$ViolentCrimesPerPop
X_test &lt;- test[,1:88]
y_test &lt;- test$ViolentCrimesPerPop</code></pre>
<p>Ahora estandaricemos las variables dependientes:</p>
<pre class="r"><code>preProc &lt;- preProcess(X_train, method = c(&quot;center&quot;, &quot;scale&quot;))
X_train_s &lt;- predict(preProc, X_train)
X_test_s &lt;- predict(preProc, X_test)</code></pre>
</div>
</div>
<div id="regularización-l2-regresión-ridge" class="section level2">
<h2>Regularización L2: Regresión Ridge</h2>
<p>Apliquemos la regresión al set de entrenamiento. Debido a que el valor de penalización (<span class="math inline">\(\alpha\)</span> en la clase, <span class="math inline">\(\lambda\)</span> en glmnet) es “arbitrario”, podemos utilizar validación cruzada para encontrar el valor que mejor se ajuste a nuestros datos. La validación cruzada consiste en hacer k particiones entrenamiento-prueba de los datos, ajustar un modelo para cada k para cada valor del parámetro que sea de nuestro interés, promediar el valor de error de cada iteración y quedarnos con el valor del parámetro que haya logrado el menor valor de nuestra medida de error. En la librería <code>glmnet</code> esto se hace con la función <code>cv.glmnet</code>, la cual recibe como argumentos una matriz de variables independientes, un vector con variables dependientes, un valor de alpha que será 0 para regresión Ridge, 1 para Lasso y algún intermedio para red elástica (no la veremos en el curso) y el tipo de medida de error, en este caso MSE.</p>
<pre class="r"><code>library(glmnet)</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## Loaded glmnet 4.0-2</code></pre>
<pre class="r"><code>cv.ridge &lt;- cv.glmnet(as.matrix(X_train_s), y_train, alpha = 0, type.measure = &quot;mse&quot;)
lambdamin &lt;- cv.ridge$lambda.min #Contiene el valor de lambda que otorga el menor valor de error
lambdamin</code></pre>
<pre><code>## [1] 127.2735</code></pre>
<p>Ajustemos entonces el modelo regularizado con ese valor de lambda. (Df representa el número de coeficientes no negativos, %Dev = R^2).</p>
<pre class="r"><code>ridge.lm &lt;- glmnet(as.matrix(X_train_s), y_train, alpha = 0, lambda = lambdamin)
print(ridge.lm)</code></pre>
<pre><code>## 
## Call:  glmnet(x = as.matrix(X_train_s), y = y_train, alpha = 0, lambda = lambdamin) 
## 
##   Df  %Dev Lambda
## 1 88 64.37  127.3</code></pre>
<pre class="r"><code>coef(ridge.lm) # Imprime los coeficientes de la regresión</code></pre>
<pre><code>## 89 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                                s0
## (Intercept)           594.3309632
## population              1.9300180
## householdsize           1.8299619
## agePct12t21            -7.3486939
## agePct12t29           -31.9576114
## agePct16t24           -13.7190597
## agePct65up             -0.7500937
## numbUrban               2.9093075
## pctUrban               48.9548756
## medIncome               4.4813095
## pctWWage              -13.4939524
## pctWFarmSelf           -2.5372388
## pctWInvInc            -39.4099456
## pctWSocSec              5.7726094
## pctWPubAsst             8.2557445
## pctWRetire            -31.5772883
## medFamInc               0.1869270
## perCapInc               7.2125911
## NumUnderPov             1.3516081
## PctPopUnderPov          1.6304773
## PctLess9thGrade       -24.2107288
## PctNotHSGrad           23.9205978
## PctBSorMore            -4.7951480
## PctUnemployed          -4.4677466
## PctEmploy              -0.6736613
## PctEmplManu           -25.2037054
## PctEmplProfServ        -0.9096683
## PctOccupManu            1.2909056
## PctOccupMgmtProf        6.1034532
## MalePctDivorce         39.3996963
## MalePctNevMarr         24.5249604
## FemalePctDiv           -5.6875449
## TotalPctDiv            12.4548611
## PersPerFam             13.1410156
## PctFam2Par            -54.0844979
## PctKids2Par           -76.7466711
## PctYoungKids2Par      -22.7957248
## PctTeen2Par           -31.7585992
## PctWorkMomYoungKids    10.6242815
## PctWorkMom            -29.0347493
## NumKidsBornNeverMar    10.5416166
## PctKidsBornNeverMar   142.4105435
## NumImmig              -19.0071427
## PctImmigRecent          5.4033013
## PctImmigRec5           -7.4524167
## PctImmigRec8            2.4384854
## PctImmigRec10          11.0250579
## PctRecentImmig         -4.3029127
## PctRecImmig5           -1.6401076
## PctRecImmig8            8.0026637
## PctRecImmig10          14.7662164
## PctSpeakEnglOnly       24.9056068
## PctNotSpeakEnglWell   -21.4562027
## PctLargHouseFam         9.3206986
## PctLargHouseOccup      -3.4064885
## PersPerOccupHous       12.3918690
## PersPerOwnOccHous      -8.3730487
## PersPerRentOccHous      8.5386052
## PctPersOwnOccup       -10.1687491
## PctPersDenseHous       36.0367459
## PctHousLess3BR          8.7490050
## MedNumBR               -3.0382968
## HousVacant             39.6081968
## PctHousOccup          -16.0266762
## PctHousOwnOcc           4.3255442
## PctVacantBoarded       48.6961138
## PctVacMore6Mos        -13.2650164
## MedYrHousBuilt         14.3259260
## PctHousNoPhone         17.6682547
## PctWOFullPlumb          1.1437346
## OwnOccLowQuart         -3.6714089
## OwnOccMedVal           -1.3201613
## OwnOccHiQuart          -0.5468553
## OwnOccQrange            4.7164888
## RentLowQ              -15.2916481
## RentMedian              0.9769829
## RentHighQ               0.1358997
## RentQrange             25.8023901
## MedRent                15.3168827
## MedRentPctHousInc      12.2762392
## MedOwnCostPctInc        3.8327009
## MedOwnCostPctIncNoMtg -31.6350261
## NumInShelters          13.7891862
## NumStreet              -8.1076432
## PctForeignBorn         25.5580343
## PctBornSameState      -15.0924908
## PctSameHouse85         20.2263294
## PctSameCity85          10.5844297
## PctSameState85         -3.4981307</code></pre>
<p>Vemos que el valor de R2 es ligeramente menor al caso anterior; sin embargo, ganamos un poco de poder predictivo en el modelo de prueba:</p>
<pre class="r"><code>ridge.pred &lt;- predict(ridge.lm, as.matrix(X_test_s))
R2(ridge.pred, y_test)*100</code></pre>
<pre><code>##            s0
## [1,] 62.57724</code></pre>
<p>Veamos cómo afecta el valor de lambda:</p>
<pre class="r"><code>for (lambda in c(0, 0.5, 1, 2, 3, 5, 10, 20, 50, round(lambdamin,2))) {
  
  ridge.lm &lt;- glmnet(as.matrix(X_train_s), y_train, alpha = 0, lambda = lambda, standardize = F, standardize.response = F)
  ridge.pred &lt;- predict(ridge.lm, as.matrix(X_test_s))
  
  print(paste(&quot;lambda = &quot;, lambda, 
              &quot;; Variables restantes:&quot;, round(ridge.lm$df, 2), 
              &quot;; R^2 entrenamiento = &quot;, round(ridge.lm$dev.ratio,2), 
              &quot;; R^2 prueba = &quot;, round(R2(ridge.pred, y_test),2)))
  
}</code></pre>
<pre><code>## [1] &quot;lambda =  0 ; Variables restantes: 88 ; R^2 entrenamiento =  0.68 ; R^2 prueba =  0.6&quot;
## [1] &quot;lambda =  0.5 ; Variables restantes: 88 ; R^2 entrenamiento =  0.68 ; R^2 prueba =  0.61&quot;
## [1] &quot;lambda =  1 ; Variables restantes: 88 ; R^2 entrenamiento =  0.68 ; R^2 prueba =  0.61&quot;
## [1] &quot;lambda =  2 ; Variables restantes: 88 ; R^2 entrenamiento =  0.67 ; R^2 prueba =  0.61&quot;
## [1] &quot;lambda =  3 ; Variables restantes: 88 ; R^2 entrenamiento =  0.67 ; R^2 prueba =  0.62&quot;
## [1] &quot;lambda =  5 ; Variables restantes: 88 ; R^2 entrenamiento =  0.67 ; R^2 prueba =  0.62&quot;
## [1] &quot;lambda =  10 ; Variables restantes: 88 ; R^2 entrenamiento =  0.67 ; R^2 prueba =  0.62&quot;
## [1] &quot;lambda =  20 ; Variables restantes: 88 ; R^2 entrenamiento =  0.66 ; R^2 prueba =  0.62&quot;
## [1] &quot;lambda =  50 ; Variables restantes: 88 ; R^2 entrenamiento =  0.66 ; R^2 prueba =  0.63&quot;
## [1] &quot;lambda =  127.27 ; Variables restantes: 88 ; R^2 entrenamiento =  0.64 ; R^2 prueba =  0.63&quot;</code></pre>
<p>Vemos que sí hay diferencias con respecto al primer caso. Apliquemos la regresión Lasso:</p>
</div>
<div id="regularización-l1-regresión-lasso" class="section level2">
<h2>Regularización L1: Regresión Lasso</h2>
<pre class="r"><code>cv.lasso &lt;- cv.glmnet(as.matrix(X_train_s), y_train, alpha = 1, type.measure = &quot;mse&quot;)
lambdamin &lt;- cv.lasso$lambda.min #Contiene el valor de lambda que otorga el menor valor de error
lambdamin</code></pre>
<pre><code>## [1] 11.0696</code></pre>
<p>Ajustemos entonces el modelo regularizado con ese valor de lambda. (Df representa el número de coeficientes no cero, %Dev = R^2).</p>
<pre class="r"><code>lasso.lm &lt;- glmnet(as.matrix(X_train_s), y_train, alpha = 1, lambda = lambdamin)
print(lasso.lm)</code></pre>
<pre><code>## 
## Call:  glmnet(x = as.matrix(X_train_s), y = y_train, alpha = 1, lambda = lambdamin) 
## 
##   Df  %Dev Lambda
## 1 18 64.32  11.07</code></pre>
<pre class="r"><code>coef(lasso.lm) # Imprime los coeficientes de la regresión</code></pre>
<pre><code>## 89 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                                s0
## (Intercept)            594.330963
## population               .       
## householdsize            .       
## agePct12t21              .       
## agePct12t29            -37.323484
## agePct16t24              .       
## agePct65up               .       
## numbUrban                .       
## pctUrban                44.217332
## medIncome                .       
## pctWWage                 .       
## pctWFarmSelf             .       
## pctWInvInc             -19.882687
## pctWSocSec               .       
## pctWPubAsst              .       
## pctWRetire             -17.233025
## medFamInc                .       
## perCapInc                .       
## NumUnderPov              .       
## PctPopUnderPov           .       
## PctLess9thGrade          .       
## PctNotHSGrad             .       
## PctBSorMore              .       
## PctUnemployed            .       
## PctEmploy                .       
## PctEmplManu            -23.410252
## PctEmplProfServ          .       
## PctOccupManu             .       
## PctOccupMgmtProf         .       
## MalePctDivorce          62.817627
## MalePctNevMarr           .       
## FemalePctDiv             .       
## TotalPctDiv              .       
## PersPerFam               .       
## PctFam2Par               .       
## PctKids2Par           -142.983563
## PctYoungKids2Par         .       
## PctTeen2Par              .       
## PctWorkMomYoungKids      .       
## PctWorkMom             -25.586129
## NumKidsBornNeverMar      .       
## PctKidsBornNeverMar    249.397294
## NumImmig                 .       
## PctImmigRecent           .       
## PctImmigRec5             .       
## PctImmigRec8             .       
## PctImmigRec10            .       
## PctRecentImmig           .       
## PctRecImmig5             .       
## PctRecImmig8             .       
## PctRecImmig10            .       
## PctSpeakEnglOnly         .       
## PctNotSpeakEnglWell      .       
## PctLargHouseFam          .       
## PctLargHouseOccup        .       
## PersPerOccupHous         .       
## PersPerOwnOccHous        .       
## PersPerRentOccHous       .       
## PctPersOwnOccup          .       
## PctPersDenseHous        39.691353
## PctHousLess3BR           .       
## MedNumBR                 .       
## HousVacant              39.025366
## PctHousOccup           -10.913215
## PctHousOwnOcc            .       
## PctVacantBoarded        28.397825
## PctVacMore6Mos           .       
## MedYrHousBuilt           .       
## PctHousNoPhone           .       
## PctWOFullPlumb           .       
## OwnOccLowQuart           .       
## OwnOccMedVal             .       
## OwnOccHiQuart            .       
## OwnOccQrange             .       
## RentLowQ                 .       
## RentMedian               .       
## RentHighQ                .       
## RentQrange              20.416482
## MedRent                  .       
## MedRentPctHousInc        7.196892
## MedOwnCostPctInc         .       
## MedOwnCostPctIncNoMtg  -29.355351
## NumInShelters            .       
## NumStreet                .       
## PctForeignBorn          14.522357
## PctBornSameState        -7.359450
## PctSameHouse85           .       
## PctSameCity85            .       
## PctSameState85           .</code></pre>
<p>Vemos que el valor de R2 no es muy diferente al caso anterior, aunque ahora únicamente tenemos 18 coeficientes ≠ 0</p>
<pre class="r"><code>lasso.pred &lt;- predict(lasso.lm, as.matrix(X_test_s))
R2(lasso.pred, y_test)*100</code></pre>
<pre><code>##            s0
## [1,] 62.25338</code></pre>
<p>En los datos de prueba tampoco hubo mucha diferencia. Veamos cómo cambia esto al modificar el valor de lambda:</p>
<pre class="r"><code>for (lambda in c(0, 0.5, 1, 2, 3, 5, 10, 20, 50, round(lambdamin,2))) {
  
  lasso.lm &lt;- glmnet(as.matrix(X_train_s), y_train, alpha = 1, lambda = lambda, standardize = F, standardize.response = F)
  lasso.pred &lt;- predict(lasso.lm, as.matrix(X_test_s))
  
  print(paste(&quot;lambda = &quot;, lambda, 
              &quot;; Variables restantes:&quot;, round(lasso.lm$df, 2), 
              &quot;; R^2 entrenamiento = &quot;, round(lasso.lm$dev.ratio,2), 
              &quot;; R^2 prueba = &quot;, round(R2(lasso.pred, y_test),2)))
  
}</code></pre>
<pre><code>## [1] &quot;lambda =  0 ; Variables restantes: 88 ; R^2 entrenamiento =  0.68 ; R^2 prueba =  0.6&quot;
## [1] &quot;lambda =  0.5 ; Variables restantes: 76 ; R^2 entrenamiento =  0.67 ; R^2 prueba =  0.62&quot;
## [1] &quot;lambda =  1 ; Variables restantes: 61 ; R^2 entrenamiento =  0.67 ; R^2 prueba =  0.62&quot;
## [1] &quot;lambda =  2 ; Variables restantes: 47 ; R^2 entrenamiento =  0.66 ; R^2 prueba =  0.62&quot;
## [1] &quot;lambda =  3 ; Variables restantes: 36 ; R^2 entrenamiento =  0.66 ; R^2 prueba =  0.62&quot;
## [1] &quot;lambda =  5 ; Variables restantes: 27 ; R^2 entrenamiento =  0.65 ; R^2 prueba =  0.62&quot;
## [1] &quot;lambda =  10 ; Variables restantes: 19 ; R^2 entrenamiento =  0.64 ; R^2 prueba =  0.62&quot;
## [1] &quot;lambda =  20 ; Variables restantes: 16 ; R^2 entrenamiento =  0.63 ; R^2 prueba =  0.62&quot;
## [1] &quot;lambda =  50 ; Variables restantes: 8 ; R^2 entrenamiento =  0.6 ; R^2 prueba =  0.61&quot;
## [1] &quot;lambda =  11.07 ; Variables restantes: 18 ; R^2 entrenamiento =  0.64 ; R^2 prueba =  0.62&quot;</code></pre>
<p>De lo anterior podemos ver que un modelo lineal puede no ser la mejor de las opciones; además, no corroboramos ninguno de los supuestos de la regresión y con una cantidad tan alta de variables es muy posible que muchas estén altamente correlacionadas:</p>
<pre class="r"><code>library(corrplot)
corrplot(cor(dr.df), method = &quot;ellipse&quot;, type = &quot;upper&quot;)</code></pre>
<p><img src="c16_regs_mv_files/figure-html/unnamed-chunk-18-1.png" width="672" /> Podemos también hacer una matriz similar, aunque utilizando gráficos de dispersión:</p>
<pre class="r"><code>library(GGally)
#pairs &lt;- ggpairs(dr.df, progress = F)
#pairs</code></pre>
<p>La visualización de los datos se hace en parte junto con la evaluación de la regresión, en el sentido de que solo podemos ver la relación entre los datos observados y predichos por el modelo</p>
<pre class="r"><code>mlm.data &lt;- data.frame(obs = y_test, s0 = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot &lt;- ggplot(data = mlm.data, aes(x = obs, y =  s0)) + 
            geom_point() + 
            geom_smooth(method = &quot;lm&quot;, colour = rgb(118,78,144, maxColorValue = 255)) +
            labs(title = &quot;Gráfico de dispersión de datos observados y predichos&quot;,
                 subtitle = sprintf(&quot;R2e: %.2f | R2p: %.2f&quot;,round(lasso.lm$dev.ratio,2), round(R2(lasso.pred, y_test),2)),
                 caption = &quot;Datos de prueba. \n El área gris representa el intervalo de confianza de la regresión al 95%&quot;,
                 x = &quot;&quot;,
                 y = &quot;&quot;) +
            theme_bw()
mlm.plot</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="c16_regs_mv_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
</div>
<div id="ingeniería-de-variables" class="section level2">
<h2>Ingeniería de variables</h2>
<p>El resultado es un modelo que no se encuentra sobreajustado,</p>
<pre class="r"><code>library(factoextra)
library(FactoMineR)

X_train_pca &lt;- FactoMineR::PCA(X_train, graph = F, ncp = length(X_train), scale.unit = F)
X_pca_train &lt;- predict(X_train_pca, X_train)$coord
X_pca_test &lt;- predict(X_train_pca, X_test)$coord</code></pre>
<p>Evaluemos las correlaciones de los nuevos predictores con nuestra variable de interés y extraigamos aquellas que tengan correlaciones significativas (≠0):</p>
<pre class="r"><code>#library(Hmisc)
c_mat &lt;- as.data.frame(cor(cbind(X_pca_train, y_train)))$y_train
p_mat &lt;-  as.data.frame(Hmisc::rcorr(cbind(X_pca_train, y_train))$P)$y_train
p_mat &lt;- data.frame(y_train = p_mat[is.na(p_mat) == F], CP = colnames(X_pca_train))
sig_cps &lt;- p_mat$CP[p_mat$y_train &lt;= 0.05]
sig_cps</code></pre>
<pre><code>##  [1] &quot;Dim.1&quot;  &quot;Dim.2&quot;  &quot;Dim.3&quot;  &quot;Dim.4&quot;  &quot;Dim.5&quot;  &quot;Dim.7&quot;  &quot;Dim.9&quot;  &quot;Dim.10&quot;
##  [9] &quot;Dim.11&quot; &quot;Dim.12&quot; &quot;Dim.15&quot; &quot;Dim.16&quot; &quot;Dim.17&quot; &quot;Dim.18&quot; &quot;Dim.19&quot; &quot;Dim.20&quot;
## [17] &quot;Dim.23&quot; &quot;Dim.25&quot; &quot;Dim.26&quot; &quot;Dim.28&quot; &quot;Dim.30&quot; &quot;Dim.42&quot; &quot;Dim.48&quot; &quot;Dim.49&quot;
## [25] &quot;Dim.58&quot; &quot;Dim.62&quot; &quot;Dim.67&quot; &quot;Dim.69&quot; &quot;Dim.87&quot; &quot;Dim.88&quot;</code></pre>
<p>Filtramos nuestros datos:</p>
<pre class="r"><code>X_filt_train &lt;- X_pca_train[,sig_cps]
X_filt_test &lt;- X_pca_test[,sig_cps]
filt_train &lt;- data.frame(X_filt_train, y_train)</code></pre>
<p>Realicemos la regresión múltiple:</p>
<pre class="r"><code>pca_lm &lt;- train(y_train~.,
                data = filt_train,
                method = &quot;lm&quot;)
summary(pca_lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = .outcome ~ ., data = dat)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1244.48  -206.63   -45.32   146.07  2507.35 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  5.759e+02  1.229e+01  46.861  &lt; 2e-16 ***
## Dim.1        3.899e-04  2.951e-05  13.212  &lt; 2e-16 ***
## Dim.2       -4.443e-04  8.890e-05  -4.998 6.49e-07 ***
## Dim.3        1.760e-03  3.902e-04   4.511 6.97e-06 ***
## Dim.4       -5.184e-03  4.973e-04 -10.423  &lt; 2e-16 ***
## Dim.5       -2.102e-02  9.046e-04 -23.238  &lt; 2e-16 ***
## Dim.7        1.831e-02  1.788e-03  10.240  &lt; 2e-16 ***
## Dim.9       -1.458e-02  3.787e-03  -3.851 0.000123 ***
## Dim.10       1.343e-02  4.009e-03   3.350 0.000830 ***
## Dim.11       5.615e-02  5.890e-03   9.533  &lt; 2e-16 ***
## Dim.12      -3.454e-02  7.395e-03  -4.671 3.28e-06 ***
## Dim.15       4.943e-01  1.431e-01   3.454 0.000568 ***
## Dim.16      -6.797e-01  1.578e-01  -4.308 1.76e-05 ***
## Dim.17       3.921e+00  3.579e-01  10.954  &lt; 2e-16 ***
## Dim.18       5.392e+00  4.182e-01  12.893  &lt; 2e-16 ***
## Dim.19       5.572e+00  5.179e-01  10.758  &lt; 2e-16 ***
## Dim.20       4.022e+00  5.436e-01   7.399 2.30e-13 ***
## Dim.23      -1.259e+01  7.098e-01 -17.741  &lt; 2e-16 ***
## Dim.25      -6.717e+00  8.911e-01  -7.538 8.33e-14 ***
## Dim.26       4.611e+00  1.006e+00   4.582 4.99e-06 ***
## Dim.28       3.878e+00  1.116e+00   3.476 0.000524 ***
## Dim.30      -6.053e+00  1.425e+00  -4.247 2.31e-05 ***
## Dim.42       8.990e+00  3.380e+00   2.660 0.007904 ** 
## Dim.48       1.630e+01  4.114e+00   3.962 7.78e-05 ***
## Dim.49       2.079e+01  4.495e+00   4.625 4.07e-06 ***
## Dim.58      -3.642e+01  7.158e+00  -5.087 4.10e-07 ***
## Dim.62      -2.630e+01  8.636e+00  -3.045 0.002368 ** 
## Dim.67       6.076e+01  1.139e+01   5.336 1.10e-07 ***
## Dim.69      -5.835e+01  1.272e+01  -4.586 4.91e-06 ***
## Dim.87      -8.223e+10  8.700e+10  -0.945 0.344729    
## Dim.88       2.215e+14  5.611e+13   3.948 8.27e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 376.9 on 1464 degrees of freedom
## Multiple R-squared:  0.6355, Adjusted R-squared:  0.6281 
## F-statistic: 85.09 on 30 and 1464 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Los resultados son similares en los datos de entrenamiento, veamos qué pasa con los datos de prueba:</p>
<pre class="r"><code>pca_tpreds &lt;- predict(pca_lm, as.data.frame(X_filt_test))
round(R2(pca_tpreds, y_test),2)</code></pre>
<pre><code>## [1] 0.6</code></pre>
<p>Los resultados también son similares a aquellos de la regresión Lasso. La conclusión que podemos generar es que un modelo lineal como este puede no ser la mejor opción para estos datos. ¿Cómo más podríamos mejorarlo?</p>
</div>
<div id="ejercicio-1" class="section level2">
<h2>Ejercicio 1</h2>
<ol style="list-style-type: decimal">
<li>Realiza una regresión Lasso con los CPs. ¿Cuántas variables se mantienen?¿Cambia el desempeño de los modelos?</li>
<li>Realiza los diagnósticos de las regresiones Ridge, Lasso y la regresión con CP. ¿Cuál está mejor ajustada? (Performance)</li>
<li>Aplica un GLM con las variables restantes en la regresión Lasso. ¿Qué familia utilizas para el error? ¿El ajuste mejora o se mantiene igual?</li>
</ol>
</div>
<div id="ejercicio-2" class="section level2">
<h2>Ejercicio 2</h2>
<p>El objetivo es predecir la edad de individuos de abulón a partir de mediciones corporales de los mismos utilizando algún modelo lineal. Puedes también utilizar algún modelo no lineal, si es de tu interés.</p>
<p>Los datos para entrenar los modelos se encuentran <a href="https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv">aquí</a>. Las columnas corresponden a: - Longitud del organismo, - Diámetro del organismo, - Altura del organismo, - Peso entero, - Peso sin concha, - Peso de las vísceras, - Peso de la cáscara, - Edad (años)</p>
<p>Los puntos a tener en cuenta son:</p>
<ol style="list-style-type: decimal">
<li>Identificar si es necesario hacer algún procesamiento a los datos y, de ser así, aplicarlo.</li>
<li>¿Es necesario, prudente y válido incluir todas las variables en el modelo?</li>
<li>A partir del punto anterior, construir el/los modelos de regresión. ¿Es necesario utilizar un modelo penalizado/regularizado?</li>
<li>Evaluar si los modelos están sobre o sub ajustados.</li>
<li>Analizar los gráficos diagnósticos de la regresión (recuerda que todos son construidos a partir de los residuales y los valores a predecir) y evaluar la bondad de ajuste de los modelos y evaluar su calidad (e.g., ¿Son los residuales normales y homocedásticos?).</li>
<li>Una vez mejorado el modelo lo más posible (i.e., escalando los valores, eliminando variables o generando nuevas (e.g. ACP)), crea un nuevo modelo con TODAS las observaciones.</li>
<li>Predice los valores de edad de los <a href="https://storage.googleapis.com/download.tensorflow.org/data/abalone_test.csv">datos de prueba</a>. ¿Cuál es el valor de MSE y <span class="math inline">\(R^2\)</span> alcanzado por el modelo?</li>
<li>Tomando en cuenta estos resultados, ¿el modelo ajustado final se encuentra bien ajustado, sobreajustado o infraajustado?</li>
</ol>
</div>
<div id="datos" class="section level2">
<h2>Datos:</h2>
<p>El código de las siguientes celdas permite descargar los datos directamente a R desde una URL:</p>
<div id="entrenamiento" class="section level3">
<h3>Entrenamiento</h3>
<pre class="r"><code>download &lt;- RCurl::getURL(&quot;https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv&quot;)
train &lt;- read.csv(text = download, header = F)
colnames(train) &lt;- c(&quot;Long&quot;, &quot;Diam&quot;, &quot;Alt&quot;, &quot;PesoEnt&quot;, &quot;PesoDesc&quot;, &quot;PesoVisc&quot;, &quot;PesoCasc&quot;, &quot;Edad&quot;)
head(train)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Long"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Diam"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Alt"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["PesoEnt"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["PesoDesc"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["PesoVisc"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["PesoCasc"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["Edad"],"name":[8],"type":["int"],"align":["right"]}],"data":[{"1":"0.435","2":"0.335","3":"0.110","4":"0.334","5":"0.1355","6":"0.0775","7":"0.0965","8":"7","_rn_":"1"},{"1":"0.585","2":"0.450","3":"0.125","4":"0.874","5":"0.3545","6":"0.2075","7":"0.2250","8":"6","_rn_":"2"},{"1":"0.655","2":"0.510","3":"0.160","4":"1.092","5":"0.3960","6":"0.2825","7":"0.3700","8":"14","_rn_":"3"},{"1":"0.545","2":"0.425","3":"0.125","4":"0.768","5":"0.2940","6":"0.1495","7":"0.2600","8":"16","_rn_":"4"},{"1":"0.545","2":"0.420","3":"0.130","4":"0.879","5":"0.3740","6":"0.1695","7":"0.2300","8":"13","_rn_":"5"},{"1":"0.570","2":"0.450","3":"0.145","4":"0.751","5":"0.2825","6":"0.2195","7":"0.2215","8":"10","_rn_":"6"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
<div id="prueba" class="section level3">
<h3>Prueba</h3>
<pre class="r"><code>download &lt;- RCurl::getURL(&quot;https://storage.googleapis.com/download.tensorflow.org/data/abalone_test.csv&quot;)
test &lt;- read.csv(text = download, header = F)
colnames(test) &lt;- c(&quot;Long&quot;, &quot;Diam&quot;, &quot;Alt&quot;, &quot;PesoEnt&quot;, &quot;PesoDesc&quot;, &quot;PesoVisc&quot;, &quot;PesoCasc&quot;, &quot;Edad&quot;)
head(test)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Long"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Diam"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Alt"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["PesoEnt"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["PesoDesc"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["PesoVisc"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["PesoCasc"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["Edad"],"name":[8],"type":["int"],"align":["right"]}],"data":[{"1":"0.570","2":"0.465","3":"0.180","4":"1.2950","5":"0.3390","6":"0.2225","7":"0.440","8":"12","_rn_":"1"},{"1":"0.660","2":"0.530","3":"0.185","4":"1.3485","5":"0.4930","6":"0.2450","7":"0.490","8":"12","_rn_":"2"},{"1":"0.440","2":"0.345","3":"0.120","4":"0.3650","5":"0.1655","6":"0.0830","7":"0.110","8":"7","_rn_":"3"},{"1":"0.620","2":"0.475","3":"0.160","4":"1.1295","5":"0.4630","6":"0.2685","7":"0.330","8":"10","_rn_":"4"},{"1":"0.505","2":"0.410","3":"0.135","4":"0.6570","5":"0.2910","6":"0.1330","7":"0.195","8":"15","_rn_":"5"},{"1":"0.625","2":"0.515","3":"0.155","4":"1.1635","5":"0.4875","6":"0.2590","7":"0.355","8":"11","_rn_":"6"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<div id="procedimiento" class="section level2">
<h2>Procedimiento:</h2>
</div>

<div id="rmd-source-code">---
title: "Regresiones Lineales Múltiples"
author: "M. en C. Arturo Bell Enríquez García"
output:
    html_document:
      df_print: paged
      theme: cosmo
      toc: TRUE
      toc_float: TRUE
      code_download: TRUE
---

**[VIDEO](https://youtu.be/Kb8CwFgC9Zs)**

## Funciones personalizadas

```{r}
# Tema personalizado
blank_theme <- function(aspect.ratio = 1/1.61){
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank(),
        axis.line = element_blank(),
        aspect.ratio = aspect.ratio,
        axis.ticks = element_blank(),
        text = element_text(colour = "gray50"), # Eliminar
        legend.position = "none"
        )
}
```

## Regresión Lineal Múltiple

Para esta sección utilizaremos los datos de la base `crime.csv`. El objetivo será predecir la tasa de crimenes/poblacion a partir de otras 88 variables:

La variable que nos interesa predecir es el la columna `ViolentCrimesPerPop`). Apliquemos un modelo de regresión lineal múltiple incluyendo todas las variables, sin dividir los datos en entrenamiento-prueba y sin escalarlos. Tampoco filtraremos los datos para evitar una fuga de información:

```{r}
dr.df <- read.csv("data/crime.csv")[,-c(1)]
head(dr.df)
```

```{r}
dr.lm <- lm(ViolentCrimesPerPop~., data = dr.df)
summary(dr.lm)
```

```{r}
summary(dr.df$RentQrange)
```


Veamos qué pasa ahora si aplicamos este mismo modelo realizando la división entrenamiento-prueba.

#### Evaluación, el PROBLEMA del exceso de dimensionalidad y el sobreajuste:
Para realizar la división utilizaremos la función `sample.split()` de librería caTools:

```{r}
library(caret)
library(caTools)
set.seed(1111)
sample <- sample.split(dr.df$ViolentCrimesPerPop, SplitRatio = .75)
train <- subset(dr.df, sample == TRUE)
test <- subset(dr.df, sample == FALSE)
```

Ajustemos el modelo de entrenamiento:
```{r}
train.dr.lm <- lm(ViolentCrimesPerPop~., data = train)
summary(train.dr.lm)$r.squared*100
```

Evaluemos el desempeño en los datos de prueba.
```{r}
pred <- predict.lm(train.dr.lm, test[,1:88]) 
R2(pred, test$ViolentCrimesPerPop)*100
```

De estos resultados vemos que el modelo está sobreajustado, ya que el $R^2$ del modelo de prueba menor al de entrenamiento. Tomando esto en consideración, 1) escalemos los datos y b) apliquemos los modelos regularizados.

Para hacer las cosas más organizadas, primero dividamos ambos sets de datos en dos objetos: uno con las variables independientes y otro con la variable dependiente:

```{r}
X_train <- train[,1:88]
y_train <- train$ViolentCrimesPerPop
X_test <- test[,1:88]
y_test <- test$ViolentCrimesPerPop
```

Ahora estandaricemos las variables dependientes:
```{r}
preProc <- preProcess(X_train, method = c("center", "scale"))
X_train_s <- predict(preProc, X_train)
X_test_s <- predict(preProc, X_test)
```

## Regularización L2: Regresión Ridge

Apliquemos la regresión al set de entrenamiento. Debido a que el valor de penalización ($\alpha$ en la clase, $\lambda$ en glmnet) es "arbitrario", podemos utilizar validación cruzada para encontrar el valor que mejor se ajuste a nuestros datos. La validación cruzada consiste en hacer k particiones entrenamiento-prueba de los datos, ajustar un modelo para cada k para cada valor del parámetro que sea de nuestro interés, promediar el valor de error de cada iteración y quedarnos con el valor del parámetro que haya logrado el menor valor de nuestra medida de error. En la librería `glmnet` esto se hace con la función `cv.glmnet`, la cual recibe como argumentos una matriz de variables independientes, un vector con variables dependientes, un valor de alpha que será 0 para regresión Ridge, 1 para Lasso y algún intermedio para red elástica (no la veremos en el curso) y el tipo de medida de error, en este caso MSE.

```{r}
library(glmnet)
cv.ridge <- cv.glmnet(as.matrix(X_train_s), y_train, alpha = 0, type.measure = "mse")
lambdamin <- cv.ridge$lambda.min #Contiene el valor de lambda que otorga el menor valor de error
lambdamin
```

Ajustemos entonces el modelo regularizado con ese valor de lambda. (Df representa el número de coeficientes no negativos, %Dev = R^2). 
```{r}
ridge.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 0, lambda = lambdamin)
print(ridge.lm)
coef(ridge.lm) # Imprime los coeficientes de la regresión
```
Vemos que el valor de R2 es ligeramente menor al caso anterior; sin embargo, ganamos un poco de poder predictivo en el modelo de prueba:
```{r}
ridge.pred <- predict(ridge.lm, as.matrix(X_test_s))
R2(ridge.pred, y_test)*100
```

Veamos cómo afecta el valor de lambda:

```{r}
for (lambda in c(0, 0.5, 1, 2, 3, 5, 10, 20, 50, round(lambdamin,2))) {
  
  ridge.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 0, lambda = lambda, standardize = F, standardize.response = F)
  ridge.pred <- predict(ridge.lm, as.matrix(X_test_s))
  
  print(paste("lambda = ", lambda, 
              "; Variables restantes:", round(ridge.lm$df, 2), 
              "; R^2 entrenamiento = ", round(ridge.lm$dev.ratio,2), 
              "; R^2 prueba = ", round(R2(ridge.pred, y_test),2)))
  
}
```

Vemos que sí hay diferencias con respecto al primer caso. Apliquemos la regresión Lasso:

## Regularización L1: Regresión Lasso
```{r}
cv.lasso <- cv.glmnet(as.matrix(X_train_s), y_train, alpha = 1, type.measure = "mse")
lambdamin <- cv.lasso$lambda.min #Contiene el valor de lambda que otorga el menor valor de error
lambdamin
```
Ajustemos entonces el modelo regularizado con ese valor de lambda. (Df representa el número de coeficientes no cero, %Dev = R^2). 
```{r}
lasso.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 1, lambda = lambdamin)
print(lasso.lm)
coef(lasso.lm) # Imprime los coeficientes de la regresión
```
Vemos que el valor de R2 no es muy diferente al caso anterior, aunque ahora únicamente tenemos 18 coeficientes ≠ 0
```{r}
lasso.pred <- predict(lasso.lm, as.matrix(X_test_s))
R2(lasso.pred, y_test)*100
```
En los datos de prueba tampoco hubo mucha diferencia. Veamos cómo cambia esto al modificar el valor de lambda:

```{r}
for (lambda in c(0, 0.5, 1, 2, 3, 5, 10, 20, 50, round(lambdamin,2))) {
  
  lasso.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 1, lambda = lambda, standardize = F, standardize.response = F)
  lasso.pred <- predict(lasso.lm, as.matrix(X_test_s))
  
  print(paste("lambda = ", lambda, 
              "; Variables restantes:", round(lasso.lm$df, 2), 
              "; R^2 entrenamiento = ", round(lasso.lm$dev.ratio,2), 
              "; R^2 prueba = ", round(R2(lasso.pred, y_test),2)))
  
}
```

De lo anterior podemos ver que un modelo lineal puede no ser la mejor de las opciones; además, no corroboramos ninguno de los supuestos de la regresión y con una cantidad tan alta de variables es muy posible que muchas estén altamente correlacionadas:
```{r}
library(corrplot)
corrplot(cor(dr.df), method = "ellipse", type = "upper")
```
Podemos también hacer una matriz similar, aunque utilizando gráficos de dispersión:
```{r, fig.height=10, fig.width=10}
library(GGally)
#pairs <- ggpairs(dr.df, progress = F)
#pairs
```

La visualización de los datos se hace en parte junto con la evaluación de la regresión, en el sentido de que solo podemos ver la relación entre los datos observados y predichos por el modelo

```{r}
mlm.data <- data.frame(obs = y_test, s0 = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(x = obs, y =  s0)) + 
            geom_point() + 
            geom_smooth(method = "lm", colour = rgb(118,78,144, maxColorValue = 255)) +
            labs(title = "Gráfico de dispersión de datos observados y predichos",
                 subtitle = sprintf("R2e: %.2f | R2p: %.2f",round(lasso.lm$dev.ratio,2), round(R2(lasso.pred, y_test),2)),
                 caption = "Datos de prueba. \n El área gris representa el intervalo de confianza de la regresión al 95%",
                 x = "",
                 y = "") +
            theme_bw()
mlm.plot
```

## Ingeniería de variables
El resultado es un modelo que no se encuentra sobreajustado, 
```{r}
library(factoextra)
library(FactoMineR)

X_train_pca <- FactoMineR::PCA(X_train, graph = F, ncp = length(X_train), scale.unit = F)
X_pca_train <- predict(X_train_pca, X_train)$coord
X_pca_test <- predict(X_train_pca, X_test)$coord
```

Evaluemos las correlaciones de los nuevos predictores con nuestra variable de interés y extraigamos aquellas que tengan correlaciones significativas (≠0):
```{r}
#library(Hmisc)
c_mat <- as.data.frame(cor(cbind(X_pca_train, y_train)))$y_train
p_mat <-  as.data.frame(Hmisc::rcorr(cbind(X_pca_train, y_train))$P)$y_train
p_mat <- data.frame(y_train = p_mat[is.na(p_mat) == F], CP = colnames(X_pca_train))
sig_cps <- p_mat$CP[p_mat$y_train <= 0.05]
sig_cps
```
Filtramos nuestros datos:
```{r}
X_filt_train <- X_pca_train[,sig_cps]
X_filt_test <- X_pca_test[,sig_cps]
filt_train <- data.frame(X_filt_train, y_train)
```


Realicemos la regresión múltiple:
```{r}
pca_lm <- train(y_train~.,
                data = filt_train,
                method = "lm")
summary(pca_lm)
```
Los resultados son similares en los datos de entrenamiento, veamos qué pasa con los datos de prueba:
```{r}
pca_tpreds <- predict(pca_lm, as.data.frame(X_filt_test))
round(R2(pca_tpreds, y_test),2)
```

Los resultados también son similares a aquellos de la regresión Lasso. La conclusión que podemos generar es que un modelo lineal como este puede no ser la mejor opción para estos datos. ¿Cómo más podríamos mejorarlo?

## Ejercicio 1

1. Realiza una regresión Lasso con los CPs. ¿Cuántas variables se mantienen?¿Cambia el desempeño de los modelos?
2. Realiza los diagnósticos de las regresiones Ridge, Lasso y la regresión con CP. ¿Cuál está mejor ajustada? (Performance)
3. Aplica un GLM con las variables restantes en la regresión Lasso. ¿Qué familia utilizas para el error? ¿El ajuste mejora o se mantiene igual?

## Ejercicio 2

El objetivo es predecir la edad de individuos de abulón a partir de mediciones corporales de los mismos utilizando algún modelo lineal. Puedes también utilizar algún modelo no lineal, si es de tu interés. 

Los datos para entrenar los modelos se encuentran [aquí](https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv). Las columnas corresponden a:
- Longitud del organismo,
- Diámetro del organismo,
- Altura del organismo,
- Peso entero,
- Peso sin concha,
- Peso de las vísceras,
- Peso de la cáscara,
- Edad (años)

Los puntos a tener en cuenta son:

1) Identificar si es necesario hacer algún procesamiento a los datos y, de ser así, aplicarlo.
2) ¿Es necesario, prudente y válido incluir todas las variables en el modelo?
3) A partir del punto anterior, construir el/los modelos de regresión. ¿Es necesario utilizar un modelo penalizado/regularizado?
4) Evaluar si los modelos están sobre o sub ajustados.
5) Analizar los gráficos diagnósticos de la regresión (recuerda que todos son construidos a partir de los residuales y los valores a predecir) y evaluar la bondad de ajuste de los modelos y evaluar su calidad (e.g., ¿Son los residuales normales y homocedásticos?).
6) Una vez mejorado el modelo lo más posible (i.e., escalando los valores, eliminando variables o generando nuevas (e.g. ACP)), crea un nuevo modelo con TODAS las observaciones.
7) Predice los valores de edad de los [datos de prueba](https://storage.googleapis.com/download.tensorflow.org/data/abalone_test.csv). ¿Cuál es el valor de MSE y $R^2$ alcanzado por el modelo?
8) Tomando en cuenta estos resultados, ¿el modelo ajustado final se encuentra bien ajustado, sobreajustado o infraajustado?

## Datos:

El código de las siguientes celdas permite descargar los datos directamente a R desde una URL:

### Entrenamiento
```{r}
download <- RCurl::getURL("https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv")
train <- read.csv(text = download, header = F)
colnames(train) <- c("Long", "Diam", "Alt", "PesoEnt", "PesoDesc", "PesoVisc", "PesoCasc", "Edad")
head(train)
```
### Prueba
```{r}
download <- RCurl::getURL("https://storage.googleapis.com/download.tensorflow.org/data/abalone_test.csv")
test <- read.csv(text = download, header = F)
colnames(test) <- c("Long", "Diam", "Alt", "PesoEnt", "PesoDesc", "PesoVisc", "PesoCasc", "Edad")
head(test)
```

## Procedimiento:

</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("c16_regs_mv.Rmd");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
