<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="M. en C. Arturo Bell Enríquez García" />


<title>T4: Clasificación</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Bioestadística con R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Clases
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Biología como Ciencia de Datos</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c1_Intro_R.html">Introducción a R</a>
        </li>
        <li>
          <a href="c2_ggplot2.html">ggplot2</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Herramientas Básicas</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c3_probabilidad.html">Probabilidad</a>
        </li>
        <li>
          <a href="c4_muestreo.html">Teoría del Muestreo</a>
        </li>
        <li>
          <a href="c5_descriptiva.html">Estadística Descriptiva</a>
        </li>
        <li>
          <a href="c6_ph0.html">Pruebas de hipótesis</a>
        </li>
        <li>
          <a href="c7_param.html">Técnicas Paramétricas</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Relaciones Lineales</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c8_rls.html">Modelo Lineal Simple</a>
        </li>
        <li>
          <a href="c9_glm.html">Modelos Lineales Generalizados</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="c10_no_par.html">Técnicas No Paramétricas</a>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Técnicas Multivariadas</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c11_intro_mv.html">Introducción</a>
        </li>
        <li>
          <a href="c12_no_sup.html">No supervisadas</a>
        </li>
        <li>
          <a href="c13_comps_mv.html">Comparaciones Multivariadas</a>
        </li>
        <li>
          <a href="c14_clasificacion.html">Clasificaciones</a>
        </li>
        <li>
          <a href="c15_regs_mv.html">Regresiones Múltiples</a>
        </li>
      </ul>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">T4: Clasificación</h1>
<h4 class="author">M. en C. Arturo Bell Enríquez García</h4>

</div>


<div id="datos" class="section level2">
<h2>Datos</h2>
<pre class="r"><code># Tema personalizado
blank_theme &lt;- function(aspect.ratio = 1/1.61){
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank(),
        axis.line = element_blank(),
        aspect.ratio = aspect.ratio,
        axis.ticks = element_blank(),
        text = element_text(colour = &quot;gray50&quot;), # Eliminar
        legend.position = &quot;none&quot;
        )
}</code></pre>
<p>El objetivo de un problema de clasificación es utilizar distintas variables (características) para <strong>predecir</strong> la clase/etiqueta de una instancia. Todas las técnicas de clasificación son técnicas de aprendizaje automatizado; es decir, bajo la definición que dimos al inicio de esta sección, no haremos pruebas de hipótesis de nulidad <em>per-se</em>.</p>
<p>Revisemos entonces algunas técnicas de clasificación utilizando la misma base de datos que utilizamos en el tema de Análisis de Componentes Principales:</p>
<pre class="r"><code>library(factoextra)
library(FactoMineR)

#Base de datos completa
  
x1n &lt;- read.table(&#39;data/Medidas.txt&#39;, header = TRUE)
#Base de datos sin nombres de especies

x1 &lt;- x1n[ ,2:length(x1n) ]
summary(x1)</code></pre>
<pre><code>##      furcal            base             radio              alto        
##  Min.   :0.2527   Min.   :0.07088   Min.   :0.04408   Min.   :0.05319  
##  1st Qu.:0.2716   1st Qu.:0.09108   1st Qu.:0.06748   1st Qu.:0.06709  
##  Median :0.2753   Median :0.09679   Median :0.07090   Median :0.07140  
##  Mean   :0.2757   Mean   :0.09645   Mean   :0.07048   Mean   :0.07116  
##  3rd Qu.:0.2801   3rd Qu.:0.10142   3rd Qu.:0.07430   3rd Qu.:0.07534  
##  Max.   :0.3202   Max.   :0.11394   Max.   :0.08311   Max.   :0.09723  
##      gordo             angos              ojo             X1erarc       
##  Min.   :0.02679   Min.   :0.02996   Min.   :0.02142   Min.   :0.03485  
##  1st Qu.:0.04139   1st Qu.:0.03465   1st Qu.:0.02451   1st Qu.:0.04332  
##  Median :0.04402   Median :0.03577   Median :0.02673   Median :0.05129  
##  Mean   :0.04405   Mean   :0.03616   Mean   :0.02740   Mean   :0.05158  
##  3rd Qu.:0.04680   3rd Qu.:0.03745   3rd Qu.:0.02875   3rd Qu.:0.05899  
##  Max.   :0.05859   Max.   :0.04727   Max.   :0.08191   Max.   :0.07738  
##      dist.              largo              cabez             hueso        
##  Min.   :0.007179   Min.   :0.004202   Min.   :0.07311   Min.   :0.02857  
##  1st Qu.:0.030485   1st Qu.:0.022402   1st Qu.:0.08476   1st Qu.:0.03236  
##  Median :0.035368   Median :0.029488   Median :0.08951   Median :0.03415  
##  Mean   :0.031366   Mean   :0.026533   Mean   :0.08860   Mean   :0.03488  
##  3rd Qu.:0.038824   3rd Qu.:0.034574   3rd Qu.:0.09284   3rd Qu.:0.03582  
##  Max.   :0.048008   Max.   :0.051843   Max.   :0.09815   Max.   :0.10411  
##      mandib           hueso.1            arriba            cabeza       
##  Min.   :0.03141   Min.   :0.02348   Min.   :0.01855   Min.   :0.07118  
##  1st Qu.:0.03598   1st Qu.:0.03917   1st Qu.:0.02546   1st Qu.:0.08309  
##  Median :0.03980   Median :0.04413   Median :0.02952   Median :0.08796  
##  Mean   :0.03923   Mean   :0.04498   Mean   :0.02946   Mean   :0.08890  
##  3rd Qu.:0.04247   3rd Qu.:0.04995   3rd Qu.:0.03391   3rd Qu.:0.09483  
##  Max.   :0.04758   Max.   :0.08783   Max.   :0.03828   Max.   :0.10760  
##       boca             abiert           cachete           largo.1        
##  Min.   :0.02828   Min.   :0.01810   Min.   :0.02938   Min.   :0.008724  
##  1st Qu.:0.03476   1st Qu.:0.02348   1st Qu.:0.03911   1st Qu.:0.012881  
##  Median :0.03830   Median :0.02531   Median :0.04308   Median :0.014240  
##  Mean   :0.03954   Mean   :0.02547   Mean   :0.04237   Mean   :0.014366  
##  3rd Qu.:0.04368   3rd Qu.:0.02741   3rd Qu.:0.04508   3rd Qu.:0.015936  
##  Max.   :0.05552   Max.   :0.03248   Max.   :0.06553   Max.   :0.026475  
##      ancho            orificio           densi            hocic        
##  Min.   :0.00274   Min.   :0.01968   Min.   :0.6990   Min.   :0.01546  
##  1st Qu.:0.02663   1st Qu.:0.03741   1st Qu.:0.7782   1st Qu.:0.02491  
##  Median :0.03031   Median :0.04381   Median :0.8451   Median :0.02929  
##  Mean   :0.03253   Mean   :0.04429   Mean   :0.8401   Mean   :0.02937  
##  3rd Qu.:0.03447   3rd Qu.:0.05085   3rd Qu.:0.9031   3rd Qu.:0.03294  
##  Max.   :0.22628   Max.   :0.07390   Max.   :1.1139   Max.   :0.04922  
##     interbr            ojoatra            proye              base.1       
##  Min.   :0.007687   Min.   :0.02685   Min.   :0.007313   Min.   :0.01546  
##  1st Qu.:0.014457   1st Qu.:0.03796   1st Qu.:0.013341   1st Qu.:0.02052  
##  Median :0.015776   Median :0.04050   Median :0.014982   Median :0.02238  
##  Mean   :0.016304   Mean   :0.04067   Mean   :0.016217   Mean   :0.02300  
##  3rd Qu.:0.017609   3rd Qu.:0.04256   3rd Qu.:0.016613   3rd Qu.:0.02474  
##  Max.   :0.028804   Max.   :0.08124   Max.   :0.127873   Max.   :0.04476  
##      altura             area             Intesti      
##  Min.   :0.02514   Min.   :0.001431   Min.   :0.1295  
##  1st Qu.:0.03815   1st Qu.:0.006723   1st Qu.:0.1774  
##  Median :0.04422   Median :0.009716   Median :0.1960  
##  Mean   :0.04474   Mean   :0.010638   Mean   :0.1980  
##  3rd Qu.:0.04928   3rd Qu.:0.014274   3rd Qu.:0.2150  
##  Max.   :0.08398   Max.   :0.027268   Max.   :0.3246</code></pre>
</div>
<div id="división-centrado-y-estandarizado-de-datos" class="section level2">
<h2>División, centrado y estandarizado de datos</h2>
<p>Al tratarse de un modelo de aprendizaje automatizado es importante que realicemos nuestra división entrenamiento/prueba para evaluar el ajuste del modelo de clasificación:</p>
<pre class="r"><code>library(caTools)
library(caret)</code></pre>
<pre><code>## 
## Attaching package: &#39;caret&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:vegan&#39;:
## 
##     tolerance</code></pre>
<pre><code>## The following objects are masked from &#39;package:DescTools&#39;:
## 
##     MAE, RMSE</code></pre>
<pre class="r"><code>set.seed(1111)
sample &lt;- sample.split(x1n$especie, SplitRatio = .75)
train &lt;- subset(x1n, sample == TRUE)
test &lt;- subset(x1n, sample == FALSE)</code></pre>
<p>Centremos y estandaricemos los datos:</p>
<pre class="r"><code>pre_pars &lt;- preProcess(train, method = c(&quot;center&quot;, &quot;scale&quot;))
train_t &lt;- predict(pre_pars, train)
test_t &lt;- predict(pre_pars, test)</code></pre>
</div>
<div id="análisis-de-funciones-discriminantes" class="section level2">
<h2>Análisis de Funciones Discriminantes</h2>
<p>El primer modelo con el que trabajaremos es el Análisis de Funciones Discriminantes. En esta técnica se utilizan <strong>combinaciones lineales</strong> de las variables originales para predecir la clase de una instancia, de modo que se tratarán de encontrar nuevas variables que <strong>maximicen</strong> la separación entre clases. Para que esta técnica funcione adecuadamente es importante que las medias entre los grupos sean diferentes (podemos aplicar un MANOVA/PERMANOVA previo) y que las dispersiones multivariadas entre los grupos sean relativamente constantes (homocedasticidad multivariada). A partir de lo anterior, es fácil entender a este análisis como una mezcla entre el MANOVA y ACP.</p>
<div id="ajuste-del-modelo" class="section level3">
<h3>Ajuste del modelo</h3>
<p>Apliquemos el Análisis Discriminante Lineal. Las probabilidades previas representan la proporción de cada grupo en la base de datos, las medias de los grupos las medias de cada grupo para cada variable, los coeficientes aprendidos por el modelo según los datos de entrenamiento y la proporción de la traza es la proporción de la varianza explicada por cada ecuación discriminante.</p>
<pre class="r"><code>lda_mod &lt;- MASS::lda(especie~., data = train_t)
lda_mod</code></pre>
<pre><code>## Call:
## lda(especie ~ ., data = train_t)
## 
## Prior probabilities of groups:
## consocium   jordani  labarcae 
## 0.3333333 0.2820513 0.3846154 
## 
## Group means:
##                furcal       base       radio       alto      gordo      angos
## consocium -0.27239867 -0.1611638  0.63378818 -0.2478593 -0.1101955 -0.3803264
## jordani    0.36978089  0.3538899 -0.08733179  0.5618379 -0.2484665  0.7205529
## labarcae  -0.03509381 -0.1198439 -0.48523978 -0.1972031  0.2777115 -0.1987893
##                   ojo    X1erarc       dist.      largo      cabez       hueso
## consocium  0.09264739  0.2144553  0.08430157  0.1499676  0.4599422  0.29791183
## jordani   -0.13400176  1.1016534  0.41922847  0.7816530 -1.1268342 -0.27518895
## labarcae   0.01797355 -0.9937404 -0.38049557 -0.7031841  0.4277285 -0.05638502
##               mandib     hueso.1      arriba     cabeza        boca     abiert
## consocium -0.1350847  0.57353663 -0.07769342  0.8313447 -0.07404553 -0.0995833
## jordani   -1.1191233  0.04897799 -1.07793758 -0.4147328 -0.77198065 -0.6994560
## labarcae   0.9377638 -0.53298228  0.85782185 -0.4163614  0.63029194  0.5992399
##               cachete    largo.1      ancho    orificio      densi       hocic
## consocium  0.14378260 -0.5532935 -0.2135984 -0.45224471  0.4142481 -0.06895108
## jordani   -0.06177900  0.3066528  0.4361758  0.40599544  0.2418548 -0.83621678
## labarcae  -0.07930699  0.2546422 -0.1347437  0.09421543 -0.5363752  0.67298324
##              interbr     ojoatra       proye      base.1      altura       area
## consocium -0.2677804 -0.02876978 -0.04894378 -0.26537856 -0.53739820 -0.3555283
## jordani   -0.1140360 -0.04914858  0.16971481 -0.06077242  0.76287054 -0.3222543
## labarcae   0.3157027  0.06097610 -0.08203958  0.27456120 -0.09369329  0.5444443
##              Intesti
## consocium -0.7077703
## jordani    0.3010229
## labarcae   0.3926508
## 
## Coefficients of linear discriminants:
##                   LD1          LD2
## furcal    0.028526771 -0.391614791
## base     -0.209139809 -0.227408806
## radio    -0.061305903  0.221130285
## alto      0.168798201 -0.224047615
## gordo     0.634093713  0.209065251
## angos    -0.758743387 -0.139034212
## ojo       0.123364337 -0.007622951
## X1erarc  -1.997627631 -0.235408480
## dist.    -0.053552688 -0.147007173
## largo    -0.046825454  0.389589901
## cabez     0.203836005  0.646888740
## hueso    -0.033319442  0.029258810
## mandib    0.918796636 -0.408134075
## hueso.1  -0.449510944  0.627524539
## arriba    1.125104935 -0.007142905
## cabeza   -0.493254681  0.948682851
## boca     -0.163258105  0.388505301
## abiert    0.011259084 -0.373641604
## cachete   0.234498784  0.639571836
## largo.1  -0.637704833 -0.263752163
## ancho    -0.125785157  0.036733196
## orificio  0.008486124 -0.513403328
## densi    -0.364318989  0.048784740
## hocic    -0.337415062  0.182388583
## interbr   0.532901007 -0.005325388
## ojoatra  -0.067049359 -0.338594926
## proye    -0.343082471 -0.025104445
## base.1    0.190284049  0.262195074
## altura   -0.094050504 -0.223923073
## area     -0.134056419 -0.247898344
## Intesti   0.243726491 -0.309536900
## 
## Proportion of trace:
##    LD1    LD2 
## 0.8141 0.1859</code></pre>
</div>
<div id="importancia-de-variables" class="section level3">
<h3>Importancia de variables</h3>
<p>Calculemos la correlación entre las variables originales y las dos funciones discriminantes</p>
<pre class="r"><code>adj_vals &lt;- as.data.frame(predict(lda_mod, train_t)$x)
adj_vals[&quot;especie&quot;] &lt;- train_t[&quot;especie&quot;]
corr &lt;- cor(cbind(as.matrix(train_t[,2:32])), 
                   adj_vals[,1:2])
corr</code></pre>
<pre><code>##                  LD1           LD2
## furcal   -0.13141273 -0.2457755403
## base     -0.17400395 -0.1640832259
## radio    -0.24496179  0.4650184432
## alto     -0.28012983 -0.2547783331
## gordo     0.23041878 -0.0444178857
## angos    -0.32899744 -0.3713816134
## ojo       0.05056099  0.0847301419
## X1erarc  -0.88877042  0.0010272598
## dist.    -0.33952156  0.0023146043
## largo    -0.62954328 -0.0008393222
## cabez     0.57984949  0.4844248183
## hueso     0.05165890  0.2509373702
## mandib    0.86274763  0.0581108077
## hueso.1  -0.31286833  0.4031217248
## arriba    0.80559067  0.0934352143
## cabeza   -0.10746724  0.6514499754
## boca      0.58585544  0.0537619900
## abiert    0.54656544  0.0254886911
## cachete  -0.02567501  0.1112945128
## largo.1   0.04970162 -0.4377992219
## ancho    -0.20721195 -0.2129277982
## orificio -0.07004645 -0.3793107927
## densi    -0.37307363  0.2626291405
## hocic     0.62914887  0.0662796506
## interbr   0.21102558 -0.1756162121
## ojoatra   0.04895785 -0.0137690705
## proye    -0.09718520 -0.0584316340
## base.1    0.17191592 -0.1812602117
## altura   -0.28301703 -0.4894841705
## area      0.40189142 -0.2095533890
## Intesti   0.12858271 -0.5474213085</code></pre>
<pre class="r"><code>corrplot::corrplot(corr, is.corr = T)</code></pre>
<p><img src="c14_clasificacion_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Creemos un gráfico de densidad bivariado para conocer la distribución de los grupos en el nuevo espacio:</p>
<pre class="r"><code>territ_plot &lt;- ggplot(data = adj_vals, aes(x = LD1, y = LD2, colour = especie)) +
               geom_density_2d(show.legend = T, alpha = 0.5) +
               geom_point() +
               theme_bw()
territ_plot</code></pre>
<p><img src="c14_clasificacion_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
<div id="diagnóstico-del-modelo-de-funciones-discriminantes" class="section level3">
<h3>Diagnóstico del modelo de funciones discriminantes:</h3>
<div id="probabilidades-de-pertenencia" class="section level4">
<h4>Probabilidades de pertenencia</h4>
<p>Probabilidad de pertenencia de cada individuo a partir de los datos de prueba:</p>
<pre class="r"><code>p &lt;- predict(lda_mod, test_t)$posterior
p.acom &lt;- data.frame(especie = test_t$especie, id = rownames(test_t), p = p)
p.acom</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["especie"],"name":[1],"type":["chr"],"align":["left"]},{"label":["id"],"name":[2],"type":["chr"],"align":["left"]},{"label":["p.consocium"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["p.jordani"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.labarcae"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"jordani","2":"3","3":"1.576647e-05","4":"9.999842e-01","5":"1.938031e-17","_rn_":"3"},{"1":"jordani","2":"6","3":"1.050268e-04","4":"9.998950e-01","5":"1.299891e-22","_rn_":"6"},{"1":"jordani","2":"7","3":"6.766174e-01","4":"3.205883e-01","5":"2.794340e-03","_rn_":"7"},{"1":"jordani","2":"15","3":"1.525816e-05","4":"9.999847e-01","5":"4.904069e-19","_rn_":"15"},{"1":"jordani","2":"17","3":"1.073441e-05","4":"9.999893e-01","5":"5.255517e-22","_rn_":"17"},{"1":"jordani","2":"19","3":"2.544053e-08","4":"1.000000e+00","5":"9.148421e-14","_rn_":"19"},{"1":"jordani","2":"24","3":"2.620872e-04","4":"9.997379e-01","5":"1.073915e-17","_rn_":"24"},{"1":"labarcae","2":"32","3":"4.402102e-12","4":"3.745222e-26","5":"1.000000e+00","_rn_":"32"},{"1":"labarcae","2":"41","3":"1.234120e-15","4":"4.780119e-29","5":"1.000000e+00","_rn_":"41"},{"1":"labarcae","2":"46","3":"2.105752e-10","4":"2.382699e-22","5":"1.000000e+00","_rn_":"46"},{"1":"labarcae","2":"48","3":"1.982179e-13","4":"1.791345e-33","5":"1.000000e+00","_rn_":"48"},{"1":"labarcae","2":"49","3":"3.036055e-18","4":"1.439861e-32","5":"1.000000e+00","_rn_":"49"},{"1":"labarcae","2":"55","3":"4.916184e-07","4":"1.176208e-14","5":"9.999995e-01","_rn_":"55"},{"1":"labarcae","2":"57","3":"3.860063e-12","4":"1.941377e-22","5":"1.000000e+00","_rn_":"57"},{"1":"labarcae","2":"59","3":"1.502760e-16","4":"2.095582e-33","5":"1.000000e+00","_rn_":"59"},{"1":"labarcae","2":"61","3":"1.071438e-02","4":"1.384241e-10","5":"9.892856e-01","_rn_":"61"},{"1":"labarcae","2":"63","3":"9.007014e-19","4":"1.617244e-38","5":"1.000000e+00","_rn_":"63"},{"1":"consocium","2":"70","3":"1.123931e-15","4":"7.836223e-32","5":"1.000000e+00","_rn_":"70"},{"1":"consocium","2":"74","3":"9.999669e-01","4":"3.306267e-05","5":"7.004830e-14","_rn_":"74"},{"1":"consocium","2":"77","3":"5.028596e-02","4":"9.497140e-01","5":"5.289779e-27","_rn_":"77"},{"1":"consocium","2":"80","3":"1.000000e+00","4":"2.253411e-14","5":"4.793196e-13","_rn_":"80"},{"1":"consocium","2":"85","3":"1.000000e+00","4":"3.011736e-11","5":"9.417053e-10","_rn_":"85"},{"1":"consocium","2":"86","3":"1.698278e-07","4":"9.999998e-01","5":"1.717979e-20","_rn_":"86"},{"1":"consocium","2":"97","3":"1.000000e+00","4":"1.538708e-12","5":"9.626341e-13","_rn_":"97"},{"1":"consocium","2":"98","3":"1.000000e+00","4":"2.712993e-12","5":"6.977327e-14","_rn_":"98"},{"1":"consocium","2":"100","3":"1.000000e+00","4":"5.416680e-14","5":"4.344065e-13","_rn_":"100"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
<div id="prueba-de-ji-cuadrada-para-verificar-un-acomodo-no-aleatorio-p0.005" class="section level4">
<h4>Prueba de Ji-cuadrada para verificar un acomodo no aleatorio (p&lt;0.005)</h4>
<pre class="r"><code>pred.clase &lt;- predict(lda_mod, test_t)$class
jicuad &lt;- chisq.test(test_t$especie, pred.clase, simulate.p.value = T)
jicuad</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with simulated p-value (based on 2000
##  replicates)
## 
## data:  test_t$especie and pred.clase
## X-squared = 31.445, df = NA, p-value = 0.0004998</code></pre>
</div>
<div id="matriz-de-confusión" class="section level4">
<h4>Matriz de confusión:</h4>
<pre class="r"><code>confusionMatrix(pred.clase, as.factor(test_t$especie))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##            Reference
## Prediction  consocium jordani labarcae
##   consocium         6       1        0
##   jordani           2       6        0
##   labarcae          1       0       10
## 
## Overall Statistics
##                                           
##                Accuracy : 0.8462          
##                  95% CI : (0.6513, 0.9564)
##     No Information Rate : 0.3846          
##     P-Value [Acc &gt; NIR] : 1.779e-06       
##                                           
##                   Kappa : 0.7673          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: consocium Class: jordani Class: labarcae
## Sensitivity                    0.6667         0.8571          1.0000
## Specificity                    0.9412         0.8947          0.9375
## Pos Pred Value                 0.8571         0.7500          0.9091
## Neg Pred Value                 0.8421         0.9444          1.0000
## Prevalence                     0.3462         0.2692          0.3846
## Detection Rate                 0.2308         0.2308          0.3846
## Detection Prevalence           0.2692         0.3077          0.4231
## Balanced Accuracy              0.8039         0.8759          0.9688</code></pre>
<div id="márgenes-de-decisión." class="section level5">
<h5>Márgenes de decisión.</h5>
<p>En este caso, mostraremos la probabilidad de pertenencia a cada clase (obtenida desde los datos de entrenamiento) como fondo del gráfico y sobrepondremos los datos de prueba. Para poder hacer esto habrá que “simular” datos para nuestro fondo y formar una malla con todos ellos. Desafortunadamente, crear la malla requiere que hagamos cierta trampa. Primero, ajustaremos un modelo LDA para predecir los valores de LD1 y LD2 de cada especie:</p>
<pre class="r"><code> # Ajustamos un LDA para &quot;predecir&quot; los valores de las nuevas dimensiones
prob_lda &lt;- MASS::lda(especie ~ ., data = adj_vals)</code></pre>
<p>Generamos una función que nos permita generar una malla utilizando esos nuevos valores y que, multiplique los valores de LDA con signo negativo por -1 para evitar una rotación de los datos:</p>
<pre class="r"><code>adjust_probs_sp &lt;- function(mesh, probs){
  mesh[&quot;adj_probs&quot;] &lt;- apply(probs, 
                           1,
                           FUN = max
                           )
  # Especies predichas; i.e., la especie con mayor probabilidad
  ## resumir con predict()$class?
  mesh[&quot;adj_esp&quot;] &lt;- apply(probs,
                           1,
                           FUN = function(x){
                                 names(which.max(x))
                                 }
                           )
  return(mesh)
}

dec_bounds &lt;- function(model, adj_vals){
  library(scales)
  # Calculamos los límites expandidos de LD1 y LD2
  ld1lim &lt;- expand_range(c(min(adj_vals$LD1), max(adj_vals$LD1)), 
                                 mul=0.1) # Amplía el intervalo un 10% hacia &quot;abajo&quot;
  ld2lim &lt;- expand_range(c(min(adj_vals$LD2), max(adj_vals$LD2)), 
                                 mul=0.1) # 10% hacia &quot;arriba&quot;
  
  # Generamos 300 valores nuevos de LD1 y LD2 en esos límites:
  ld1 &lt;- seq(ld1lim[[1]], ld1lim[[2]], 
             length.out=300)
  ld2 &lt;- seq(ld2lim[[1]], ld1lim[[2]],
             length.out=300)
  
  # Generamos un objeto con todas las combinaciones de nuevos valores
  newdat &lt;- expand.grid(list(LD1=ld1,LD2=ld2))
  
  # Realizamos predicciones a partir de estos valores
  preds &lt;-predict(prob_lda, newdata = newdat)
  
  # Generamos un objeto que contendrá la &quot;malla&quot; con los valores de LD1, LD2, adj_probs y adj_esp
  mesh &lt;- as.data.frame(preds$x)
  
  # Probabilidad de pertenencia de los valores simulados:
  prob_sim &lt;- as.data.frame(preds$posterior)
  
  # Probabilidades &quot;ajustadas&quot;; i.e., la probabilidad mayor - la suma del resto de probabilidades
  
  mesh &lt;- adjust_probs_sp(mesh, prob_sim)
  
  # Corregimos los valores del eje negativo
  axes &lt;- diag(model$scaling)
  axis &lt;- names(axes[axes &lt; 0])
  mesh[,axis] &lt;- -mesh[,axis]
  
  return(mesh)
}</code></pre>
<p>Ahora formamos el gráfico</p>
<pre class="r"><code>mesh &lt;- dec_bounds(prob_lda, adj_vals) # Generamos la malla

# Graficamos las probabilidades de decisión
dec.probs &lt;- ggplot(data = mesh, aes(x = LD1, y = LD2, color = adj_esp)) +
             geom_raster(aes(fill = adj_esp), alpha = mesh$adj_probs*0.3, show.legend = F) + 
             theme_minimal()

#adj_vals &lt;- as.data.frame(predict(lda_mod, train_t)$x)
#adj_vals[&quot;especie&quot;] &lt;- train_t[&quot;especie&quot;]

# Añadimos los datos de prueba
mesh_test &lt;- as.data.frame(predict(lda_mod, test_t)$x) # Valores de LDA para los datos de prueba
mesh_test &lt;- adjust_probs_sp(mesh_test, predict(lda_mod, test_t)$posterior) # Obtener las probabilidades y especies predichas
mesh_test[&quot;mark&quot;] &lt;- ifelse(test_t$especie == mesh_test$adj_esp,
                            test_t$especie,
                            &quot;Mal clasificado&quot;) # Una etiqueta para saber si la instancia está correctamente clasificada
# Añadimos los puntos de prueba, cambiando la forma según la clase predicha por el modelo y el color por la clase observada:
clas.plot &lt;- dec.probs + geom_point(data = mesh_test, aes(x = LD1, y = LD2, shape = mark, color = test$especie), size = 2) + 
             scale_shape_discrete(name = &quot;Clasificación&quot;) +
             scale_color_discrete(name = &quot;Clases&quot;) +
             scale_alpha_continuous(name = &quot;P(decisión)&quot;) +
             labs(title = &quot;Límites de decisión del LDA&quot;,
                  subtitle = &quot;Primeras dos funciones discriminantes&quot;,
                  x = element_blank(),
                  y = element_blank())

# Imprimimos el gráfico
clas.plot</code></pre>
<p><img src="c14_clasificacion_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<pre class="r"><code>mesh_test[mesh_test$mark == &quot;Mal clasificado&quot;,]</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["LD1"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["LD2"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["adj_probs"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["adj_esp"],"name":[4],"type":["chr"],"align":["left"]},{"label":["mark"],"name":[5],"type":["chr"],"align":["left"]}],"data":[{"1":"-0.7471448","2":"-1.6503592","3":"0.6766174","4":"consocium","5":"Mal clasificado","_rn_":"7"},{"1":"6.8164930","2":"-0.6894308","3":"1.0000000","4":"labarcae","5":"Mal clasificado","_rn_":"70"},{"1":"-6.7280520","2":"3.0847575","3":"0.9497140","4":"jordani","5":"Mal clasificado","_rn_":"77"},{"1":"-4.8481683","2":"-1.4215721","3":"0.9999998","4":"jordani","5":"Mal clasificado","_rn_":"86"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>x1n[7,]</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["especie"],"name":[1],"type":["chr"],"align":["left"]},{"label":["furcal"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["base"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["radio"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["alto"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["gordo"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["angos"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["ojo"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["X1erarc"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["dist."],"name":[10],"type":["dbl"],"align":["right"]},{"label":["largo"],"name":[11],"type":["dbl"],"align":["right"]},{"label":["cabez"],"name":[12],"type":["dbl"],"align":["right"]},{"label":["hueso"],"name":[13],"type":["dbl"],"align":["right"]},{"label":["mandib"],"name":[14],"type":["dbl"],"align":["right"]},{"label":["hueso.1"],"name":[15],"type":["dbl"],"align":["right"]},{"label":["arriba"],"name":[16],"type":["dbl"],"align":["right"]},{"label":["cabeza"],"name":[17],"type":["dbl"],"align":["right"]},{"label":["boca"],"name":[18],"type":["dbl"],"align":["right"]},{"label":["abiert"],"name":[19],"type":["dbl"],"align":["right"]},{"label":["cachete"],"name":[20],"type":["dbl"],"align":["right"]},{"label":["largo.1"],"name":[21],"type":["dbl"],"align":["right"]},{"label":["ancho"],"name":[22],"type":["dbl"],"align":["right"]},{"label":["orificio"],"name":[23],"type":["dbl"],"align":["right"]},{"label":["densi"],"name":[24],"type":["dbl"],"align":["right"]},{"label":["hocic"],"name":[25],"type":["dbl"],"align":["right"]},{"label":["interbr"],"name":[26],"type":["dbl"],"align":["right"]},{"label":["ojoatra"],"name":[27],"type":["dbl"],"align":["right"]},{"label":["proye"],"name":[28],"type":["dbl"],"align":["right"]},{"label":["base.1"],"name":[29],"type":["dbl"],"align":["right"]},{"label":["altura"],"name":[30],"type":["dbl"],"align":["right"]},{"label":["area"],"name":[31],"type":["dbl"],"align":["right"]},{"label":["Intesti"],"name":[32],"type":["dbl"],"align":["right"]}],"data":[{"1":"jordani","2":"0.281895","3":"0.09631057","4":"0.06971912","5":"0.07162811","6":"0.04002912","7":"0.03453165","8":"0.02756048","9":"0.04568261","10":"0.0366289","11":"0.0366289","12":"0.08476112","13":"0.03314634","14":"0.03591256","15":"0.04610479","16":"0.02544712","17":"0.0939045","18":"0.03797572","19":"0.02756048","20":"0.03866126","21":"0.01472326","22":"0.0366289","23":"0.0523091","24":"0.90309","25":"0.02403248","26":"0.01760895","27":"0.04071144","28":"0.01181827","29":"0.0197607","30":"0.05842602","31":"0.01042717","32":"0.2447462","_rn_":"7"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Podemos también mostrar un gráfico de partición, en el cual se muestra la clasificación según cada variable. Utilizamos la base iris debido a la altísima dimensionalidad de los datos del ejercicio</p>
<pre class="r"><code>klaR::partimat(Species~., data = iris, method = &quot;lda&quot;)</code></pre>
<pre><code>## Registered S3 methods overwritten by &#39;klaR&#39;:
##   method      from 
##   predict.rda vegan
##   print.rda   vegan
##   plot.rda    vegan</code></pre>
<p><img src="c14_clasificacion_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
</div>
</div>
<div id="curva-roc-y-valor-auc." class="section level4">
<h4>Curva ROC y valor AUC.</h4>
<p>Primero obtengamos la curva ROC y el valor de AUC multi-clase.</p>
<pre class="r"><code>library(pROC)</code></pre>
<pre><code>## Type &#39;citation(&quot;pROC&quot;)&#39; for a citation.</code></pre>
<pre><code>## 
## Attaching package: &#39;pROC&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     cov, smooth, var</code></pre>
<pre class="r"><code>library(gridExtra)

test_sp_num &lt;- as.numeric(as.factor(test_t$especie))
pred_clase_num &lt;- as.numeric(as.factor(pred.clase))
roc_cons &lt;- multiclass.roc(test_sp_num, pred_clase_num)</code></pre>
<pre><code>## Setting direction: controls &lt; cases</code></pre>
<pre><code>## Setting direction: controls &lt; cases
## Setting direction: controls &lt; cases</code></pre>
<p>Ahora creemos una función personalizada para utilizar un ciclo for para graficar las curvas ROC</p>
<pre class="r"><code>plot_rocs &lt;- function(classes, multi_roc, colors, theme, test_t){
  theme_set(theme) # Establece el tema a utilizar en todas las gráficas
  rocs_plots &lt;- list() # Lista vacía para llenar con las gráficas
  
  counter &lt;- seq_along(unique(classes)) # Valores a ciclar (clases)

  for (i in counter) { # para cada i en clases
    if (i == 1) { # Si i == 1
      rocs_plots[[i]] &lt;- ggroc(multi_roc$rocs[[i]], color = colors[i], size = 1, legacy.axes = T) + # graficado de la curva ROC para la especie i
                         labs(title = paste(&quot;Curvas ROC. AUC multi-clase = &quot;, round(roc_cons$auc[1],2)), # Establecemos el título global de la gráfica
                              subtitle = sprintf(&quot;%s&quot;, unique(test_t$especie)[i]), # clase como subtítulo
                              x = element_blank(), # Sin nombre del eje x
                              y = &quot;TVP (Sensibilidad)&quot;) +
                         geom_abline(intercept = 0, slope = 1, color = &quot;gray50&quot;, size = 1, linetype = &quot;dashed&quot;) # Línea de referencia (Azar)
    }
    if (i &lt; length(counter) &amp; i &gt; 1) {
      rocs_plots[[i]] &lt;- ggroc(roc_cons$rocs[[i]], color = colors[i], size = 1, legacy.axes = T) +
                         labs(subtitle = sprintf(&quot;%s&quot;, unique(test_t$especie)[i]),
                              x = element_blank(),
                              y = &quot;TVP (Sensibilidad)&quot;) +
                         geom_abline(intercept = 0, slope = 1, color = &quot;gray50&quot;, size = 1, linetype = &quot;dashed&quot;)
    }
    if (i == length(counter)) {
      rocs_plots[[i]] &lt;- ggroc(roc_cons$rocs[[i]], color = colors[i], size = 1, legacy.axes = T) +
                         labs(subtitle = sprintf(&quot;%s&quot;, unique(test_t$especie)[i]),
                              x = &quot;TFP (1 - especificidad)&quot;, # Se agrega el nombre del eje x para todas las gráficas (ojo a que es una sola columna)
                              y = &quot;TVP (Sensibilidad)&quot;) +
                         geom_abline(intercept = 0, slope = 1,color = &quot;gray50&quot;, size = 1, linetype = &quot;dashed&quot;)
    }
      
    }
  do.call(&#39;grid.arrange&#39;, c(rocs_plots, ncol = 1))
}</code></pre>
<p>Ahora grafiquémoslas:</p>
<pre class="r"><code># Colores de las especies:
colors &lt;- c(&quot;brown3&quot;, &quot;chartreuse4&quot;, &quot;deepskyblue4&quot;)
#cairo_pdf(&quot;ROC_LDA.pdf&quot;, height = 12.9, width = 7 )
plot_rocs(test_sp_num, roc_cons, colors, theme_bw(), test_t)</code></pre>
<p><img src="c14_clasificacion_files/figure-html/unnamed-chunk-20-1.png" width="576" /></p>
<pre class="r"><code>#dev.off()</code></pre>
</div>
</div>
</div>
<div id="regresión-logística" class="section level2">
<h2>Regresión logística</h2>
<p>Otra técnica que podemos utilizar es la regresión logística. Es importante recordar que este modelo de clasificación fue desarrollado originalmente para clasificaciones binarias, aunque ya ha sido extendido a clasificaciones multinomiales. Comencemos con el caso binario. En este caso, utilicemos la base iris para cambiar un poco de aires y cambiemos las etiquetas a versicolor y otra</p>
<pre class="r"><code>iris_dat &lt;- iris
iris_dat$Species &lt;- ifelse(iris_dat$Species == &quot;versicolor&quot;, &quot;versicolor&quot;, &quot;otra&quot;)
samples &lt;- sample.split(iris_dat$Species, SplitRatio = .75)
train2 &lt;- subset(iris_dat, sample == TRUE)
test2 &lt;- subset(iris_dat, sample == FALSE)</code></pre>
<p>Centremos y estandaricemos:</p>
<pre class="r"><code>pre_pars &lt;- preProcess(train2, method = c(&quot;center&quot;, &quot;scale&quot;))
train_t2 &lt;- predict(pre_pars, train2)
test_t2 &lt;- predict(pre_pars, test2)</code></pre>
<div id="ajuste-del-modelo-1" class="section level3">
<h3>Ajuste del modelo</h3>
<p>A diferencia del caso anterior, vamos a implementar el modelo utilizando la librería caret (Classification and Regression Training). Esta librería nos permite entrenar modelos de clasificación o regresión de manera sencilla o, mejor dicho, homogeneiza el proceso de declaración de modelos y nos evita estar batallando con las librerías propias. Veámoslo en acción:</p>
<pre class="r"><code>logit_reg &lt;- caret::train(form = as.factor(Species)~.,
                          data = train_t2,
                          method = &quot;glm&quot;,
                          family = &quot;binomial&quot;)</code></pre>
</div>
<div id="importancia-de-variables-1" class="section level3">
<h3>Importancia de variables</h3>
<p>Veamos los coeficientes:</p>
<pre class="r"><code>summary(logit_reg)</code></pre>
<pre><code>## 
## Call:
## NULL
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.0676  -0.7632  -0.4016   0.8363   2.0392  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   -1.0835     0.2603  -4.162 3.16e-05 ***
## Sepal.Length   0.1491     0.6608   0.226 0.821483    
## Sepal.Width   -1.3483     0.4002  -3.369 0.000754 ***
## Petal.Length   1.4449     1.3274   1.089 0.276350    
## Petal.Width   -1.5854     0.9569  -1.657 0.097566 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 142.19  on 113  degrees of freedom
## Residual deviance: 111.24  on 109  degrees of freedom
## AIC: 121.24
## 
## Number of Fisher Scoring iterations: 5</code></pre>
</div>
<div id="diagnóstico-de-la-regresión-logística" class="section level3">
<h3>Diagnóstico de la regresión logística</h3>
<div id="matriz-de-confusión-1" class="section level4">
<h4>Matriz de confusión</h4>
<pre class="r"><code>test_preds &lt;- predict(logit_reg, test_t2)
confusionMatrix(test_preds, as.factor(test_t2$Species))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   otra versicolor
##   otra         19          8
##   versicolor    3          6
##                                           
##                Accuracy : 0.6944          
##                  95% CI : (0.5189, 0.8365)
##     No Information Rate : 0.6111          
##     P-Value [Acc &gt; NIR] : 0.1975          
##                                           
##                   Kappa : 0.3125          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.2278          
##                                           
##             Sensitivity : 0.8636          
##             Specificity : 0.4286          
##          Pos Pred Value : 0.7037          
##          Neg Pred Value : 0.6667          
##              Prevalence : 0.6111          
##          Detection Rate : 0.5278          
##    Detection Prevalence : 0.7500          
##       Balanced Accuracy : 0.6461          
##                                           
##        &#39;Positive&#39; Class : otra            
## </code></pre>
<pre class="r"><code>confusionMatrix(predict(logit_reg, train_t2), as.factor(train_t2$Species))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   otra versicolor
##   otra         69         19
##   versicolor    9         17
##                                           
##                Accuracy : 0.7544          
##                  95% CI : (0.6649, 0.8302)
##     No Information Rate : 0.6842          
##     P-Value [Acc &gt; NIR] : 0.06303         
##                                           
##                   Kappa : 0.3857          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.08897         
##                                           
##             Sensitivity : 0.8846          
##             Specificity : 0.4722          
##          Pos Pred Value : 0.7841          
##          Neg Pred Value : 0.6538          
##              Prevalence : 0.6842          
##          Detection Rate : 0.6053          
##    Detection Prevalence : 0.7719          
##       Balanced Accuracy : 0.6784          
##                                           
##        &#39;Positive&#39; Class : otra            
## </code></pre>
</div>
<div id="predicciones-y-observaciones" class="section level4">
<h4>Predicciones y observaciones</h4>
<pre class="r"><code>preds_probs &lt;- data.frame(test_t2, P_vers = predict(logit_reg, test_t2, type = &quot;prob&quot;)$versicolor, adj_sp = test_preds)
preds_probs</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Sepal.Length"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Sepal.Width"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Petal.Length"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Petal.Width"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Species"],"name":[5],"type":["chr"],"align":["left"]},{"label":["P_vers"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["adj_sp"],"name":[7],"type":["fct"],"align":["left"]}],"data":[{"1":"-1.37235530","2":"0.3615629","3":"-1.39984001","4":"-1.300304330","5":"otra","6":"0.14971955","7":"otra","_rn_":"3"},{"1":"-0.51677754","2":"2.0009219","3":"-1.17300026","4":"-1.040471387","5":"otra","6":"0.01976614","7":"otra","_rn_":"6"},{"1":"-1.49458070","2":"0.8299512","3":"-1.34313007","4":"-1.170387859","5":"otra","6":"0.07511804","7":"otra","_rn_":"7"},{"1":"-0.02787597","2":"2.2351160","3":"-1.45654994","4":"-1.300304330","5":"otra","6":"0.01560462","7":"otra","_rn_":"15"},{"1":"-0.51677754","2":"2.0009219","3":"-1.39984001","4":"-1.040471387","5":"otra","6":"0.01432123","7":"otra","_rn_":"17"},{"1":"-0.15010136","2":"1.7667277","3":"-1.17300026","4":"-1.170387859","5":"otra","6":"0.03464308","7":"otra","_rn_":"19"},{"1":"-0.88345373","2":"0.5957570","3":"-1.17300026","4":"-0.910554916","5":"otra","6":"0.09365334","7":"otra","_rn_":"24"},{"1":"-0.51677754","2":"0.8299512","3":"-1.28642013","4":"-1.040471387","5":"otra","6":"0.07664476","7":"otra","_rn_":"32"},{"1":"-1.00567912","2":"1.0641453","3":"-1.39984001","4":"-1.170387859","5":"otra","6":"0.05543986","7":"otra","_rn_":"41"},{"1":"-1.25012991","2":"-0.1068254","3":"-1.34313007","4":"-1.170387859","5":"otra","6":"0.22951393","7":"otra","_rn_":"46"},{"1":"-1.49458070","2":"0.3615629","3":"-1.34313007","4":"-1.300304330","5":"otra","6":"0.15801319","7":"otra","_rn_":"48"},{"1":"-0.63900294","2":"1.5325336","3":"-1.28642013","4":"-1.300304330","5":"otra","6":"0.04554503","7":"otra","_rn_":"49"},{"1":"0.82770179","2":"-0.5752137","3":"0.47158789","4":"0.388609795","5":"versicolor","6":"0.47023607","7":"otra","_rn_":"55"},{"1":"0.58325100","2":"0.5957570","3":"0.52829783","4":"0.518526266","5":"versicolor","6":"0.13487243","7":"otra","_rn_":"57"},{"1":"0.94992719","2":"-0.3410195","3":"0.47158789","4":"0.128776853","5":"versicolor","6":"0.49879907","7":"otra","_rn_":"59"},{"1":"-1.00567912","2":"-2.4487668","3":"-0.15222141","4":"-0.260972560","5":"versicolor","6":"0.90569044","7":"versicolor","_rn_":"61"},{"1":"0.21657482","2":"-1.9803785","3":"0.13132827","4":"-0.260972560","5":"versicolor","6":"0.90225431","7":"versicolor","_rn_":"63"},{"1":"-0.27232676","2":"-1.2777961","3":"0.07461834","4":"-0.131056089","5":"versicolor","6":"0.71389785","7":"versicolor","_rn_":"70"},{"1":"0.33880022","2":"-0.5752137","3":"0.52829783","4":"-0.001139618","5":"versicolor","6":"0.62428056","7":"versicolor","_rn_":"74"},{"1":"1.19437798","2":"-0.5752137","3":"0.58500776","4":"0.258693324","5":"versicolor","6":"0.57574581","7":"versicolor","_rn_":"77"},{"1":"-0.15010136","2":"-1.0436020","3":"-0.15222141","4":"-0.260972560","5":"versicolor","6":"0.62129439","7":"versicolor","_rn_":"80"},{"1":"-0.51677754","2":"-0.1068254","3":"0.41487795","4":"0.388609795","5":"versicolor","6":"0.26247111","7":"otra","_rn_":"85"},{"1":"0.21657482","2":"0.8299512","3":"0.41487795","4":"0.518526266","5":"versicolor","6":"0.08371717","7":"otra","_rn_":"86"},{"1":"-0.15010136","2":"-0.3410195","3":"0.24474815","4":"0.128776853","5":"versicolor","6":"0.37834058","7":"otra","_rn_":"97"},{"1":"0.46102561","2":"-0.3410195","3":"0.30145808","4":"0.128776853","5":"versicolor","6":"0.41981575","7":"otra","_rn_":"98"},{"1":"-0.15010136","2":"-0.5752137","3":"0.18803821","4":"0.128776853","5":"versicolor","6":"0.43468411","7":"otra","_rn_":"100"},{"1":"-1.12790452","2":"-1.2777961","3":"0.41487795","4":"0.648442738","5":"otra","6":"0.51065815","7":"versicolor","_rn_":"107"},{"1":"1.68327955","2":"1.2983394","3":"1.32223694","4":"1.687774507","5":"otra","6":"0.03394767","7":"otra","_rn_":"110"},{"1":"0.82770179","2":"0.3615629","3":"0.75513757","4":"1.038192151","5":"otra","6":"0.11894699","7":"otra","_rn_":"111"},{"1":"2.29440653","2":"-1.0436020","3":"1.77591643","4":"1.427941565","5":"otra","6":"0.72471005","7":"versicolor","_rn_":"119"},{"1":"1.31660337","2":"0.3615629","3":"1.09539719","4":"1.427941565","5":"otra","6":"0.11346749","7":"otra","_rn_":"121"},{"1":"2.29440653","2":"-0.5752137","3":"1.66249655","4":"1.038192151","5":"otra","6":"0.68792315","7":"versicolor","_rn_":"123"},{"1":"0.33880022","2":"-0.1068254","3":"0.64171770","4":"0.778359209","5":"otra","6":"0.23223504","7":"otra","_rn_":"128"},{"1":"2.29440653","2":"-0.1068254","3":"1.32223694","4":"1.427941565","5":"otra","6":"0.27874723","7":"otra","_rn_":"136"},{"1":"1.07215258","2":"0.5957570","3":"1.09539719","4":"1.687774507","5":"otra","6":"0.05625463","7":"otra","_rn_":"145"},{"1":"0.09434943","2":"-0.1068254","3":"0.75513757","4":"0.778359209","5":"otra","6":"0.25572639","7":"otra","_rn_":"150"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
<div id="curvas-de-decisión" class="section level4">
<h4>Curvas de decisión</h4>
<p>Ahora realicemos el gráfico de la regresión logística o, mejor dicho, los gráficos para cada variable. Al igual que para el LDA el proceso es generar nuevos valores para la línea de decisión y después superponer los valores de prueba.Generemos entonces los valores:</p>
<pre class="r"><code>sim_values &lt;- function(x){
  library(scales)
  # Calculamos los límites expandidos de LD1 y LD2
  varlim &lt;- expand_range(c(min(x), max(x)), 
                                 mul=0.1) # Amplía el intervalo un 5% hacia &quot;abajo&quot;
  
  # Generamos 300 valores nuevos de LD1 y LD2 en esos límites:
  var_exp &lt;- seq(varlim[[1]], varlim[[2]], 
             length.out=300)
  
  return(var_exp)
}

sim_logdata &lt;- as.data.frame(apply(train_t2[-c(5)], 2, sim_values))
sim_logdata[&quot;probs&quot;] &lt;- predict(logit_reg, sim_logdata, type = &quot;prob&quot;)$versicolor
head(sim_logdata)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Sepal.Length"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Sepal.Width"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Petal.Length"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Petal.Width"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["probs"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"-2.301268","2":"-2.495606","3":"-1.893216","4":"-1.742020","5":"0.8770235","_rn_":"1"},{"1":"-2.283609","2":"-2.474928","3":"-1.880243","4":"-1.729507","5":"0.8741541","_rn_":"2"},{"1":"-2.265950","2":"-2.454250","3":"-1.867270","4":"-1.716993","5":"0.8712275","_rn_":"3"},{"1":"-2.248290","2":"-2.433572","3":"-1.854297","4":"-1.704479","5":"0.8682432","_rn_":"4"},{"1":"-2.230631","2":"-2.412894","3":"-1.841324","4":"-1.691966","5":"0.8652004","_rn_":"5"},{"1":"-2.212972","2":"-2.392216","3":"-1.828351","4":"-1.679452","5":"0.8620985","_rn_":"6"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Formemos el gráfico. Al igual que en el caso anterior lo haremos mediante una función para poder generarlos todos en un solo paso</p>
<pre class="r"><code>plot_partials &lt;- function(sim_data, test_preds, prob_col, prob_col2, pos_class){
  partials &lt;- list()
  vars &lt;- colnames(sim_data)[colnames(sim_data)!=prob_col]
  
  for (i in seq_along(vars)) {
    
    temp &lt;- data.frame(a = sim_data[,vars[i]], probs = sim_data[,prob_col])
    temp2 &lt;- data.frame(b = test_preds[,vars[i]], test_preds)
    
    if ((i%%2) != 0) { # Si el residuo de la división es != 0; el número de gráfica es non
       partials[[i]] &lt;- ggplot(data = temp, aes(x = a, y = probs)) + 
                        geom_line() + 
                        geom_point(data = temp2, 
                                   aes(x = b, y = P_vers, color = adj_sp, shape = Species),
                                   size = 2) +
                        labs(title = vars[i],
                             x = element_blank(),
                             y = sprintf(&quot;p(%s)&quot;, pos_class)) +
                        scale_color_discrete(name = &quot;Predicción&quot;) +
                        scale_shape_discrete(name = &quot;Observado&quot;)
    }
    else {# Si el residuo de la división es == 0; el número de gráfica es par
      partials[[i]] &lt;- ggplot(data = temp, aes(x = a, y = probs)) + 
                        geom_line() + 
                        geom_point(data = temp2, 
                                   aes(x = b, y = P_vers, color = adj_sp, shape = Species),
                                   size = 2) +
                        labs(title = vars[i],
                             x = element_blank(),
                             y = element_blank()) +
                        scale_color_discrete(name = &quot;Predicción&quot;) +
                        scale_shape_discrete(name = &quot;Observado&quot;)
    }
  }
  
  do.call(&#39;grid.arrange&#39;, c(partials, nrow = 2))
}</code></pre>
<pre class="r"><code>plot_partials(sim_logdata, preds_probs, &quot;probs&quot;, &quot;P_vers&quot;, &quot;versicolor&quot;)</code></pre>
<p><img src="c14_clasificacion_files/figure-html/unnamed-chunk-30-1.png" width="1152" /></p>
</div>
<div id="roc-y-auc" class="section level4">
<h4>ROC y AUC</h4>
<pre class="r"><code>test_sp_num &lt;- as.numeric(as.factor(test_t2$Species))
pred_clase_num &lt;- as.numeric(as.factor(test_preds))
roc_logit &lt;- roc(test_sp_num, pred_clase_num)</code></pre>
<pre><code>## Setting levels: control = 1, case = 2</code></pre>
<pre><code>## Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code>auc_logit &lt;- auc(test_sp_num, pred_clase_num)</code></pre>
<pre><code>## Setting levels: control = 1, case = 2
## Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code>roc_plot &lt;- ggroc(roc_logit, color = &quot;deepskyblue4&quot;, size = 1, legacy.axes = T) + # graficado de la curva ROC para la especie i
            labs(title = paste(&quot;Curva ROC. AUC = &quot;, round(auc_logit,2)), # Establecemos el título global de la gráfica
                subtitle = &quot;Versicolor vs otras.&quot;, # clase como subtítulo
                x = &quot;TFP (1 - especificidad)&quot;, # Sin nombre del eje x
                y = &quot;TVP (Sensibilidad)&quot;,
                caption = &quot;Datos de prueba&quot;) +
            geom_abline(intercept = 0, slope = 1, color = &quot;gray50&quot;, size = 1, linetype = &quot;dashed&quot;) # Línea de referencia (Azar)
roc_plot</code></pre>
<p><img src="c14_clasificacion_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="regresión-logística-multinomial" class="section level2">
<h2>Regresión Logística multinomial</h2>
<p>Por último, veamos cómo se ajusta un modelo multinomial; i.e., un clasificador para más de dos clases</p>
<pre class="r"><code>iris_dat &lt;- iris
samples &lt;- sample.split(iris_dat$Species, SplitRatio = .75)
train3 &lt;- subset(iris_dat, sample == TRUE)
test3 &lt;- subset(iris_dat, sample == FALSE)</code></pre>
<p>Centremos y estandaricemos:</p>
<pre class="r"><code>pre_pars &lt;- preProcess(train3, method = c(&quot;center&quot;, &quot;scale&quot;))
train_t3 &lt;- predict(pre_pars, train3)
test_t3 &lt;- predict(pre_pars, test3)</code></pre>
<div id="ajuste-del-modelo-2" class="section level4">
<h4>Ajuste del modelo</h4>
<p>A diferencia del caso anterior, vamos a implementar el modelo utilizando la librería caret (Classification and Regression Training). Esta librería nos permite entrenar modelos de clasificación o regresión de manera sencilla o, mejor dicho, homogeneiza el proceso de declaración de modelos y nos evita estar batallando con las librerías propias. Veámoslo en acción:</p>
<pre class="r"><code>logit_mult &lt;- caret::train(form = as.factor(Species)~.,
                          data = train_t3,
                          method = &quot;multinom&quot;,
                          trace = F)
summary(logit_mult)</code></pre>
<pre><code>## Call:
## nnet::multinom(formula = .outcome ~ ., data = dat, decay = param$decay, 
##     trace = ..1)
## 
## Coefficients:
##            (Intercept) Sepal.Length Sepal.Width Petal.Length Petal.Width
## versicolor     8.06394    1.4575030   -2.263957     6.711222     5.27363
## virginica    -10.38752    0.5382543   -4.804585    22.046350    17.55141
## 
## Std. Errors:
##            (Intercept) Sepal.Length Sepal.Width Petal.Length Petal.Width
## versicolor    34.96486     64.58124    19.70423     71.79894    67.67309
## virginica     36.15874     64.62893    19.78369     72.27143    68.05214
## 
## Residual Deviance: 11.04544 
## AIC: 31.04544</code></pre>
<pre class="r"><code>test_preds &lt;- predict(logit_mult, test_t3)
confusionMatrix(test_preds, as.factor(test_t3$Species))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         12          0         0
##   versicolor      0         14         0
##   virginica       0          0        10
## 
## Overall Statistics
##                                      
##                Accuracy : 1          
##                  95% CI : (0.9026, 1)
##     No Information Rate : 0.3889     
##     P-Value [Acc &gt; NIR] : 1.713e-15  
##                                      
##                   Kappa : 1          
##                                      
##  Mcnemar&#39;s Test P-Value : NA         
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           1.0000
## Specificity                 1.0000            1.0000           1.0000
## Pos Pred Value              1.0000            1.0000           1.0000
## Neg Pred Value              1.0000            1.0000           1.0000
## Prevalence                  0.3333            0.3889           0.2778
## Detection Rate              0.3333            0.3889           0.2778
## Detection Prevalence        0.3333            0.3889           0.2778
## Balanced Accuracy           1.0000            1.0000           1.0000</code></pre>
<p>Y la importancia de variables:</p>
<pre class="r"><code>varImp(logit_mult, scale = T)</code></pre>
<pre><code>## multinom variable importance
## 
##              Overall
## Petal.Length  100.00
## Petal.Width    77.83
## Sepal.Width    18.96
## Sepal.Length    0.00</code></pre>
</div>
</div>
<div id="ejercicio" class="section level2">
<h2>Ejercicio</h2>
<p>Realizar una regresión logística multinomial con los datos de morfometría de peces (<code>Medidas.txt</code>). Responde lo siguiente: 1. ¿El modelo se encuentra sobre ajustado? ¿Por qué? 2. Obtén las curvas ROC y el valor de AUC multi-clase. ¿que tan bueno consideras al modelo? 3. ¿Cuáles fueron las variables más importantes para la clasificación? Compara con los resultados del ACP de la clase de reducción de dimensionalidad y los del LDA.</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
