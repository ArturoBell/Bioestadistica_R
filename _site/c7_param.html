<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Arturo Bell" />


<title>Análisis paramétricos</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Bioestadística con R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Clases
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Biología como Ciencia de Datos</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c1_Intro_R.html">Introducción a R</a>
        </li>
        <li>
          <a href="c2_ggplot2.html">ggplot2</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Herramientas Básicas</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c3_probabilidad.html">Probabilidad</a>
        </li>
        <li>
          <a href="c4_muestreo.html">Teoría del Muestreo</a>
        </li>
        <li>
          <a href="c5_descriptiva.html">Estadística Descriptiva</a>
        </li>
        <li>
          <a href="c6_ph0.html">Pruebas de hipótesis</a>
        </li>
        <li>
          <a href="c7_param.html">Técnicas Paramétricas</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Relaciones Lineales</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c8_rls.html">Modelo Lineal Simple</a>
        </li>
        <li>
          <a href="c9_glm.html">Modelos Lineales Generalizados</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="c10_no_par.html">Técnicas No Paramétricas</a>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Técnicas Multivariadas</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c11_intro_mv.html">Introducción</a>
        </li>
        <li>
          <a href="c12_no_sup.html">No supervisadas</a>
        </li>
        <li>
          <a href="c13_comps_mv.html">Comparaciones Multivariadas</a>
        </li>
        <li>
          <a href="c14_clasificacion.html">Clasificaciones</a>
        </li>
        <li>
          <a href="c15_regs_mv.html">Regresiones Múltiples</a>
        </li>
      </ul>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Análisis paramétricos</h1>
<h4 class="author">Arturo Bell</h4>

</div>


<div id="librerías" class="section level2">
<h2>Librerías</h2>
<pre class="r"><code>library(ggplot2)
library(corrplot)
library(gridExtra)
library(rstatix)</code></pre>
<pre><code>## 
## Attaching package: &#39;rstatix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:plyr&#39;:
## 
##     desc, mutate</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     filter</code></pre>
<pre class="r"><code>#library(car)
library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:plyr&#39;:
## 
##     arrange, count, desc, failwith, id, mutate, rename, summarise,
##     summarize</code></pre>
<pre><code>## The following object is masked from &#39;package:gridExtra&#39;:
## 
##     combine</code></pre>
<pre><code>## The following object is masked from &#39;package:car&#39;:
## 
##     recode</code></pre>
<pre><code>## The following objects are masked from &#39;package:xts&#39;:
## 
##     first, last</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>library(ggpubr)</code></pre>
<pre><code>## 
## Attaching package: &#39;ggpubr&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:plyr&#39;:
## 
##     mutate</code></pre>
<pre><code>## The following object is masked from &#39;package:dendextend&#39;:
## 
##     rotate</code></pre>
</div>
<div id="teorema-del-límite-central" class="section level2">
<h2>Teorema del Límite Central</h2>
<p>“Dadas muestras aleatorias e independientes con N observaciones cada una, la distribución de sus medias se aproxima a una distribución normal conforme N incrementa, INDEPENDIENTEMENTE de la distribución poblacional”; es decir, mientras N sea grande, <span class="math inline">\(\bar{x} \sim Normal\)</span>. Para probar esto podemos hacer un ejercicio en el cual simulemos una población con distribución Gamma, cuya zona de mayor densidad se encuentra desplazada a la izquierda:</p>
<pre class="r"><code>set.seed(0)
datos &lt;- data.frame(x = 1:1000, y = rgamma(1000, 1))
gamma &lt;- ggplot(data = datos, aes(y)) + 
         geom_density(fill = rgb(118,78,144, maxColorValue = 255), alpha = 0.5, colour = &quot;white&quot;) +
         theme_bw() +
         labs(title = &quot;Distribución Gamma&quot;,
              x = element_blank(),
              y = element_blank()) +
         theme(text = element_text(colour = &quot;gray40&quot;))

#cairo_pdf(&quot;gamma.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
gamma</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>Con nuestra población definida, podemos seleccionar algunos tamaños de muestra, realizar 1000 muestreos aleatorios, obtener la media de cada muestreo y graficar su distribución. Primero para N = 3</p>
<pre class="r"><code>N = 3
medias &lt;- data.frame(x = 1:1000, y = replicate(1000, mean(sample(datos$y, N))))


dist_n3 &lt;- ggplot(data = medias, aes(y)) +
           geom_density(fill = &quot;dodgerblue4&quot;, alpha = 0.5, colour = &quot;white&quot;) +
           theme_bw() +
           labs(title = sprintf(&quot;Distribución muestreal con N = %d&quot;, N),
                x = element_blank(),
                y = element_blank()) +
           theme(text = element_text(colour = &quot;gray40&quot;))

#cairo_pdf(&quot;n_3.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
dist_n3</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>Ahora para N = 10. La distribución se aproxima más a una distribución normal.</p>
<pre class="r"><code>N = 10
medias &lt;- data.frame(x = 1:1000, y = replicate(1000, mean(sample(datos$y, N))))

dist_n10 &lt;- ggplot(data = medias, aes(y)) +
            geom_density(fill = &quot;dodgerblue4&quot;, alpha = 0.5, colour = &quot;white&quot;) +
            theme_bw() +
            labs(title = sprintf(&quot;Distribución muestreal con N = %d&quot;, N),
                 x = element_blank(),
                 y = element_blank()) +
            theme(text = element_text(colour = &quot;gray40&quot;))

#cairo_pdf(&quot;n_10.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
dist_n10</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>Con N = 30 la distribución es más cercana a una normal que a la gamma, por lo que usualmente se acepta que: con N≥30 la distribución muestreal de la media DEBERÁ ser normal:</p>
<pre class="r"><code>N = 30
medias &lt;- data.frame(x = 1:1000, y = replicate(1000, mean(sample(datos$y, N))))


dist_n30 &lt;- ggplot(data = medias, aes(y)) +
            geom_density(fill = &quot;dodgerblue4&quot;, alpha = 0.5, colour = &quot;white&quot;) +
            theme_bw() +
            labs(title = sprintf(&quot;Distribución muestreal con N = %d&quot;, N),
                 x = element_blank(),
                 y = element_blank()) +
            theme(text = element_text(colour = &quot;gray40&quot;))

#cairo_pdf(&quot;n_30.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
dist_n30</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>Para comprobar, hagámos el ejercicio con una distribución uniforme; es decir, en la cual todos los valores tienen la misma probabilidad de ser obtenidos (desviaciones debido al generador de números “aleatorios”):</p>
<pre class="r"><code>N = 30
datos &lt;- data.frame(x = 1:1000, y = runif(1000))
unif &lt;- ggplot(data = datos, aes(y)) + 
        geom_density(fill = rgb(118,78,144, maxColorValue = 255), alpha = 0.5, colour = &quot;white&quot;) +
        theme_bw() +
        labs(title = &quot;Distribución \&quot;uniforme\&quot;&quot;,
             x = element_blank(),
             y = element_blank()) +
        theme(text = element_text(colour = &quot;gray40&quot;))

#cairo_pdf(&quot;unif.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
unif</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<pre class="r"><code>medias &lt;- data.frame(x = 1:1000, y = replicate(1000, mean(sample(datos$y, N))))

dist_n30 &lt;- ggplot(data = medias, aes(y)) +
            geom_density(fill = &quot;dodgerblue4&quot;, alpha = 0.5, colour = &quot;white&quot;) +
            theme_bw() +
            labs(title = sprintf(&quot;Distribución muestreal con N = %d&quot;, N),
                 x = element_blank(),
                 y = element_blank()) +
            theme(text = element_text(colour = &quot;gray40&quot;))

#cairo_pdf(&quot;n_30u.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
dist_n30</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>Un aspecto importante a considerar es la “Primera Propiedad Conocida” de la distribución normal: <em>dadas muestras aleatorias e independientes con N observaciones cada una (tomadas de una distribución normal), la distribución de medias muestreales es normal e insesgada (i.e., centrada en la media poblacional), independientemente del tamaño de N</em>. Por lo tanto, aún un N de 1 debería dar una distribución parecida a la normal. Comprobemos:</p>
<pre class="r"><code>N = 1
datos &lt;- data.frame(x = 1:1000, y = rnorm(1000))
norm &lt;- ggplot(data = datos, aes(y)) + 
        geom_density(fill = rgb(118,78,144, maxColorValue = 255), alpha = 0.5, colour = &quot;white&quot;) +
        theme_bw() +
        labs(title = &quot;Distribución Normal&quot;,
             x = element_blank(),
             y = element_blank()) +
        theme(text = element_text(colour = &quot;gray40&quot;))

#cairo_pdf(&quot;norm.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
norm</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<pre class="r"><code>medias &lt;- data.frame(x = 1:1000, y = replicate(1000, mean(sample(datos$y, N))))

dist_n1 &lt;- ggplot(data = medias, aes(y)) +
           geom_density(fill = &quot;dodgerblue4&quot;, alpha = 0.5, colour = &quot;white&quot;) +
           theme_bw() +
           labs(title = sprintf(&quot;Distribución muestreal con N = %d&quot;, N),
                x = element_blank(),
                y = element_blank()) +
           theme(text = element_text(colour = &quot;gray40&quot;))

#cairo_pdf(&quot;n_1.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
dist_n1</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>La implicación de esta propiedad es que entre menos “normal” (en términos de su distribución estadística) sea nuestra población de estudio, necesitaremos un mayor tamaño de muestra para que nuestra distribución muestral de la media sea normal. El problema surge cuando nos debemos de enfrentar a tamaños de muestra pequeños (n &lt; 30). Aunque siempre podemos asumir (literalmente) que nuestra población se encuentra normalmente distribuida y “capitalizar en la robustez del modelo estadístico subyacente”, abusando del TLC, o reconocer que tamaños de muestra más pequeños nos pueden acercar lo suficiente (n &gt; 30 es para casos extremos). La tercera opción es la evaluación formal, la cual consiste en hacer una prueba de bondad de ajuste para conocer si nuestros datos se desvían o no de una distribución normal teórica. Antes de entrar a esos métodos, analicemos la prueba de bondad de ajuste más conocida: la prueba <span class="math inline">\(\chi^2\)</span> de independencia.</p>
</div>
<div id="pruebas-de-bondad-de-ajuste-chi2" class="section level2">
<h2>Pruebas de bondad de ajuste: <span class="math inline">\(\chi^2\)</span></h2>
<p>Esta prueba nos permite probar si la distribución de nuestros datos (frecuencias de variables nominales) son iguales a una distribución teórica. El ejemplo más sencillo lo tenemos al evaluar si la distribución de sexos en una población es diferente de 1:1. En este caso, la distribución de nuestros datos es binomial (dos categorías, verdadero/falso, éxito/fracaso, macho/hembra, etc.). En nuestro muestreo contamos 142 machos y 190 hembras. Coloquemos esos datos en un objeto y realicemos la prueba:</p>
<pre class="r"><code>sexos &lt;- c(machos = 142, hembras = 190)
sex_chi &lt;- chisq.test(sexos)
sex_chi</code></pre>
<pre><code>## 
##  Chi-squared test for given probabilities
## 
## data:  sexos
## X-squared = 6.9398, df = 1, p-value = 0.00843</code></pre>
<p>Veamos la distribución teórica gráficamente y veamos la ubicación del estadístico de prueba:</p>
<pre class="r"><code>chi_data &lt;- data.frame(x = rchisq(1000, 1))

chisq_plot &lt;- ggplot(data = chi_data, aes(x)) +
              geom_density(fill = rgb(118,78,144, maxColorValue = 255), alpha = 0.5, colour = &quot;white&quot;) +
              geom_vline(xintercept = sex_chi$statistic, color = &quot;firebrick&quot;) +
              annotate(geom = &quot;text&quot;, x = sex_chi$statistic+1.1, y = 1, label = sprintf(&quot;X^2 = %.2f&quot;, round(sex_chi$statistic, 2))) +
              theme_bw() +
              labs(title = sprintf(&quot;Distribución X^2 teórica (g.l = %d)&quot;, sex_chi$parameter),
                   x = element_blank(),
                   y = element_blank()) +
             theme(text = element_text(colour = &quot;gray40&quot;))
#cairo_pdf(&quot;chi_plot.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
chisq_plot</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>Partiendo del valor de p podemos concluir que la proporción fue diferente de nuestro modelo teórico 1:1, pero ¿qué pasa si nos interesara comprobar si es diferente a otra proporción, por ejemplo 40% machos y 60% hembras? En ese caso únicamente debemos de proporcionar un vector <code>p</code> en el cual establezcamos la probabilidad correspondiente a cada grupo:</p>
<pre class="r"><code>chisq.test(sexos, p = c(0.4, 0.6))</code></pre>
<pre><code>## 
##  Chi-squared test for given probabilities
## 
## data:  sexos
## X-squared = 1.0622, df = 1, p-value = 0.3027</code></pre>
<p>Aquí nuestros datos no ridiculizan a nuestra hipótesis de nulidad, por lo que no podemos rechazarla. Un ejemplo más complejo es el de la presentación, en donde tratamos de probar si el proceso de vacunación hizo alguna diferencia en el estado de salud de los empleados o, en otras palabras, ¿la incidencia de pneumonía fue la misma, INDEPENDIENTEMENTE de si los empleados se vacunaron o no? Al igual que en el caso anterior, coloquemos los datos en un objeto:</p>
<pre class="r"><code>vacunas &lt;- data.frame(no_vacuna = c(23, 8, 61), vacuna = c(5, 10, 77), row.names = c(&quot;neumococo&quot;, &quot;otra_neumonia&quot;, &quot;sin_neumonia&quot;))
vacunas</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["no_vacuna"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["vacuna"],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"23","2":"5","_rn_":"neumococo"},{"1":"8","2":"10","_rn_":"otra_neumonia"},{"1":"61","2":"77","_rn_":"sin_neumonia"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Ahora apliquemos la prueba:</p>
<pre class="r"><code>vacs &lt;- chisq.test(vacunas)
vacs</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  vacunas
## X-squared = 13.649, df = 2, p-value = 0.001087</code></pre>
<p>Como era de esperarse al ver las frecuencias, la incidencia de pneumonía aparentemente no fue la misma entre los empleados vacunados y los que no se vacunaron. En este caso, podemos extraer aún más información, tal y como la dependencia entre las variables. Para ello accederemos al atributo residuals de la salida de chisq.test, el cual representa los residuales de Pearson para cada celda:</p>
<pre class="r"><code>vacs$residuals</code></pre>
<pre><code>##                no_vacuna     vacuna
## neumococo      2.4053512 -2.4053512
## otra_neumonia -0.3333333  0.3333333
## sin_neumonia  -0.9630868  0.9630868</code></pre>
<p>Valores positivos muestran una asociación positiva entre las variables correspondientes; es decir, la incidencia de neumonía por neumococo aumentó (signo positivo) en aquellos empleados que no fueron vacunados y viceversa, valores negativos muestran una asociación negativa; es decir, la incidencia disminuyó en aquellos que sí fueron vacunados. Si nuestro interés fuera saber qué tanto contribuyó cada celda al valor de <span class="math inline">\(\chi^2\)</span> podemos elevar cada residual al cuadrado y dividirlo entre el valor de <span class="math inline">\(\chi^2\)</span> observado, tal que:</p>
<pre class="r"><code>contrib &lt;- 100*((vacs$residuals^2)/vacs$statistic)
contrib</code></pre>
<pre><code>##               no_vacuna    vacuna
## neumococo     42.390150 42.390150
## otra_neumonia  0.814077  0.814077
## sin_neumonia   6.795773  6.795773</code></pre>
<p>Evidentemente, los residuales más grandes tuvieron la mayor contribución que, en este caso, estuvo dada por la incidencia de neumonía por neumococo en ambos grupos. Podemos ver estos resultados de manera gráfica utilizando la librería corrplot:</p>
<pre class="r"><code>corrplot::corrplot(contrib, is.corr = F)</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Ahora que tenemos una idea sobre cómo funcionan las pruebas de bondad de ajuste, podemos regresar a hablar sobre las pruebas de normalidad.</p>
<div id="supuesto-de-normalidad" class="section level3">
<h3>Supuesto de Normalidad</h3>
<p>Como imaginarás, las pruebas de normalidad son pruebas de bondad de ajuste en donde la distribución teórica es una distribución normal, aunque el modo en el cual se evalúan las desviaciones de la normalidad (<em>i.e.</em>, las diferencias) es diferente para cada prueba. Para aplicarlas, utilizaremos la base de datos de muestras independientes del archivo <code>datos_t</code>, particularmente la columna DC:</p>
<pre class="r"><code>dc &lt;- openxlsx::read.xlsx(&quot;data/datos_t.xlsx&quot;, sheet = 1)
dc</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["DC"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["CH"],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"48.2","2":"52.3","_rn_":"1"},{"1":"54.6","2":"57.4","_rn_":"2"},{"1":"58.3","2":"55.6","_rn_":"3"},{"1":"47.8","2":"53.2","_rn_":"4"},{"1":"51.4","2":"61.3","_rn_":"5"},{"1":"52.0","2":"58.0","_rn_":"6"},{"1":"55.2","2":"59.8","_rn_":"7"},{"1":"49.1","2":"54.8","_rn_":"8"},{"1":"49.9","2":"NA","_rn_":"9"},{"1":"52.6","2":"NA","_rn_":"10"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Podemos hacer una primera valoración utilizando un gráfico de densidad con un gráfico de densidad normal teórico superpuesto:</p>
<pre class="r"><code>set.seed(0)
norm_plot &lt;- ggplot(data = dc, aes(DC)) +
             geom_density(fill = rgb(118,78,144, maxColorValue = 255), colour = &quot;white&quot;, alpha = 0.5) +
             stat_function(fun = dnorm, n = 100, args = list(mean = mean(dc$DC), sd = sd(dc$DC))) +
             # Límites expandidos para visualizar el kde normal &quot;completo&quot;.
             #El kde observado se encuentra extendido más allá de los límites de los datos:
             xlim(c(40, 65)) + 
             theme_bw() +
             labs(title = &quot;Gráfico de densidad de DC (morado) vs. normal teórica (línea negra)&quot;,
                  x = element_blank(),
                  y = element_blank()) +
             theme(text = element_text(colour = &quot;gray40&quot;))

#cairo_pdf(&quot;norm_plot.pdf&quot;, height = 5, width = 5*1.6, pointsize = 20)
norm_plot</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>¿Qué opinas? Apliquemos ahora las pruebas de normalidad:</p>
<div id="prueba-de-shapiro-wilk" class="section level4">
<h4>Prueba de Shapiro-Wilk</h4>
<p>La prueba más conocida para evaluar la normalidad de un conjunto de datos es la prueba de Shapiro-Wilk. Su estadístico de prueba (W) se calcula de una manera poco amigable, pero conceptualmente implica ordenar los valores de la muestra y evaluar las desviaciones (diferencias) con respecto a la media, la varianza y su covarianza (este concepto se retoma más adelante) esperadas. En pocas palabras, la covarianza indica cuánto cambia una variable (la media) con respecto a otra (la varianza).</p>
<p>¿Qué tiene que ver la covarianza con el Supuesto de Normalidad? Tiene que ver con la Segunda Propiedad Conocida de la Distribución Normal, la cual establece que <em>Dadas observaciones aleatorias e independientes (de una distribución normal), la media muestral y la varianza muestral son independientes</em>. En otras palabras, cuando tomas una muestra y la usas para estimar tanto la media como la varianza de la población, qué tanto puedes equivocarte sobre la media es independiente de qué tanto puedes equivocarte sobre la varianza. Esta es una característica <strong>única</strong> de la distribución normal y es una de las razones por la que la prueba de S-W es de las más (por no decir la más) utilizada y recomendada, especialmente para muestras pequeñas. En algunos estudios de simulación como <a href="http://www.ukm.my/jsm/pdf_files/SM-PDF-40-6-2011/15%20NorAishah.pdf">este</a> ha demostrado ser más sensible a las desviaciones de la normalidad que la prueba de Kolmogorov-Smirnov, aunque antes de explicarla apliquemos la prueba de S-W:</p>
<pre class="r"><code>shapiro.test(dc$DC)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  dc$DC
## W = 0.95125, p-value = 0.6833</code></pre>
<p>El valor de p no nos permite rechazar nuestra hipótesis de nulidad a un <span class="math inline">\(\alpha = 0.05\)</span>, por lo que podemos concluir que los datos se ajustan a una distribución normal. Vuelve al gráfico de densidad normal, ¿qué opinas?</p>
<p>Como añadido, visualicemos la segunda propiedad conocida de la distribución normal:</p>
<pre class="r"><code>means &lt;- NA
sds &lt;- NA

for (i in 1:1000) {
  norm_data &lt;- rnorm(10)
  means[i] &lt;- mean(norm_data)
  sds[i] &lt;- sd(norm_data)
}

mean_sd &lt;- data.frame(mean = means, sd = sds)

prop_2 &lt;- ggplot(data = mean_sd, aes(x = mean, y = sd)) +
          geom_point(color = &quot;dodgerblue4&quot;, size = 2, alpha = 0.5) +
          theme_bw() +
          labs(title = &quot;Segunda Propiedad Conocida de la Distribución Normal&quot;,
               subtitle = &quot;1000 muestreos de una población normal&quot;,
               x = &quot;Media&quot;,
               y = &quot;Desviación Estándar&quot;) +
          theme(text = element_text(colour = &quot;gray40&quot;))
#cairo_pdf(&quot;prop_2.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
prop_2</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>Con una distribución Gamma:</p>
<pre class="r"><code>means &lt;- NA
sds &lt;- NA

for (i in 1:1000) {
  gamma_data &lt;- rgamma(10, shape = 1)
  means[i] &lt;- mean(gamma_data)
  sds[i] &lt;- sd(gamma_data)
}

mean_sd &lt;- data.frame(mean = means, sd = sds)

prop_g &lt;- ggplot(data = mean_sd, aes(x = mean, y = sd)) +
          geom_point(color = &quot;dodgerblue4&quot;, size = 2, alpha = 0.5) +
          theme_bw() +
          labs(title = &quot;Segunda Propiedad Conocida de la Distribución Normal&quot;,
               subtitle = &quot;1000 muestreos de una población gamma&quot;,
               x = &quot;Media&quot;,
               y = &quot;Desviación Estándar&quot;) +
          theme(text = element_text(colour = &quot;gray40&quot;))

#cairo_pdf(&quot;prop_g.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
prop_g</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>Ejericio opcional: Realiza el mismo gráfico para la columna DC y para la columna CH.</p>
</div>
<div id="prueba-kolmogorov-smirnov" class="section level4">
<h4>Prueba Kolmogorov-Smirnov</h4>
<p>A diferencia de la prueba S-W, la prueba K-S compara las función de densidad acumulada empírica (observada) vs. una función de densidad acumulada teórica (no necesariamente normal), lo cual causa que sea sensible a desviaciones en el centro de la distribución pero no en las colas; sin embargo, es importante mencionar, que la prueba K-S es convergente; es decir, que conforme <span class="math inline">\(N \rightarrow \infty\)</span> la prueba converge a la “respuesta verdadera” en términos de probabilidad. Esta razón hace que esta prueba no se recomiende para tamaños de muestra pequeños. Para aplicarla:</p>
<pre class="r"><code>ks.test(dc$DC, &quot;pnorm&quot;)</code></pre>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  dc$DC
## D = 1, p-value &lt; 2.2e-16
## alternative hypothesis: two-sided</code></pre>
<p>A diferencia del caso anterior, esta prueba si tuvo evidencia suficiente para ridiculizar nuestra hipótesis nula, por lo que podemos concluir que nuestros datos no se ajustan a una distribución normal. Vuelve nuevamente al gráfico KDE. ¿Qué opinas?</p>
<p>Veamos las densidades acumuladas:</p>
<pre class="r"><code># Generamos una cdf normal teórica:
cdf &lt;- data.frame(norm = rnorm(1000, mean = mean(dc$DC), sd = sd(dc$DC)))
# Graficamos una vs. la otra:
cdfplot &lt;- ggplot(data = dc, aes(DC)) +
           stat_ecdf(geom = &quot;step&quot;, colour = rgb(118,78,144, maxColorValue = 255), alpha = 1) +
           stat_ecdf(data = cdf, aes(norm), geom = &quot;line&quot;, colour = &quot;black&quot;) +
           theme_bw() +
           labs(title = &quot;Densidades empírica (morado) y teórica (negro) Acumuladas para DC&quot;,
                x = element_blank(),
                y = element_blank())

#cairo_pdf(&quot;cdf.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
cdfplot</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>Conjuntando con el gráfico kde original podemos ver por qué la prueba K-S arrojó un resultado significativo, ya que hubo desviaciones importantes en la zona central. Interpretar correctamente un gráfico CDF NO es sencillo y requiere de experiencia, por lo que únicamente lo incluí para acompañar a la prueba que se basa en la densidad acumulada.</p>
<p>Habiendo explicado dos de las pruebas de normalidad más comunes, pasemos a los análisis paramétricos. El primero de ellos lo revisamos durante la clase de pruebas de hipótesis: la prueba t de Student, por lo que pasaremos directamente al Análisis de la Varianza.</p>
</div>
</div>
</div>
<div id="análisis-de-la-varianza" class="section level2">
<h2>Análisis de la Varianza</h2>
<p>En términos simples, podemos pensar en el ANOVA como una extensión de la prueba t-Student a más de dos grupos a comparar. Durante la clase de Comparaciones Multivariadas abordamos el riesgo que conlleva realizar múltiples pruebas de hipótesis (comparaciones) en nuestros datos; es decir, el problema de realizar dos o más comparaciones entre grupos como si se tratara de pruebas independientes. Por el momento, solo ten en mente que se incrementa la posibilidad de obtener un falso positivo únicamente por azar, por lo que hay que utilizar una técnica adecuada y es ahí donde entra el ANOVA o, mejor dicho, los ANOVAs. Como te imaginarás, estas pruebas nos permiten comparar medias entre más de dos grupos, aunque aquí la comparación se realiza de manera global y la hipótesis alternativa se expresa como “Al menos una de las medias es diferente”. Esto quiere decir que el ANOVA no nos dirá entre qué par(es) de grupos se encontraron las diferencias, sino que habrá que acompañarlo de una prueba post-hoc. Esta prueba es la prueba de diferencias honestas (HSD) de Tukey, la cual se encuentra basada en la distribución de los rangos estudentizados y fue diseñada para no incrementar la probabilidad de falsos positivos al realizar múltiples comparaciones. En esta sesión revisaremos tres modaliades de ANOVA: de una vía, de dos vías y factorial, de menor a mayor complejidad, aunque estos no son los únicos. Entre los demás diseños de ANOVA se encuentran el ANOVA de medidas repetidas (estudios de crecimiento en laboratorio con medidas intermedias entre el inicio y el final, por ejemplo) o el ANOVA anidado, en el cual el diseño es similar a una muñeca rusa.</p>
<p>Antes de aplicar y explicar los modelos de ANOVA, es necesario desarrollar una intuición sobre el procedimiento. El nombre “Análisis de Varianza” viene de que, literalmente, se utilizan las varianzas para comparar las medias. Aunque el proceso matemático implica calcular promedios de promedios, varias sumas de cuadrados y cuadrados medios del error, podemos resumirlo para fines prácticos en que la comparación se realiza mediante una razón/cociente, tal que:</p>
<p><span class="math display">\[F = \frac{\sigma^2_{entre}}{\sigma^2_{dentro}}\]</span></p>
<p>Sé que esto puede sonar muy poco intuitivo, pero si nos detenemos un poco a analizar la ecuación podemos darle mucho sentido. La varianza dentro de los grupos podemos considerarla como la varianza “promedio” de cada grupo (razón por la que es importante que estas sean homogéneas entre todos nuestros grupos), mientras que la varianza entre los grupos representa la “separación” (dispersión) entre los grupos (sin considerar el error). Partiendo de esto, es evidente que si la varianza entre grupos es muy grande en relación a la varianza dentro de los grupos podemos inferir que existe un efecto del factor de agrupamiento pues “no hay” (ojo a las comillas y los supuestos) otra forma de que las distribuciones de los grupos se desplacen.</p>
<p>Gráficamente la varianza dentro de los grupos se representaría de la siguiente manera:</p>
<pre class="r"><code>anov_sim &lt;- data.frame(grupo = as.factor(c(rep(&quot;A&quot;, 1000), rep(&quot;B&quot;, 1000))),
                       y = c(rnorm(1000, mean = 10, sd = 1), rnorm(1000, mean = 20, sd = 1)))

dentro_plot &lt;- ggplot(data = anov_sim, aes(y, fill = grupo, alpha = 0.5)) +
               geom_density(trim = T, show.legend = F, colour = &quot;white&quot;) +
               theme_minimal() +
               labs(title = &quot;Varianza dentro de los grupos&quot;,
                    x = element_blank(),
                    y = element_blank()) +
               scale_y_continuous(labels = NULL) +
               xlim(c(5, 25))
dentro_plot</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>Mientras que la varianza entre los grupos podemos, para fines de interpretación, visualizarla como la varianza dada por ambos grupos. En realidad esto representaría la varianza total y la varianza entre los grupos es el resultado de eliminar la varianza dada por el error, pero sigamos con el ejemplo:</p>
<pre class="r"><code>anov_sim$tot &lt;- rnorm(200, mean = 15, sd = sd(anov_sim$y))
entre_plot &lt;- ggplot(data = anov_sim, aes(tot)) + 
              geom_density(fill = &quot;dodgerblue4&quot;, alpha = 0.5, colour = &quot;white&quot;) +
              theme_minimal() +
              labs(title = &quot;Varianza entre los grupos&quot;,
                   x = element_blank(),
                   y = element_blank()) +
              scale_y_continuous(labels = NULL) +
              xlim(c(5, 25))
entre_plot</code></pre>
<pre><code>## Warning: Removed 90 rows containing non-finite values (stat_density).</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Visualizándolas como si de un cociente se tratara es posible darse cuenta cómo la varianza “entre” los grupos es mucho mayor que la varianza dentro de los grupos, lo cual daría un valor de la razón de varianzas muy alto, sugiriendo un efecto del factor de agrupamiento.</p>
<pre class="r"><code>#cairo_pdf(&quot;anova_plot.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
gridExtra::grid.arrange(entre_plot, dentro_plot)</code></pre>
<pre><code>## Warning: Removed 90 rows containing non-finite values (stat_density).</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>Veamos qué pasa cuando las medias son más cercanas entre sí:</p>
<pre class="r"><code>anov_sim2 &lt;- data.frame(grupo = as.factor(c(rep(&quot;A&quot;, 1000), rep(&quot;B&quot;, 1000))),
                        y = c(rnorm(1000, mean = 10, sd = 1), rnorm(1000, mean = 11, sd = 1)))
anov_sim2$tot &lt;- rnorm(2000, mean(10.5), sd(anov_sim2$y))
dentro_plot2 &lt;- ggplot(data = anov_sim2, aes(y, fill = grupo, alpha = 0.5)) +
               geom_density(trim = T, show.legend = F, colour = &quot;white&quot;) +
               theme_minimal() +
               labs(title = &quot;Varianza dentro de los grupos&quot;,
                    x = element_blank(),
                    y = element_blank()) +
               scale_y_continuous(labels = NULL) +
               xlim(c(5, 15))
entre_plot2 &lt;- ggplot(data = anov_sim2, aes(tot)) + 
              geom_density(fill = &quot;dodgerblue4&quot;, alpha = 0.5, colour = &quot;white&quot;) +
              theme_minimal() +
              labs(title = &quot;Varianza entre los grupos&quot;,
                   x = element_blank(),
                   y = element_blank()) +
              scale_y_continuous(labels = NULL) +
              xlim(c(5, 15))
#cairo_pdf(&quot;anova_plot2.pdf&quot;, family = &quot;Montserrat&quot;, height = 5, width = 5*1.6, pointsize = 20)
gridExtra::grid.arrange(entre_plot2, dentro_plot2)</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<div id="supuesto-de-homogeneidad-de-varianzas" class="section level3">
<h3>Supuesto de homogeneidad de Varianzas</h3>
<p>Como podrás imaginar, el que las varianzas de los grupos no sean homogéneas generará un sesgo al momento de calcular el cociente y, en consecuencia, el nivel de significancia de la prueba. Esto es lo que da origen al Supuesto de Homogeneidad de Varianzas. Existe una gran diversidad de pruebas, cada una con sus consideraciones, fortalezas y desventajas, pero analizaremos únicamente las (posiblemente) más conocidas.</p>
<div id="prueba-de-bartlett" class="section level4">
<h4>Prueba de Bartlett</h4>
<p>La prueba de Bartlett se considera como la prueba Uniformemente Más Poderosa; es decir, la que es menos propensa a cometer un falso negativo para cualquier valor de <span class="math inline">\(\alpha\)</span>. Este poder, sin embargo, tiene sus bemoles o su bemol, mejor dicho. Esta prueba se apoya TOTALMENTE en que la variable de interés en cada factor se encuentra normalmente distribuída (¡Hola de nuevo, Supuesto de Normalidad!). De violarse este supuesto el valor de <span class="math inline">\(\alpha_v\)</span> (verdadero) para la prueba puede ser mayor o menor al definido por nosotros (<span class="math inline">\(\alpha_n\)</span>, nominal). De manera particular, si la distribución de la variable analizada presenta una curtosis negativa el <span class="math inline">\(\alpha_v\)</span> será menor al nominal, mientras que con una curtosis positiva será el caso contrario. Esto lleva a que hagamos una prueba más o menos estricta de lo que habíamos planeado originalmente y que nuestros resultados no sean confiables. De cualquier manera, veamos cómo aplicarla:</p>
<pre class="r"><code>bartlett.test(y~grupo, data = anov_sim)</code></pre>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  y by grupo
## Bartlett&#39;s K-squared = 0.4309, df = 1, p-value = 0.5115</code></pre>
<p>En este caso, no podemos ridiculizar nuestra hipótesis de nulidad, por lo que podemos concluir que las varianzas entre nuestros grupos son homogéneas (y deben serlo, pues así las especificamos).</p>
</div>
<div id="prueba-de-levene" class="section level4">
<h4>Prueba de Levene</h4>
<p>Es la alternativa recomendada por muchos a la prueba de Bartlett. Aunque no es tan poderosa, sí es robusta a las violaciones al supuesto de normalidad, de modo que el <span class="math inline">\(\alpha\)</span> verdadero es muy similar al nominal para una gran cantidad de distribuciones, aunque es insensible a distribuciones simétricas con colas altas como la t de Student o doble exponencial (también conocida como distribución de Laplace). Aplicarla también es sumamente sencillo:</p>
<pre class="r"><code>car::leveneTest(y~grupo, data = anov_sim)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Df"],"name":[1],"type":["int"],"align":["right"]},{"label":["F value"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Pr(>F)"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"1.109031","3":"0.2924199","_rn_":"group"},{"1":"1998","2":"NA","3":"NA","_rn_":""}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Como era de esperarse, el resultado es consistente con la prueba de Bartlett para este caso.</p>
</div>
</div>
<div id="anova-de-una-sola-vía" class="section level3">
<h3>ANOVA de una sola vía</h3>
<p>Habiendo revisado los conceptos básicos detrás del ANOVA, podemos pasar a aplicar algunos modelos. El más sencillo es el ANOVA de una sola vía, el cual es el caso más sencillo; es decir, comparamos una sola variable numérica entre los niveles de un solo factor (pesos finales para tres alimentos distintos, por ejemplo). Para ejemplificarlo utilizaremos la base <code>datos1</code> que se trabajó para la tarea de Intervalos de confianza, con una columna extra: id, el cual es un identificador para cada individuo. Esta columna fue añadida únicamente para ejemplificar un caso de ANOVA posterior. En este ejemplo, compararemos los pesos totales entre los tres periodos (OJO: este es un diseño para un ANOVA factorial, únicamente lo utilizaremos como ejemplo).</p>
<p>El primer paso es, evidentemente, cargar la base de datos:</p>
<pre class="r"><code>df &lt;- read.table(&quot;data/Datos1.csv&quot;, header = F, skip = 1, sep = &quot;,&quot;)
colnames(df) &lt;- c(&quot;Dieta&quot;, &quot;Periodo&quot;, &quot;Rep&quot;, &quot;LT&quot;, &quot;PT&quot;, &quot;id&quot;)
df$Periodo &lt;- factor(df$Periodo, levels = c(&quot;I&quot;, &quot;M&quot;, &quot;F&quot;))
head(df)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Dieta"],"name":[1],"type":["chr"],"align":["left"]},{"label":["Periodo"],"name":[2],"type":["fct"],"align":["left"]},{"label":["Rep"],"name":[3],"type":["chr"],"align":["left"]},{"label":["LT"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["PT"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["id"],"name":[6],"type":["int"],"align":["right"]}],"data":[{"1":"A","2":"I","3":"A","4":"0.883","5":"0.50","6":"1","_rn_":"1"},{"1":"A","2":"I","3":"A","4":"0.909","5":"0.52","6":"2","_rn_":"2"},{"1":"A","2":"I","3":"A","4":"1.018","5":"0.58","6":"3","_rn_":"3"},{"1":"A","2":"I","3":"A","4":"0.909","5":"0.52","6":"4","_rn_":"4"},{"1":"A","2":"I","3":"A","4":"1.200","5":"0.68","6":"5","_rn_":"5"},{"1":"A","2":"I","3":"A","4":"0.891","5":"0.51","6":"6","_rn_":"6"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<div id="comprobación-de-supuestos" class="section level4">
<h4>Comprobación de supuestos</h4>
<p>El segundo paso es la comprobación de supuestos. Primero el de Normalidad:</p>
<pre class="r"><code>#Normalidad
## Data.frame a llenar
norm &lt;- data.frame(grupo = NA, W = NA, p = NA)

## Niveles a probar:
lvls &lt;- levels(df$Periodo)

for (i in seq_along(lvls)) {
  temp &lt;- shapiro.test(df$PT[df$Periodo == lvls[i]])
  norm[i,] &lt;- c(lvls[i], temp$statistic, temp$p.value)
}
norm</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["grupo"],"name":[1],"type":["chr"],"align":["left"]},{"label":["W"],"name":[2],"type":["chr"],"align":["left"]},{"label":["p"],"name":[3],"type":["chr"],"align":["left"]}],"data":[{"1":"I","2":"0.982542554966552","3":"0.54497164092451","_rn_":"1"},{"1":"M","2":"0.969626501609841","3":"0.203731304462396","_rn_":"2"},{"1":"F","2":"0.979597150613742","3":"0.589565206853954","_rn_":"3"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>La prueba de S-W sugiere que no hay desviaciones significativas de la normalidad. Corroboremos con un gráfico de violín. Al parecer, los resultados son coherentes con la distribución de los datos.</p>
<pre class="r"><code>ggplot(data = df, aes(x = Periodo, y = PT, fill = Periodo)) +
  geom_violin(alpha = 0.5, show.legend = F) +
  labs(title = &quot;Distribución de PT en los tres momentos de medición&quot;,
       x = element_blank(),
       y = element_blank()) +
  theme_bw()</code></pre>
<pre><code>## Warning: Removed 22 rows containing non-finite values (stat_ydensity).</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>Ahora el supuesto de igualdad de varianzas, utilizando la prueba de Levene. Podemos concluir que las varianzas no son homogéneas, por lo que la recomendación sería recurrir a una prueba no paramétrica; sin embargo, sigamos con el ejercicio y escalando la complejidad del análisis antes de saltar apresuradamente a conclusiones.</p>
<pre class="r"><code>car::leveneTest(PT~Periodo, data = df)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Df"],"name":[1],"type":["int"],"align":["right"]},{"label":["F value"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Pr(>F)"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"2","2":"14.53569","3":"1.637836e-06","_rn_":"group"},{"1":"155","2":"NA","3":"NA","_rn_":""}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
<div id="aplicación-del-anova" class="section level4">
<h4>Aplicación del ANOVA</h4>
<p>El siguiente paso es aplicar el ANOVA. El valor de p es bastante bajo, lo cual ridiculiza nuestra hipótesis de nulidad y concluimos que al menos un par de medias son significativamente diferentes entre sí (F(2, 155) = 574.3; p &lt; 0.0001).</p>
<pre class="r"><code>una_via &lt;- aov(PT~Periodo, data = df)
summary(una_via)</code></pre>
<pre><code>##              Df Sum Sq Mean Sq F value Pr(&gt;F)    
## Periodo       2 10.600   5.300   574.3 &lt;2e-16 ***
## Residuals   155  1.431   0.009                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 22 observations deleted due to missingness</code></pre>
</div>
<div id="prueba-post-hoc" class="section level4">
<h4>Prueba post-hoc</h4>
<p>El último paso es aplicar la prueba post-hoc. Esta prueba se construye a partir de la distribución de rangos estudentizados, y fue diseñada para evitar el conflicto entre el <span class="math inline">\(\alpha\)</span> y el número de comparaciones, por lo que la interpretación del valor de p es directa. En este caso, el valor de p fue muy pequeño para las tres comparaciones, por lo que rechazamos nuestra hipótesis de nulidad en los tres casos. El resto de la tabla es también informativo, pues nos indica la magnitud de las diferencias y sus intervalos de confianza (tal y como en la prueba t de Student):</p>
<pre class="r"><code>TukeyHSD(una_via)</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = PT ~ Periodo, data = df)
## 
## $Periodo
##          diff       lwr       upr p adj
## M-I 0.2949615 0.2518882 0.3380349     0
## F-I 0.6376957 0.5931429 0.6822484     0
## F-M 0.3427341 0.2967181 0.3887501     0</code></pre>
<p>Con esos 4 pasos terminamos nuestro ANOVA de una vía. Pasemos entonces al ANOVA de dos vías.</p>
</div>
</div>
<div id="anova-de-dos-vías" class="section level3">
<h3>ANOVA de dos vías</h3>
<p>Si una vía es a un factor, dos vías es a dos factores. En este análisis compararemos el efecto de ambos factores simultáneamente, pero de manera independiente; es decir, aunque se hará la comparación para ambos, no se considerará la interacción entre ellos. Nuestro segundo factor será la Dieta. Los pasos son exactamente los mismos que en el anterior:</p>
<div id="comprobación-de-supuestos-1" class="section level4">
<h4>Comprobación de Supuestos</h4>
<p>Dado que ya comprobamos los supuestos para el factor Periodo, solo habrá que hacerlo para el factor Dieta:</p>
<pre class="r"><code>#Normalidad
df$Dieta &lt;- factor(df$Dieta, levels = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;))
## Data.frame a llenar
norm &lt;- data.frame(grupo = NA, W = NA, p = NA)

## Niveles a probar:
lvls &lt;- levels(df$Dieta)

for (i in seq_along(lvls)) {
  temp &lt;- shapiro.test(df$PT[df$Dieta == lvls[i]])
  norm[i,] &lt;- c(lvls[i], temp$statistic, temp$p.value)
}
norm</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["grupo"],"name":[1],"type":["chr"],"align":["left"]},{"label":["W"],"name":[2],"type":["chr"],"align":["left"]},{"label":["p"],"name":[3],"type":["chr"],"align":["left"]}],"data":[{"1":"A","2":"0.924872954092129","3":"0.00149640934002103","_rn_":"1"},{"1":"B","2":"0.959693445283575","3":"0.058721841724151","_rn_":"2"},{"1":"C","2":"0.928647969386013","3":"0.00937090708077498","_rn_":"3"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Debido a que el factor dieta incluye el efecto del periodo de medición y detectamos diferencias entre ellos, es esperable que no se cumpla el supuesto de normalidad. En este caso, el diseño sería mejor analizado utilizando un ANOVA factorial que uno de dos vías pero, al igual que en el caso anterior, seguiremos únicamente para fines ilustrativos.</p>
<p>Para la homogeneidad de varianzas la interpretación es la misma, aunque la consecuencia es la contraria. No violamos el supuesto de homogeneidad de varianzas debido a que tampoco se violó entre los periodos. Esto da un poco más de respaldo a seguir con el análisis, pues es más robusto a la violación del supuesto de normalidad que al de homogeneidad de varianzas.</p>
<pre class="r"><code>car::leveneTest(PT~Dieta, data = df)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Df"],"name":[1],"type":["int"],"align":["right"]},{"label":["F value"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Pr(>F)"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"2","2":"1.016406","3":"0.3642923","_rn_":"group"},{"1":"155","2":"NA","3":"NA","_rn_":""}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
<div id="aplicación-del-anova." class="section level4">
<h4>Aplicación del ANOVA.</h4>
<p>El ANOVA de dos vías es un caso especial del ANOVA factorial, en el cuál únicamente hay dos factores y NO se considera su interacción, por lo que el modo de declararlo es una fórmula en la cuál los factores se consideran de manera aditiva. La forma tradicional de reportar los resultados de este ANOVA sería: hubo un efecto significativo de las dietas (F(2, 153) = 11.45; p &lt; 0.0001) y de los periodos (F(2, 153) = 560.42; p &lt; 0.0001).</p>
<pre class="r"><code>dos_vias &lt;- aov(PT~Dieta+Periodo, data = df)
summary(dos_vias)</code></pre>
<pre><code>##              Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Dieta         2  0.212   0.106   11.45 2.33e-05 ***
## Periodo       2 10.399   5.199  560.42  &lt; 2e-16 ***
## Residuals   153  1.419   0.009                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 22 observations deleted due to missingness</code></pre>
</div>
<div id="prueba-post-hoc." class="section level4">
<h4>Prueba post-hoc.</h4>
<p>En este caso tuvimos valores de p muy pequeños para ambos factores, realicemos la prueba HSD de Tukey. Al ver la salida puedes interpretar que esta es una lista, y que podríamos acceder a los resultados de cualquier factor utilizando el operador <code>$</code> (<code>TukeyHSD(aov_obj)$factor</code>). Aquí, las diferencias se encontraron entre la dieta C y las otras dos, pero no entre A y B.</p>
<pre class="r"><code>TukeyHSD(dos_vias)</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = PT ~ Dieta + Periodo, data = df)
## 
## $Dieta
##            diff         lwr         upr     p adj
## B-A -0.02402094 -0.06672932  0.01868745 0.3801380
## C-A -0.09036834 -0.13594353 -0.04479315 0.0000176
## C-B -0.06634740 -0.11227232 -0.02042249 0.0023101
## 
## $Periodo
##          diff       lwr       upr p adj
## M-I 0.2912145 0.2480228 0.3344062     0
## F-I 0.6266462 0.5819709 0.6713214     0
## F-M 0.3354316 0.2892891 0.3815741     0</code></pre>
<p>Considerando el diseño factorial de la base de datos, ¿cómo interpretarías estos resultados? ¿podemos confiar en ellos? La respuesta que yo esperaría es que no, pues si el experimento fue bien diseñado al inicio todos los animales debían tener aproximadamente las mismas características y vimos tanto gráficamente como en ambos ANOVAs que hubo un crecimiento. Veamos qué pasa con las distribuciones utilizando un gráfico de interacción.</p>
<pre class="r"><code>ggplot(data = df, aes(x = Dieta, y = PT, fill = Periodo)) +
  geom_violin(alpha = 0.5, show.legend = T) +
  labs(title = &quot;Distribución de PT en los tres momentos de medición&quot;,
       x = element_blank(),
       y = element_blank()) +
  theme_bw()</code></pre>
<pre><code>## Warning: Removed 22 rows containing non-finite values (stat_ydensity).</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<p>Es evidente que en los tres tratamientos hubo un crecimiento, el cual además parece haber sido bastante similar. Este es un ejemplo del error de tipo III que mencionaba en la clase de pruebas de hipótesis: utilizar la matemática correcta para responder la pregunta equivocada. Veamos qué pasa si realizamos un ANOVA factorial.</p>
</div>
</div>
<div id="anova-factorial" class="section level3">
<h3>ANOVA factorial</h3>
<p>Como te podrás imaginar a partir de lo mencionado sobre el ANOVA de dos vías, este ANOVA es la versión más generalizada en la cual podemos utilzar más de dos factores y además analizar su interacción. Sigamos con la base anterior, en este caso considerando también el factor réplica:</p>
<pre class="r"><code>df$Rep &lt;- factor(df$Rep, levels = c(&quot;A&quot;, &quot;B&quot;))</code></pre>
<div id="comprobación-de-supuestos-2" class="section level4">
<h4>Comprobación de supuestos</h4>
<p>No hay sorpresas en ninguno de los dos casos, las interpretaciones de los resultados son las mismas que en el caso anterior; es decir, este NO es el modo correcto de comprobar la normalidad. Cuando hablemos del ANOVA de medidas repetidas veremos un ejemplo de cómo hacerlo de manera correcta (normalidad de un factor dados los niveles del otro factor).</p>
<pre class="r"><code>## Data.frame a llenar
norm &lt;- data.frame(grupo = NA, W = NA, p = NA)

## Niveles a probar:
lvls &lt;- levels(df$Rep)

for (i in seq_along(lvls)) {
  temp &lt;- shapiro.test(df$PT[df$Rep == lvls[i]])
  norm[i,] &lt;- c(lvls[i], temp$statistic, temp$p.value)
}
norm</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["grupo"],"name":[1],"type":["chr"],"align":["left"]},{"label":["W"],"name":[2],"type":["chr"],"align":["left"]},{"label":["p"],"name":[3],"type":["chr"],"align":["left"]}],"data":[{"1":"A","2":"0.941613188003489","3":"0.0012766184500003","_rn_":"1"},{"1":"B","2":"0.931198033759898","3":"0.000367262220957672","_rn_":"2"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>car::leveneTest(PT~Rep, data = df)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Df"],"name":[1],"type":["int"],"align":["right"]},{"label":["F value"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Pr(>F)"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"0.1280073","3":"0.7209908","_rn_":"group"},{"1":"156","2":"NA","3":"NA","_rn_":""}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
<div id="aplicación-del-anova-1" class="section level4">
<h4>Aplicación del ANOVA</h4>
<p>La única diferencia con el caso anterior es que esta vez utilizaremos el operador <code>*</code> para añadir los nuevos términos, en vez de hacerlo de forma aditiva. Haciendo esto la tabla del ANOVA cambia, en donde primero aparece el efecto de cada factor analizado de manera independiete (como si hubieramos hecho un ANOVA de “tres vías”) y después los términos de interacción. La interacción entre dos factores representa un efecto combinado de los factores involucrados en la variable analizada; es decir, cuando hay interacción entre dos factores el efecto de uno “depende” del el nivel del otro.</p>
<pre class="r"><code>fact &lt;- aov(PT~Dieta*Periodo*Rep, data = df)
summary(fact)</code></pre>
<pre><code>##                    Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Dieta               2  0.212   0.106  12.185 1.32e-05 ***
## Periodo             2 10.399   5.199 596.509  &lt; 2e-16 ***
## Rep                 1  0.060   0.060   6.874  0.00971 ** 
## Dieta:Periodo       4  0.053   0.013   1.522  0.19912    
## Dieta:Rep           2  0.001   0.000   0.038  0.96240    
## Periodo:Rep         2  0.048   0.024   2.755  0.06703 .  
## Dieta:Periodo:Rep   4  0.038   0.009   1.076  0.37066    
## Residuals         140  1.220   0.009                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 22 observations deleted due to missingness</code></pre>
</div>
<div id="prueba-post-hoc-1" class="section level4">
<h4>Prueba post-hoc</h4>
<p>En este caso el único término de interacción con resultados significativos es la interacción entre Periodo y Réplica (<code>Periodo:Rep</code>), lo cual indica que el comportamiento de los periodos fue diferente entre réplicas. Realicemos las pruebas post-hoc correspondientes. Aunque encontramos un efecto significativo de las réplicas, este factor únicamente tiene dos niveles, por lo que realizar la prueba post-hoc es ocioso y, por tanto, la realizaremos únicamente para Periodo:Rep. Nota que debido a la presencia del operador <code>:</code> en el nombre del término es necesario utilizar comillas para poder acceder a ese atributo:</p>
<pre class="r"><code>TukeyHSD(fact)$&quot;Periodo:Rep&quot;</code></pre>
<pre><code>##                diff         lwr         upr        p adj
## M:A-I:A  0.28301798  0.20959477  0.35644118 4.152234e-14
## F:A-I:A  0.66044327  0.58556599  0.73532054 1.265654e-14
## I:B-I:A -0.02480111 -0.09480740  0.04520517 9.092990e-01
## M:B-I:A  0.27169429  0.19681702  0.34657157 6.084022e-14
## F:B-I:A  0.55653205  0.47803934  0.63502476 1.265654e-14
## F:A-M:A  0.37742529  0.30254802  0.45230257 1.265654e-14
## I:B-M:A -0.30781909 -0.37782537 -0.23781281 1.376677e-14
## M:B-M:A -0.01132368 -0.08620096  0.06355359 9.979453e-01
## F:B-M:A  0.27351408  0.19502137  0.35200679 6.727952e-14
## I:B-F:A -0.68524438 -0.75677422 -0.61371454 1.265654e-14
## M:B-F:A -0.38874898 -0.46505261 -0.31244534 1.265654e-14
## F:B-F:A -0.10391121 -0.18376573 -0.02405669 3.335386e-03
## M:B-I:B  0.29649541  0.22496556  0.36802525 1.909584e-14
## F:B-I:B  0.58133317  0.50602701  0.65663933 1.265654e-14
## F:B-M:B  0.28483776  0.20498324  0.36469228 6.306067e-14</code></pre>
<p>Vemos que prácticamente todos los contrastes fueron significativos, con excepción del periodo inicial (p = 0.9). Esto sugeriría que el comportamiento de las réplicas no fue homogéneo a través del tiempo. Si regresamos brevemente a la tabla del ANOVA veremos que hubo 22 observaciones faltantes, las cuales corresponden a la mortalidad durante el experimento y podrían también explicar estos cambios. Debido a la impraciticidad/imposibilidad de marcar o identificar cada guppy no es posible aplicar un anova de medidas repetidas con estos datos; sin embargo, podemos ejemplificarlo con otros datos.</p>
</div>
</div>
<div id="anova-de-medidas-repetidas" class="section level3">
<h3>ANOVA de medidas repetidas</h3>
<p>El ANOVA de medidas repetidas es otro de los modelos de ANOVA, el cual podemos considerar como una extensión de la prueba t para muestras dependientes; es decir, en la cual los mismos individuos fueron medidos en más de dos ocasiones, denominado ANOVA de medidas repetidas de una vía. Si tenemos no solo los distintos tiempos de medición sino también factores adicionales entonces tendremos ANOVAs de medidas repetidas de dos vías (tiempo y un factor adicional) o de tres vías (tiempo y dos factores adicionales). Al igual que en el ANOVA “normal” comencemos desde abajo con el de una vía.</p>
<div id="anova-de-medidas-repetidas-de-una-vía" class="section level4">
<h4>ANOVA de medidas repetidas de una vía</h4>
<p>Carguemos los datos de ejemplo (selfesteem de la librería datarium), los cuales son una medida de autoestima medida en tres ocasiones distintas:</p>
<pre class="r"><code>data(&quot;selfesteem&quot;, package = &quot;datarium&quot;)
head(selfesteem)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["id"],"name":[1],"type":["int"],"align":["right"]},{"label":["t1"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["t2"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["t3"],"name":[4],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"4.005027","3":"5.182286","4":"7.107831"},{"1":"2","2":"2.558124","3":"6.912915","4":"6.308434"},{"1":"3","2":"3.244241","3":"4.443434","4":"9.778410"},{"1":"4","2":"3.419538","3":"4.711696","4":"8.347124"},{"1":"5","2":"2.871243","3":"3.908429","4":"6.457287"},{"1":"6","2":"2.045868","3":"5.340549","4":"6.653224"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>La base se encuentra en formato corto, por lo que habrá que pasarla a formato largo:</p>
<pre class="r"><code>estima &lt;- reshape2::melt(selfesteem, # Datos a modificar
                         id.vars = &quot;id&quot;, # Identificador para cada individuo
                         measure.vars = c(&quot;t1&quot;, &quot;t2&quot;, &quot;t3&quot;), # Variables en columnas
                         variable.name = &quot;tiempo&quot;, # Nombre de la nueva variable de agrupamiento
                         value.name = &quot;estima&quot;) # Nombre de la nueva variable medida
head(estima)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["id"],"name":[1],"type":["int"],"align":["right"]},{"label":["tiempo"],"name":[2],"type":["fct"],"align":["left"]},{"label":["estima"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"t1","3":"4.005027","_rn_":"1"},{"1":"2","2":"t1","3":"2.558124","_rn_":"2"},{"1":"3","2":"t1","3":"3.244241","_rn_":"3"},{"1":"4","2":"t1","3":"3.419538","_rn_":"4"},{"1":"5","2":"t1","3":"2.871243","_rn_":"5"},{"1":"6","2":"t1","3":"2.045868","_rn_":"6"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<div id="comprobación-de-supuestos-3" class="section level5">
<h5>Comprobación de supuestos</h5>
<p>Para agilizar las cosas (y un poco a mi pesar), utilicemos <code>dplyr</code> para aplicar la prueba de normalidad a los niveles de Periodo. <code>Tidyverse</code> es algo así como un dialecto dentro de R, compuesto de múltiples librerías, en donde el código se puede encadenar para hacerlo más compacto y, según algunos, más legible. “A mi pesar” porque no considero buena práctica didáctica enseñarlo a quienes van comenzando a adquirir experiencia, pues añade un paso más de abstracción al proceso. Habiendo dicho esto, el encadenamiento lo indicamos con el operador <code>%&gt;%</code> (pipe), y lo que hacemos es que lo que está a la izquierda se lo pasamos como argumento a lo que está a la derecha. Esto te sonará familiar a la forma de construir gráficos en <code>ggplot2</code> y con justa razón, pues también forma parte del <code>Tidiverse</code>. Como último comentario al respecto, las funciones de las distintas librerías de <code>Tidiverse</code> pueden utilizarse con la sintaxis de R “normal” y viceversa, las funciones de R “normal” pueden utilizarse con el operador de encadenamiento. Con esto quiero decir que no es necesario utilizar únicamente una u otra opción, sino que podemos aplicarlas a nuestra conveniencia (esa es la idea de escribir nuestro código ;)) Apliquemos entonces la prueba de Shapiro-Wilk a los datos agrupados:</p>
<pre class="r"><code># Toma el data.frame, agrúpalo por tiempo y para cada nivel aplica la función shapiro_test a la columna estima:
estima %&gt;% group_by(tiempo) %&gt;% shapiro_test(estima)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["tiempo"],"name":[1],"type":["fct"],"align":["left"]},{"label":["variable"],"name":[2],"type":["chr"],"align":["left"]},{"label":["statistic"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["p"],"name":[4],"type":["dbl"],"align":["right"]}],"data":[{"1":"t1","2":"estima","3":"0.9666901","4":"0.8585757"},{"1":"t2","2":"estima","3":"0.8758846","4":"0.1169956"},{"1":"t3","2":"estima","3":"0.9227150","4":"0.3801563"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Ahora la homocedasticidad o, mejor dicho, el supuesto de esfericidad. Este supuesto es una “extensión” del supuesto de homogeneidad de varianzas. Definimos esfericidad como la condición en la que las varianzas de las <strong>diferencias</strong> entre todas las combinaciones de los niveles de interés son iguales. La violación de este supuesto conlleva un incremento en la probabilidad de un falso positivo; es decir, vuelve a la prueba demasiado “liberal” o “crédula”. Aunque este supuesto es sumamente importante, no necesitamos probarlo directamente, pues la función con la que implementaremos el análisis hace la prueba correspondiente (prueba de Mauchly para esfericidad) y, además, aplica una corrección (corrección de Greenhouse-Geisser) a los grados de libertad de aquellos factores que violen el supuesto.</p>
</div>
<div id="aplicación-del-anova-2" class="section level5">
<h5>Aplicación del ANOVA</h5>
<p>Esta vez no utilizaremos la notación de fórmula ni tan siquiera la función aov, sino que recurriremos a la función <code>anova_test()</code> de la librería <code>rstatix</code> para hacer más intuitiva la declaración, donde <code>data</code> es el data.frame con los datos (dah!), <code>dv</code> es la variable dependiente; es decir, nuestra variable a comparar, <code>wid</code> es un identificador único para cada individuo y <code>within</code> el factor dentro del cual queremos hacer las comparaciones:</p>
<pre class="r"><code>anova_rep1 &lt;- rstatix::anova_test(data = estima, dv = estima, wid = id, within = tiempo)
get_anova_table(anova_rep1)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Effect"],"name":[1],"type":["chr"],"align":["left"]},{"label":["DFn"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["DFd"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["F"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["p<.05"],"name":[6],"type":["chr"],"align":["left"]},{"label":["ges"],"name":[7],"type":["dbl"],"align":["right"]}],"data":[{"1":"tiempo","2":"2","3":"18","4":"55.469","5":"2.01e-08","6":"*","7":"0.829","_rn_":"1"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Lo primero que llama la atención es que la tabla de ANOVA reporta resultados para una prueba de tipo III. OJO! esto no tiene nada que ver con el error tipo III que mencioné en la clase de pruebas de hipótesis (ese error no es formal). El tipo de prueba hace referencia al tipo de ANOVA que se está realizando o, mejor dicho, al modo en el que se calculan las sumas de cuadrados. Si te interesa leer más al respecto, visita <a href="https://www.ibm.com/support/knowledgecenter/SSLVMB_24.0.0/spss/com%20mon/glm_general_factorial_sum_of_squares.html">este</a> o <a href="http://www.statsoft.com/textbook/">este</a> enlace.</p>
<p>Otra cosa que debe llamar tu atención es el término ges. Este es el factor de corrección de Greenhouse-Geisser a los grados de libertad. El modo de reportar estos resultados sería algo como <em>“las medidas de autoestima a través del tiempo fueron significativamente diferentes (F(2,18) = 55.5, p &lt; 0.0001; <span class="math inline">\(\eta^2\)</span> generalizado = 0.82)”</em>. El término <span class="math inline">\(\eta^2\)</span> generalizado lo puedes encontrar también como <span class="math inline">\(\hat{\epsilon}\)</span>.</p>
</div>
<div id="prueba-post-hoc-2" class="section level5">
<h5>Prueba post-hoc</h5>
<p>Debido a que las medidas son repetidas, no podemos aplicar la prueba de diferencias honestas de Tukey, pero sí podemos aplicar pruebas t de Student pareadas y corregir el valor de p con una corrección de Bonferroni. En la sección de multivariado se abordará esta corrección, pero entiéndela en este momento como el modo de evitar que incrementemos la probabilidad de un falso positivo y, en consecuencia, deberemos de interpretar los valores de la columna p.adj. Viendo la tabla, es posible concluir que hubo diferencias entre las medidas de autoestima en los tres periodos.</p>
<pre class="r"><code>pwt &lt;- pairwise_t_test(data = estima, estima~tiempo, paired = T, p.adjust.method = &quot;bonferroni&quot;)
pwt</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":[".y."],"name":[1],"type":["chr"],"align":["left"]},{"label":["group1"],"name":[2],"type":["chr"],"align":["left"]},{"label":["group2"],"name":[3],"type":["chr"],"align":["left"]},{"label":["n1"],"name":[4],"type":["int"],"align":["right"]},{"label":["n2"],"name":[5],"type":["int"],"align":["right"]},{"label":["statistic"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["df"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["p"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["p.adj"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["p.adj.signif"],"name":[10],"type":["chr"],"align":["left"]}],"data":[{"1":"estima","2":"t1","3":"t2","4":"10","5":"10","6":"-4.967618","7":"9","8":"7.72e-04","9":"2e-03","10":"**","_rn_":"1"},{"1":"estima","2":"t1","3":"t3","4":"10","5":"10","6":"-13.228148","7":"9","8":"3.34e-07","9":"1e-06","10":"****","_rn_":"2"},{"1":"estima","2":"t2","3":"t3","4":"10","5":"10","6":"-4.867816","7":"9","8":"8.86e-04","9":"3e-03","10":"**","_rn_":"3"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<div id="anova-de-medidas-repetidas-de-dos-vías" class="section level4">
<h4>ANOVA de medidas repetidas de dos vías</h4>
<p>Al igual que en el ANOVA “normal”, hablamos de dos vías cuando tenemos dos factores, en este caso son el tiempo y alguno adicional. Para ejemplificarlo utilizaremos la base de datos <code>selfesteem2</code> de <code>datarium</code>.</p>
<pre class="r"><code>data(&quot;selfesteem2&quot;, package = &quot;datarium&quot;)
estima2 &lt;- reshape2::melt(selfesteem2, # Datos a modificar
                         id.vars = c(&quot;id&quot;, &quot;treatment&quot;), # Identificadores para cada individuo
                         measure.vars = c(&quot;t1&quot;, &quot;t2&quot;, &quot;t3&quot;), # Variables en columnas
                         variable.name = &quot;tiempo&quot;, # Nombre de la nueva variable de agrupamiento
                         value.name = &quot;estima&quot;) # Nombre de la nueva variable medida
head(estima2)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["id"],"name":[1],"type":["fct"],"align":["left"]},{"label":["treatment"],"name":[2],"type":["fct"],"align":["left"]},{"label":["tiempo"],"name":[3],"type":["fct"],"align":["left"]},{"label":["estima"],"name":[4],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"ctr","3":"t1","4":"83","_rn_":"1"},{"1":"2","2":"ctr","3":"t1","4":"97","_rn_":"2"},{"1":"3","2":"ctr","3":"t1","4":"93","_rn_":"3"},{"1":"4","2":"ctr","3":"t1","4":"92","_rn_":"4"},{"1":"5","2":"ctr","3":"t1","4":"77","_rn_":"5"},{"1":"6","2":"ctr","3":"t1","4":"72","_rn_":"6"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<div id="comprobación-de-supuestos-4" class="section level5">
<h5>Comprobación de supuestos</h5>
<p>Al igual que en el ANOVA de medidas repetidas, únicamente comprobaremos el Supuesto de Normalidad, solo que aquí lo haremos considerando la “anidación” de los factores; es decir, que las medidas repetidas fueron para cada tratamiento:</p>
<pre class="r"><code>estima2 %&gt;% group_by(treatment, tiempo) %&gt;% shapiro_test(estima)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["treatment"],"name":[1],"type":["fct"],"align":["left"]},{"label":["tiempo"],"name":[2],"type":["fct"],"align":["left"]},{"label":["variable"],"name":[3],"type":["chr"],"align":["left"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"ctr","2":"t1","3":"estima","4":"0.8282109","5":"0.01996624"},{"1":"ctr","2":"t2","3":"estima","4":"0.8681048","5":"0.06183503"},{"1":"ctr","2":"t3","3":"estima","4":"0.8868127","5":"0.10720878"},{"1":"Diet","2":"t1","3":"estima","4":"0.9191145","5":"0.27866459"},{"1":"Diet","2":"t2","3":"estima","4":"0.9234678","5":"0.31596236"},{"1":"Diet","2":"t3","3":"estima","4":"0.8858129","5":"0.10407920"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Aparentemente hubo desviaciones de la normalidad en el t1 para el grupo control. Podemos corroborarlo con un gráfico QQ. Aparentemente es culpa de de algunos puntos ligeramente fuera del resto de la tendencia ubicados en el centro. Recordemos que el ANOVA es robusto a ciertas violaciones de la normalidad, y en este caso no parecen ser especialmente serias. Sigamos con el análisis.</p>
<pre class="r"><code>ggpubr::ggqqplot(estima2, &quot;estima&quot;, ggtheme = theme_bw()) + facet_grid(tiempo~treatment, labeller = &quot;label_both&quot;)</code></pre>
<p><img src="c7_param_files/figure-html/unnamed-chunk-54-1.png" width="420" /></p>
</div>
<div id="aplicación-del-anova-3" class="section level5">
<h5>Aplicación del ANOVA</h5>
<p>Utilizaremos la misma estructura que en el caso anterior; la unica diferencia es que al argumento <code>within</code> le pasaremos un vector con dos factores:</p>
<pre class="r"><code>anova_rep2 &lt;- anova_test(data = estima2, dv = estima, wid = id, within = c(treatment, tiempo))
get_anova_table(anova_rep2)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Effect"],"name":[1],"type":["chr"],"align":["left"]},{"label":["DFn"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["DFd"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["F"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["p<.05"],"name":[6],"type":["chr"],"align":["left"]},{"label":["ges"],"name":[7],"type":["dbl"],"align":["right"]}],"data":[{"1":"treatment","2":"1.00","3":"11.00","4":"15.541","5":"2.00e-03","6":"*","7":"0.059","_rn_":"1"},{"1":"tiempo","2":"1.31","3":"14.37","4":"27.369","5":"5.03e-05","6":"*","7":"0.049","_rn_":"2"},{"1":"treatment:tiempo","2":"2.00","3":"22.00","4":"30.424","5":"4.63e-07","6":"*","7":"0.050","_rn_":"3"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>De la tabla podemos concluir que todos los contrastes fueron significativos, lo cual indica que hubo diferencias entre los tratamientos (F(1, 11), = 15.5; p = 0.02), entre los tiempos (F(1.31, 14.37), = 27.4; p &lt; 0.0001) y tambien un efecto combinado (F(2,22) = 30.4; p &lt; 0.0001). Debido a que los efectos principales (“solos”) no son suficientes para describir los datos, el proceso post-hoc es un poco más complicado que en el caso anterior.</p>
</div>
<div id="pruebas-post-hoc" class="section level5">
<h5>Pruebas post-hoc</h5>
<p>Debido a la significancia del término de interacción es necesario descomponerlo en:</p>
<ol style="list-style-type: lower-alpha">
<li>Efecto principal simple; es decir, un modelo de una vía de la primera variable para cada nivel de la segunda. Debido a que hacerlo a mano es un poco tedioso, encadenemos el proceso:</li>
</ol>
<pre class="r"><code>anova_rep2_post1 &lt;- estima2 %&gt;%
                    group_by(tiempo) %&gt;% # Agrupa la base por cada nivel de tiempo
                    anova_test(dv = estima, wid = id, within = treatment) %&gt;% # Aplica un ANOVA de medidas repetidas para cada nivel
                    get_anova_table() %&gt;% # Extrae los resultados
                    adjust_pvalue(method = &quot;bonferroni&quot;) # Ajusta los valores de p

anova_rep2_post1</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["tiempo"],"name":[1],"type":["fct"],"align":["left"]},{"label":["Effect"],"name":[2],"type":["chr"],"align":["left"]},{"label":["DFn"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["DFd"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["F"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["p"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["p<.05"],"name":[7],"type":["chr"],"align":["left"]},{"label":["ges"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["p.adj"],"name":[9],"type":["dbl"],"align":["right"]}],"data":[{"1":"t1","2":"treatment","3":"1","4":"11","5":"0.376","6":"0.55200","7":"","8":"0.000767","9":"1.00000"},{"1":"t2","2":"treatment","3":"1","4":"11","5":"9.026","6":"0.01200","7":"*","8":"0.052000","9":"0.03600"},{"1":"t3","2":"treatment","3":"1","4":"11","5":"30.902","6":"0.00017","7":"*","8":"0.199000","9":"0.00051"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Aplicar una prueba t de Student para datos dependientes en los términos significativos. Debido a que tratamiento tiene solo dos niveles, realizar este proceso es redundante; de hecho, los valores de p serán iguales a los mostrados atrás; sin embargo, hagámoslo con fines demostrativos:</li>
</ol>
<pre class="r"><code>pwt_2 &lt;- estima2 %&gt;%
         group_by(tiempo) %&gt;%
         pairwise_t_test(estima~treatment, paired = T, p.adjust.method = &quot;bonferroni&quot;)
pwt_2</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["tiempo"],"name":[1],"type":["fct"],"align":["left"]},{"label":[".y."],"name":[2],"type":["chr"],"align":["left"]},{"label":["group1"],"name":[3],"type":["chr"],"align":["left"]},{"label":["group2"],"name":[4],"type":["chr"],"align":["left"]},{"label":["n1"],"name":[5],"type":["int"],"align":["right"]},{"label":["n2"],"name":[6],"type":["int"],"align":["right"]},{"label":["statistic"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["df"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["p"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["p.adj"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["p.adj.signif"],"name":[11],"type":["chr"],"align":["left"]}],"data":[{"1":"t1","2":"estima","3":"ctr","4":"Diet","5":"12","6":"12","7":"0.613349","8":"11","9":"0.55200","10":"0.55200","11":"ns","_rn_":"1"},{"1":"t2","2":"estima","3":"ctr","4":"Diet","5":"12","6":"12","7":"-3.004270","8":"11","9":"0.01200","10":"0.01200","11":"*","_rn_":"2"},{"1":"t3","2":"estima","3":"ctr","4":"Diet","5":"12","6":"12","7":"-5.558933","8":"11","9":"0.00017","10":"0.00017","11":"***","_rn_":"3"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Esto es todo para la clase de hoy. Es una clase bastante extensa y aún con ello se quedaron fuera algunas variantes de ANOVA; sin embargo, creo que estos cubren los casos más generales. ¡Nos vemos en la siguiente!</p>
</div>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
