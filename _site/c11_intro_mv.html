<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Arturo Bell Enríquez García" />


<title>Análisis Multivariado: Introducción</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Bioestadística con R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Clases
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Biología como Ciencia de Datos</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c1_Intro_R.html">Introducción a R</a>
        </li>
        <li>
          <a href="c2_ggplot2.html">ggplot2</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Herramientas Básicas</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c3_probabilidad.html">Probabilidad</a>
        </li>
        <li>
          <a href="c4_muestreo.html">Teoría del Muestreo</a>
        </li>
        <li>
          <a href="c5_descriptiva.html">Estadística Descriptiva</a>
        </li>
        <li>
          <a href="c6_ph0.html">Pruebas de hipótesis</a>
        </li>
        <li>
          <a href="c7_param.html">Técnicas Paramétricas</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Relaciones Lineales</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c8_rls.html">Modelo Lineal Simple</a>
        </li>
        <li>
          <a href="c9_glm.html">Modelos Lineales Generalizados</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="c10_no_par.html">Técnicas No Paramétricas</a>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Técnicas Multivariadas</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="c11_intro_mv.html">Introducción</a>
        </li>
        <li>
          <a href="c12_no_sup.html">No supervisadas</a>
        </li>
        <li>
          <a href="c13_comps_mv.html">Comparaciones Multivariadas</a>
        </li>
        <li>
          <a href="c14_clasificacion.html">Clasificaciones</a>
        </li>
        <li>
          <a href="c15_regs_mv.html">Regresiones Múltiples</a>
        </li>
      </ul>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Análisis Multivariado: Introducción</h1>
<h4 class="author">Arturo Bell Enríquez García</h4>

</div>


<div id="matrices-de-correlación-y-covarianzas" class="section level2">
<h2>Matrices de correlación y covarianzas:</h2>
<p>Para obtenerlas utilizaremos las mismas funciones que para el cálculo individual (y por consiguiente podremos calcular también la <span class="math inline">\(\rho\)</span> de Spearman). Utilicemos como ejemplo la base de datos <code>mtcars</code>:</p>
<pre class="r"><code>head(mtcars)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["mpg"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["cyl"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["disp"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["hp"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["drat"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["wt"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["qsec"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["vs"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["am"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["gear"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["carb"],"name":[11],"type":["dbl"],"align":["right"]}],"data":[{"1":"21.0","2":"6","3":"160","4":"110","5":"3.90","6":"2.620","7":"16.46","8":"0","9":"1","10":"4","11":"4","_rn_":"Mazda RX4"},{"1":"21.0","2":"6","3":"160","4":"110","5":"3.90","6":"2.875","7":"17.02","8":"0","9":"1","10":"4","11":"4","_rn_":"Mazda RX4 Wag"},{"1":"22.8","2":"4","3":"108","4":"93","5":"3.85","6":"2.320","7":"18.61","8":"1","9":"1","10":"4","11":"1","_rn_":"Datsun 710"},{"1":"21.4","2":"6","3":"258","4":"110","5":"3.08","6":"3.215","7":"19.44","8":"1","9":"0","10":"3","11":"1","_rn_":"Hornet 4 Drive"},{"1":"18.7","2":"8","3":"360","4":"175","5":"3.15","6":"3.440","7":"17.02","8":"0","9":"0","10":"3","11":"2","_rn_":"Hornet Sportabout"},{"1":"18.1","2":"6","3":"225","4":"105","5":"2.76","6":"3.460","7":"20.22","8":"1","9":"0","10":"3","11":"1","_rn_":"Valiant"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Ahora estimemos ambas matrices:</p>
<pre class="r"><code># Matriz de covarianzas
cov.mat &lt;- cov(mtcars)

# Matriz de correlación
cor.mat &lt;- cor(mtcars)

# Las imprimimos en pantalla
cov.mat</code></pre>
<pre><code>##              mpg         cyl        disp          hp         drat          wt
## mpg    36.324103  -9.1723790  -633.09721 -320.732056   2.19506351  -5.1166847
## cyl    -9.172379   3.1895161   199.66028  101.931452  -0.66836694   1.3673710
## disp -633.097208 199.6602823 15360.79983 6721.158669 -47.06401915 107.6842040
## hp   -320.732056 101.9314516  6721.15867 4700.866935 -16.45110887  44.1926613
## drat    2.195064  -0.6683669   -47.06402  -16.451109   0.28588135  -0.3727207
## wt     -5.116685   1.3673710   107.68420   44.192661  -0.37272073   0.9573790
## qsec    4.509149  -1.8868548   -96.05168  -86.770081   0.08714073  -0.3054816
## vs      2.017137  -0.7298387   -44.37762  -24.987903   0.11864919  -0.2736613
## am      1.803931  -0.4657258   -36.56401   -8.320565   0.19015121  -0.3381048
## gear    2.135685  -0.6491935   -50.80262   -6.358871   0.27598790  -0.4210806
## carb   -5.363105   1.5201613    79.06875   83.036290  -0.07840726   0.6757903
##              qsec           vs           am        gear        carb
## mpg    4.50914919   2.01713710   1.80393145   2.1356855 -5.36310484
## cyl   -1.88685484  -0.72983871  -0.46572581  -0.6491935  1.52016129
## disp -96.05168145 -44.37762097 -36.56401210 -50.8026210 79.06875000
## hp   -86.77008065 -24.98790323  -8.32056452  -6.3588710 83.03629032
## drat   0.08714073   0.11864919   0.19015121   0.2759879 -0.07840726
## wt    -0.30548161  -0.27366129  -0.33810484  -0.4210806  0.67579032
## qsec   3.19316613   0.67056452  -0.20495968  -0.2804032 -1.89411290
## vs     0.67056452   0.25403226   0.04233871   0.0766129 -0.46370968
## am    -0.20495968   0.04233871   0.24899194   0.2923387  0.04637097
## gear  -0.28040323   0.07661290   0.29233871   0.5443548  0.32661290
## carb  -1.89411290  -0.46370968   0.04637097   0.3266129  2.60887097</code></pre>
<pre class="r"><code>cor.mat</code></pre>
<pre><code>##             mpg        cyl       disp         hp        drat         wt
## mpg   1.0000000 -0.8521620 -0.8475514 -0.7761684  0.68117191 -0.8676594
## cyl  -0.8521620  1.0000000  0.9020329  0.8324475 -0.69993811  0.7824958
## disp -0.8475514  0.9020329  1.0000000  0.7909486 -0.71021393  0.8879799
## hp   -0.7761684  0.8324475  0.7909486  1.0000000 -0.44875912  0.6587479
## drat  0.6811719 -0.6999381 -0.7102139 -0.4487591  1.00000000 -0.7124406
## wt   -0.8676594  0.7824958  0.8879799  0.6587479 -0.71244065  1.0000000
## qsec  0.4186840 -0.5912421 -0.4336979 -0.7082234  0.09120476 -0.1747159
## vs    0.6640389 -0.8108118 -0.7104159 -0.7230967  0.44027846 -0.5549157
## am    0.5998324 -0.5226070 -0.5912270 -0.2432043  0.71271113 -0.6924953
## gear  0.4802848 -0.4926866 -0.5555692 -0.1257043  0.69961013 -0.5832870
## carb -0.5509251  0.5269883  0.3949769  0.7498125 -0.09078980  0.4276059
##             qsec         vs          am       gear        carb
## mpg   0.41868403  0.6640389  0.59983243  0.4802848 -0.55092507
## cyl  -0.59124207 -0.8108118 -0.52260705 -0.4926866  0.52698829
## disp -0.43369788 -0.7104159 -0.59122704 -0.5555692  0.39497686
## hp   -0.70822339 -0.7230967 -0.24320426 -0.1257043  0.74981247
## drat  0.09120476  0.4402785  0.71271113  0.6996101 -0.09078980
## wt   -0.17471588 -0.5549157 -0.69249526 -0.5832870  0.42760594
## qsec  1.00000000  0.7445354 -0.22986086 -0.2126822 -0.65624923
## vs    0.74453544  1.0000000  0.16834512  0.2060233 -0.56960714
## am   -0.22986086  0.1683451  1.00000000  0.7940588  0.05753435
## gear -0.21268223  0.2060233  0.79405876  1.0000000  0.27407284
## carb -0.65624923 -0.5696071  0.05753435  0.2740728  1.00000000</code></pre>
<p>Veámos la matriz de correlaciones gráficamente:</p>
<pre class="r"><code>library(corrplot)</code></pre>
<pre><code>## corrplot 0.84 loaded</code></pre>
<pre class="r"><code>corrplot(cor.mat, method = &quot;ellipse&quot;, type = &quot;upper&quot;)</code></pre>
<p><img src="c11_intro_mv_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Ahora utilicemos una función que, en un solo paso, computará la matriz de correlación, realizará una prueba de significancia para cada una y además nos presentará la matriz de manera gráfica:</p>
<pre class="r"><code>source(&quot;http://www.sthda.com/upload/rquery_cormat.r&quot;) # Descarga la función desde esa url y la carga en memoria
mydata &lt;- mtcars[, c(1,3,4,5,6,7)] # Para fines prácticos se extrae un subconjunto de las columnas
rquery.cormat(mydata) # Se aplica la función</code></pre>
<p><img src="c11_intro_mv_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre><code>## $r
##         hp  disp    wt  qsec  mpg drat
## hp       1                            
## disp  0.79     1                      
## wt    0.66  0.89     1                
## qsec -0.71 -0.43 -0.17     1          
## mpg  -0.78 -0.85 -0.87  0.42    1     
## drat -0.45 -0.71 -0.71 0.091 0.68    1
## 
## $p
##           hp    disp      wt  qsec     mpg drat
## hp         0                                   
## disp 7.1e-08       0                           
## wt   4.1e-05 1.2e-11       0                   
## qsec 5.8e-06   0.013    0.34     0             
## mpg  1.8e-07 9.4e-10 1.3e-10 0.017       0     
## drat    0.01 5.3e-06 4.8e-06  0.62 1.8e-05    0
## 
## $sym
##      hp disp wt qsec mpg drat
## hp   1                       
## disp ,  1                    
## wt   ,  +    1               
## qsec ,  .       1            
## mpg  ,  +    +  .    1       
## drat .  ,    ,       ,   1   
## attr(,&quot;legend&quot;)
## [1] 0 &#39; &#39; 0.3 &#39;.&#39; 0.6 &#39;,&#39; 0.8 &#39;+&#39; 0.9 &#39;*&#39; 0.95 &#39;B&#39; 1</code></pre>
<p>Otra alternativa es utilizar la función <code>chart.Correlation(data, histogram)</code> de la librería <code>PerformanceAnalytics</code>, en la cual se muestran todos resultados en una misma gráfica:</p>
<pre class="r"><code>library(PerformanceAnalytics)</code></pre>
<pre><code>## Loading required package: xts</code></pre>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## 
## Attaching package: &#39;zoo&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<pre><code>## 
## Attaching package: &#39;PerformanceAnalytics&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:moments&#39;:
## 
##     kurtosis, skewness</code></pre>
<pre><code>## The following object is masked from &#39;package:graphics&#39;:
## 
##     legend</code></pre>
<pre class="r"><code>chart.Correlation(mydata, histogram = T, pch = 19)</code></pre>
<p><img src="c11_intro_mv_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Un comentario final al respecto de estas matrices es que, además de ser la base de las técnicas multivariadas, nos permiten evaluar la asociación entre nuestras variables sin comprometer un modelo predictivo, a la vez que nos permitirán hacer un filtrado de nuestras variables para evitar autocorrelaciones o incluir variables poco informativas, aunque de esto hablaremos más adelante.</p>
</div>
<div id="normalidad-multivariada" class="section level2">
<h2>Normalidad multivariada</h2>
<p>Para analizar si nuestros datos multivariados se ajustan a una distribución normal multivariada utilizaremos la librería <code>MVN</code>, cuya función <code>mvn(data, mvnTest, multivariatePlot)</code> nos permite realizar una serie de pruebas tanto multi como univariadas:</p>
<div id="prueba-de-mardia-1970" class="section level3">
<h3>Prueba de Mardia (1970)</h3>
<p>Consiste en analizar si los momentos de la distribución Mv de los datos difieren de los esperados de una distribución Normal Mv (<a href="http://bit.ly/mardia_test">Mardia 1970</a>), las hipótesis nulas son:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(H_0: S_{obs} = S_{NMv_{µ, \Sigma}}\)</span></li>
<li><span class="math inline">\(H_0: K_{obs} = K_{NMv_{µ, \Sigma}}\)</span></li>
</ol>
<p>Donde <span class="math inline">\(\mu\)</span> representa el vector de medias de cada variable y <span class="math inline">\(\Sigma\)</span> la matriz de covarianzas.</p>
<p>Al realizar esta prueba vemos que la distribución Mv observada tiene una curtosis adecuada, aunque se encuentra fuertemente sesgada. Si analizamos los datos univariados vemos que en apariencia 2/6 variables presentan normalidad univariada.</p>
<pre class="r"><code>library(MVN)</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;GGally&#39;:
##   method from   
##   +.gg   ggplot2</code></pre>
<pre><code>## sROC 0.1-2 loaded</code></pre>
<pre class="r"><code>mvntest &lt;- mvn(mydata, mvnTest = &quot;mardia&quot;)
mardia.test &lt;- mvntest$multivariateNormality
unitest &lt;- mvntest$univariateNormality

mardia.test</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Test"],"name":[1],"type":["chr"],"align":["left"]},{"label":["Statistic"],"name":[2],"type":["fct"],"align":["left"]},{"label":["p value"],"name":[3],"type":["fct"],"align":["left"]},{"label":["Result"],"name":[4],"type":["chr"],"align":["left"]}],"data":[{"1":"Mardia Skewness","2":"77.6519454787057","3":"0.0293424460277968","4":"NO"},{"1":"Mardia Kurtosis","2":"0.241701622075929","3":"0.80901137258975","4":"YES"},{"1":"MVN","2":"NA","3":"NA","4":"NO"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>unitest</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Test"],"name":[1],"type":["I<chr>"],"align":["right"]},{"label":["Variable"],"name":[2],"type":["I<chr>"],"align":["right"]},{"label":["Statistic"],"name":[3],"type":["I<chr>"],"align":["right"]},{"label":["p value"],"name":[4],"type":["I<chr>"],"align":["right"]},{"label":["Normality"],"name":[5],"type":["I<chr>"],"align":["right"]}],"data":[{"1":"Shapiro-Wilk","2":"mpg","3":"0.9476","4":"0.1229","5":"YES","_rn_":"1"},{"1":"Shapiro-Wilk","2":"disp","3":"0.9200","4":"0.0208","5":"NO","_rn_":"2"},{"1":"Shapiro-Wilk","2":"hp","3":"0.9334","4":"0.0488","5":"NO","_rn_":"3"},{"1":"Shapiro-Wilk","2":"drat","3":"0.9459","4":"0.1101","5":"YES","_rn_":"4"},{"1":"Shapiro-Wilk","2":"wt","3":"0.9433","4":"0.0927","5":"YES","_rn_":"5"},{"1":"Shapiro-Wilk","2":"qsec","3":"0.9733","4":"0.5935","5":"YES","_rn_":"6"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
<div id="prueba-de-henze-zirkler" class="section level3">
<h3>Prueba de Henze-Zirkler</h3>
<p>Si observamos con atención los valores de p, veremos que hay algunos que se encuentran cercanos al umbral de 0.05 por lo que un análisis a partir de los cuantiles de la distribución puede ser una alternativa más informativa. Para ello podemos utilizar la prueba de Henze-Zirkler. Esta prueba considera una hipótesis compuesta, en la cual <em>la distribución de X es una distribución normal no degenerada</em>, cuyos resultados son consistentes contra cualquier distribución alternativa no normal (por ello compuesta). La representación está dada en términos de <span class="math inline">\(L^2\)</span> (Distancia de Mahalanobis, más adelante hablaremos sobre medidas de distancia). Al ser una prueba de bondad de ajuste (observado vs. esperado), el estadístico de prueba sigue una distribución <span class="math inline">\(\chi^2\)</span> (<a href="http://bit.ly/Henze_Zirkler">Henze y Zirkler 2007</a>).</p>
<p>Aplicandola con <code>mvn()</code> vemos que también sugiere una falta de normalidad, lo cual podemos comprobar al ver el gráfico Cuantil-Cuantil</p>
<pre class="r"><code>hz.test &lt;- mvn(mydata, mvnTest = &quot;hz&quot;, multivariatePlot = &quot;qq&quot;)$multivariateNormality</code></pre>
<p><img src="c11_intro_mv_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>hz.test</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Test"],"name":[1],"type":["chr"],"align":["left"]},{"label":["HZ"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["p value"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["MVN"],"name":[4],"type":["chr"],"align":["left"]}],"data":[{"1":"Henze-Zirkler","2":"1.046162","3":"0.001459679","4":"NO"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Ese gráfico, aunque informativo, puede trabajarse para hacerse más agradable a la vista utilizando ggplot2 utilizando la siguiente función personalizada creada a partir del código utilizado para la gráfica anterior:</p>
<pre class="r"><code># Funciones personalizadas:

# Extraida de la función mvn(multivariatePlot = &quot;qq&quot;) para un gráfico QQ para normalidad multivariada utilizando la distancia de mahalanobis
ji2.plot &lt;- function(df){
  # Datos
  n &lt;- dim(mydata)[1] # número de datos
  p &lt;- dim(mydata)[2] # número de grupos
  dif &lt;- scale(mydata, scale = F) # Centramos los datos (a-µ(a)) sin escalarlos (sin dividir por su \sigma)
  d &lt;- diag(dif %*% solve(cov(mydata), tol = 1e-25) %*% t(dif)) # Cálculo de la distancia de mahalanobis^2
  r &lt;- rank(d) # Asignación de rangos a las distancias
  ji2 &lt;-  qchisq((r - 0.5)/n, p) # Obtención de los cuantiles teóricos según la distribución ji^2
  ji2.plot.data &lt;- data.frame(d, ji2) # Reunimos los objetos en un data.frame para graficar con ggplot2
  
  # Graficado
  library(ggplot2)
  ji2.qq &lt;- ggplot(data = ji2.plot.data, aes(x = d, y = ji2)) + 
            geom_point(colour = &quot;deepskyblue4&quot;, alpha = 0.5, size = 4) + 
            geom_abline(slope = 1, colour = rgb(118,78,144, maxColorValue = 255), size = 1) +
            labs(title = bquote(&quot;Gráfico QQ de&quot; ~~ {chi^2} ~~ &quot;, g.l = &quot;~ .(p)),
                 subtitle = bquote(&quot;Distancia de Mahalanobis (&quot;~{D^2}~&quot;) vs. Cuantiles teóricos&quot;),
                 x = element_blank(),
                 y = element_blank(),
                 caption = &quot;Basado en mvn(..., multivariatePlot == \&quot;qq\&quot;)&quot;
                 )

  return(ji2.qq)
}

# Tema personalizado
blank_theme &lt;- function(){
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank(),
        axis.line = element_blank(),
        aspect.ratio = 1/1.61,
        axis.ticks = element_blank(),
        text = element_text(colour = &quot;gray50&quot;), # Eliminar
        legend.position = &quot;none&quot;
        )
}</code></pre>
<pre class="r"><code>qqjiplot &lt;- ji2.plot(mydata) + blank_theme()
qqjiplot</code></pre>
<p><img src="c11_intro_mv_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="prueba-de-royston" class="section level3">
<h3>Prueba de Royston</h3>
<p>Esta prueba es una extensión multivariada de la prueba por excelencia para la normalidad univariada: la prueba de Shapiro-Wilk’s. Originalmente propuesta en 1983, aunque fue corregida/ampliada por el mismo autor en 1992 (<a href="http://bit.ly/Royston_otros">Royston vs. otras</a>). Funciona mejor para muestras pequeñas, aunque no se recomienda emplearla con menos de 3 observaciones o con más de 2000.</p>
<p>Su implementación sigue la misma línea que los casos anteriores. Si analizamos el valor de p, veremos que se encuentra en el límite de la significancia a un <span class="math inline">\(\alpha = 0.05\)</span>; sin embargo, si consideramos también el gráfico QQ que elaboramos anteriormente, no podemos asumir que esas desviaciones sean despreciables.</p>
<pre class="r"><code>royston.test &lt;- mvn(mydata, mvnTest = &quot;royston&quot;)$multivariateNormality
royston.test</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Test"],"name":[1],"type":["chr"],"align":["left"]},{"label":["H"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["p value"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["MVN"],"name":[4],"type":["chr"],"align":["left"]}],"data":[{"1":"Royston","2":"6.680718","3":"0.04965041","4":"NO"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<div id="igualdad-de-dispersiones-multivariadas" class="section level2">
<h2>Igualdad de dispersiones multivariadas</h2>
<p>Conforme vayamos avanzando en el curso veremos que, entre los supuestos de algunas pruebas, vamos a encontrar el de “igualdad de dispersiones multivariadas”; <em>i.e.</em>, igualdad de matrices de covarianza. Una alternativa es utilizar la prueba de <a href="http://bit.ly/Homo_mvdisp">Anderson (2006)</a>, la cual es un análogo multivariado a la prueba de Levene para la homogeneidad de varianzas. La prueba de hipótesis está basada en distancias no euclidianas entre los grupos (<em>i.e.</em>, no utiliza el teorema de Pitágoras :( ). Un dato curioso es que este método también se ha utilizado para evaluar la diversidad <span class="math inline">\(\beta\)</span> de una comunidad.</p>
<p>Para su implementación en R utilizaremos la función <code>betadisper</code> de la librería <code>vegan</code>. Al ser un método basado en distancias, primero habrá que transformar los datos a una matriz de distancias utilizando alguna de las funciones <code>dist</code>, <code>betadiver</code> o <code>vegdist</code>. Necesitamos, además, establecer los grupos a utilizar.</p>
<pre class="r"><code>library(vegan)</code></pre>
<pre><code>## Loading required package: permute</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## This is vegan 2.5-7</code></pre>
<pre class="r"><code>dist.mat &lt;- vegdist(mydata, method = &quot;bray&quot;, type = c(&quot;median&quot;))
groups &lt;- as.character(mtcars$cyl)
#dist.mat # Por fines prácticos no se muestra, ya que calcula una distancia entre cada par de instancias o grupos, resultando en matrices sumamente grandes</code></pre>
<p>Ahora utilizaremos la función <code>betadisper</code> para comprobar la homogeneidad de dispersiones entre los distintos cilindros. Esta prueba únicamente genera el espacio multivariado para realizar la prueba, realizando un ACP para reducir la dimensionalidad de la base de datos y estimar las distancias a la mediana de cada uno de los grupos establecidos.</p>
<pre class="r"><code>disp.mv &lt;- betadisper(dist.mat, group = groups, type = &quot;median&quot;) # Realizar el procedimiento
disp.mv</code></pre>
<pre><code>## 
##  Homogeneity of multivariate dispersions
## 
## Call: betadisper(d = dist.mat, group = groups, type = &quot;median&quot;)
## 
## No. of Positive Eigenvalues: 18
## No. of Negative Eigenvalues: 13
## 
## Average distance to median:
##       4       6       8 
## 0.09587 0.06171 0.08251 
## 
## Eigenvalues for PCoA axes:
## (Showing 8 of 31 eigenvalues)
##    PCoA1    PCoA2    PCoA3    PCoA4    PCoA5    PCoA6    PCoA7    PCoA8 
## 1.392690 0.091453 0.040689 0.037914 0.025951 0.009016 0.007642 0.004007</code></pre>
<p>Si realizamos la prueba de hipótesis vemos que, al parecer, las dispersiones multiviariadas son similares entre los 3 grupos.</p>
<pre class="r"><code>anova(disp.mv) # Prueba de hipótesis</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Df"],"name":[1],"type":["int"],"align":["right"]},{"label":["Sum Sq"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Mean Sq"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["F value"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(>F)"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"2","2":"0.00499152","3":"0.00249576","4":"1.238726","5":"0.3046332","_rn_":"Groups"},{"1":"29","2":"0.05842862","3":"0.00201478","4":"NA","5":"NA","_rn_":"Residuals"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Ahora veamos las dispersiones gráficamente:</p>
<pre class="r"><code>plot(disp.mv, ellipse = T, hull = F) # Análisis gráfico</code></pre>
<p><img src="c11_intro_mv_files/figure-html/unnamed-chunk-14-1.png" width="672" /> Al analizar el gráfico vemos que las dispersiones son similares; sin embargo, pareciera que la dispersión del grupo 6 es más pequeña que la de los grupos 4 y 8, en tonces realicemos las comparaciones pareadas univariadas con la prueba Honesta de Diferencias Significativas de Tukey (<code>TukeyHSD</code>). Los resultados sugieren que las dispersiones con un <span class="math inline">\(\alpha = 0.05\)</span> son similares, lo cual a su vez pudiera sugerir que hay un equilibrio entre las dispersiones en el eje x con respecto a las dispersiones en el eje y.</p>
<pre class="r"><code>mod.HSD &lt;- TukeyHSD(disp.mv)
mod.HSD &lt;- data.frame(mod.HSD$group, comp = dimnames(mod.HSD$group)[[1]])
mod.HSD</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["diff"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["lwr"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["upr"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["p.adj"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["comp"],"name":[5],"type":["chr"],"align":["left"]}],"data":[{"1":"-0.03415902","2":"-0.08775592","3":"0.01943787","4":"0.2727664","5":"6-4","_rn_":"6-4"},{"1":"-0.01335766","2":"-0.05802174","3":"0.03130642","4":"0.7427965","5":"8-4","_rn_":"8-4"},{"1":"0.02080137","2":"-0.03051376","3":"0.07211649","4":"0.5820846","5":"8-6","_rn_":"8-6"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Al igual que en el caso anterior podemos utilizar ggplot para personalizar el gráfico:</p>
<pre class="r"><code>hsd.plot &lt;- ggplot(data = mod.HSD, 
                   aes(x = comp)) + 
            geom_point(aes(y = diff), 
                       colour = &quot;deepskyblue4&quot;, 
                       size = 4, 
                       alpha = 0.7)+ 
            geom_errorbar(aes(ymin = lwr, ymax = upr), 
                          colour = &quot;deepskyblue4&quot;) + 
            blank_theme() + 
            labs(title = &quot;Diferencias en dispersión multivariada e IC&quot;,
                 subtitle = &quot;Prueba HSD de Tukey&quot;,
                 x = &quot;Grupos&quot;,
                 y = element_blank()) +
            scale_y_continuous(breaks = NULL) + 
            geom_hline(yintercept = 0, colour = rgb(118,78,144, maxColorValue = 255), linetype = &quot;dashed&quot;) +
            annotate(&quot;text&quot;,
                     x = 0.5, y = 0+0.005, 
                     label = as.character(0),
                     colour = rgb(118,78,144, maxColorValue = 255)
                     ) +
            geom_hline(yintercept = max(mod.HSD$upr), colour = &quot;firebrick&quot;, alpha = 0.7, linetype = &quot;dashed&quot;) +
            annotate(&quot;text&quot;,
                     x = 0.5, y = max(mod.HSD$upr)-0.005, 
                     label = as.character(round(max(mod.HSD$upr),2)),
                     colour = &quot;firebrick&quot;
                     ) +
            geom_hline(yintercept = min(mod.HSD$lwr), colour = &quot;firebrick&quot;, alpha = 0.7, linetype = &quot;dashed&quot;) +
            annotate(&quot;text&quot;,
                     x = 0.5, y = min(mod.HSD$lwr)-0.005, 
                     label = as.character(round(min(mod.HSD$lwr),2)),
                     colour = &quot;firebrick&quot;
                     ) +
            geom_text(aes(label = paste(&quot;p = &quot;, round(p.adj,2)), y = 0),
                       stat = &quot;identity&quot;,
                       nudge_y = max(mod.HSD$upr)+0.005, colour = &quot;gray50&quot;)
            
hsd.plot</code></pre>
<p><img src="c11_intro_mv_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
</div>
<div id="implicaciones-analíticas-de-la-multidimensionalidad" class="section level2">
<h2>Implicaciones analíticas de la multidimensionalidad</h2>
<p>Es importante mencionar que entre más incrementemos la dimensionalidad de nuestro problema más difícil será resumir en un solo resultado las pruebas de nuestros análisis y, en consecuencia, deberemos de considerar distintas técnicas/estrategias que analicen nuestros datos desde distintas perspectivas antes de emitir un juicio o extraer conclusiones. Por esta razón, es sumamente importante que realicemos una selección de variables de manera rigurosa antes de comenzar nuestro análisis, ya que incluir variables innecesariamente únicamente incrementará la varianza de los datos sin aportarnos ninguna información adicional, causando desviaciones de la normalidad, modelos complejos sobre o infra ajustados y pérdidas de poder estadístico.</p>
<p>En cuanto a la normalidad, hay un par de consideraciones a tener en cuenta. La primera es que si nuestro análisis está basado en la matriz de correlación estaremos cumpliendo el supuesto de normalidad de la técnica que estemos aplicando (de tenerlo), ya que, explícitamente ajustamos los datos a una distribución normal. Por otra parte, es importante mencionar que si nuestros datos en realidad no se ajustan o se encuentran fuertemente desviados de la normalidad, las conclusiones que extraigamos serán únicamente sobre la tendencia más general de nuestros datos (Revisar: desigualdad/teorema de Chebyshev) y, en consecuencia, pueden no ser una representación completa de nuestras muestras. Si esto es importante o no, dependerá de nuesta pregunta de investigación y qué tan fino querramos que sea el análisis.</p>
</div>
<div id="transformaciones-o-deformaciones" class="section level2">
<h2>Transformaciones o deformaciones</h2>
<p>Habiendo tocado el tema de la estandarización, hablemos también del resto de transformaciones. En general, podemos considerar que existen dos tipos de transformaciones: 1. Aquellas que afectan la distribución de los datos (logarítmica) 2. Aquellas que simplemente cambian los límites de la distribución original (MinMax)</p>
<p>¿Cuál utilizar? Dependerá de nuestros objetivos para hacerla, lo cual me lleva al punto de que: NINGUNA transformación debe de ser aplicada sin cuidado. Hay que tener en cuenta que aunque no se cambie la distribución de los datos, el análisis ya no se realiza sobre los datos originales, lo cual puede causar errores de interpretación. Con esto no quiero decir que las transformaciones sean malas, solo que hay que emplearlas con una justificación y asegurarnos de re-transformar los datos antes de hacer inferencias.</p>
<p>Veamos algunas de las transformaciones más comunes y cuáles son sus consecuencias en los datos. Para ello, consideremos estos datos sin transformar. Vemos que están altamente sesgados y en consecuencia bastante alejados de la normalidad:</p>
<pre class="r"><code># Función de graficado
kdeplots &lt;- function(data, aes){
  kdeplots &lt;- ggplot(data, aes) + 
            geom_density() + 
            blank_theme() +
            labs(title = &quot;Conteo de peces&quot;,
                 subtitle = &quot;Gráfico de densidad con datos y distrintas transformaciones&quot;,
                 caption = &quot;Datos: http://bit.ly/comm_transf&quot;,
                 x = element_blank(),
                 y = element_blank()) +
            scale_y_continuous(breaks = NULL)
  return(kdeplots)
}</code></pre>
<pre class="r"><code>df &lt;- data.frame(datos = c(38, 1, 13, 2, 13, 20, 150, 9, 28, 6, 4, 43), transf = &quot;originales&quot;)

kde.plots &lt;- kdeplots(df, aes(datos, color = transf))
kde.plots</code></pre>
<p><img src="c11_intro_mv_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<div id="estandarización" class="section level3">
<h3>Estandarización</h3>
<p>Veamos el efecto de estandarizar los datos; es decir, utilizar la distribución Z. El resultado es la misma distribución, aunque los datos ahora se encuentran escalados en el intervalo [-3,3] indicando a cuantas SD de la media se encuentra cada punto.</p>
<pre class="r"><code>df2 &lt;- rbind(df, data.frame(datos = (df$datos-mean(df$datos))/sd(df$datos), transf = &quot;Z&quot;))
kde.plots &lt;- kdeplots(df2, aes(datos, color = transf)) + facet_wrap(~transf, scales = &quot;free&quot;)
kde.plots</code></pre>
<p><img src="c11_intro_mv_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
</div>
<div id="transformación-logarítmica" class="section level3">
<h3>Transformación logarítmica:</h3>
<p>Posiblemente la transformación más conocida, utilizada y, en consecuencia, abusada.Se realiza aplicando la ecuación <span class="math inline">\(X_{log} = log_n(X)\)</span>. (OJO: si hay ceros será <span class="math inline">\(X_{log} = log_n(X+1)\)</span>, ya que el logaritmo de 0 no existe). Veamos qué le pasa a la distribución al aplicarla. La distribución cambió notablemente, ahora se encuentra mucho más cerca de una forma de campana. ¿Cuándo aplicarla? Cuando querramos forzar nuestros datos a una distribución normal para cumplir con los supuestos de alguna prueba paramétrica, linealizar los datos y, equivocadamente, ponerlos en la misma escala que otra variable. Con excepción del último caso, cualquiera de las formas está matemáticamente justificada, solo hay que tener en consideración que los datos no son los originales y que pueden no representar adecuadamente nuestro muestreo. Otro caso en el cual es válido utilizarlo es si queremos ver cuál es cuando tenemos distintos factores y nuestra variable de respuesta es el resultado de su interacción (producto) tal que <span class="math inline">\(Y = a \times b \times c \times d\times ... \times z\)</span> (efecto multiplicativo y no aditivo), ya que el resultado es una distribución con forma log-normal que no es posible capturar con los datos originales. Su re-transformación es <span class="math inline">\(n^{X_{log}}\)</span>. Salvo en el último caso, recomiendo contrastar los resultados con una prueba no paramétrica utilizando los datos originales y ver cuáles son las diferencias.</p>
<pre class="r"><code>df2 &lt;- rbind(df2, data.frame(datos = log(df$datos), transf = &quot;log(x)&quot;))
kde.plots &lt;- kdeplots(df2, aes(datos, color = transf)) + facet_wrap(~transf, scales = &quot;free&quot;)
kde.plots</code></pre>
<p><img src="c11_intro_mv_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
</div>
<div id="raíz-cuadrada" class="section level3">
<h3>Raíz cuadrada</h3>
<p>Otra transformación muy empleada, consiste en en obtener la raíz cuadrada de cada uno de los datos (<span class="math inline">\(\sqrt{X}\)</span>, OJO: si hay valores negativos no se puede utilizar, hay que pasarlos a valores absolutos o añadir una constante para volverlos positivos). Veamos su efecto en la distribución. En este caso el cambio en la forma no es tan agresivo, y la consecuencia es únicamente que las diferencias entre los valores más altos y los más pequeños se redujo. Su re-transformación es: <span class="math inline">\(\sqrt{x}^2\)</span>. Su uso más común es con datos de conteo (abundancias, bacterias en una caja petri, etc.)</p>
<pre class="r"><code>df2 &lt;- rbind(df2, data.frame(datos = sqrt(df$datos), transf = &quot;sqrt(x)&quot;))
kde.plots &lt;- kdeplots(df2, aes(datos, color = transf)) + facet_wrap(~transf, scales = &quot;free&quot;)
kde.plots</code></pre>
<p><img src="c11_intro_mv_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
