---
title: "Clasificación"
author: "M. en C. Arturo Bell Enríquez García"
output: 
  distill::distill_article:
    toc: true
    toc_float: true
    code_download: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(R.options = list(width = 80))
```

**[VIDEO](https://youtu.be/e0ysgJL1ldQ)**

## Funciones personalizadas
```{r}
# Tema personalizado
blank_theme <- function(aspect.ratio = 1/1.61){
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank(),
        axis.line = element_blank(),
        aspect.ratio = aspect.ratio,
        axis.ticks = element_blank(),
        text = element_text(colour = "gray50"), # Eliminar
        legend.position = "none"
        )
}
```

El objetivo de un problema de clasificación es utilizar distintas variables (características) para **predecir** la clase/etiqueta de una instancia. Todas las técnicas de clasificación son técnicas de aprendizaje automatizado; es decir, bajo la definición que dimos al inicio de esta sección, no haremos pruebas de hipótesis de nulidad *per-se*.

Revisemos entonces algunas técnicas de clasificación utilizando la misma base de datos que utilizamos en el tema de Análisis de Componentes Principales:

```{r}
library(factoextra)
library(FactoMineR)

#Base de datos completa
  
x1n <- read.table('data/Medidas.txt', header = TRUE)
#Base de datos sin nombres de especies

x1 <- x1n[ ,2:length(x1n) ]
summary(x1)
```


## División, centrado y estandarizado de datos
Al tratarse de un modelo de aprendizaje automatizado es importante que realicemos nuestra división entrenamiento/prueba para evaluar el ajuste del modelo de clasificación:

```{r}
library(caTools)
library(caret)
set.seed(1111)
sample <- sample.split(x1n$especie, SplitRatio = .75)
train <- subset(x1n, sample == TRUE)
test <- subset(x1n, sample == FALSE)
```

Centremos y estandaricemos los datos:
```{r}
pre_pars <- preProcess(train, method = c("center", "scale"))
train_t <- predict(pre_pars, train)
test_t <- predict(pre_pars, test)
```

## Análisis de Funciones Discriminantes

El primer modelo con el que trabajaremos es el Análisis de Funciones Discriminantes. En esta técnica se utilizan **combinaciones lineales** de las variables originales para predecir la clase de una instancia, de modo que se tratarán de encontrar nuevas variables que **maximicen** la separación entre clases. Para que esta técnica funcione adecuadamente es importante que las medias entre los grupos sean diferentes (podemos aplicar un MANOVA/PERMANOVA previo) y que las dispersiones multivariadas entre los grupos sean relativamente constantes (homocedasticidad multivariada). A partir de lo anterior, es fácil entender a este análisis como una mezcla entre el MANOVA y ACP.

### Ajuste del modelo

Apliquemos el Análisis Discriminante Lineal. Las probabilidades previas representan la proporción de cada grupo en la base de datos, las medias de los grupos las medias de cada grupo para cada variable, los coeficientes aprendidos por el modelo según los datos de entrenamiento y la proporción de la traza es la proporción de la varianza explicada por cada ecuación discriminante.

```{r}
lda_mod <- MASS::lda(especie~., data = train_t)
lda_mod
```

### Importancia de variables

Calculemos la correlación entre las variables originales y las dos funciones discriminantes

```{r}
adj_vals <- as.data.frame(predict(lda_mod, train_t)$x)
adj_vals["especie"] <- train_t["especie"]
corr <- cor(cbind(as.matrix(train_t[,2:32])), 
                   adj_vals[,1:2])
corr
```
```{r}
corrplot::corrplot(corr, is.corr = T)
```

Creemos un gráfico de densidad bivariado para conocer la distribución de los grupos en el nuevo espacio:

```{r}
territ_plot <- ggplot(data = adj_vals,
                      aes(x = LD1, y = LD2, colour = especie)) +
               geom_density_2d(show.legend = T, alpha = 0.5) +
               geom_point() +
               theme_bw()
territ_plot
```

### Diagnóstico del modelo de funciones discriminantes:

#### Probabilidades de pertenencia

Probabilidad de pertenencia de cada individuo a partir de los datos de prueba:

```{r}
p <- predict(lda_mod, test_t)$posterior
p.acom <- data.frame(especie = test_t$especie, id = rownames(test_t), p = p)
p.acom
```

#### Matriz de confusión

Recordemos que la matriz de confusión es una tabla de contingencia que permite obtener métricas relacionadas con proporciones de predicciones correctas. La función `confusionMatrix` de la librería `caret` da, además de las vistas en la presentación, algunas otras que pueden ser interesantes, pues minimizan el efecto de la Tasa de No Información (NIR):

  - p-value [Acc>NIR]: es el valor de p de una prueba binomial de una cola para probar que la exactitud observada es mayor que la tasa de no información; es decir, que no estamos tratando con un modelo bobo.
  - Kappa: Este es el valor del estadístico Kappa de Cohen, que es una medida de el porcentaje de las predicciones del modelo que no pueden ser explicadas adivinando al azar.
  - McNemar's test p-value: Es una prueba $\chi^2$ para la simetría de los renglones y columnas de una tabla de contingencia, de modo que la hipótesis de nulidad es que las probabilidades de ser clasificado en las celdas [i,j] y [j, i] son las mismas; es decir, que lo que está debajo de la diagonal sea igual a lo que está encima de la diagonal.

```{r}
pred.clase <- predict(lda_mod, test_t)$class
confusionMatrix(pred.clase, as.factor(test_t$especie))
```

Es importante mencionar que, por lo general, el valor AUC de la curva ROC es una medida más robusta que estas; sin embargo, habrá veces en las que nos interese que los positivos predichos sean realmente positivos, aunque tengamos falsos negativos, por ejemplo. Pensemos que nos interesa asegurarnos que los individuos clasificados como consocium realmente sean consocium. ¿Qué medida utilizarías para saber en qué proporción se da ese caso? Pista: no es ni la exactitud ni el AUC. Regresa a la presentación si es necesario.

##### Márgenes de decisión

Nos interesaremos en los márgenes de decisión de un clasificador cuando nos interesa saber cómo es que nuestro modelo está haciendo las decisiones. En este caso, mostraremos la probabilidad de pertenencia a cada clase (obtenida desde los datos de entrenamiento) como fondo de un gráfico en donde los ejes x y y serán las ecuaciones discriminantes, y le sobrepondremos los datos de prueba. Para poder hacer esto habrá que "simular" datos para nuestro fondo y formar una malla con todos ellos. Desafortunadamente, crear la malla requiere que hagamos cierta trampa. Primero, ajustaremos un modelo LDA para predecir los valores de LD1 y LD2 de cada especie:

```{r}
 # Ajustamos un LDA para "predecir" los valores de las nuevas dimensiones
prob_lda <- MASS::lda(especie ~ ., data = adj_vals)
```

Generamos una función que nos permita generar una malla utilizando esos nuevos valores y que, multiplique los valores de LDA con signo negativo por -1 para evitar una rotación de los datos:

```{r}
adjust_probs_sp <- function(mesh, probs){
  # Obtener la mayor probabilidad
  mesh["adj_probs"] <- apply(probs, 
                           1,
                           FUN = max
                           )
  # Obtener la especie a la que le corresponde
  mesh["adj_esp"] <- apply(probs,
                           1,
                           FUN = function(x){
                                 names(which.max(x))
                                 }
                           )
  return(mesh)
}

dec_bounds <- function(model, adj_vals){
  library(scales)
  # Calculamos los límites expandidos de LD1 y LD2
  ld1lim <- expand_range(c(min(adj_vals$LD1), max(adj_vals$LD1)), 
                                 mul=0.1) # + 10% hacia "abajo"
  ld2lim <- expand_range(c(min(adj_vals$LD2), max(adj_vals$LD2)), 
                                 mul=0.1) # + 10% hacia "arriba"
  
  # Generamos 300 valores nuevos de LD1 y LD2 en esos límites:
  ld1 <- seq(ld1lim[[1]], ld1lim[[2]], 
             length.out=300)
  ld2 <- seq(ld2lim[[1]], ld1lim[[2]],
             length.out=300)
  
  # Generamos un objeto con todas las combinaciones de nuevos valores
  newdat <- expand.grid(list(LD1 = ld1,
                             LD2 = ld2))
  
  # Realizamos predicciones a partir de estos valores
  preds <- predict(prob_lda, newdata = newdat)
  
  # Generamos un objeto que contendrá la "malla" con los valores de
  # LD1, LD2, adj_probs y adj_esp
  mesh <- as.data.frame(preds$x)
  
  # Probabilidad de pertenencia de los valores simulados:
  prob_sim <- as.data.frame(preds$posterior)
  
  # Probabilidades "ajustadas" para cada punto en la malla:
  
  mesh <- adjust_probs_sp(mesh, prob_sim)
  
  # Corregimos los valores del eje negativo
  axes <- diag(model$scaling)
  axis <- names(axes[axes < 0])
  mesh[,axis] <- -mesh[,axis]
  
  return(mesh)
}
```

Ahora formamos el gráfico

```{r}
# Generamos la malla
mesh <- dec_bounds(prob_lda, adj_vals)

# Graficamos las probabilidades de decisión
dec.probs <- ggplot(data = mesh, aes(x = LD1, y = LD2, color = adj_esp)) +
             geom_raster(aes(fill = adj_esp), alpha = mesh$adj_probs*0.3, show.legend = F) + 
             theme_minimal()

# Añadimos los datos de prueba al gráfico
# Valores de LDA para los datos de prueba;
# i.e., utilizar los parámetros del modelo:
mesh_test <- as.data.frame(predict(lda_mod, test_t)$x) 

# Obtener las probabilidades y especies predichas
mesh_test <- adjust_probs_sp(mesh_test,
                             predict(lda_mod, test_t)$posterior) 

# Etiqueta para saber si la instancia está correctamente clasificada
mesh_test["mark"] <- ifelse(test_t$especie == mesh_test$adj_esp,
                            test_t$especie,
                            "Mal clasificado")

# Añadimos los puntos de prueba,
# cambiando el marcador según la clase predicha por el modelo,
# y el color según la clase observada:
clas.plot <- dec.probs + 
             geom_point(data = mesh_test,
                        aes(x = LD1, y = LD2, shape = mark,
                            color = test$especie),
                        size = 2) + 
             scale_shape_discrete(name = "Clasificación") +
             scale_color_discrete(name = "Clases") +
             scale_alpha_continuous(name = "P(decisión)") +
             labs(title = "Límites de decisión del LDA",
                  subtitle = "Primeras dos funciones discriminantes",
                  x = element_blank(),
                  y = element_blank())

# Imprimimos el gráfico
clas.plot
```

```{r}
mesh_test[mesh_test$mark == "Mal clasificado",]
```

```{r}
x1n[7,]
```

#### Curva ROC y valor AUC

Primero obtengamos la curva ROC y el valor de AUC multi-clase. 

```{r}
library(pROC)
library(gridExtra)

test_sp_num <- as.numeric(as.factor(test_t$especie))
pred_clase_num <- as.numeric(as.factor(pred.clase))
roc_cons <- multiclass.roc(test_sp_num, pred_clase_num)
```

Ahora creemos una función personalizada para utilizar un ciclo for para graficar las curvas ROC:

```{r}
plot_rocs <- function(classes, multi_roc, colors, theme, test_t){
  theme_set(theme)
  
  # Lista vacía para llenar con las gráficas
  rocs_plots <- list()
  
  # Valores a ciclar (clases)
  counter <- seq_along(classes) 

  for (i in counter) { # para cada i en clases
    if (i == 1) { # Si i == 1
      # curva ROC para la primera clase
      rocs_plots[[i]] <- ggroc(multi_roc$rocs[[i]],
                               color = colors[i], size = 1,
                               legacy.axes = T) +
                         # Establecemos el título global de la gráfica
                         labs(title =
                                paste("AUC multi-clase = ",
                                      round(roc_cons$auc[1],2)),
                              # clase como subtítulo
                              subtitle = sprintf("%s",
                                                 classes[i]),
                              # Sin nombre del eje x
                              x = element_blank(), 
                              y = "TVP (Sensibilidad)") +
                         geom_abline(intercept = 0, slope = 1,
                                     color = "gray50", size = 1,
                                     # Línea de referencia (Azar)
                                     linetype = "dashed")
    } # curva ROC para clase intermedias
    if (i < length(counter) & i > 1) {
      rocs_plots[[i]] <- ggroc(roc_cons$rocs[[i]],
                               color = colors[i], size = 1,
                               legacy.axes = T) +
                         labs(subtitle = sprintf("%s",
                                                 classes[i]),
                              x = element_blank(),
                              y = "TVP (Sensibilidad)") +
                         geom_abline(intercept = 0, slope = 1,
                                     color = "gray50", size = 1, 
                                     linetype = "dashed")
    } # curva ROC para la última clase
    if (i == length(counter)) {
      rocs_plots[[i]] <- ggroc(roc_cons$rocs[[i]], color = colors[i], 
                               size = 1, legacy.axes = T) +
                         labs(subtitle = sprintf("%s",
                                                 classes[i]),
                              # Se agrega el nombre del eje x para todas las
                              # gráficas (ojo a que es una sola columna)
                              x = "TFP (1 - especificidad)", 
                              y = "TVP (Sensibilidad)") +
                         geom_abline(intercept = 0, slope = 1,
                                     color = "gray50", size = 1,
                                     linetype = "dashed")
    }
    }
  do.call('grid.arrange', c(rocs_plots, ncol = 1))
}
```


Ahora grafiquémoslas:

```{r, fig.height=5, fig.width=3}
# Colores de las especies:
colors <- c("brown3", "chartreuse4", "deepskyblue4")
#cairo_pdf("ROC_LDA.pdf", height = 12.9, width = 7 )
plot_rocs(sort(unique(test_t$especie)),
          roc_cons, colors, theme_bw(), test_t)
#dev.off()
```
 
## Regresión logística

Otra técnica que podemos utilizar es la regresión logística. Es importante recordar que este modelo de clasificación fue desarrollado originalmente para clasificaciones binarias, aunque ya ha sido extendido a clasificaciones multinomiales. Esta técnica la veremos a detalle en la sesión de GLMs, aunque es importante mencionar que todas las formas de evaluación (entrenamiento-prueba, matriz de confusión, ROC-AUC) siguen aplicando. Para fines ilustrativos, realicemos el ajuste de un modelo multinomial; i.e., más de dos clases:


```{r}
iris_dat <- iris
samples <- sample.split(iris_dat$Species, SplitRatio = .75)
train2 <- subset(iris_dat, samples == TRUE)
test2 <- subset(iris_dat, samples == FALSE)
```

Centremos y estandaricemos:

```{r}
pre_pars <- preProcess(train2, method = c("center", "scale"))
train_t2 <- predict(pre_pars, train2)
test_t2 <- predict(pre_pars, test2)
```

#### Ajuste del modelo

A diferencia del caso anterior, vamos a implementar el modelo utilizando la librería caret (Classification and Regression Training). Esta librería nos permite homogeneizar el proceso de declaración de modelos de aprendizaje supervizado, y nos evita estar batallando con las librerías independientes. Veámoslo en acción:

```{r}
logit_mult <- caret::train(form = as.factor(Species)~.,
                          data = train_t2,
                          method = "multinom",
                          trace = F)
```

```{r}
test_preds <- predict(logit_mult, test_t2)
confusionMatrix(test_preds, as.factor(test_t2$Species))
```

Y la importancia de variables:

```{r}
varImp(logit_mult, scale = T)
```

## Ejercicio

Realizar una regresión logística multinomial con los datos de morfometría de peces (`Medidas.txt`). Responde lo siguiente:
1. ¿El modelo se encuentra sobre ajustado? ¿Por qué?
2. Obtén las curvas ROC y el valor de AUC multi-clase. ¿que tan bueno consideras al modelo?
3. ¿Cuáles fueron las variables más importantes para la clasificación? Compara con los resultados del ACP de la clase de reducción de dimensionalidad y los del LDA.
