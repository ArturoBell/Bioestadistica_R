# Probabilidad

Antes de entrar a aplicar pruebas estadísticas y técnicas de aprendizaje automatizado es necesario que te familiarices con el concepto más fundamental de todo el curso: la probabilidad. Somos conscientes de que la mayor parte de las situaciones en nuestro día a día no son completamente predecibles, ni que decir de los problemas que queremos resolver en nuestras investigaciones, y entonces nos topamos con una pared cuando tratamos de aplicar la lógica deductiva en este escenario de incertidumbre. Si yo te digo que “hay un 40% de probabiliidad de lluvia para hoy” y te pregunto si sales con una sombrilla es bastante posible que no puedas dar una respuesta inmediatamente. La lógica deductiva tipo “Dado que A entonces B” solo sirve en escenarios de certeza. Mira el diagrama de Venn de la diapositiva de abajo. Si te digo que ocurrió A, ¿qué me puedes decir sobre B? Es esencialmente el mismo escenario que con la probabilidad de lluvia. No podemos dar una respuesta definitiva, lo único que sabemos es que están traslapados en una fracción y que en otra fracción no, por lo tanto, lo único que podemos decir es que hay cierta posibilidad de que también haya ocurrido B.

## Definiciones básicas

Habrás notado que he evitado utilizar la palabra **probabilidad** hasta este momento. Esto es porque la probabilidad es justamente el asignarle un número a las posibilidades y, por lo tanto, podemos pensar en la probabilidad com una **medida de incertidumbre**. ¿Cómo la expresamos numéricamente? La manera más sencilla de entender a la probabilidad es desde un punto de vista geométrico; es decir, como **una proporción o una frecuencia relativa**, de la forma ¿cuántas veces ha ocurrido B en relación al número de veces que han ocurrido tanto A como B? Pero vayamos paso a paso.
Primero, algunas (tediosas y obligadas) definiciones:

- **Experimento aleatorio**: Es, como su nombre lo indica, un experimento, prueba (o como quieras llamarlo) en el cual no puedes saber con certeza cuál va a ser el **resultado**.
- **Espacio muestreal**: Son todos y cada uno de los posibles resultados de un experimento.
- **Evento**: Podemos pensar en un evento como un conjunto de datos/resultados, por lo tanto, el espacio muestreal es un evento.

Otros eventos son:

- **Universo**: Que incluye al espacio muestreal y el **conjunto vacío**. Como te imaginarás, este conjunto está vacío, no tiene nada.
- **Unión**: Denotada como $\cup$ (diferente de u y U), representa la unión de dos conjuntos/eventos; es decir, el caso donde nos interesa encontrar A **o** B.
- **Intersección**: Denotada como $\cap$ (diferente de n), representa el traslape entre dos conjuntos/eventos; es decir, el caso donde nos interesa encontrar A **y** B.
- **Complemento**: Denotado como $\tilde{A}$, representa lo que no es ese conjunto, en este caso, lo que NO es A, que es el área restante de B y el conjunto vacío.

![Eventos y diagramas de Venn](){#fig-events}

## Axiomas de la probabilidad

¿Qué tiene que ver esto con probabilidad? Pues que estas denominaciones dan lugar sus leyes/reglas; es decir los **Axiomas de la Probabilidad**:

1. $P(A) \geq 0$; es decir, todo evento tiene una probabilidad positiva y no mayor a 1. No necesita mayor explicación, simplemente ¿cómo interpretarías una probabilidad negativa?
2. $P(U) = 1$; es decir, la probabilidad de nuestro espacio muestreal y el conjunto vacío es 1. Eso tiene sentido, si hacemos un experimento aleatorio vamos a tener un resultado, independientemente de cuál sea, lo cual está relacionado con el tercer axioma:
3. Si A y B son mútuamente excluyentes: $P(A \cup B) = P(A) + P(B)$. Básicamente, si nos interesa saber cuál es la probabilidad de que ocurran dos resultados, en donde si ocurre uno ya no ocurre el otro, lo único que tenemos que hacer es sumar la probabilidad de cada uno de ellos. Si lanzo una moneda al aire, la probabilidad de que caiga cara es del 50% y la probabilidad de que caiga cruz es del 50%, pero la probabilidad de que caiga es del 100%.

Adicionales a estos tres axiomas tenemos dos casos especiales y una generalización:

1. $P(\varnothing) = 0$; el cual es autoexplicativo, la probabilidad de que ocurra el evento vacío es 0.
2. $P(\tilde{A}) = 1 - P(A)$; es decir, si $\tilde{A}$ representa lo que no es A y dado que $P(U) = 1$, solo debemos de restarle a ese universo la probabilidad de A.
3. $P(A\cup B) = P(A) + P(B) - P(A \cap B)$. Te darás cuenta que este se parece al tercer axioma y es porque es una generalización al caso donde A y B no son mútuamente excluyentes. ¿De dónde sale la resta? De que si A y B se encuentran unidos (el diagrama de Venn inferior) y sumamos el área de A con el área de B terminamos sumando dos veces la zona en la que están sobrelapados (intersección); por lo tanto, tenemos que quitarlo una vez para no sobre estimar. A esta generalización se le conoce como la **regla aditiva de la probabilidad**.

![Axiomas de la probabilidad](){#fig-axiomas}

## Probabilidades marginales y condicionales

Ahora entendimos que podemos hacer operaciones con la probabilidad, y eso nos lleva a los siguientes dos conceptos que son sumamente importantes: las probabilidades **marginal** y **condicional**.

Hablamos de una **probabilidad marginal** cuando nos interesa la P(A) cuando $A \cup B$. En este caso, podemos expresar al conjunto A como $A = (A \cap B) \cup (A \cup \tilde{B})$. ¿En Español? El conjunto A está dado por la unión de la intersección de A y B y la intersección de A con el complemento de B. ¿Aún menos rebuscado? **Es la suma de las partes no unidas**. El procedimiento aquí es justamente un caso similar a la regla aditiva de la probabilidad. Estamos sumando la zona traslapada entre A y B con lo que no es B, que nos deja únicamente con A. Te preguntarás por qué se denomina marginal. Para esto primero necesitamos definir una **tabla de contingencia**. Esta es simplemente una tabla en la que cada renglón tiene frecuencias relativas de los distintos niveles de una variable categórica y las columnas tienen las frecuencias relativas de cada nivel de otra variable categórica. En los **márgenes** de la tabla tenemos los totales para cada nivel (evento o conjunto) y de ahí viene el nombre.

Por otra parte, la **probabilidad condicional** nos permite responder a la pregunta ¿cuál es la P(A) si **ya sé** que B ocurrió?. Matemáticamente la representamos como $P(A|B)$ (probabilidad de A **dado** B), y es una razón de la probabilidad conjunta de A y B ($P(A,B)$ o $P(A \cap B)$) y la probabilidad marginal de B ($P(B)$); es decir: $P(A|B) = \frac{P(A,B)}{P(B)}$. La **probabilidad conjunta** representa la probabilidad de que dos eventos ocurran **al mismo tiempo** y puede llegar a ser un poco problemática. Si ambos eventos son independientes, obtenerla es sencillo: $P(A,B) = P(A)P(B)$. El problema surge si A y B no son independientes, en cuyo caso: $P(A,B) = P(A)P(B|A)$, lo cual nos lleva a una referencia cruzada. Por practicidad, y porque el interés del curso no es que sepas hacer estas cosas a mano, obtengamos la probabilidad conjunta desde su posición en la tabla de contingencia; es decir, cada una de sus celdas.

![Probabilidades marginales y condicionales](){}

En el ejemplo de la diapositiva (OJO: los datos no son representativos de ninguna población) calculamos la $P(Blond|Blue)$; es decir, la probabilidad de que alguien sea rubio si sabemos que tiene los ojos azules, dada por la división de la probabilidad conjunta $P(Blond,Blue) = 0.16$ y la marginal $P(B) = 0.36$ que resulta en $P(Blond|Blue) \approx 0.44$. ¿Cuál sería entonces la $P(Green|Red)$?

## Distribuciones de probabilidad

Dejando los memes de las viñetas (la inferior es bastante trágica), hablemos de cómo escalar de valores puntuales a algo más aplicado a la investigación. Podemos utilizar nuestra intución de probabilidad de manera cotidiana (e.g., probabilidad de lluvia), pero en cuestiones académicas tenemos una **hipótesis de trabajo**, la cual trasladamos a **pruebas de significancia** para realizar **inferencias**. Eso es algo que abordaremos más a detalle en la siguiente sección; sin embargo, vamos a tener múltiples datos, cuya distribución probabilidad es lo que va a moldear nuestros análisis. Es necesario, entonces, definir qué es una distribución de probabilidad.

En pocas palabras, una **distribución de probabilidad** es una lista con todos los resultados de un evento y sus probabilidades correspondientes. Hay una gran diversidad de distribuciones teóricas de probabilidad, cada una con sus peculiaridades, parámetros, momentos y lugares para utilizarlas. No te preocupes por aprenderlas todas, hablaremos de las distribuciones relevantes para cada modelo que apliquemos. Por ahora solo es importante que conozcas que, si hablamos de **distribuciones discretas**, hablamos entonces de la probabilidad de cada resultado. Si tenemos una **distribución continua**, podemos partirla en intervalos para discretizarla y hablar de la probabilidad de que una observación pertenezca a ese intervalo. Sea cual sea el caso, estas son masas de probabilidad, las cuales suman a 1, tal que:

$$
\sum_{i = 1}^n P(x_i) = 1 
$$
![Algunas distribuciones de probabilidad](){}

::: {.callout-note}
¿A qué me refiero con **discreta** o **continua**? A los valores que pueden tomar los resultados que dan forma a una distribución. Una distribución de probabilidad **discreta** solo toma valores enteros o categóricos, mientras que una **continua** puede tomar valores decimales. La relación de esto con nuestros datos la veremos en la siguiente sesión: muestreo.
:::

Pero volvamos al tema de las distribuciones continuas, porque tienen una propiedad bastante interesante. Resulta que si tenemos una distribución continua, la probabilidad de cada valor ($P(x)$) *es* 0. ¿Por qué? Porque, por definición, todos los valores en el intervalo de la distribución son posibles y hay una cantidad infinita de ellos (de aquí sale también el problema de la precisión de punto flotante, pero esa es otra historia). ¿Cómo contender con esto? Podemos **discretizar** la distribución y hablar de masas de probabilidad de los intervalos resultantes (regla de Sturgess, por ejemplo); sin embargo, estos intervalos son, por mucho apellido de autor que lleven, arbitrarios. ¿Entonces? Podemos hacerlos infinitesimalmente pequeños; es decir, aproximar la amplitud de los intervalos a 0 (pero no exactamente 0) y entonces tenemos **densidades de probabilidad**. ¿Por qué densidad? Porque dividimos la masa de ese intervalo infinitesimalmente pequeño entre su amplitud, lo cual nos deja con una definición similar a $densidad = \frac{masa}{área}$. Si hacemos eso, nuestras densidades pueden ser mayores a 1, lo cual indica que tenemos una alta masa en relación a la escala. El otro cambio es que, como recordarás de tus clases de cálculo, al pasar de una variable discreta a una continua pasamos de una sumatoria a una integral:

$$
\sum_{i = 1}^n \frac{p([x_i, i_i+\Delta x])}{\Delta x} \Rightarrow \int dxp(x) = 1
$$

No es necesario que memorices esto, solo que tengas en cuenta la diferencia entre masas y densidades de probabilidad. Como añadido, este mismo problema es lo que causa que un gráfico de frecuencias (histograma) no sea la mejor solución para ver la distribución de una variable continua. En su lugar podemos utilizar gráficos de densidad, los cuales hacen lo que acabamos de mencionar (al menos en escencia).

Dejando las ecuaciones de lado, la selección de la distribución de probabilidad que utilizaremos depende del problema. ¿Tienes datos de conteos? Puedes utilizar las distribuciones Poisson o binomial negativa. ¿Tienes datos continuos en el intervalo 0-1? Vale la pena echarle un ojo a la distribución Beta. ¿Tienes datos binarios? Deberías voltear hacia la distribución binomial.