<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-99.9.9">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Bioestad√≠stica Aplicada con R y RStudio - 11&nbsp; Modelo lineal</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./s03_noparnolin.html" rel="next">
<link href="./c10_param.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la b√∫squeda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar"
  }
}</script>

<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Modelo lineal</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bioestad√≠stica Aplicada con R y RStudio</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Prefacio</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./s0_preparacion.html" class="sidebar-item-text sidebar-link">Preparaci√≥n</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./s01_biolcdatos.html" class="sidebar-item-text sidebar-link">Biolog√≠a, Ciencia de Datos y `R`</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c01_biolcdatos.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Ciencia de datos y biolog√≠a</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c02_intro_rs.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introducci√≥n a <code>RStudio</code> y <code>Quarto</code></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c03_bases_r.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bases de R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c04_tidyverse.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducci√≥n a <code>tidyverse</code></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./s02_fundan.html" class="sidebar-item-text sidebar-link">Fundamentos del an√°lisis de datos</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c05_ggplot2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Principios de visualizaci√≥n de datos y <code>ggplot2</code></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c06_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Probabilidad</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c07_muestreo.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introducci√≥n al muestreo</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./s03_basics.html" class="sidebar-item-text sidebar-link">T√©cnicas b√°sicas</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c08_descriptiva.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Estad√≠stica descriptiva</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c09_ph0.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Pruebas de significancia estad√≠stica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c10_param.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">T√©cnicas param√©tricas</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c11_rls.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Modelo lineal</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./s03_noparnolin.html" class="sidebar-item-text sidebar-link">T√©cnicas no param√©tricas y modelaci√≥n no lineal</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c12_nopar.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">T√©cnicas no param√©tricas</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c13_nolin.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Modelos no lineales</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./s04_mv.html" class="sidebar-item-text sidebar-link">T√©cnicas Multivariadas</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c14_intromv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">T√©cnicas multivariadas: Introducci√≥n</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c15_nosup.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Aprendizaje No Supervisado</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c16_mvcomps.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Hip√≥tesis Multivariadas</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c17_clasif.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Aprendizaje supervisado: Clasificaci√≥n</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c18_mvregs.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Regresiones m√∫ltiples</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./c19_glm.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Modelos Lineales Generalizados</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./s06_despedida.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Despedida</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">Referencias</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#librer√≠as" id="toc-librer√≠as" class="nav-link active" data-scroll-target="#librer√≠as"><span class="toc-section-number">11.1</span>  Librer√≠as</a></li>
  <li><a href="#introducci√≥n" id="toc-introducci√≥n" class="nav-link" data-scroll-target="#introducci√≥n"><span class="toc-section-number">11.2</span>  Introducci√≥n</a></li>
  <li><a href="#regla-de-tres-y-el-modelo-lineal" id="toc-regla-de-tres-y-el-modelo-lineal" class="nav-link" data-scroll-target="#regla-de-tres-y-el-modelo-lineal"><span class="toc-section-number">11.3</span>  Regla de tres y el modelo lineal</a></li>
  <li><a href="#regresi√≥n-lineal-simple" id="toc-regresi√≥n-lineal-simple" class="nav-link" data-scroll-target="#regresi√≥n-lineal-simple"><span class="toc-section-number">11.4</span>  Regresi√≥n lineal simple</a>
  <ul class="collapse">
  <li><a href="#m√≠nimos-cuadrados" id="toc-m√≠nimos-cuadrados" class="nav-link" data-scroll-target="#m√≠nimos-cuadrados"><span class="toc-section-number">11.4.1</span>  M√≠nimos cuadrados</a></li>
  <li><a href="#supuestos-de-la-regresi√≥n-lineal" id="toc-supuestos-de-la-regresi√≥n-lineal" class="nav-link" data-scroll-target="#supuestos-de-la-regresi√≥n-lineal"><span class="toc-section-number">11.4.2</span>  Supuestos de la Regresi√≥n Lineal</a></li>
  <li><a href="#predicci√≥n-vs.-interpretaci√≥n" id="toc-predicci√≥n-vs.-interpretaci√≥n" class="nav-link" data-scroll-target="#predicci√≥n-vs.-interpretaci√≥n"><span class="toc-section-number">11.4.3</span>  Predicci√≥n vs.&nbsp;Interpretaci√≥n</a></li>
  <li><a href="#m√°xima-verosimilitud" id="toc-m√°xima-verosimilitud" class="nav-link" data-scroll-target="#m√°xima-verosimilitud"><span class="toc-section-number">11.4.4</span>  M√°xima verosimilitud</a></li>
  </ul></li>
  <li><a href="#correlaci√≥n-y-covarianza" id="toc-correlaci√≥n-y-covarianza" class="nav-link" data-scroll-target="#correlaci√≥n-y-covarianza"><span class="toc-section-number">11.5</span>  Correlaci√≥n y covarianza</a></li>
  <li><a href="#ejercicio" id="toc-ejercicio" class="nav-link" data-scroll-target="#ejercicio"><span class="toc-section-number">11.6</span>  Ejercicio</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-rls" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Modelo lineal</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="librer√≠as" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="librer√≠as"><span class="header-section-number">11.1</span> Librer√≠as</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(performance)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(stats4)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Metrics)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="introducci√≥n" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="introducci√≥n"><span class="header-section-number">11.2</span> Introducci√≥n</h2>
<p>En much√≠simos lugares encontramos, de forma completamente natural, patrones que se repiten una y otra vez, tal y como en la m√∫sica. El mundo de la estad√≠stica y del <strong>aprendizaje automatizado</strong> se construye de la misma manera, partiendo de peque√±os <em>motivos</em> que aparecen una y otra vez. En esta sesi√≥n vamos a hablar de el, posiblemente, m√°s popular de todos: el <strong>modelo lineal</strong>. Hablaremos entonces del caso m√°s b√°sico y escalaremos paso a paso en la complejidad.</p>
</section>
<section id="regla-de-tres-y-el-modelo-lineal" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="regla-de-tres-y-el-modelo-lineal"><span class="header-section-number">11.3</span> Regla de tres y el modelo lineal</h2>
<p>Antes de empezar a hablar propiamente de la regresi√≥n lineal, sus diferencias con la correlaci√≥n, en qu√© consiste, c√≥mo aplicarlas y dem√°s detalles, demos un paso hacia atr√°s y expliquemos el fundamento con manzanitas (literalmente).</p>
<p>Imagina que te digo que gast√© 50 pesos para comprar 10 manzanas y luego te pregunto ¬øcu√°nto cuesta una? Para responder a la pregunta aplicar√°s, aunque no seas consciente, el modelo lineal, pero primero resolvamos el problema con una regla de tres</p>
<p><span class="math display">\[\begin{align*}
10 üçé = \$50 \\
1üçé = ?
\end{align*}\]</span></p>
<p>Aqu√≠ multiplicar√≠amos <span class="math inline">\(1üçé \times 50\$\)</span> y dividimos entre <span class="math inline">\(10üçé\)</span>, lo cual nos lleva a decir que una manzana me cost√≥ 5<span class="math inline">\(\$\)</span>:</p>
<p><span class="math display">\[
\frac{1üçé \times 50 \$}{10üçé} = 5\frac{\$}{üçé}
\]</span></p>
<p>Hasta aqu√≠ nada nuevo, as√≠ que hagamos ese resultado a un lado por el momento y volvamos al problema del modelo lineal. ¬øEn qu√© consiste un modelo lineal? En utilizar la ecuaci√≥n de la recta (<span class="math inline">\(y = a + bx\)</span>) para establecer una relaci√≥n (lineal, dah) entre dos variables. Con nuestras manzanas podemos representarlo de la siguiente manera, donde <span class="math inline">\(y\)</span> es el dinero (<span class="math inline">\(\$\)</span>) gastado para alguna cantidad de manzanas (üçé):</p>
<p><span class="math display">\[
\$ = a + b*üçé
\]</span></p>
<p>¬øQu√© representan <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> Empecemos, por simplicidad did√°ctica, definiendo <span class="math inline">\(b\)</span>:</p>
<p><span class="math display">\[\begin{align*}
Si \\
\$ = a + b*üçé \\
\Rightarrow \$ - a = b*üçé \\
\therefore \frac{\$ - a}{üçé} = b
\end{align*}\]</span></p>
<p>Este peque√±o ejercicio algebr√°ico nos dice que <span class="math inline">\(b\)</span> es el resultado de <strong>dividir nuestro precio</strong> (menos <span class="math inline">\(a\)</span>) entre <strong>el n√∫mero de manzanas</strong>. ¬øTe suena? ¬°Es el <strong>precio por una manzana</strong>! Te preguntar√°s: ¬øentonces **qu√© es <span class="math inline">\(a\)</span> y por qu√© no lo consideramos antes? Para darle sentido pensemos en qu√© har√≠a que ambas aproximaciones nos lleven al mismo resultado: que <span class="math inline">\(a\)</span> fuera 0, ¬øno? Pues eso tiene todo el sentido del mundo, pues es el precio de 0 manzanas. Tomando esto en cuenta podemos asignarle nombre a nuestros distintos elementos:</p>
<ol type="1">
<li><span class="math inline">\(y\)</span> es nuestra variable dependiente (lo que queremos predecir); es decir, el n√∫mero de pesos gastados.</li>
<li><span class="math inline">\(x\)</span> es nuestra variable independiente (con lo que vamos a predecir); es decir, el n√∫mero de manzanas compradas.</li>
<li><span class="math inline">\(a\)</span> es la <strong>ordenada al origen</strong> o <strong>intercepto</strong>, representada como <span class="math inline">\(\beta_0\)</span> o <span class="math inline">\(\alpha\)</span>, indica el precio de 0 manzanas. Matem√°ticamente esto lo definimos como el punto donde la recta corta a la ordenada (eje y) o, en palabras m√°s sencillas, el punto donde x = 0.</li>
<li><span class="math inline">\(b\)</span> es la <strong>pendiente</strong>, representada como <span class="math inline">\(\beta_1\)</span> o <span class="math inline">\(\beta\)</span>, e indica el precio de una manzana. Formalmente es la <strong>tasa de cambio</strong> que existe del eje <span class="math inline">\(x\)</span> al eje <span class="math inline">\(y\)</span>; es decir, ‚Äúcu√°ntas unidades nos vamos a mover en el eje y por una unidad en el eje x‚Äù.</li>
</ol>
<div id="fig-ruleofthree" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/ruleofthree.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;11.1: De la regla de tres al modelo lineal</figcaption><p></p>
</figure>
</div>
<p>¬øPor qu√© se le denomina lineal? Porque si lo graficamos tendremos una l√≠nea recta:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>manzanas <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">10</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>precio <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(manzanas, <span class="at">precio =</span> a<span class="sc">+</span>b<span class="sc">*</span>manzanas)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> precio, <span class="fu">aes</span>(<span class="at">x =</span> manzanas, <span class="at">y =</span> precio)) <span class="sc">+</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"dodgerblue4"</span>) <span class="sc">+</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"dodgerblue4"</span>) <span class="sc">+</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> scales<span class="sc">::</span><span class="fu">pretty_breaks</span>()) <span class="sc">+</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  see<span class="sc">::</span><span class="fu">theme_lucid</span>() <span class="sc">+</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Precio por cantidad de manzanas (n)"</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Modelo: $ = 0 + 5*n"</span>,</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="fu">element_blank</span>())</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-linmod" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="c11_rls_files/figure-html/fig-linmod-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;11.2: Modelo lineal con el precio por cantidad de manzanas.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Aunque esto nos lleva a un peque√±o inconveniente o una consideraci√≥n. Si utilizamos un modelo lineal estamos asumiendo expl√≠citamente (aunque a veces inconscientemente) que el <strong>cambio entre nuestras variables es constante</strong>, determinado por <span class="math inline">\(\beta\)</span>. Reflexiona: ¬øen la naturaleza cu√°ntos procesos crees que sean realmente lineales? Con esto no quiero decir que debamos de olvidarnos del modelo lineal y que, entonces, esta sesi√≥n es una p√©rdida de tiempo, no. Quiero decir que debemos de ser consciente del <strong>supuesto</strong> bajo el cual estamos trabajando, muchas veces para simplificarnos la existencia.</p>
<div class="callout callout-style-default callout-note callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>¬øRecuerdas la definici√≥n formal de un modelo? Es una <strong>representaci√≥n SIMPLIFICADA de la realidad</strong>; es decir, siempre que involucremos un modelo, sea cual sea, estamos dejando cosas en el tintero. Recuerda: ‚ÄúTodos los modelos est√°n equivocados, pero algunos son √∫tiles‚Äù <span class="citation" data-cites="Box_1976">(<a href="references.html#ref-Box_1976" role="doc-biblioref">Box, 1976</a>)</span>.</p>
</div>
</div>
</section>
<section id="regresi√≥n-lineal-simple" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="regresi√≥n-lineal-simple"><span class="header-section-number">11.4</span> Regresi√≥n lineal simple</h2>
<p>Antes mencion√© que la regla de tres es una aplicaci√≥n del modelo lineal, lo que no dije es que es, en realidad, un ejercicio de <strong>regresi√≥n</strong>. ¬øQu√© es una regresi√≥n? Es una parte del <strong>aprendizaje automatizado supervisado</strong>, del cual hablaremos con m√°s lujo de detalle en la secci√≥n correspondiente, pero podemos definirla como el proceso de <strong>estimar los par√°metros de un modelo matem√°tico a partir de ciertos datos</strong>. En una regresi√≥n <strong>la variable dependiente siempre es continua</strong>. ¬øQu√© pasa si tenemos una variable dependiente categ√≥rica? Entonces estamos en un escenario de clasificaci√≥n, pero no nos adelantemos.</p>
<div class="callout callout-style-default callout-note callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>¬øQu√© es el aprendizaje automatizado? Por el momento entiendelo como la filosof√≠a de ‚Äúense√±ar con ejemplos‚Äù llevada a modelos matem√°ticos y predicciones. En cualquier modelo de aprendizaje automatizado supervisado tenemos una serie de ejemplos (datos), en los cuales una o m√°s variables sirven como predictoras de otra(s); es decir, el objetivo es generar buenas predicciones.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>¬øQu√© es un par√°metro en este contexto? Una manera f√°cil de entender los par√°metros de un modelo es verlos como perillas que regulan c√≥mo se transforma lo que est√° a la derecha del s√≠mbolo de igualdad para llegar a lo que est√° a la izquierda. Si te das cuenta es b√°sicamente lo que sucede con las distribuciones de probabilidad, y con justa raz√≥n: las distribuciones de probabilidad son, en s√≠ mismas, modelos. No confundas esta definici√≥n con la definici√≥n de par√°metro poblacional.</p>
</div>
</div>
<p>Ahora bien, hay una gran cantidad de <strong>m√©todos de auste</strong> de una regresi√≥n, pero todos se reducen a una cosa: <strong>minimizar una funci√≥n de p√©rdida</strong>. ¬øQu√© es una funci√≥n de p√©rdida y con qu√© se come? Es una forma rebuscada de llamarle a la <strong>distancia que existe entre nuestros valores observados y los valores predichos por el modelo</strong> o, en palabras m√°s sencillas, qu√© tan lejos qued√≥ la flecha del blanco; es decir, <strong>al ajustar un modelo estamos minimizando su error</strong>. ¬øCu√°les valores predichos? Aaaah, que bueno que preguntaste. Si vuelves a la <a href="#fig-linmod">Figura&nbsp;<span>11.2</span></a> te dar√°s cuenta que, utilizando los <strong>par√°metros</strong> estimados con nuestra regla de tres (<span class="math inline">\(a\)</span> = 0 y <span class="math inline">\(b\)</span> = 5) calculamos cu√°nto gastar√≠amos si compraramos desde 1 hasta 10 manzanas. De esos costos solo ten√≠amos el dato de que <span class="math inline">\(10 üçé = \$50\)</span>, todo lo dem√°s es una predicci√≥n.</p>
<div class="callout callout-style-default callout-note callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Lo que hicimos fue, de hecho, una <strong>extrapolaci√≥n</strong>, pues <strong>predijimos valores fuera del alcance de nuestros datos observados</strong>. Si tuvieramos ‚Äúhuecos‚Äù en nuestros datos y quisi√©ramos rellenarlos con el modelo tendr√≠amos una <strong>interpolaci√≥n</strong>; es decir, <strong>predecir√≠amos valores dentro del alcance de nuestros datos observados</strong>.</p>
</div>
</div>
<p>Pero volvamos a nuestra regresi√≥n lineal. El modelo m√°s simple es el que veremos en esta sesi√≥n: la regresi√≥n lineal simple. En esta, tal y como en nuestro ejemplo con las manzanas, describimos la relaci√≥n entre dos variables continuas utilizando la ecuaci√≥n de la recta. Formalmente este lo expresamos como:</p>
<p><span class="math display">\[
Y = \beta_0 + \beta_1*x + \epsilon
\]</span></p>
<p>Mencion√© que existen distintas formas de ajustar sus par√°metros, entre las que tenemos (ordenadas de mayor a menor complejidad):</p>
<ul>
<li>M√≠nimos cuadrados, que veremos a continuaci√≥n.</li>
<li>M√°xima verosimilitud, que tambi√©n veremos a continuaci√≥n.</li>
<li>Inferencia Bayesiana, que en realidad incluye como caso especial a la m√°xima verosimilitud.</li>
<li>Descenso estoc√°stico de gradiente, en ciertos escenarios de redes neuronales.</li>
</ul>
<p>Empecemos entonces con el ajuste por m√≠nimos cuadrados.</p>
<section id="m√≠nimos-cuadrados" class="level3" data-number="11.4.1">
<h3 data-number="11.4.1" class="anchored" data-anchor-id="m√≠nimos-cuadrados"><span class="header-section-number">11.4.1</span> M√≠nimos cuadrados</h3>
<p>En este m√©todo de ajuste la funci√≥n de p√©rdida es la funci√≥n cuadr√°tica:</p>
<p><span class="math display">\[
D(y_i - \hat{y_i}) = \sum_{i=1}^n(y_i - \hat{y_i})^2 = \sum_{i=1}^n \epsilon^2
\]</span></p>
<p>Es decir, <strong>minimizamos la distancia</strong> (diferencia) <strong>cuadr√°tica entre los valores observados y los valores predichos</strong>. Anal√≠ticamente (c√°lculo) el proceso consiste en obtener la derivada parcial de <span class="math inline">\(D(y_i - \hat{y_i})\)</span>, igualarla a 0, y encontrar una expresi√≥n para <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>. Te voy a ahorrar toda la <a href="https://bit.ly/minimos_cuadrados">matem√°tica correspondiente</a> y te dar√©, solo como referencia, estas √∫ltimas expresiones. Para <span class="math inline">\(\beta_1\)</span>:</p>
<p><span class="math display">\[
  \beta_1 = \frac{\Sigma_{i = 1}^n(x_i - \overline{x})(y_i - \overline{y})}{\Sigma_{i = 1}^n(x_i - \overline{x})^2}
\]</span></p>
<p>Y para <span class="math inline">\(\beta_0\)</span>:</p>
<p><span class="math display">\[
\beta_0 = \overline{y}- \beta_1*\overline{x}
\]</span></p>
<p>¬øPor qu√© solo como referencia? Porque (afortunadamente para nosotros) <code>R</code> ya tiene codificado todo el proceso en la funci√≥n <code>lm(formula, data)</code> y no tenemos que preocuparnos por nada de eso.</p>
<div class="callout callout-style-default callout-note callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Recordar√°s que en el <a href="c04_tidyverse.html"><span>Cap√≠tulo&nbsp;4</span></a> habl√© (y ejemplifiqu√©) sobre c√≥mo ajustar una regresi√≥n lineal simple, tanto con <code>R</code> como con <code>tidymodels</code>. En esta sesi√≥n <code>tidymodels</code> a√∫n nos queda ‚Äúun poco grande‚Äù, en el sentido de que a√∫n no podemos aprovechar todo lo que ofrece, por lo que me voy a limitar a utilizar la forma de <code>R</code> base.</p>
</div>
</div>
<p>Para ejemplificarlo carguemos los datos contenidos en <code>example_data.csv</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df_reg1 <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"datos/example_data.csv"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Luego grafiqu√©moslos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>plot_data_reg1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> df_reg1,</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>                         <span class="fu">aes</span>(<span class="at">x =</span> v1, <span class="at">y =</span> v2)) <span class="sc">+</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"dodgerblue4"</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                             <span class="at">alpha =</span> <span class="fl">0.7</span>,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>                             <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Relaci√≥n entre v1 y v2"</span>) <span class="sc">+</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>                  see<span class="sc">::</span><span class="fu">theme_lucid</span>()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>plot_data_reg1</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="c11_rls_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<section id="ajuste-y-bondad-de-ajuste" class="level4" data-number="11.4.1.1">
<h4 data-number="11.4.1.1" class="anchored" data-anchor-id="ajuste-y-bondad-de-ajuste"><span class="header-section-number">11.4.1.1</span> Ajuste y Bondad de ajuste</h4>
<p>Ahora ajustemos el modelo de m√≠nimos cuadrados (<code>lm()</code>) a los datos y veamos los resultados de la regresi√≥n (<code>summary()</code>):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>reg1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(v2<span class="sc">~</span>v1, <span class="at">data =</span> df_reg1)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reg1)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = v2 ~ v1, data = df_reg1)

Residuals:
    Min      1Q  Median      3Q     Max 
-5.8956 -1.9924 -0.5525  1.5351 15.3006 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -3.72654    0.73213   -5.09 1.81e-06 ***
v1           1.17765    0.08141   14.47  &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.095 on 95 degrees of freedom
Multiple R-squared:  0.6878,    Adjusted R-squared:  0.6845 
F-statistic: 209.3 on 1 and 95 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Describamos la salida elemento por elemento:</p>
<ul>
<li><code>Call</code>: es el c√≥mo llamamos a la funci√≥n. ¬øLa raz√≥n? En caso de que estemos llamando a la funci√≥n <code>lm</code> dentro de otra funci√≥n, cosa que no hicimos. De cualquier manera, sirve como una forma de verificar que pusimos las cosas en orden. -<code>Residuals</code>: Nos da informaci√≥n sobre la distribuci√≥n de los residuales (la diferencia entre observado y predicho). Esta es √∫til con fines diagn√≥sticos, pero hablaremos m√°s a fondo de ellos m√°s adelante.</li>
<li><code>Coefficients</code>: Nos da una tabla con los valores de los par√°metros del modelo, donde la pendiente tiene el nombre de la variable predictora, su error est√°ndar y una prueba <span class="math inline">\(t\)</span> para cada uno. ¬øContra qu√© est√° comparando? Contra un <strong>modelo nulo</strong>; es decir, contra un modelo donde ese par√°metro tenga un valor = 0.</li>
<li><code>Residual standard error</code>: M√°s informaci√≥n sobre los residuales, aunque en este caso es el error est√°ndar. Este es sumamente √∫til para darnos una idea de qu√© tan preciso es el modelo, pues indica en cu√°ntas unidades, en promedio, se desv√≠a la predicci√≥n de los datos observados. Este valor, dividido entre el promedio de la variable predicha nos da la tasa de error del modelo.</li>
<li><code>Multiple R-squared</code>: Es el valor del famos√≠simo (¬øinfame?) <strong>coeficiente de determinaci√≥n</strong> (<span class="math inline">\(R^2\)</span>). Si ya has llevado clases de estad√≠stica y de regresi√≥n lineal es muy posible que lo entiendas como ‚Äúla varianza de los datos explicada por el modelo‚Äù. ¬øPor qu√© digo infame? Porque, al igual que el valor de p, es un valor del cu√°l se abusa. Nuevamente, los seres humanos somos flojos por naturaleza, por lo que nos gusta resumir las cosas en un solo n√∫mero. En este sentido, el <span class="math inline">\(R^2\)</span> es una medida de <strong>bondad de ajuste</strong>; es decir, de qu√© tan bien ajustado est√° el modelo. Es muy pr√°ctico, pues est√° contenido en el intervalo <span class="math inline">\([0,1]\)</span> y representa un porcentaje; sin embargo, para que podamos confiar en √©l debemos de haber cubierto con el resto de <strong>supuestos de la RLS</strong>. Personalmtente te sugiero mejor tomar el RSE como medida de ajuste, aunque la interpretaci√≥n no sea tan directa.</li>
<li><code>Adjusted R-squared</code>: Es un ajuste al <span class="math inline">\(R^2\)</span> que lo hace menos optimista, especialmente dise√±ado para escenarios de regresi√≥n m√∫ltiple (de ah√≠ el ‚ÄúMultiple‚Äù del punto anterior). Por el momento lo vamos a ignorar.</li>
<li><code>F-statistic</code>: Resultados de un ANOVA que, al igual que el punto anterior vamos a ignorar porque es informativo solo en regresiones m√∫ltiples. Es un ANOVA para comparar todo el modelo contra un modelo nulo, por lo que aqu√≠ solo es redundante con las pruebas <span class="math inline">\(t\)</span> para cada par√°metro.</li>
</ul>
<div class="callout callout-style-default callout-note callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>¬øQu√© es la bondad de ajuste? Como dice el nombre, qu√© tan bien ajustado est√° el modelo, en el sentido de qu√© tan buenas son las predicciones.</p>
</div>
</div>
<p>Los resultados del modelo los podemos reportar como:</p>
<p>En el modelo de regresi√≥n lineal simple tanto el intercepto (<span class="math inline">\(\beta_0 = -3.72\)</span>) como la pendiente (<span class="math inline">\(\beta_1 = 1.17\)</span>) son significativamente diferentes de 0 (<span class="math inline">\(\beta_0: t_{\nu = 95} = -5.09; p &lt; 0.0001\)</span>; <span class="math inline">\(\beta_1: t_{\nu = 95} = 14.47; p &lt; 0.0001\)</span>). El valor de <span class="math inline">\(R^2\)</span> indica que el modelo explica alrededor del 70% de la varianza de los datos, lo cual sugiere un ajuste aceptable, con un error est√°ndar de los residuales de 3.095 unidades.</p>
<p>Usualmente acompa√±ar√≠amos este reporte de un gr√°fico, el cual podemos construir con la capa <code>geom_smooth(method = "lm", se = FALSE)</code>, tal que:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>plot_reg1 <span class="ot">&lt;-</span> plot_data_reg1 <span class="sc">+</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>             <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">se =</span> <span class="cn">FALSE</span>,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                         <span class="at">colour =</span> <span class="fu">rgb</span>(<span class="dv">118</span>,<span class="dv">78</span>,<span class="dv">144</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>                                      <span class="at">maxColorValue =</span> <span class="dv">255</span>)) <span class="sc">+</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>             <span class="fu">labs</span>(<span class="at">caption =</span> <span class="fu">paste</span>(<span class="st">"Modelo ajustado: v2 = "</span>, </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>                                   <span class="fu">round</span>(reg1<span class="sc">$</span>coefficients[<span class="dv">1</span>],<span class="dv">2</span>), </span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>                                   <span class="st">" + "</span>,</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>                                   <span class="fu">round</span>(reg1<span class="sc">$</span>coefficients[<span class="dv">2</span>],<span class="dv">2</span>),</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>                                   <span class="st">"*v1 + e"</span>))</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>plot_reg1</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<p><img src="c11_rls_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Ahora bien, recordar√°s que ninguna estimaci√≥n es infalible, por lo que tanto el reporte como el gr√°fico est√°n incompletos. Hablemos entonces de los intervalos de confianza.</p>
<section id="intervalos-de-confianza-para-los-par√°metros" class="level5" data-number="11.4.1.1.1">
<h5 data-number="11.4.1.1.1" class="anchored" data-anchor-id="intervalos-de-confianza-para-los-par√°metros"><span class="header-section-number">11.4.1.1.1</span> Intervalos de confianza para los par√°metros</h5>
<p>En un modelo de regresi√≥n lineal tenemos ‚Äúdos‚Äù intervalos de confianza: los intervalos de confianza para la estimaci√≥n de los par√°metros y el intervalo de confianza para la regresi√≥n. Los primeros, como te imaginar√°s, representan la incertidumbre alrededor de la estimaci√≥n de nuestros par√°metros de regresi√≥n. Como recordar√°s de lo que mencion√© en el cap√≠tulo <a href="c08_descriptiva.html"><span>Cap√≠tulo&nbsp;8</span></a>, estos se construyen a partir de su error est√°ndar (<span class="math inline">\(IC_{95\%} = \beta ¬± 1.96*EE\)</span>) y, a diferencia de lo que vimos en el <a href="c09_ph0.html"><span>Cap√≠tulo&nbsp;9</span></a>, ahora los obtenemos con la funci√≥n <code>confint()</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>confint_reg1 <span class="ot">&lt;-</span> <span class="fu">confint</span>(reg1, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>confint_reg1</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                2.5 %    97.5 %
(Intercept) -5.179989 -2.273085
v1           1.016035  1.339263</code></pre>
</div>
</div>
<p>Con esta informaci√≥n podemos realizar un gr√°fico donde representemos esta incertidumbre, en donde obtengamos dos l√≠mites para la l√≠nea de regresi√≥n utilizando esos valores, tal que:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Construimos el l√≠mite inferior con el l√≠mite del 2.5% de los intervalos</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>df_reg1[<span class="st">"inf_int"</span>] <span class="ot">&lt;-</span> confint_reg1[<span class="dv">1</span>,<span class="dv">1</span>] <span class="sc">+</span> confint_reg1[<span class="dv">2</span>,<span class="dv">1</span>]<span class="sc">*</span>df_reg1<span class="sc">$</span>v1</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Construimos el l√≠mite superior con el l√≠mite del 97.5% de los intervalos</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>df_reg1[<span class="st">"sup_int"</span>] <span class="ot">&lt;-</span> confint_reg1[<span class="dv">1</span>,<span class="dv">2</span>] <span class="sc">+</span> confint_reg1[<span class="dv">2</span>,<span class="dv">2</span>]<span class="sc">*</span>df_reg1<span class="sc">$</span>v1</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>A√±adi√©ndolos al gr√°fico de los datos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>plot_reg1 <span class="sc">+</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> df_reg1,</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">ymin =</span> inf_int,</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">ymax =</span> sup_int),</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">"gray70"</span>,</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">"Intervalos de confianza para los par√°metros"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<p><img src="c11_rls_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Pero este no es el gr√°fico que usualmente veremos. Si dese√°ramos inlcuir esta informaci√≥n solo a√±adir√≠amos los IC al reporte, tal que:</p>
<p>En el modelo de regresi√≥n lineal simple tanto el intercepto (<span class="math inline">\(\beta_0 = -3.72\)</span>; <span class="math inline">\(IC_{95\%}: [-5.18, -2.27]\)</span>) como la pendiente (<span class="math inline">\(\beta_1 = 1.17\)</span>; <span class="math inline">\(IC_{95\%}: [1.02, 1.34]\)</span>) son significativamente diferentes de 0 (<span class="math inline">\(\beta_0: t_{\nu = 95} = -5.09; p &lt; 0.0001\)</span>; <span class="math inline">\(\beta_1: t_{\nu = 95} = 14.47; p &lt; 0.0001\)</span>). El valor de <span class="math inline">\(R^2\)</span> indica que el modelo explica alrededor del 70% de la varianza de los datos, lo cual sugiere un ajuste aceptable, con un error est√°ndar de los residuales de 3.095 unidades.</p>
<div class="callout callout-style-default callout-warning callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Advertencia
</div>
</div>
<div class="callout-body-container callout-body">
<p>En este caso nuestros datos son ‚Äúadimensionales‚Äù; es decir, no tenemos unidades de ninguna variable. Si nuestras variables no son adimensionales debemos de incluir tambi√©n las unidades correspondientes (pesos, manzanas y pesos/manzana, si volvemos a nuestro ejemplo).</p>
</div>
</div>
</section>
<section id="intervalo-de-confianza-para-la-regresi√≥n" class="level5" data-number="11.4.1.1.2">
<h5 data-number="11.4.1.1.2" class="anchored" data-anchor-id="intervalo-de-confianza-para-la-regresi√≥n"><span class="header-section-number">11.4.1.1.2</span> Intervalo de confianza para la regresi√≥n</h5>
<p>¬øSi el gr√°fico anterior no es el que presentamos, cu√°l es? Uno que incluya el intervalo de confianza para la regresi√≥n <em>per-se</em> (tambi√©n llamado para la recta). ¬øRecuerdas el RSE? Pues se construye con ese valor. Para incluirlo en el gr√°fico solo tenemos que modificar ligeramente <code>geom_smooth()</code> y hacer <code>se = TRUE</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>plot_reg1 <span class="sc">+</span> </span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>,</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">se =</span> <span class="cn">TRUE</span>,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">colour =</span> <span class="fu">rgb</span>(<span class="dv">118</span>,<span class="dv">78</span>,<span class="dv">144</span>, <span class="at">maxColorValue =</span> <span class="dv">255</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'
`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-rls1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="c11_rls_files/figure-html/fig-rls1-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;11.3: Modelo de regresi√≥n lineal simple de <code>v2</code> y <code>v1</code>. La l√≠nea morada representa el ajuste lineal, y el √°rea sombreada el intervalo de confianza para la regresi√≥n</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Estamos obteniendo dos mensajes de <code>geom_smooth()</code> porque en <code>plot_reg1</code> ya ten√≠amos esa capa (con <code>se = FALSE</code>). Dir√© lo obvio, pero cuando hagas tus gr√°ficos NO es necesario que repitas capas.</p>
</div>
</div>
<p>Nuestro reporte completo quedar√≠a entonces como:</p>
<p>En el modelo de regresi√≥n lineal simple (<a href="#fig-rls1">Figura&nbsp;<span>11.3</span></a>) tanto el intercepto (<span class="math inline">\(\beta_0 = -3.72\)</span>; <span class="math inline">\(IC_{95\%}: [-5.18, -2.27]\)</span>) como la pendiente (<span class="math inline">\(\beta_1 = 1.17\)</span>; <span class="math inline">\(IC_{95\%}: [1.02, 1.34]\)</span>) son significativamente diferentes de 0 (<span class="math inline">\(\beta_0: t_{\nu = 95} = -5.09; p &lt; 0.0001\)</span>; <span class="math inline">\(\beta_1: t_{\nu = 95} = 14.47; p &lt; 0.0001\)</span>). El valor de <span class="math inline">\(R^2\)</span> indica que el modelo explica alrededor del 70% de la varianza de los datos, lo cual sugiere un ajuste aceptable, con un error est√°ndar de los residuales de 3.095 unidades.</p>
<p>Y ahora toca abordar el ‚Äúelefante en el cuarto‚Äù y comprobar que nuestra regresi√≥n sea confiable.</p>
</section>
</section>
</section>
<section id="supuestos-de-la-regresi√≥n-lineal" class="level3" data-number="11.4.2">
<h3 data-number="11.4.2" class="anchored" data-anchor-id="supuestos-de-la-regresi√≥n-lineal"><span class="header-section-number">11.4.2</span> Supuestos de la Regresi√≥n Lineal</h3>
<p>¬øQu√© no ya hab√≠amos evaluado la bondad del ajuste? S√≠ y no. En realidad hice una peque√±a trampa para que veas por qu√© el <span class="math inline">\(R^2\)</span> no cuenta toda la historia, y por qu√© no debemos de confiar ciegamente en √©l. La regresi√≥n lineal simple, como buena t√©cnica param√©trica, tiene sus supuestos:</p>
<ul>
<li><strong>Linealidad</strong>: Existe una relaci√≥n lineal entre las variables involucradas.</li>
<li><strong>Independencia</strong>: El error es independiente; <em>i.e.</em>, no hay correlaci√≥n entre el error de puntos consecutivos (aplica para series de tiempo).</li>
<li><strong>Normalidad</strong>: El error sigue una distribuci√≥n normal.</li>
<li><strong>Homocedasticidad</strong>: El error tiene una varianza constante para cada valor de <span class="math inline">\(X\)</span>.</li>
</ul>
<div class="callout callout-style-default callout-note callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Te dar√°s cuenta de que todo est√° en t√©rminos del ‚Äúerror‚Äù, tal y como habl√°bamos de distribuciones muestrales de la media en el cap√≠tulo <a href="c10_param.html"><span>Cap√≠tulo&nbsp;10</span></a>. Siguiendo la misma l√≥gica, nuestras inferencias para comprobar los supuestos las haremos sobre los residuales.</p>
</div>
</div>
<p>Si no cumplimos con uno, varios, o ninguno, la confiabilidad de nuestro modelo de regresi√≥n para fines de interpretaci√≥n va disminuyendo. Los primeros dos son bastante l√≥gicos. El primero es auto-explicativo: si la relaci√≥n no es lineal, el modelo lineal no es suficiente para describirla. El segundo tiene que ver con datos de series de tiempo y algo que se conoce como <strong>autocorrelaci√≥n</strong>, pero esto se reduce a que el error del punto <span class="math inline">\(t_i\)</span> no dependa del punto <span class="math inline">\(t_{i-1}\)</span>.</p>
<p>El <strong>supuesto de normalidad</strong>, para variar, requiere de un poco m√°s de explicaci√≥n: <strong>la distribuci√≥n que debe ser normal es la del error</strong>. En ning√∫n lugar se habla de que <span class="math inline">\(Y\)</span> o <span class="math inline">\(X\)</span> deban de estar normalmente distribuidos, solamente el error. Esto puede sonarte extra√±o, pero tiene todo el sentido del mundo: si estamos optimizando el modelo a partir de los residuales, ¬øpor qu√© habr√≠a de importarnos la distribuci√≥n cruda de las variables?</p>
<p>El <strong>supuesto de homocedasticidad</strong>, por otra parte, es an√°logo al supuesto de homogeneidad de varianzas pero, nuevamente, nos interesa qu√© pasa con el error, no con las variables originales (por favor, no hagas una prueba de Levene con tus variables como grupos). En este caso lo importante es que el error sea parejo, independientemente de si tenemos valores peque√±os o grandes del predictor.</p>
<p>¬øC√≥mo evaluamos estos supuestos? Mayoritariamente con gr√°ficos de dispersi√≥n, pero vamos uno a uno:</p>
<ul>
<li><strong>Linealidad</strong>: Con un gr√°fico de residuales. En este gr√°fico tenemos los residuales estandarizados (cada residual menos el promedio de los residuales, dividido entre la desviaci√≥n est√°ndar) en el eje <span class="math inline">\(y\)</span>, y los valores ajustados por el modelo (predicciones) en el eje <span class="math inline">\(x\)</span>. Se pueden a√±adir dos referencias: una l√≠nea de referencia horizontal en <span class="math inline">\(y = 0\)</span> y una curva LOESS (hablaremos un poco de este modelo en el <a href="c13_nolin.html"><span>Cap√≠tulo&nbsp;13</span></a>). Si la relaci√≥n entre nuestras variables predicha y predictora es perfectamente lineal, entonces todos los puntos caer√°n sobre la l√≠nea de referencia y la curva LOESS ser√° completamente horizontal en 0. Entre menos lineal sea la relaci√≥n m√°s se alejar√°n los puntos de la l√≠nea y mayores curvaturas tendr√° el modelo LOESS. Adicionalmente, puede servir para identificar valores extremos (puntos que caigan fuera de <span class="math inline">\([-1.96, 1.96]\)</span> si se trabaja a un 95% de confianza).</li>
<li><strong>Independencia</strong>: Con un gr√°fico de autocorrelaci√≥n. Dado que el an√°lisis de series de tiempo est√° fuera del alcance de este grupo lo vamos a obivar.</li>
<li><strong>Normalidad</strong>: Una prueba de normalidad de los residuales y con un gr√°fico cuantil-cuantil (QQ plot). En este gr√°fico se grafican (valga la redundancia) los residuales en el eje <span class="math inline">\(y\)</span>, y cuantiles te√≥ricos seg√∫n una distribuci√≥n normal en el eje <span class="math inline">\(x\)</span>. Adem√°s se traza una l√≠nea de referencia con una pendiente de 1, que representa una distribuci√≥n normal perfecta. El objetivo es que la prueba de normalidad sea no significativa y que los residuales caigan lo m√°s cercanamente posible a la l√≠nea de referencia.</li>
<li><strong>Homocedasticidad</strong>: Una prueba <span class="citation" data-cites="BreuschPagan_1979">Breusch &amp; Pagan (<a href="references.html#ref-BreuschPagan_1979" role="doc-biblioref">1979</a>)</span> y un gr√°fico de escala-locaci√≥n (scale-location). La prueba, como te imaginar√°s, tiene la hip√≥tesis de nulidad de que el error (residuales) est√° homog√©neamente distribuido. En el gr√°fico tenemos en el eje <span class="math inline">\(y\)</span> la ra√≠z cuadrada del absoluto de los residuales estandarizados (<span class="math inline">\(\sqrt{|re|}\)</span>) y en el eje <span class="math inline">\(x\)</span> los valores ajustados. ¬øPor qu√© la ra√≠z del absoluto? Ese detalle ya es clavarse demasiado, y prefiero que nos adentremos bien a otro tema un poco m√°s adelante, as√≠ que conformemonos por saber que queremos que los puntos est√©n distribuidos de manera aleatoria (homog√©nea) en todo el eje <span class="math inline">\(x\)</span>. ¬øQu√© quiere decir esto? que no tengamos una mayor dispersi√≥n de los puntos (varianza de los residuales) en valores ajustados peque√±os (a la izquierda del gr√°fico) que en los valores m√°s grandes (derecha del gr√°fico), lo que se ver√≠a como un &gt; imaginario, o viceversa, o alg√∫n otro patr√≥n.</li>
</ul>
<p>¬øMuchos gr√°ficos? Tal vez. Podr√≠amos hacerlo a mano, o podemos aprovechar la librer√≠a <code>performance</code> y obtenerlos todos de una vez con la funci√≥n <code>check_model(object)</code>, donde <code>object</code> es el objeto con los resultados del ajuste. Esta funci√≥n nos da todos los gr√°ficos en un solo paso:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>reg1_diags <span class="ot">&lt;-</span> performance<span class="sc">::</span><span class="fu">check_model</span>(reg1)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>reg1_diags</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-performance" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="c11_rls_files/figure-html/fig-performance-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;11.4: Gr√°ficos diagn√≥sticos de la regresi√≥n.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Y se acab√≥ el encanto. Resulta que no cumplimos con ninguno de los supuestos, y entonces nuestro <span class="math inline">\(R^2 \approx 0.7\)</span> nos minti√≥ vilmente. Cada quien reacciona de forma diferente a cu√°ndo alguien le miente, pero lo que es seguro que pase es que desconfiar√°, al menos un poco, de todo lo que esa persona le diga en un futuro. En defensa del <span class="math inline">\(R^2\)</span>, no es su culpa y, de hecho, estoy siendo demasiado duro con √©l. Me explico: el <span class="math inline">\(R^2\)</span> es confiable como medida de ajuste s√≠ y solo si se cumplen los mismos supuestos de la regresi√≥n lineal simple, lo cual no es el caso; <em>ergo</em>, no pod√≠amos confiar en √©l desde un principio porque nuestros datos no lo permiten. El problema es que se ha malversado su uso, y muchas personas lo utilizan como si fuera el √∫nico sello de garant√≠a, cuando en realidad es el √∫ltimo.</p>
<p>Pero volvamos a nuestros gr√°ficos. En la <a href="#fig-performance">Figura&nbsp;<span>11.4</span></a> se ven muy peque√±os, y hay un par que no hemos explicado:</p>
<ol type="1">
<li><strong>Posterior predictive check</strong>: Este tipo de gr√°ficos es uno de los m√°s socorridos en inferencia Bayesiana, para comprobar que la distribuci√≥n posterior obtenida por el modelo sea consistente con los datos observados. Aqu√≠ no tenemos un modelo Bayesiano, pero s√≠ que podemos utilizar la informaci√≥n de la distribuci√≥n de los par√°metros (estimaci√≥n y error est√°ndar) para simular datos aleatorios. Si el modelo tiene una buena capacidad predictiva, entonces los datos observados <span class="math inline">\(Y\)</span> deben de caer dentro del √°rea comprendida por las l√≠neas de los datos predichos <span class="math inline">\(\hat{Y}\)</span>. En este caso, la capacidad predictiva del modelo no es del todo mala, solamente tenemos una sobre-estimaci√≥n notable en valores cercanos a 10. Esto nos habla de la robustez del modelo lineal, pero no por ello hay que abusar de √©l.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(performance<span class="sc">::</span><span class="fu">check_predictions</span>(reg1)) <span class="sc">+</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  see<span class="sc">::</span><span class="fu">theme_lucid</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="c11_rls_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ol start="2" type="1">
<li><strong>Linearity</strong>: Es el gr√°fico de residuales. Desafortunadamente no hay una forma de obtenerlo en una sola l√≠nea, as√≠ que tocar√° construirlo a mano y, de paso, modificar un par de cosas. La primera es graficar los residuales estandarizados (menos su media y divididos entre su desviaci√≥n est√°ndar) para poder darnos una idea de si tenemos valores extremos o no. La segunda es asignar una escala de colores para facilitarlo. Para poder hacer esto vamos a pasarle a <code>ggplot()</code> directamente el objeto de regresi√≥n, y en <code>aes()</code> vamos a utilizar dos atributos ocultos del objeto <code>reg1</code>: <code>.fitted</code> con los valores predichos y <code>.stdresid</code> con los residuales estandarizados. En el gr√°fico resultante podemos ver que hay varios valores con residuales altos (tonos rojizos), y algunos extremos (&gt; 1.96). La curva LOESS no se ve exageradamente desviada de la l√≠nea de referencia, lo cual indica que un modelo lineal puede no ser tan mala elecci√≥n.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inicializar el espacio gr√°fico</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> reg1, <span class="co"># Objeto de regresi√≥n</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>       <span class="co"># Datos ajustados y residuales estandarizados</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .stdresid,</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">colour =</span> .stdresid)) <span class="sc">+</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Gr√°fico de dispersi√≥n</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>,</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>             <span class="at">alpha =</span> <span class="fl">0.7</span>,</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>             <span class="at">show.legend =</span> F) <span class="sc">+</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Referencia en 0</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>,</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>             <span class="at">colour =</span> <span class="st">"black"</span>,</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Referencia loess</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"loess"</span>,</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>              <span class="at">colour =</span> <span class="st">"#3aaf85"</span>) <span class="sc">+</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Gradiente de colores</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># "#cd201f": color para los extremos (rojo)</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># "#1b6ca8": color para el punto intermedio (0)</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Escala de -2 a 2 (deber√≠a ser 1.96)</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># oob: ¬øqu√© hacer con datos fuera de los l√≠mites?</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># scales::squish : marcarlos como si estuvieran en el l√≠mite</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_gradient2</span>(<span class="at">low =</span> <span class="st">"#cd201f"</span>,</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>                        <span class="at">midpoint =</span> <span class="dv">0</span>, </span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>                        <span class="at">mid =</span> <span class="st">"#1b6ca8"</span>, </span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>                        <span class="at">high =</span> <span class="st">"#cd201f"</span>,</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>                        <span class="at">breaks =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">2</span>),</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>                        <span class="at">limits =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>),</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>                        <span class="at">oob =</span> scales<span class="sc">::</span>squish) <span class="sc">+</span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Linearity"</span>,</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Reference line should be flat and horizontal"</span>,</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Standardized residuals"</span>,</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Fitted values"</span>) <span class="sc">+</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>  see<span class="sc">::</span><span class="fu">theme_lucid</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<p><img src="c11_rls_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ol start="3" type="1">
<li><strong>Homogeneity of variance</strong>: Homocedasticidad/Heterocedasticidad. Con un poco de imaginaci√≥n puedes trazar un &gt;, indicando que hay una mayor varianza en los valores peque√±os que en los valores grandes. La prueba <span class="citation" data-cites="BreuschPagan_1979">Breusch &amp; Pagan (<a href="references.html#ref-BreuschPagan_1979" role="doc-biblioref">1979</a>)</span>, por otra parte, sugiere que la varianza es homog√©nea. Este es un t√≠pico caso donde conviene errar en el lado de la precauci√≥n y profundizar en el an√°lisis antes de sacar una conclusi√≥n. ¬øQu√© pasa con nuestro &gt; si quitamos el punto extremo con un residual estandarizado &gt; 4? Se vuelve mucho menos marcado, ¬øno? Posiblemente sea eso lo que est√° viendo la prueba y que no est√© siendo enga√±ada por ese punto. Dada la estructura de los datos (muchos acumulados en valores peque√±os y pocos en valores grandes), yo decidir√≠a que no se cumple el supuesto de homogeneidad de varianzas.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>reg1_homoced <span class="ot">&lt;-</span> performance<span class="sc">::</span><span class="fu">check_heteroscedasticity</span>(reg1)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(reg1_homoced) <span class="sc">+</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  see<span class="sc">::</span><span class="fu">theme_lucid</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="c11_rls_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>reg1_homoced</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>OK: Error variance appears to be homoscedastic (p = 0.206).</code></pre>
</div>
</div>
<ol start="4" type="1">
<li><strong>Influential Observations</strong>: Este es otro gr√°fico diagn√≥stico que no hab√≠a mencionado porque no est√° directamente relacionado con los supuestos. Este gr√°fico se conoce como <strong>gr√°fico de apalancamiento</strong>, y se√±ala observaciones que pudieran estar ‚Äúenga√±ando‚Äù o afectando de manera importante la estimaci√≥n de la recta. En otras palabras, que ‚Äújalen‚Äù la recta hacia ellos, por estar extremadamente lejos de la tendencia central de <span class="math inline">\(y\)</span> para ese punto <span class="math inline">\(x\)</span>. En menos palabras: nos permite identificar ‚Äúoutliers‚Äù. Hay una gran cantidad de m√©todos, y la funci√≥n <code>performance::check_outliers()</code> califica cada valor con una nota compuesta por el promedio de los resultados binarios (‚Äúoutlier‚Äù o no, 1 o 0) de cada m√©todo. Representa la probabilidad de que cada observaci√≥n sea clasificada como ‚Äúoutlier‚Äù por al menos un m√©todo. Se considera un ‚Äúoutlier‚Äù si su calificaci√≥n es superior o igual a 0.5 (l√≠neas verdes punteadas); es decir, vamos a buscar puntos que est√©n fuera del ‚Äúcono‚Äù formado por los contornos. En este caso ninguno est√° fuera del contorno, pero el punto 1 se ve sospechoso.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>reg1_outliers <span class="ot">&lt;-</span> performance<span class="sc">::</span><span class="fu">check_outliers</span>(reg1)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(reg1_outliers)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="c11_rls_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ol start="5" type="1">
<li><strong>Normality</strong>: Por √∫ltimo, el gr√°fico de normalidad. No es de sorprender que tengamos ‚Äúdesviaciones de la normalidad‚Äù bastante marcadas en algunos puntos, especialmente cerca de la cola derecha de la distribuci√≥n. La prueba de normalidad de los residuales tambi√©n rechaza que se cumpla el supuesto.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>reg1_norm <span class="ot">&lt;-</span> performance<span class="sc">::</span><span class="fu">check_normality</span>(reg1)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(reg1_norm, <span class="at">type =</span> <span class="st">"qq"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>For confidence bands, please install `qqplotr`.</code></pre>
</div>
<div class="cell-output-display">
<p><img src="c11_rls_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>reg1_norm</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Warning: Non-normality of residuals detected (p &lt; .001).</code></pre>
</div>
</div>
<p>Independientemente de mi ‚Äúbullying‚Äù al <span class="math inline">\(R^2\)</span>, ahora ya sabes todo lo que implica hacer una regresi√≥n lineal simple, y que es mucho m√°s que simplemente picar botones en alguna suite estad√≠stica o utilizar la funci√≥n <code>lm</code> en <code>R</code> o alguna otra funci√≥n en otro lenguaje de programaci√≥n.</p>
</section>
<section id="predicci√≥n-vs.-interpretaci√≥n" class="level3" data-number="11.4.3">
<h3 data-number="11.4.3" class="anchored" data-anchor-id="predicci√≥n-vs.-interpretaci√≥n"><span class="header-section-number">11.4.3</span> Predicci√≥n vs.&nbsp;Interpretaci√≥n</h3>
<p>Ahora bien, mencion√© en varias ocasiones cosas relacionadas con la ‚Äúpredicci√≥n‚Äù y la ‚Äúinterpretaci√≥n‚Äù. Pues resulta que, como vimos arriba, para fines predictivos no importan demasiado los supuestos, y antes de que agarres un trinche y una antorcha escucha lo que tengo que decir. Antes te dije que la regresi√≥n forma parte del aprendizaje automatizado supervisado y, como tal, su principal (por no decir √∫nico) objetivo es la predicci√≥n. Un modelo de regresi√≥n exitoso es un modelo que pueda predecir adecuadamente, punto. ¬øY la interpretaci√≥n? Esa es otra cara de la moneda. De hecho, est√°n inversamente correlacionadas, en el sentido de que entre m√°s poderosa es una t√©cnica, menos interpretable es. De todos estos detalles vamos a hablar m√°s adelante en el <a href="c17_clasif.html"><span>Cap√≠tulo&nbsp;17</span></a>, pero por el momento quiero que te quedes con lo siguiente:</p>
<div class="callout callout-style-default callout-important callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Importante
</div>
</div>
<div class="callout-body-container callout-body">
<p>La validaci√≥n de supuestos es solo necesaria si nos interesa explicar los par√°metros del modelo, no si solo nos interesan sus predicciones.</p>
</div>
</div>
<p>Sin ir demasiado lejos, el modelo que construimos arriba no cumple con el supuesto de normalidad (los dem√°s est√°n en la cuerda floja) y a√∫n as√≠ las predicciones posteriores (en el <em>posterior predictive check</em>) se ven bastante aceptables. Desafortunadamente para nostros, usualmente nos interesa la interpretaci√≥n, as√≠ que hay que hacer la tarea completa.</p>
<p>¬øY si solo me interesan las predicciones? Bueno, igual hay que verificar algunas cosas, pero eso lo veremos en el <a href="c17_clasif.html"><span>Cap√≠tulo&nbsp;17</span></a>.</p>
</section>
<section id="m√°xima-verosimilitud" class="level3" data-number="11.4.4">
<h3 data-number="11.4.4" class="anchored" data-anchor-id="m√°xima-verosimilitud"><span class="header-section-number">11.4.4</span> M√°xima verosimilitud</h3>
<p>Bueno, ya sabemos c√≥mo aplicar, interpretar, y validar los supuestos de una regresi√≥n lineal en <code>R</code> utilizando el m√©todo de m√≠nimos cuadrados, pero antes te mencion√© que tambi√©n hab√≠a otros m√©todos entre los que se encuentra el <strong>ajuste por m√°xima verosimilitud</strong>. Entonces es necesario explicar qu√© es la verosimilitud para luego ver c√≥mo maximizarla, ¬øno crees?</p>
<p>Recordemos por un momento lo que revisamos en el <a href="c06_prob.html"><span>Cap√≠tulo&nbsp;6</span></a> sobre la probabilidad. Dijimos que, cuando tenemos resultados mutuamente excluyentes y exhaustivos (todos los resultados), la suma de todas sus probabilidades es exactamente 1, tal que:</p>
<p><span class="math display">\[
\sum_i^n p_i == 1
\]</span></p>
<p>Hasta aqu√≠ todo bien, pero ¬ød√≥nde entra la <strong>verosimilitud</strong>? Si buscas en el diccionario de la Real Academia Espa√±ola te vas a encontrar con una de sus siempre √∫tiles definiciones: ‚ÄúCualidad de veros√≠mil‚Äù, por lo que hay que definir veros√≠mil: ‚Äú<strong>que tiene apariencia de verdadero</strong>‚Äù. Eso ya tiene m√°s sentido. En un escenario de investigaci√≥n nosotros podemos plantear m√∫ltiples hip√≥tesis, que no son necesariamente excluyentes entre s√≠, entonces no podemos simplemente utilizar la probabilidad. Entendamos la verosimilitud con un ejemplo:</p>
<p>Imagina que alguien a quien conoces te dice que uno de sus amigos tiene poderes ps√≠quicos. T√∫, como persona de ciencia, decides ponerlo a prueba. Acuerdan una reuni√≥n y le pones un ‚Äúdesaf√≠o‚Äù simple: vas a lanzar diez volados, y el debe de adivinar el resultado. Al final, √©l adivina correctamente 7/10 volados. Sin dejarte llevar por tu escepticismo planteas algunas hip√≥tesis: i) simple coincidencia, el tama√±o de muestra no es lo suficientemente grande; ii) la moneda no es del todo ‚Äújusta‚Äù, sino que tiende a caer m√°s hacia cierto lado; iii) esta persona tiene una visi√≥n cin√©tica sobre-humana y puede ver qu√© es lo que est√° arriba antes de que atrapes la moneda, iv) esta persona realmente tiene algo de clarividente. ¬øCu√°l crees que sea m√°s veros√≠mil? Espero que me digas que la primera hip√≥tesis, especialmente despu√©s de lo que vimos en el <a href="c06_prob.html"><span>Cap√≠tulo&nbsp;6</span></a>. Si por el contrario hubieran sido 1000 lanzamientos y hubiera adivinado 700, la historia ser√≠a otra, pero con 7/10 puede ser un capricho del mundo. Eso que hicimos fue, justamente, un ajuste por <strong>m√°xima verosimilitud</strong>: <strong>seleccionar la hip√≥tesis m√°s veros√≠mil de entre un conjunto dado</strong>, solo que vamos a cambiar hip√≥tesis por valores de par√°metros.</p>
<p>¬øFormalmente? Un ajuste por m√°xima verosimilitud consiste en <strong>estimar par√°metros</strong> de un modelo, dado un conjunto de observaciones, en donde se encuentra <strong>valores que maximicen la verosimilitud de las observaciones dados los valores de los par√°metros</strong>. Puesto de otra manera, buscamos el conjunto de valores que maximicen la probabilidad de que nos hayamos encontrado nuestros datos, seg√∫n el modelo que escogimos. Esto se parece mucho a lo que vimos en el <a href="c09_ph0.html"><span>Cap√≠tulo&nbsp;9</span></a> sobre el nivel de significancia, solo que nuestro modelo ‚Äúdeja de ser una distribuci√≥n de probabilidades‚Äù para ser un modelo de regresi√≥n. ¬øPor qu√© las comillas? Porque nuestro error no puede quedar ‚Äúsuelto‚Äù, pero en m√°xima verosimilitud podemos trabajar con <strong>cualquier distribuci√≥n de probabilidad que se ajuste a nuestro problema</strong>; de hecho, esto es lo que da lugar a los <strong>modelos lineales generalizados</strong>, pero eso lo veremos en el <a href="c19_glm.html"><span>Cap√≠tulo&nbsp;19</span></a>.</p>
<p>¬øC√≥mo lo llevamos a la pr√°ctica? Primero quiero que te des la oportunidad de ver una relaci√≥n interesante que puede ahorrarte mucho trabajo, o que puede abrirte la puerta a otro tipo de an√°lisis.</p>
<section id="m√≠nimos-cuadrados-m√°xima-verosimilitud-e-inferencia-bayesiana" class="level4" data-number="11.4.4.1">
<h4 data-number="11.4.4.1" class="anchored" data-anchor-id="m√≠nimos-cuadrados-m√°xima-verosimilitud-e-inferencia-bayesiana"><span class="header-section-number">11.4.4.1</span> M√≠nimos cuadrados, m√°xima verosimilitud e inferencia Bayesiana</h4>
<p>Esta parte es completamente te√≥rica y asumo que el ver procedimientos algebraicos no te supone un problema. De no ser as√≠, puedes saltar al final para obtener la idea clave. Si decides que te interesa, vamos all√°.</p>
<p>Recordemos que un problema de <strong>regresi√≥n</strong> consiste en <strong>estimar los par√°metros de un modelo matem√°tico dado un conjunto de observaciones</strong>, y que tenemos una gran diversidad de formas de hacerlo. Comencemos hablando del m√©todo de ajuste m√°s com√∫n para una RLS: <strong>m√≠nimos cuadrados</strong>. Como mencion√© antes, con este m√©todo <strong>minimizamos</strong> la <strong>funci√≥n de p√©rdida cuadr√°tica</strong>; es decir:</p>
<p><span class="math display">\[\begin{align*}
\epsilon = y - \hat{y}\\
L = \epsilon^2
\end{align*}\]</span></p>
<p>Cuando utilizamos este m√©todo <strong>asumimos</strong> algunas cosas, entre ellas que nuestros <strong>residuales</strong> (no nuestra variable) se encuentran <strong>normalmente distribuidos</strong>. Aunque este m√©todo funciona, se prefiere utilizar m√©todos probabil√≠sticos <span class="citation" data-cites="Gerrodette_2011">(<a href="references.html#ref-Gerrodette_2011" role="doc-biblioref">Gerrodette, 2011</a>)</span>, tal como la aproximaci√≥n por <strong>m√°xima verosimilitud</strong>. Antes utilizamos un ejemplo pr√°ctico para definirla, pero ahora aproxim√©mosla desde el <strong>teorema de Bayes</strong>:</p>
<p><span class="math display">\[
p(\theta|x) = \frac{p(x|\theta)p(\theta)}{p(x)}
\]</span></p>
<p>Que podemos simplificar como:</p>
<p><span class="math display">\[
Posterior = \frac{verosimilitud \times previa}{evidencia}
\]</span></p>
<p>El teorema de Bayes es lo que da lugar al <strong>parad√≠gma de la inferencia Bayesiana</strong>, el cual no vemos en este curso; sin embargo explicar el teorema es bastante sencillo: <strong>¬øqu√© tan probable es una hip√≥tesis (<span class="math inline">\(\theta\)</span>), dada cierta evidencia (datos, <span class="math inline">\(x\)</span>)? (probabilidad posterior, <span class="math inline">\(p(\theta|x)\)</span>)</strong>. Para responderlo vamos a obtener la <strong>relaci√≥n que hay entre qu√© tan probable es la evidencia, dada la hip√≥tesis (<span class="math inline">\(p(x|\theta)\)</span>, nuestra verosimilitud), qu√© tan probable creamos nosotros que es nuestra hip√≥tesis (probabilidad previa, <span class="math inline">\(p(\theta)\)</span>) y la probabilidad de la evidencia en s√≠ misma (<span class="math inline">\(p(x)\)</span>)</strong>. Obtener la probabilidad de la evidencia es un tema en s√≠ mismo (en realidad solo la aproximamos), as√≠ que lo vamos a obviarla de la ecuaci√≥n. Recordar√°s que en la inferencia estad√≠stica frecuentista partimos del hecho de que <strong>no sabemos nada</strong> sobre nuestro problema, y podemos entonces, al menos de manera te√≥rica, establecer eso en el teorema de Bayes, lo cual nos lleva a <strong>cancelar nuestros t√©rminos de previa y evidencia</strong> y terminar con la siguiente equivalencia:</p>
<p><span class="math display">\[
Posterior \equiv verosimilitud
\]</span></p>
<p>Este <strong>caso especial</strong> de la <strong>inferencia Bayesiana</strong> tiene un nombre: <strong>Estimaci√≥n M√°xima A posteriori</strong> (Maximum A posteriori Estimate, MAP) y es <strong>equivalente a la estimaci√≥n puntual de un ajuste por m√°xima verosimilitud</strong>. ¬øPor qu√©? Porque en esa aproximaci√≥n tratamos de encontrar valores de nuestros par√°metros que maximicen la verosimilitud de las observaciones, dados los par√°metros. De manera matem√°tica definimos la equivalencia como:</p>
<p><span class="math display">\[
p(x|\theta) \equiv L(\theta|x) \implies p(x_1, x_2, ..., x_n|\theta)
\]</span></p>
<p>Otro de nuestros supuestos en este paradigma es que las muestras son independientes entre s√≠, por lo que podemos expandir nuestra probabilidad conjunta con <span class="math inline">\(P(A,B) = P(A)P(B)\)</span>:</p>
<p><span class="math display">\[
L(\theta|x_1, x_2, ..., x_n) \equiv p(x_1|\theta)p(x_2|\theta),...,p(x_n|\theta)= \prod p(x_i|\theta)
\]</span></p>
<p>Y este t√©rmino es lo que queremos maximizar, por lo cual lo podemos escribir tal que:</p>
<p><span class="math display">\[
\begin{matrix} max \\ \theta \end{matrix}
\left\{ \prod p(x_i|\theta) \right\}
\]</span></p>
<p>El problema es que ni a nosotros ni a las computadoras nos gusta hacer multiplicaciones, por lo que podemos aplicar un logaritmo para convertir el productorio en una sumatoria. Recuerda: el logaritmo de un producto es igual a la suma del logaritmo de cada uno de sus componentes, por lo tanto:</p>
<p><span class="math display">\[
\begin{matrix} max \\ \theta \end{matrix}
\left\{ log \left( \prod p(x_i|\theta) \right) \right\} \implies
\begin{matrix} max \\ \theta \end{matrix}
\left\{ \sum_i^n log(p(x_i|\theta)) \right\}
\]</span></p>
<p>Esta √∫ltima parte era un poco innecesaria, nada m√°s que un breviario cultural para que conocieras por qu√© utilizamos logaritmos de verosimilitud, cosa que haremos m√°s adelante, pero ahora vayamos al meollo del asunto:</p>
<div class="callout callout-style-default callout-important callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Importante
</div>
</div>
<div class="callout-body-container callout-body">
<p>Uno de los supuestos del ajuste por m√≠nimos cuadrados es un error normalmente distribuido. En m√°xima verosimilitud podemos ajustar nuestro error a cualquier distribuci√≥n de probabilidad. Si utilizamos a la distribuci√≥n normal como la distribuci√≥n del error, entonces <strong>m√≠nimos cuadrados, m√°xima verosimilitud (distribuci√≥n normal) e inferencia Bayesiana (verosimilitud normal y previas muy planas)</strong> dan <strong>estimaciones equivalentes</strong>.</p>
</div>
</div>
</section>
<section id="ajuste-por-m√°xima-verosimilitud" class="level4" data-number="11.4.4.2">
<h4 data-number="11.4.4.2" class="anchored" data-anchor-id="ajuste-por-m√°xima-verosimilitud"><span class="header-section-number">11.4.4.2</span> Ajuste por m√°xima verosimilitud</h4>
<p>En este punto puedes estar en uno de estos escenarios: a) lograste seguir toda la explicaci√≥n y se te hizo l√≥gica (si fue as√≠, ¬°felicidades! Eres un tan √±o√±o o √±o√±a como yo); b) seguiste la explicaci√≥n y se te hizo l√≥gica, pero no terminaste de entender el teorema de Bayes (igualmente, ¬°felicidades! Vas para √±o√±o/√±o√±a que chutas); c) lo le√≠ste pero te perdiste solo con las ecuaciones (tambi√©n ¬°felicidades!, tienes la intenci√≥n de convertirte en √±o√±o/√±o√±a); o d) saltaste directamente a lo importante (¬°felicidades a ti tambi√©n! Tienes una vida ü•≤). Si est√°s en los casos c y d, y puede que b seguramente no est√©s del todo convencido de que m√≠nimos cuadrados y m√°xima verosimlitud con un error normal sean equivalentes. Si est√°s en el caso a, te gustar√≠a una demostraci√≥n. ¬øY si no te interesa? Igual la vamos a hacer.</p>
<p>A diferencia de la implementaci√≥n de una regresi√≥n por m√≠nimos cuadrados, ajustar el modelo mediante m√°xima verosimilitud no es tan intuitivo. El primer paso es establecer manualmente nuestra funci√≥n de verosimilitud, ajustando una distribuci√≥n normal a los residuales:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> df_reg1[<span class="fu">c</span>(<span class="st">"v1"</span>, <span class="st">"v2"</span>)]</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>LL <span class="ot">&lt;-</span> <span class="cf">function</span>(b0, b1, mu, sigma){</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Encontrar los residuales. Modelo a ajustar</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>  R <span class="ot">=</span> data<span class="sc">$</span>v2 <span class="sc">-</span> data<span class="sc">$</span>v1 <span class="sc">*</span> b1 <span class="sc">-</span> b0</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calcular la verosimilitud. Residuales con distribuci√≥n normal.</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>  R <span class="ot">=</span> <span class="fu">suppressWarnings</span>(<span class="fu">dnorm</span>(R, mu, sigma))</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sumar el logaritmo de las verosimilitudes para</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># todos los puntos de datos.</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>  <span class="sc">-</span><span class="fu">sum</span>(<span class="fu">log</span>(R))</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ahora ajustemos el modelo que acabamos de crear, utilizando la funci√≥n <code>stats4::mle(fun, start = list())</code> (*maximum likelihood estimation), donde <code>fun</code> es la funci√≥n de verosimilitud a ajustar y <code>start</code> son los valores iniciales de los par√°metros. En este paso lo que estamos haciendo es estimar los dos par√°metros (media y desviaci√≥n est√°ndar) que mejor describen los datos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>mle_fit <span class="ot">&lt;-</span> <span class="fu">mle</span>(LL, <span class="at">start =</span> <span class="fu">list</span>(<span class="at">b0 =</span> <span class="dv">1</span>, <span class="at">b1 =</span> <span class="dv">1</span>, <span class="at">sigma =</span> <span class="dv">1</span>), </span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>               <span class="at">fixed =</span> <span class="fu">list</span>(<span class="at">mu =</span> <span class="dv">0</span>), </span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">nobs =</span> <span class="fu">length</span>(data<span class="sc">$</span>v2))</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mle_fit)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Maximum likelihood estimation

Call:
mle(minuslogl = LL, start = list(b0 = 1, b1 = 1, sigma = 1), 
    fixed = list(mu = 0), nobs = length(data$v2))

Coefficients:
       Estimate Std. Error
b0    -3.726537 0.72453828
b1     1.177649 0.08056368
sigma  3.063056 0.21991454

-2 log L: 492.4402 </code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Hay que definir valores iniciales para los par√°metros porque, a diferencia de por m√≠nimos cuadrados, el proceso de minimizaci√≥n del negativo de la suma del logaritmo de la verosimilitud es <strong>iterativo</strong> mediante un algoritmo de b√∫squeda. El m√°s com√∫n es el algoritmo de b√∫squeda de Newton-Raphson (o Newton-Fourier). ¬øA qu√© me refiero con iterativo? A que la computadora variar√° los par√°metros hasta llegar a la soluci√≥n ‚Äúoptima‚Äù:</p>
<div id="fig-iterative" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/iterative.gif" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;11.5: Ajuste iterativo de par√°metros</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Esta salida fue un poco m√°s simple que la salida de la funci√≥n <code>lm()</code> pero, ¬øfue de diferente la estimaci√≥n? Si vemos los coeficientes de nuestro ajuste por m√≠nimos cuadrados veremos que la estimaci√≥n puntual es la misma, y los errores est√°ndares son pr√°cticamente iguales:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reg1)<span class="sc">$</span>coefficients</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             Estimate Std. Error   t value     Pr(&gt;|t|)
(Intercept) -3.726537 0.73212521 -5.090027 1.805160e-06
v1           1.177649 0.08140729 14.466134 9.513254e-26</code></pre>
</div>
</div>
<p>Adem√°s, el error est√°ndar de la estimaci√≥n por m√≠nimos cuadrados es pr√°cticamente igual al <code>sigma</code> de la estimaci√≥n por m√°xima verosimilitud:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reg1)<span class="sc">$</span>sigma</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.095131</code></pre>
</div>
</div>
<p>Moraleja: no utilices estimaci√≥n por m√°xima verosimilitud si vas a utilizar una distribuci√≥n normal. Lo √∫nico que ganas es hacer pasos adicionales. ¬øC√≥mo utilizar otras distribuciones? Eso lo veremos a detalle en el <a href="c19_glm.html"><span>Cap√≠tulo&nbsp;19</span></a>.</p>
</section>
</section>
</section>
<section id="correlaci√≥n-y-covarianza" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="correlaci√≥n-y-covarianza"><span class="header-section-number">11.5</span> Correlaci√≥n y covarianza</h2>
<p>S√© que la sesi√≥n hasta este momento ha sido larga y tediosa, pero el tema de regresi√≥n merece entrar a la teor√≠a para no obtener conclusiones equivocadas. Dejemos de lado esa parte y cerremos hablando de dos conceptos relacionados: la correlaci√≥n y la covarianza.</p>
<p>La <strong>covarianza</strong> nos indica <strong>c√≥mo var√≠a una variable en relaci√≥n a otra</strong>. La <strong>correlaci√≥n</strong> describe <strong>la relaci√≥n entre dos variables</strong>. Ya me imagino la expresi√≥n de confusi√≥n que tienes mientras te preguntas ¬øentonces son lo mismo? Pues no, la diferencia es que la <strong>correlaci√≥n</strong> es un <strong>√≠ndice</strong>; es decir, est√° contenida en el intervalo <span class="math inline">\([-1, 1]\)</span>, por lo que esta mide no solo la direcci√≥n, sino la ‚Äúfuerza‚Äù o el grado de linealidad de la relaci√≥n, donde 0 es una relaci√≥n lineal nula. Matem√°ticamente la diferencia es que la correlaci√≥n entre dos variables es su covarianza dividida entre el producto de sus desviaciones est√°ndar:</p>
<p><span class="math display">\[\begin{align*}
cov(X,Y) = \frac{\Sigma_{i=1}^n(X_i-\bar{X})(Y_i-\bar{Y})}{n-1} \\
cor(X,Y) = \frac{cov(X,Y)}{\sigma_x * \sigma_y}
\end{align*}\]</span></p>
<p>Es decir, son conceptos que est√°n muy relacionados entre s√≠. En ambos el <strong>signo</strong> del valor indica la <strong>direcci√≥n de la relaci√≥n</strong>, mientras que la <strong>magnitud</strong> indica la <strong>fuerza</strong> de la relaci√≥n. El problema con la covarianza es que no tiene l√≠mites, entonces no puedes saber si una covarianza de 500 es particularmente grande salvo que tengas otra covarianza con la cual comparar, mientras que una correlaci√≥n de 0.7 es una correlaci√≥n moderadamente fuerte.</p>
<p>Muy seguramente por tu cabeza haya pasado la pregunta: ‚Äúsi ambas nos dicen c√≥mo es la relaci√≥n entre dos variables, ¬øcu√°l es la diferencia con la regresi√≥n?‚Äù. Pues que la <strong>regresi√≥n es un modelo predictivo</strong>, mientras que la <strong>correlaci√≥n/covarianza es un estad√≠stico descriptivo</strong>. Aqu√≠ no estamos comprometiendo que haya una tasa de cambio de <span class="math inline">\(X\)</span> hacia <span class="math inline">\(Y\)</span>, ni estamos interesados en qu√© valor de <span class="math inline">\(X\)</span> le corresponde a <span class="math inline">\(y = 0\)</span>. Aqu√≠ <strong>no nos interesa predecir, sino describir</strong>. Si no quieres comprometerte con todo lo que implica un modelo predictivo (a√∫n nos falt√≥ ver el tema del sobre-ajuste), solo calcula el <strong>coeficiente de correlaci√≥n</strong> correspondiente.</p>
<p>¬øPor qu√© correspondiente? Porque tenemos m√°s de una forma de calcular la correlaci√≥n, y cada una tiene sus bemoles. La ecuaci√≥n que vimos arriba es para el <strong>coeficiente de correlaci√≥n de Pearson</strong>, el cual elevado al cuadrado nos da el coeficiente de determinaci√≥n que vimos antes. Como tal, es un coeficiente <strong>param√©trico</strong> y tiene algunos supuestos:</p>
<ol type="1">
<li><strong>Variables en escala de intervalo o raz√≥n</strong></li>
<li><strong>Relaci√≥n lineal</strong> entre ambas variables. S√≠, asume que el cambio de una variable a otra es constante.</li>
<li><strong>Normalidad</strong> Ambas variables deben de tener una distribuci√≥n aproximadamente normal, por lo que aqu√≠ s√≠ nos interesa la distribuci√≥n de nuestras variables.</li>
<li>Cada observaci√≥n debe de tener el par de datos <span class="math inline">\((v1, v2)\)</span>.</li>
</ol>
<p>Estos supuestos, a estas alturas, son autoexplicativos. ¬øQu√© pasa si no cumplimos con alguno de los primeros tres? Podemos utilizar la alternativa <strong>no param√©trica</strong>: el coeficiente de correlaci√≥n <span class="math inline">\(\rho\)</span> de Spearman. En este los supuestos son:</p>
<ol type="1">
<li><strong>Variables al menos en escala ordinal</strong></li>
<li><strong>Relaci√≥n mon√≥tona entre ambas variables</strong>; es decir, que la relaci√≥n vaya en un solo sentido (conforme aumenta una aumenta la otra, o conforme aumenta la otra disminuye), independientemente de que la tasa de cambio de una a otra no sea constante.</li>
<li>Cada observaci√≥n debe de tener el par de datos <span class="math inline">\((v1, v2)\)</span></li>
</ol>
<p>Bastante m√°s relajado, ¬øno? Pero esto no quiere decir que solo debas de utilizar este coeficiente, utiliza el que m√°s se ajuste a tus datos particulares.</p>
<div class="callout callout-style-default callout-note callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>En el <a href="c12_nopar.html"><span>Cap√≠tulo&nbsp;12</span></a> vamos a hablar de las t√©cnicas no param√©tricas y sus ventajas y desventajas con respecto a las t√©cnicas param√©tricas.</p>
</div>
</div>
<p>Ahora bien, ¬øc√≥mo obtenemos estos coeficientes en <code>R</code>? Muy sencillo, con las funciones <code>cor(X, Y)</code> y <code>cov(X, Y)</code>:</p>
<div class="callout callout-style-default callout-note callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Estos coeficientes son sim√©tricos, por lo que asignar variables <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span> como dependientes e independientes es un error. ¬øNotaste que arriba todo lo puse en t√©rminos de <span class="math inline">\(v1\)</span> y <span class="math inline">\(v2\)</span>?</p>
</div>
</div>
<p>Primero, generemos un par de variables donde la segunda sea una funci√≥n lineal de la primera:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>df1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">v1 =</span> <span class="sc">-</span><span class="dv">20</span><span class="sc">:</span><span class="dv">20</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>df1[<span class="st">"v2"</span>] <span class="ot">&lt;-</span> (<span class="dv">10</span><span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>df1<span class="sc">$</span>v1)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>df1</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["v1"],"name":[1],"type":["int"],"align":["right"]},{"label":["v2"],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"-20","2":"-30"},{"1":"-19","2":"-28"},{"1":"-18","2":"-26"},{"1":"-17","2":"-24"},{"1":"-16","2":"-22"},{"1":"-15","2":"-20"},{"1":"-14","2":"-18"},{"1":"-13","2":"-16"},{"1":"-12","2":"-14"},{"1":"-11","2":"-12"},{"1":"-10","2":"-10"},{"1":"-9","2":"-8"},{"1":"-8","2":"-6"},{"1":"-7","2":"-4"},{"1":"-6","2":"-2"},{"1":"-5","2":"0"},{"1":"-4","2":"2"},{"1":"-3","2":"4"},{"1":"-2","2":"6"},{"1":"-1","2":"8"},{"1":"0","2":"10"},{"1":"1","2":"12"},{"1":"2","2":"14"},{"1":"3","2":"16"},{"1":"4","2":"18"},{"1":"5","2":"20"},{"1":"6","2":"22"},{"1":"7","2":"24"},{"1":"8","2":"26"},{"1":"9","2":"28"},{"1":"10","2":"30"},{"1":"11","2":"32"},{"1":"12","2":"34"},{"1":"13","2":"36"},{"1":"14","2":"38"},{"1":"15","2":"40"},{"1":"16","2":"42"},{"1":"17","2":"44"},{"1":"18","2":"46"},{"1":"19","2":"48"},{"1":"20","2":"50"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>Ahora obtengamos la covarianza:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>covar <span class="ot">&lt;-</span> <span class="fu">cov</span>(df1<span class="sc">$</span>v1, df1<span class="sc">$</span>v2)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>covar</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 287</code></pre>
</div>
</div>
<p>Y el √≠ndice de correlaci√≥n de <code>Pearson</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>corre <span class="ot">&lt;-</span> <span class="fu">cor</span>(df1<span class="sc">$</span>v1, df1<span class="sc">$</span>v2)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>corre</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
</div>
<p>Aqu√≠ queda tambi√©n demostrado por qu√© la covarianza es tan dif√≠cil de interpretar por s√≠ sola, pues en este caso con una relaci√≥n lineal perfecta fue de 287, pero si cambias los valores de <code>v1</code> de alguna manera vas a obtener otro valor, mientras que la correlaci√≥n seguir√° siendo 1. Gr√°ficamente:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> df1, <span class="fu">aes</span>(<span class="at">x =</span> v1, <span class="at">y =</span> v2)) <span class="sc">+</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">colour =</span> <span class="st">"dodgerblue4"</span>, <span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Relaci√≥n entre v2 y v1"</span>) <span class="sc">+</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">15</span>, <span class="at">y =</span> <span class="dv">0</span>,</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"R = "</span>, <span class="fu">round</span>(corre, <span class="dv">2</span>))) <span class="sc">+</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">15</span>, <span class="at">y =</span> <span class="sc">-</span><span class="dv">5</span>,</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"Cov. = "</span>, <span class="fu">round</span>(covar, <span class="dv">2</span>))) <span class="sc">+</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>  see<span class="sc">::</span><span class="fu">theme_lucid</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="c11_rls_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>¬øQu√© pasa cuando nos alejamos de esta relaci√≥n lineal?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>df1[<span class="st">"v3"</span>] <span class="ot">&lt;-</span> (<span class="sc">-</span>df1<span class="sc">$</span>v1<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>corre <span class="ot">&lt;-</span> <span class="fu">cor</span>(df1<span class="sc">$</span>v1, df1<span class="sc">$</span>v3)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>covar <span class="ot">&lt;-</span> <span class="fu">cor</span>(df1<span class="sc">$</span>v1, df1<span class="sc">$</span>v3)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> df1, <span class="fu">aes</span>(<span class="at">x =</span> v1, <span class="at">y =</span> v3)) <span class="sc">+</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">colour =</span> <span class="st">"dodgerblue4"</span>, <span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Relaci√≥n entre v2 y v1"</span>) <span class="sc">+</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">15</span>, <span class="at">y =</span> <span class="dv">0</span>,</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"R = "</span>, <span class="fu">round</span>(corre, <span class="dv">2</span>))) <span class="sc">+</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">15</span>, <span class="at">y =</span> <span class="sc">-</span><span class="dv">50</span>,</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"Cov. = "</span>, <span class="fu">round</span>(covar, <span class="dv">2</span>))) <span class="sc">+</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>  see<span class="sc">::</span><span class="fu">theme_lucid</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="c11_rls_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Otro ejemplo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>df1[<span class="st">"v4"</span>] <span class="ot">&lt;-</span> <span class="fu">sin</span>(df1<span class="sc">$</span>v1)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>corre <span class="ot">&lt;-</span> <span class="fu">cor</span>(df1<span class="sc">$</span>v1, df1<span class="sc">$</span>v4)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>covar <span class="ot">&lt;-</span> <span class="fu">cor</span>(df1<span class="sc">$</span>v1, df1<span class="sc">$</span>v4)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> df1, <span class="fu">aes</span>(<span class="at">x =</span> v1, <span class="at">y =</span> v4)) <span class="sc">+</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">colour =</span> <span class="st">"dodgerblue4"</span>, <span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Relaci√≥n entre v2 y v1"</span>) <span class="sc">+</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">15</span>, <span class="at">y =</span> <span class="dv">3</span>,</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"R = "</span>, <span class="fu">round</span>(corre, <span class="dv">2</span>))) <span class="sc">+</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">15</span>, <span class="at">y =</span> <span class="dv">2</span>,</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"Cov. = "</span>, <span class="fu">round</span>(covar, <span class="dv">2</span>))) <span class="sc">+</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">expand_limits</span>(<span class="at">y =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="sc">-</span><span class="dv">3</span>)) <span class="sc">+</span></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>  see<span class="sc">::</span><span class="fu">theme_lucid</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="c11_rls_files/figure-html/unnamed-chunk-26-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Aunque todas estas relaciones pueden ser predichas, un coeficiente de correlaci√≥n lineal no es capaz de capturarlas y, por definici√≥n, tampoco un modelo de regresi√≥n lineal. ¬øQu√© hacer en estos casos? Veremos algunas alternativas en el <a href="c13_nolin.html"><span>Cap√≠tulo&nbsp;13</span></a>. Ahora ejemplifiquemos el coeficiente de correlaci√≥n de Spearman. Primero, y para dejar m√°s claro el concepto, veamos la diferencia entre una relaci√≥n mon√≥tona y una no mon√≥tona:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>df2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">v1 =</span> df1<span class="sc">$</span>v1[df1<span class="sc">$</span>v1 <span class="sc">&gt;</span> <span class="dv">0</span>], </span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">v2 =</span> df1<span class="sc">$</span>v1[df1<span class="sc">$</span>v1 <span class="sc">&gt;</span> <span class="dv">0</span>]<span class="sc">^</span><span class="dv">2</span>,</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">mono =</span> <span class="st">"mon√≥tona"</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>df2 <span class="ot">&lt;-</span> <span class="fu">rbind</span>(df2, <span class="fu">data.frame</span>(<span class="at">v1=</span> df1<span class="sc">$</span>v1, </span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>                             <span class="at">v2 =</span> df1<span class="sc">$</span>v3, </span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>                             <span class="at">mono =</span> <span class="st">"no mon√≥tona"</span>))</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> df2, <span class="fu">aes</span>(<span class="at">x =</span> v1, <span class="at">y =</span> v2)) <span class="sc">+</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">colour =</span> <span class="st">"dodgerblue4"</span>, <span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>mono, <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">scales =</span> <span class="st">"free_y"</span>) <span class="sc">+</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>  see<span class="sc">::</span><span class="fu">theme_lucid</span>() <span class="sc">+</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">aspect.ratio =</span> <span class="dv">1</span><span class="sc">/</span><span class="fl">1.61</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="c11_rls_files/figure-html/unnamed-chunk-27-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Y ahora calculemos los coeficientes de correlaci√≥n de Pearson y Spearman para la relaci√≥n mon√≥tona. La diferencia fue de 0.3, lo cual no es muy grande, pero conforme nos empezamos a alejar de escenarios ideales el coeficiente de Pearson empieza a perder sensibilidad y confiabilidad.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">paste</span>(<span class="st">"Pearson = "</span>,</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>      <span class="fu">round</span>((<span class="fu">cor</span>(df2<span class="sc">$</span>v1[df2<span class="sc">$</span>mono <span class="sc">==</span> <span class="st">"mon√≥tona"</span>],</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>                 df2<span class="sc">$</span>v2[df2<span class="sc">$</span>mono <span class="sc">==</span> <span class="st">"mon√≥tona"</span>], </span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">method =</span> <span class="st">"pearson"</span>)), <span class="dv">2</span>)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>      )</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Pearson =  0.97"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">paste</span>(<span class="st">"Spearman = "</span>,</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>      <span class="fu">round</span>((<span class="fu">cor</span>(df2<span class="sc">$</span>v1[df2<span class="sc">$</span>mono <span class="sc">==</span> <span class="st">"mon√≥tona"</span>],</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>                 df2<span class="sc">$</span>v2[df2<span class="sc">$</span>mono <span class="sc">==</span> <span class="st">"mon√≥tona"</span>], </span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">method =</span> <span class="st">"spearman"</span>)), <span class="dv">2</span>)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>      )</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Spearman =  1"</code></pre>
</div>
</div>
<p>Ya para cerrar, ¬øson estos los √∫nicos coeficientes de correlaci√≥n? Para nada, tenemos tambi√©n: <span class="math inline">\(\tau\)</span> de Kendall, <span class="math inline">\(\phi k\)</span> (<span class="citation" data-cites="Baaketal_2019">Baak et&nbsp;al. (<a href="references.html#ref-Baaketal_2019" role="doc-biblioref">2019</a>)</span>), V de Cramer, <a href="https://bit.ly/PPS_medium">Predictive Power Score</a> y el coeficiente de M√°xima Informaci√≥n (<span class="citation" data-cites="Reshefetal_2011">Reshef et&nbsp;al. (<a href="references.html#ref-Reshefetal_2011" role="doc-biblioref">2011</a>)</span>). Te invito a que leas m√°s sobre ellos, sus ventajas y sus desventajas. Predictive Power Score no es direccional, por ejemplo (<a href="#fig-pps">Figura&nbsp;<span>11.6</span></a>).</p>
<div id="fig-pps" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/pps.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;11.6: Predictive Power Score en una relaci√≥n parab√≥lica</figcaption><p></p>
</figure>
</div>
<p>Por fin llegamos al final de esta extensa (pero espero no aburrida) sesi√≥n. Espero que la hayas encontrado √∫til, y que te motive a hacer toda la chamba detr√°s de un modelo de predicci√≥n como lo es la regresi√≥n lineal simple.</p>
</section>
<section id="ejercicio" class="level2" data-number="11.6">
<h2 data-number="11.6" class="anchored" data-anchor-id="ejercicio"><span class="header-section-number">11.6</span> Ejercicio</h2>
<p>Aunque me encantar√≠a que para esta sesi√≥n no hubiera ejercicio, es importante que practiques lo que discutimos aqu√≠. El ejercicio que vas a realizar es realizar una regresi√≥n entre las variables <code>LT</code> (longitud total) y <code>AM</code> (altura m√°xima) de los datos de peces haem√∫lidos de los datos <code>Haem.csv</code>. Responde:</p>
<ol type="1">
<li>La regresi√≥n asume un cambio direccional entre las variables <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span>; es decir, el cambio en una modifica a la otra. ¬øCu√°l es la variable dependiente? ¬ø<code>LT</code> o <code>AM</code>? ¬øPor qu√©?</li>
<li>Calcula la correlaci√≥n entre ambas variables. ¬øQu√© coeficiente utilizas y por qu√©?</li>
<li>Realiza la regresi√≥n lineal simple. ¬øQu√© m√©todo de ajuste utilizas y por qu√©?</li>
<li>Reporta los resultados de la regresi√≥n (incluyendo el gr√°fico correspondiente).</li>
<li>Realiza la comprobaci√≥n de los supuestos. ¬øEs confiable el modelo para fines de predicci√≥n? ¬øY para interpretaci√≥n?</li>
</ol>


<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="doc-bibliography" style="display: none">
<div id="ref-Baaketal_2019" class="csl-entry" role="doc-biblioentry">
Baak M, Koopman R, Snoek H, Klous S. 2019. A new correlation coefficient between categorical, ordinal and interval variables with <span>Pearson</span> characteristics. <em>ArXiV</em>. DOI: <a href="https://doi.org/10.48550/arxiv.1811.11440">10.48550/arxiv.1811.11440</a>.
</div>
<div id="ref-Box_1976" class="csl-entry" role="doc-biblioentry">
Box GE. 1976. Science and Statistics. <em>Journal of the American Statistical Association</em> 71:791-799. DOI: <a href="https://doi.org/10.1080/01621459.1976.10480949">10.1080/01621459.1976.10480949</a>.
</div>
<div id="ref-BreuschPagan_1979" class="csl-entry" role="doc-biblioentry">
Breusch TS, Pagan AR. 1979. <a href="">A simple test for heteroscedasticity and random coefficient variation</a>. <em>Econometrica</em> 47:1287-1294.
</div>
<div id="ref-Gerrodette_2011" class="csl-entry" role="doc-biblioentry">
Gerrodette T. 2011. Inference without significance: measuring support for hypotheses rather than rejecting them. <em>Marine Ecology</em> 32:404-418. DOI: <a href="https://doi.org/10.1111/j.1439-0485.2011.00466.x">10.1111/j.1439-0485.2011.00466.x</a>.
</div>
<div id="ref-Reshefetal_2011" class="csl-entry" role="doc-biblioentry">
Reshef DN, Reshef YA, Finucane HK, Grossman SR, McVean G, Turnbaugh PJ, Lander ES, Mitzenmacher M, Sabeti PC. 2011. Detecting Novel Associations in Large Datasets. <em>Science</em> 334:1518-1524. DOI: <a href="https://doi.org/10.1126/science.1205438">10.1126/science.1205438</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./c10_param.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">T√©cnicas param√©tricas</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./s03_noparnolin.html" class="pagination-link">
        <span class="nav-page-text">T√©cnicas no param√©tricas y modelaci√≥n no lineal</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center">Copyright 2022, Dr.&nbsp;Plancton</div>
  </div>
</footer>



</body></html>