[
  {
    "objectID": "c05_ggplot2.html",
    "href": "c05_ggplot2.html",
    "title": "5  Principios de visualización de datos y ggplot2",
    "section": "",
    "text": "Como seres humanos, con una tendencia a encontrar el camino que ofrezca una menor resistencia (otra forma de decir que somos flojos), usualmente resumimos una realidad altamente compleja utilizando distintas estrategias. Si yo te pido que me digas “qué es una orca” puedes darme una descripción textual del tipo “las orcas son mamíferos del orden Cetartiodactyla”, una descripción numérica en forma de mediciones (Longitud: 6-8 m) o medidas de tendencia central/dispersión (Peso máximo: 5.5 toneladas), pero usualmente preferimos medios audiovisuales como un dibujo, un video o, en el caso de la investigación y el tema principal de hoy, gráficos."
  },
  {
    "objectID": "c05_ggplot2.html#datos-y-variables",
    "href": "c05_ggplot2.html#datos-y-variables",
    "title": "5  Principios de visualización de datos y ggplot2",
    "section": "5.2 Datos y variables",
    "text": "5.2 Datos y variables\nEn una investigación reunimos datos que después representamos con gráficos. Pues bien comencemos definiendo un dato como una representación puntual de la realidad. Son un solo valor, sea una sola medición, un promedio, una desviación estándar, una proporción de sexos, etc, y el conjunto de datos de un mismo atributo medidos en distintos individuos nos dan una variable. Es decir, en nuestros conjuntos de datos cada valor es un dato, y cada columna (usualmente) es una variable. ¿Por qué es importante conocer esto? Porque hay distintos tipos de variables, los cuales definen cómo es que vamos a graficar y tratar esos datos:\n\nCualitativas: hacen referencia a las cualidades de nuestros individuos, y tienen dos escalas:\n\nNominal: hace referencia a categorías en las que no hay un orden o distintas importancias. Ejemplos pueden el sexo o el color.\nOrdinal: aquí hay un órden, y un ejemplo muy claro son las encuestas: 0 es nunca, 1 es casi nunca, 2 es ocasionalmente, 3 es casi siempre y 4 es siempre. Aunque son categorías bien definidas, 2 < 3 y 3 < 4. No son cuantitativas porque las respuestas están sujetas a la interpretación personal, pero descartar el órden en el análisis sería un error.\n\nCuantitativas, que hacen referencia a atributos cuantificables de manera objetiva. Hay dos tipos, cada uno con dos escalas.\n\nTipos:\n\nDiscretas: Son solo números enteros. Un ejemplo cotidiano es la edad, que usualmente la expresamos en años. No vamos por la vida diciendo tengo 18.5 años o 18 años con 6 meses, solo decimos tengo 18 años.\nContinuas: Es el caso contrario, son números fraccionarios. Se les denomina continuas porque hay un número infinito de valores posibles entre un valor y el otro, un ejemplo es la temperatura (35.1ºC, 100 K, etc.)\n\nEscalas:\n\nIntervalo: La escala de intervalo es aquella en donde el 0 NO es absoluto o, mejor dicho, donde el 0 es arbitrario. La temperatura expresada en grados centígrados es un ejemplo claro, 0ºC no indica ausencia de movimiento molecular, solo toma como referencia arbitraria el punto de congelación del agua.\nRazón: Aquí el 0 sí es absoluto y representa la ausencia del atributo en cuestión. La longitud es un ejemplo, si algo tiene longitud 0 más bien no tiene longitud, o si algo tiene una temperatura de 0 K quiere decir que no tiene movimiento molecular (~-273.15ºC).\n\n\n\nAlgo que es muy importante tener siempre bien presente es que, aún cuando existen herramientas y técnicas que nos permiten procesar múltiples variables, en cualquier procedimiento de ciencia de datos es INDISPENSABLE que los datos sean de excelente calidad y, sobre todo, que sean adecuados para responder la pregunta que nos interesa, lo cual nos debe de llevar, invariablemente, a preguntarnos “¿qué datos debo de obtener?” O, en otras palabras, “¿qué debo medir?” Una frase que se me quedó marcada de mis clases de la licenciatura es “La investigación inicia y termina en el escritorio del investigador”; es decir, no salimos a hacer trabajo de campo y a registrar todo lo que se nos atraviese, caso contrario podemos terminar en una conclusión como “los bebés son traídos por cigüeñas”, la cual tiene una anécdota bastante divertida.\nSituémonos en"
  },
  {
    "objectID": "c05_ggplot2.html#introducción-a-ggplot2",
    "href": "c05_ggplot2.html#introducción-a-ggplot2",
    "title": "5  Principios de visualización de datos y ggplot2",
    "section": "5.3 Introducción a ggplot2",
    "text": "5.3 Introducción a ggplot2\nRecordarás de las primeras sesiones que un componente muy importante de R es la realización de gráficos, lo cual quiere decir que R base nos permite realizar visualizaciones de datos. De hecho, el graficador por defecto es sumamente potente, pero desafortunadamente no es precisamente intuitivo. En este sentido, la librería ggplot2 es una (¿mejor?) alternativa en la que los gráficos se crean de manera declarativa, y está basada en el libro “Grammar of Graphics” (Wilkinson 2005). Digo “¿mejor?” porque, como en todo, es una cuestión de gustos y costumbre; sin embargo, pedagógicamente es bastante amable. La creación de gráficos se realiza mediante capas, donde tenemos nuestros datos, en un data.frame, luego indicamos qué queremos que grafique y en dónde, luego cómo queremos que lo grafique, y luego cómo queremos los demás elementos. En código tendríamos algo así:\nggplot(data = datos, aes(x, y)) + geom_*() + ...\nPodría explicarte qué es cada cosa aquí, o podemos mejor aprender haciendo y crear una visualización. Antes de comenzar una visualización es necesario saber qué queremos responder con ella. En este caso, utilizaremos la base de datos mpg incluída en ggplot2. El primer paso es, entonces, conocer la información que contiene. Para ello guardaremos la base en una variable que llamaremos df1:\n\nlibrary(ggplot2)\n\ndf1 <- ggplot2::mpg\ndf1\n\n\n\n  \n\n\n\nUna manera rápida de tener una idea de cómo está dispuesta una base de datos es utilizando la función head(var). Esta nos mostrará solo las primeras instancias (renglones) del data.frame que estemos analizando. En la tabla inferior podemos ver que se trata de una base de datos sobre automóviles y que las columnas representan: el fabricante, el modelo, el desplazamiento de combustible (litros), el año del modelo, el número de cilindros, el tipo de transmisión, el tipo de tracción, los consumos en ciudad y autopista (en millas por galón, mpg), el tipo de combustible que utilizan y la clase a la que pertenencen. También nos plantearemos el objetivo de eliminar la mayor cantidad de elementos posibles hasta solo tener el esqueleto y de ahí agregar algunos elementos que favorezcan la interpretación.\n\nhead(df1)\n\n\n\n  \n\n\n\n\n5.3.1 ggplot() + ...\nA partir de esta información podemos tratar de responder si existe una relación apreciable entre el consumo de combustible (por ejemplo en autopista) y el desplazamiento del motor, considerando la clase del vehículo. Para atender a esta pregunta utilizaremos un gráfico de dispersión, con el desplazamiento en el eje x, el consumo en el eje y y la clase indicada por los colores de los puntos. Ahora que tenemos claro qué queremos visualizar y cómo lo vamos a visualizar podemos empezar a graficar. El primer paso es inicializar el espacio de graficado con la función ggplot() y pasarle los parámetros estéticos utilizando la función aes(x, y, colour). Es importante mencionar que en este momento aparecerá únicamente el espacio de graficado en blanco. Esto es normal, ya que únicamente definimos el “qué”, pero no el “cómo”.\n\nggplot(data = df1, aes(x = displ, y = cty, colour = class))\n\n\n\n\nYa que inicializamos el espacio gráfico podemos agregar la información que nos interesa. Para facilitar la construcción paso a paso y evitar el repetir código innecesariamente podemos almacenar la gráfica completa en una variable (por ejemplo plot2) e ir añadiendo capas (operador +) posteriormente. Para ver un gráfico guardado en una variable simplemente hay que llamar a esa variable. La primera capa que agregaremos será la que indicará el tipo de gráfico que deseamos (nombrados como geom_*), en este caso un gráfico de dispersión:\n\nplot1 <- ggplot(data = df1, aes(x = displ, y = hwy, colour = class)) +\n         geom_point()\nplot1 # Imprime el gráfico\n\n\n\n\nAhora sí tenemos la información que necesitamos y podríamos comenzar a describir el gráfico, pero en realidad hay demasiados elementos que son innecesarios y otros que son poco informativos en su estado actual (etiquetas de ejes), entonces trabajemos uno por uno. Para modificar las etiquetas de los ejes podemos utilizar las funciones xlab() y ylab() como capas separadas; sin embargo, podemos modificar todas las etiquetas y títulos en un mismo paso utilizando la función labs(title, x, y, caption, colour, ...).\n\nplot2 <- plot1 + labs(x = \"Desplazamiento (l)\",\n                      y = 'Consumo (mpg)',\n                      colour = 'Clase',\n                      title = \n                        'Tamaño del motor y Rendimiento de combustible',\n                      subtitle = 'Consumo en carretera',\n                      caption = 'Datos: ggplot2::mpg')\nplot2\n\n\n\n\n\n\n5.3.2 Tema de ggplot2\nAhora que está claro cuáles son las variables que estamos mostrando podemos empezar a modificar la estética. Recordemos que debemos mantener la relación datos/tinta lo más alta posible, y uno de los elementos más prevalentes del gráfico es el fondo gris con todo y cuadrículas. Para modificar esos elementos tenemos que modificar el “tema” de la gráfica, que no es otra cosa mas que utilizar una función que nos permita modificar en una sola línea la estética general del gráfico. Los temas se encuentran señalados con el nombre theme_*. Probemos con theme_minimal():\n\nplot2 + theme_minimal()\n\n\n\n\nLogramos eliminar el fondo gris y de paso las “espinas” (líneas de los ejes) y ahora el gráfico está en mucho mejor condición para ser presentado; sin embargo aún podemos ir más lejos. El objetivo de esta gráfica no es ver los detalles precisos de la información, si no extraer la información más relevante, por lo que la cuadrícula es un elemento que no aporta nada a la visualización. Para retirarla utilizaremos la función theme(), la cual permite modificar el aspecto de todos los elementos del gráfico. En realidad, las funciones theme_*() son aplicaciones de theme() con diferentes valores por defecto, por lo que podemos replicar el efecto de theme_minimal() e incluir otras modificaciones. Otra función muy útil para este procedimiento es la función element_blank(), la cual le indica a ggplot2 que no debe mostrar ese elemento. Otra cuestión importante que debemos de considerar es la relación de aspecto. Debido a que esta puede modificar enormemente la percepción de los datos, su selección no es algo trivial. En general, la proporción áurea (1:1.61) es un buen punto de partida y en series de tiempo es la proporción que menos deforma los datos. Una proporción cuadrada tiene sentido únicamente en aquellos casos en los que ambos ejes tengan la misma magnitud de variación y procuraremos que el eje más largo sea aquel con la variación más pequeña. En este caso, la variación del eje y (5 a 45) es mucho mayor que la del eje x (1.5 a 7), por lo cual una proporción cuadrada no sería una buena alternativa. En su lugar, utilicemos la proporción áurea. El último elemento que eliminaremos aquí son las marcas de los ejes, ya que realmente no aportan demasiada información.\n\nplot2 <- plot2 + \n         # Eliminamos la cuadrícula menor\n         theme(panel.grid.minor = element_blank(),\n               # Eliminamos la cuadrícula mayor\n               panel.grid.major = element_blank(),\n               # Eliminamos el color de fondo\n               panel.background = element_blank(),\n               # Eliminamos las líneas de los ejes\n               axis.line = element_blank(),\n               # Eliminamos la leyenda\n               legend.key = element_blank(),\n               # Cambiamos la relación de aspecto\n               aspect.ratio = 1/1.61,\n               # Eliminamos las marcas de los ejes\n               axis.ticks = element_blank()\n                       )\nplot2\n\n\n\n\n\n\n5.3.3 Personalizar los ejes\nAhora que nos deshicimos del fondo, la cuadrícula y las líneas y marcas de los ejes podemos trabajar en los valores de los ejes. Una de las mejores maneras de hacerlo es utilizando las funciones scale_x_*() o scale_y_*(), sustituyendo el * por continuous o discrete dependiendo del tipo de variable con el que estemos trabajando. En este caso, eliminaremos por completo las marcas del eje y y dejaremos únicamente los desplazamientos más comunes en el eje x.\n\nplot2 <- plot2 + scale_x_continuous(breaks = c(1.8, 2.5, 5, 7)) +\n                 scale_y_continuous(breaks = NULL)\nplot2\n\n\n\n\n\n\n5.3.4 Añadir líneas de referencia\nAhora que nos deshicimos de los valores del eje la gráfica ya no es entendible debido a que no sabemos cuál es la orientación o la escala de los datos. Una alternativa es añadir un par de líneas de referencia. Esto lo haremos con la función geom_hline(), la cual nos permite añadir líneas horizontales a través de todo el gráfico que cruzan al eje y en una posición que nosotros determinamos:\n\n# Valores de referencia como el mínimo, la media y\n# el máximo de los consumos\n\nrefs <- c(round(min(df1$hwy),0),\n          round(mean(df1$hwy),0),\n          round(max(df1$hwy),0))\n\n# Líneas de referencia, una verde para el mejor consumo,\n# una gris para el consumo promedio y una roja para el peor consumo\nplot2 <- plot2 + geom_hline(yintercept = refs[1],\n                            colour = 'firebrick', alpha = 0.5,\n                            linetype = 'dashed') +\n                 geom_hline(yintercept = refs[2],\n                            colour = 'lightslategrey', alpha = 0.5,\n                            linetype = 'dashed') +\n                 geom_hline(yintercept = refs[3],\n                            colour = 'forestgreen', alpha = 0.5,\n                            linetype = 'dashed')\nplot2\n\n\n\n\nAhora el gráifico ya cuenta nuevamente con un sentido de dimensión, pero no tenemos los valores de referencia, entonces habrá que poner esas anotaciones con la función geom_text(), utilizando como valores de posición en y los mismos que las líneas de referencia + un pequeño valor:\n\n# Líneas de referencia con los mismos colores\nplot2 <- plot2 + annotate('text', x = 1.3, y = refs[1]+1, \n                          label = as.character(refs[1]),\n                          colour = 'firebrick') +\n                 annotate('text', x = 1.3, y = refs[2]+1,\n                          label = as.character(refs[2]),\n                          colour = 'lightslategrey') +\n                 annotate('text', x = 1.3, y = refs[3]+1,\n                          label = as.character(refs[3]),\n                          colour = 'forestgreen')\nplot2\n\n\n\n\nCon esta última modificación terminamos de explorar algunas de las funciones más básicas e importantes para personalizar los elementos que más impactan en una visualización, pero antes de terminar de discutir este punto me gustaría terminar el objetivo que nos propusimos al inicio de sacar información de la gráfica. En general, existe una tendencia a que el consumo de combustible incremente conforme incrementa el desplazamiento, lo cual es de esperarse, ya que el desplazamiento es una medida de el volumen máximo de combustible que puede entrar al motor en un momento dado; sin embargo, podemos también observar que, independientemente del desplazamiento, las SUVs y pickups tienden a tener los peores rendimientos de combustible, mientras que los subcompactos tienden al otro extremo. Podemos también analizar a los vehículos de dos plazas y ver que aún cuando tienen desplazamientos altos, sus rendimientos son mejores que los de las SUVs.\n\n\n5.3.5 Conclusión y ejercicio\nEn cuanto a la parte visual, se podría argumentar que esta visualización final no es tan precisa como la primera, que algún elemento podría embellecerse, o que podriamos eliminar la leyenda y poner etiquetas de texto en algunos puntos para indicar las clases. Todos estos argumentos y muchos otros serían válidos ya que la estética es algo subjetivo; sin embargo, las decisiones que tomemos deberán estar en función del medio de distribución de la visualización (no es lo mismo una página web que en un medio impreso, por ejemplo) y sobre todo del público objetivo. Esta visualización en particular funciona para los fines didácticos que tenía en mente, es adecuada para una presentación de resultados de manera electrónica como este video, pero no es una visualización adecuada para una publicación científica. Arreglar eso será tu ejercicio para esta sesión.\nPara finalizar con el objetivo principal de la clase te presento la visualización inicial y la final, una junto a la otra, para ver en dónde comenzamos, dónde terminamos y cómo llegamos hasta aquí. También te sugiero revises y descargues el PDF de esta página, que es un acordeón donde se encuentran los gráficos y funciones más comunes. Más adelante revisaremos algunos de ellos pero es un recurso que vale la pena tener a la mano.\n\n\n\n\n\n\n\n\n\n\n\n5.3.5.1 Gráfico final\nY también el código necesario para el gráfico final, todo en un solo bloque de código.\n\n# Valores de referencia para utilizar en la gráfica\nrefs <- c(round(min(df1$hwy),0),  # Valor mínimo = peor consumo\n          round(mean(df1$hwy),0), # Valor promedio\n          round(max(df1$hwy),0))  # Valor máximo = mejor consumo\n\n# Objeto con todos los pasos para llegar a la gráfica final\n# Inicializamos el espacio gráfico\nfinal.plot <- ggplot(data = df1, aes(x = displ, y = hwy,\n                                     colour = class)) +\n              # Gráfico de dispersión\n              geom_point() +\n              # Establecemos los títulos, subtítulos y un pie de foto\n              labs(x = 'Desplazamiento (l)',\n                   y = 'Consumo (mpg)',\n                   colour = 'Clase',\n                   title = 'Tamaño del motor y Rendimiento de combustible',\n                   subtitle = 'Consumo en carretera',\n                   caption = 'Datos: ggplot2::mpg'\n                   ) +\n              #Eliminamos la cuadrícula menor\n              theme(panel.grid.minor = element_blank(),\n                    #Eliminamos la cuadrícula mayor\n                    panel.grid.major = element_blank(),\n                    #Eliminamos el color de fondo\n                    panel.background = element_blank(),\n                    #Eliminamos las líneas de ejes\n                    axis.line = element_blank(),\n                    #Eliminamos el fondo de la leyenda\n                    legend.key = element_blank(),\n                    #Establecemos la rel. de aspecto\n                    aspect.ratio = 1/1.61,\n                    #Eliminamos las marcas de los ejes\n                    axis.ticks = element_blank(),\n                    #Cambiamos el tipo de letra\n                    text = element_text(family = 'Times',\n                                        colour = 'gray50')\n                    ) + \n              # Reducimos las divisiones del eje ex a 4 valores\n              scale_x_continuous(breaks = c(1.8, 2.5, 5, 7)) +\n              # Eliminamos las divisiones del eje y\n              scale_y_continuous(breaks = NULL) +\n              # Añadimos una línea roja en el peor consumo\n              geom_hline(yintercept = refs[1],\n                         colour = 'firebrick', alpha = 0.5, \n                         linetype = 'dashed') +\n              # Añadimos una línea gris en el consumo promedio\n              geom_hline(yintercept = refs[2],\n                         colour = 'lightslategrey', alpha = 0.5, \n                         linetype = 'dashed') +\n              # Añadimos una línea verde en el mejor consumo\n              geom_hline(yintercept = refs[3],\n                         colour = 'forestgreen', alpha = 0.5,\n                         linetype = 'dashed') +\n              # Etiqueta del peor consumo\n              annotate('text', x = 1.3, y = refs[1]+1,\n                       label = as.character(refs[1]),\n                       colour = 'firebrick') +\n              #Etiqueta del consumo promedio\n              annotate('text', x = 1.3, y = refs[2]+1,\n                       label = as.character(refs[2]),\n                       colour = 'lightslategrey') +\n              # Etiqueta del mejor consumo\n              annotate('text', x = 1.3, y = refs[3]+1,\n                       label = as.character(refs[3]),\n                       colour = 'forestgreen') \n              \nfinal.plot\n\n\n\n\n\n\n\n5.3.6 Extras\nAunque estas modificaciones no necesariamente forman parte del proceso necesario para la visualización que era de nuestro interés, sí que son rutinarias, por lo que vale la pena echarles un ojo.\n\n5.3.6.1 Colores de puntos\nModificar los colores de los puntos. Podemos utilizar la función randomColor(n) de la librería con el mismo nombre. Esta función solamente recibe el número de colores que queremos y los generará de manera aleatoria:\n\naleat <- randomcoloR::randomColor(7)\nfinal.plot + scale_color_manual(name = \"Clase\", values = aleat)\n\n\n\n\nPodemos también especificar una paleta predefinida, utilizando la capa scale_color_brewer():\n\nfinal.plot + scale_color_brewer(type = \"seq\", palette = \"Paired\")\n\n\n\n\nOtra opción es directamente pasar un vector con los nombres de los colores que sean de nuestro interés:\n\ncolor_names <- c(\"red\", \"blue\", \"yellow\", \"black\",\n                 \"dodgerblue\", \"pink\", \"gray\")\nfinal.plot + scale_color_manual(name = \"Clase\", values = color_names)\n\n\n\n\n\n\n5.3.6.2 Tamaño de los puntos\nPara modificar el tamaño de los puntos solamente hay que agregar el argumento size a la capa geom_point, en el cuál indicaremos qué tamaños tomarán los puntos. Puede ser un solo valor:\n\nfinal.plot + geom_point(size = 0.1)\n\n\n\n\nO también a partir de una columna de la base de datos (dividida entre 5 para no obtener únicamente “manchas”):\n\nfinal.plot + geom_point(size = df1$hwy/5)\n\n\n\n\n\n\n5.3.6.3 Tipografías y Exportación de gráficos\nEl manejo de las tipografías en R es un poco especial, por ello usualmente recomiendo generar el gráfico en R, exportarlo como PDF (cairo_pdf(\"filename.pdf\", width, height, family)) y agregar las cursivas donde sea necesario; sin embargo, un paquete que puede resultar especialmente útil es ggtext. Este añade un nuevo tipo de “elemento” de texto que recibe formato Markdown (element_markdown()); es decir, podemos agregar itálicas o negritas. Para poder utilizarlo, sin embargo, es necesario modificar ligeramente nuestros datos de antemano. Para facilitarnos las cosas agregaremos una nueva columna a df1 que contenga las clases en itálicas y extraeremos los valores únicos (algo más eficiente sería hacerlo al revés, pero es más lógico de esta manera):\n\ndf1$clase <- paste0(\"*\",df1$class,\"*\")\nclases <- unique(df1$clase)\n\nFinalmente lo agregaremos a la gráfica. ¡OJO! Es necesario modificar el tema para que entienda el formato markdown:\n\nif(!require(ggtext)) {install.packages(\"ggtext\", dependencies = T)}\n\nLoading required package: ggtext\n\nfinal.plot + scale_color_discrete(name = \"Clase\",labels = clases) +\n             theme(legend.text = ggtext::element_markdown())\n\n\n\n\nCon este elemento podemos modificar también fracciones de cualquier texto de nuestra gráfica, por ejemplo carretera en negritas:\n\nfinal.plot + labs(subtitle = \"Consumo en **carretera**\") +\n             theme(plot.subtitle = ggtext::element_markdown())\n\n\n\n\nMezclando ambas modificaciones:\n\nfinal.plot + scale_color_discrete(name = \"Clase\",labels = clases) +\n             labs(subtitle = \"Consumo en **carretera**\") +\n             theme(plot.subtitle = ggtext::element_markdown(),\n                   legend.text = ggtext::element_markdown())\n\n\n\n\nAhora sí, esto es todo para esta clase. ¡Nos vemos en la siguiente!"
  },
  {
    "objectID": "c02_intro_rs.html",
    "href": "c02_intro_rs.html",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "",
    "text": "En la sesión anterior hablamos de cómo la ciencia de datos nos proveé de las herramientas que necesitamos para poder extraer conclusiones sensibles desde nuestros datos; sin embargo, el análisis de nuestros datos va (o debería ir) mucho más allá de aplicar una prueba estadística y dar a conocer el valor de p correspondiente. El análisis de datos es un proceso, y como científicos debemos de ser capaces de reportar ese proceso de una manera ordenada, transparente y reproducible. Es ahí donde entran RStudio y Quarto (la evolución de RMarkdown), así que antes de entrar propiamente al lenguaje de programación R, hablemos de cómo realizar reportes y cómo podemos aprovechar al máximo la interfaz que provee RStudio. Te adelanto: si lo utilizas adecuadamente, RStudio (en conjunto con Quarto) puede ser el lugar donde escribas tu tesis, por muy inverosímil que parezca. De hecho, este sitio fue construido utilizando ambas cosas. Sin más preámbulo, comencemos por hablar de qué es RStudio."
  },
  {
    "objectID": "c02_intro_rs.html#r-vs.-rstudio",
    "href": "c02_intro_rs.html#r-vs.-rstudio",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "2.1 R vs. RStudio",
    "text": "2.1 R vs. RStudio\nAntes de volar y pretender formar un sitio web o una tesis, comencemos hablando de RStudio. En la sección de preparación instalamos tres cosas diferentes: R, RStudio, y Quarto. Olvidemos a este último por un momento y centrémonos en los dos primeros. R es un lenguaje de programación. Como tal, se ejecuta en consola, ya sea el terminal (macOS/Linux) o el interpretador de comandos cmd en Windows. Lo único que veremos si abrimos/ejecutamos R per-se es una ventana como la siguiente:\n\n\n\nFigure 2.1: Consola de R (R GUI)\n\n\nEs decir, solamente veremos nuestra consola, compuesta por una descripción de la versión de R que estamos utilizando y un prompt (el símbolo >) que nos presiona a darle a la computadora una instrucción. Más allá de ser una interfaz extremadamente simple, no está pensada para el desarrollo de reportes como los que nosotros realizamos. No podemos escribir texto libre, ni tampoco podemos guardar nuestro progreso. Para eso habría que abrir un script, pero hay una mejor alternativa que nos permite hacer eso y mucho más: RStudio. Por el momento hasta aquí vamos a llegar con R, pero no te preocupes, le vamos a dedicar mucho más tiempo posteriormente."
  },
  {
    "objectID": "c02_intro_rs.html#el-ide-rstudio",
    "href": "c02_intro_rs.html#el-ide-rstudio",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "2.2 El IDE RStudio",
    "text": "2.2 El IDE RStudio\nMientras que R es un lenguaje de programación ejecutable en consola, RStudio es un ambiente gráfico de desarrollo (IDE). ¿Qué significa? Que es una interfaz gráfica que nos permite no solo ejecutar nuestro código línea a línea, sino que también incluye otros páneles que nos facilitan enormemente la existencia y, además, abre otras puertas para la creación de documentos como este libro. Vayamos por partes.\n\n2.2.1 La ventana de RStudio\nAl abrir RStudio por primera vez te vas a topar con una ventana como la siguiente:\n\n\n\nFigure 2.2: Ventana de RStudio\n\n\nYa sé, ya sé, no se ve mucho más amable que la ventana de R. Es más, se ve mucho más intimidante porque ahora tenemos la consola y otros 3 espacios. Al ser un IDE, RStudio incluye elementos gráficos para todo lo que pudiéramos llegar a necesitar mientras desarrollamos nuestros análisis, entonces vamos a descomponer esta ventana panel por panel, de arriba a abajo y de izquierda a derecha.\n\n2.2.1.1 El editor\nEl primer panel es el editor:\n\n\n\nFigure 2.3: Editor en RStudio\n\n\nEste es, como el nombre sugiere, un editor de textos, que no debemos de confundir con procesador de palabras (i.e., Word o similares). En él vamos a poder escribir sripts o libretas que contengan la serie de pasos que realizamos durante nuestro análisis. Cada una de las pestañas en este panel es siempre un documento de texto simple, independientemente de si es un script o una libreta. Esto tiene varias ventajas, pero la más importante es que nos podemos llevar esos archivos a cualquier computadora y estar bastante seguros de que podremos, cuando menos, ver su contenido y editarlo sin preocuparnos por problemas de compatibilidad entre versiones del software o, peor aún, sistemas operativos (*ejem* Word *ejem*). Estos archivos de texto simple pueden, dependiendo del tipo de archivo, enviar instrucciones a R.\n\n\n2.2.1.2 La consola\nEl siguiente panel es la consola:\n\n\n\nFigure 2.4: Consola en RStudio\n\n\nEste panel es, literalmente, lo que veíamos al abrir R en sí mismo; es decir, un espacio donde tenemos nuestro prompt y donde se ejecutarán nuestras instrucciones o líneas de comandos. Notarás que hay otras tres pestañas: una llamada Terminal, y otra llamada Background Jobs. Estas son interfaces a la terminal del sistema y a los trabajos que estemos ejecutando en segundo plano. Nuestra interacción con estas dos pestañas va a ser limitada, salvo que realicemos algo muy especializado. En el curso solo entraremos ocasionalmente al Terminal.\n\n\n2.2.1.3 ¿Reportes como scripts?\nAntes de pasar al siguiente panel es importante hablar de los scripts, las libretas, e intentar hacer un poco de labor de convencimiento. Si has tenido un acercamiento previo a R/RStudio, es bastante probable que trabajar con scripts te sea familiar. Si no es así, un script de R es un archivo de texto con extensión .R en el que ponemos nuestro código línea a línea. Pensemos en un ejercicio en el que queremos primero sumar 1 y 1, y luego 2 y 2. Nuestro script en RStudio se vería así:\n\n\n\nFigure 2.5: Script en el editor\n\n\nSolo tenemos el código, no tenemos los resultados. ¿La razón? Aún no le hemos dicho a la computadora que queremos que las ejecute. ¿Cómo le decimos? Tenemos dos formas:\n\nEjecutar el script línea a línea, para lo que debemos posicionar nuestro cursor (dar click) sobre la línea a ejecutar, utilizar el atajo de teclado CMD + R en macOS/Linux o CTRL + R en Windows, o dar click sobre el botón Run que está cerca de la esquina superior derecha del panel.\nEjecutar el script completo, para lo que seleccionaríamos todo su contenido y utilizaríamos el mismo atajo de teclado o botón que antes.\n\nSea cual sea la opción que hayas escogido, la salida (el resultado) aparecerá en la consola:\n\n\n\nFigure 2.6: Script ejecutado en consola\n\n\n¿Cuál es el problema? El primero es que en el momento en el que cerremos RStudio esos resultados se van a perder, salvo que los hayamos guardado manualmente en algún lugar. El segundo tiene que ver con una falta de unificación: el código (las sumas) están por un lado, mientras que los resultados están en otro que, además, es volátil. El tercero se deriva de los dos anteriores: falta de legibilidad y reproducibilidad. No podemos hacer el reporte al mismo tiempo en que analizamos los datos y, si en algún momento volvemos al script, debemos de ejecutarlo todo nuevamente para ver los resultados. Suena engorroso, ¿no? Un cuarto problema es que no tenemos descripciones de nuestros resultados. Si ya has trabajado con estos archivos me vas a decir “para eso existen los comentarios”, a lo que yo te respondería que no, los comentarios no son para eso. Si no has trabajado con R ni ningún otro lenguaje de programación te preguntarás qué es un comentario. Bien, un comentario es un fragmento de texto no ejecutable; es decir, es algo que podemos escribir y pasarle a la consola pero que no se va a ejecutar. En R estos están dados por el operador #. Agreguemos un comentario a nuestro script con la palabra “Sumas” y ejecutémoslo todo nuevamente:\n\n\n\nFigure 2.7: Script con comentarios ejecutado en consola\n\n\nComo esperábamos, en la consola no hay una salida asociada a la instrucción # Sumas, por lo tanto puedo usar esos comentarios para describir mis resultados, ¿no? La respuesta es, como en muchas otras cosas, depende. O, mejor dicho, de que se puede, se puede, que debamos hacerlo, es otra historia. Los comentarios tienen la función de describir muy brevemente qué intención tiene el código, no escribir párrafos completos con el reporte de los resultados. Comentarios válidos son agregar al inicio del script quién lo escribió, qué hace el código contenido en él, un medio de contacto, y breves descripciones de qué se hace en cada línea, sin repetir el código en texto simple (no decir # Suma 1 y 1 si el código es 1+1, por ejemplo). Existe otro gran problema el cuál no es obvio en este ejercicio, pero que tiene que ver con la carga de datos en archivos dentro de nuestra computadora (archivos .csv o .xlsx, por ejemplo), pero eso lo veremos en un tema posterior. Por el momento veamos una alternativa que resuelve todos estos problemas.\n\n\n2.2.1.4 Libretas y reportes: Quarto\nAquí es donde entran Quarto y las libretas. Al instalar Quarto no instalamos un programa per-se, sino que instalamos una extensión a RStudio que es, y cito textualmente, “un sistema de publicación científica y técnica de código abierto construido sobre Pandoc”, que permite, citando nuevamente: i) crear contenido dinámico no solo con R sino con otros lenguajes de programación; ii) escribir documentos como texto plano; iii) publicar artículos, reportes, presentaciones, sitios web, blogs y libros de alta calidad en formatos HTML, PDF, MS Word, ePUB; y iv) escribir con markdown científico, incluyendo ecuaciones, citas, referencias cruzadas, páneles de figuras, anotaciones, diseños avanzados y más. ¿A que ya suena mejor que los scripts? Sin ir más lejos, todo el material que utilizaremos en este curso fue escrito en RStudio utilizando Quarto, y puedes ver la versión final en el sitio web de acompañamiento. Debido a que explicar Quarto es un tema que merece le dediquemos tiempo y estar más arriba que un subtema de IDE RStudio, vamos a dejarlo de lado por el momento, solo revisemos cómo crear un nuevo documento y las diferencias fundamentales con los scritps. Para crear un documento podemos ir a la barra de herramientas -> File -> New file -> Quarto document, o utilizar el botón correspondiente en la ventana de RStudio:\n\n\n\nFigure 2.8: Nuevo documento Quarto\n\n\nAl darle click nos va a aparecer la siguiente ventana para personalizar el documento:\n\n\n\nFigure 2.9: Opciones documento Quarto\n\n\nAquí añadirás el título de tu documento y opcionalmente el autor. Por el momento dejaremos todo lo demás tal y como está y daremos click en Create, lo que abrirá una pestaña nueva en el editor:\n\n\n\nFigure 2.10: Opciones documento Quarto\n\n\nLa pestaña se parece al contenido de un script, la única diferencia es un texto contenido entre ---. A esta parte la podemos identificar como el preámbulo del documento, y es un fragmento de nuestro documento escrito en formato YAML ¿Qué es eso y con qué se come? No te preocupes ahorita por eso, solo necesitas saber ahorita que vamos a desarrollar nuestro trabajo debajo del preámbulo. En la Figure 2.11 puedes ver un ejemplo básico de un documento Quarto con el código de nuestras sumas.\n\n\n\nFigure 2.11: Un documento Quarto básico\n\n\nUn ejemplo más claro del potencial de Quarto es, nuevamente, el material de este curso. Pero sigamos explorando la ventana de RStudio\n\n\n\n2.2.2 El ambiente de trabajo\nEl siguiente panel es lo que se conoce como el ambiente de trabajo (workspace), que nos da un listado de las cosas que le hemos dado a R para que recuerde (objetos). En la siguiente sesión hablaremos largo y tendido de esto, pero veamos un ejemplo donde, utilizando la consola, le digamos a R que recuerde el resultado de la suma 1 + 1, asignándolo a una referencia que arbitráriamente llamaré suma:\n\n\n\nFigure 2.12: Guardar un resultado en la consola\n\n\nDos cosas: 1) La asignación se hizo con el operador <-. Esto es sumamente importante, en R guardamos cosas utilizando ese operador y no =. 2) Al ejecutar la línea no obtuvimos el resultado. Esto es porque solo le dijimos que lo recordara, que lo anotara en un post-it, si quieres, no que nos lo mostrara. Si queremos que nos lo muestre solo tenemos que llamarlo por su nombre (ejecutar en la consola):\n\n\n\nFigure 2.13: Imprimir el resultado\n\n\n¿Qué tiene que ver esto con el ambiente de trabajo? Pues ahora ya no está vacío, ya tenemos una entrada en la lista, en donde se muestra el nombre del objeto y su valor. Conforme vayamos creando más objetos, más entradas tendrá esa lista. Prueba a crear un objeto que contenga el texto \"Hola mundo\" (ojo a las comillas) y dar click en su nombre en el ambiente de trabajo. ¿Qué ocurre?\n\n\n2.2.3 El ambiente gráfico\nEl último panel corresponde al ambiente gráfico. Este panel junta varios elementos a los que es más fácil acceder visualmente. La primera pestaña es un explorador de archivos. puedes dar click a cada carpeta para ver sus elementos, crear nuevas carpetas, y mucho más. En este curso no lo utilizaremos más que como una referencia visual de dónde están ubicados nuestros archivos.\n\n\n\nFigure 2.14: Explorador de archivos\n\n\nLa siguiente pestaña nos muestra la serie de gráficos que hemos ido generando. Podemos ejecutar en la consola el comando plot(cars) y verás que el gráfico se muestra en esta pestaña.\n\n\n\nFigure 2.15: Gráfico en el ambiente gráfico\n\n\nEn la siguiente pestaña encontraremos un listado de las librerías/paqueterías que tenemos instaladas, sus versiones, una breve descripción de para qué son, así como botones para instalarlas o actualizarlas.\n\n\n\nFigure 2.16: Paquetes\n\n\nDespués tenemos la pestaña de ayuda. Aquí podemos ver, valga la redundancia, ayuda sobre R, pero también sobre funciones en las que estemos interesados. Si queremos ver la ayuda de una función FUN vamos a utilizar el comando ?FUN, tal que:\n\n\n\nFigure 2.17: ¡Ayuda!\n\n\nEn la siguiente pestaña tenemos un visor (Viewer), donde tendremos vistas previas de los documentos RMarkdown o Quarto con los que estemos trabajando. Tomando como ejemplo el documento que generamos antes, le daremos click al botón Render con la flecha azul, lo que da como resultado la vista previa en Viewer\n\n\n\nFigure 2.18: Documento Quarto y su renderizado\n\n\nLa última pestaña es un visor de presentaciones, el cual no utilizaremos en este curso.\n\n\n2.2.4 Personalizando RStudio\nComo todo IDE, podemos personalizar la apariencia de RStudio. Para hacerlo simplemente ve a la barra de herramientas, Tools -> Global Options. Te aparecerá la siguiente ventana\n\n\n\nFigure 2.19: Ventana de ajustes\n\n\nVamos a revisar algunas de las opciones que te recomiendo tener presentes. Puedes hacer los cambios y aplicarlos todos juntos al final con el botón Apply:\n\nGeneral\n\nBasic\n\nWorkspace: Restore .RData into workspace at startup & Save workspace to .RData on exit. ¿Quieres que cada que cierres RStudio todos los objetos de tu espacio de trabajo se guarden en un archivo, y que esos mismos se carguen la siguiente vez que abras RStudio? Personalmente no es algo con lo que esté de acuerdo, porque más frecuentemente que no vas a querer un ambiente limpio, por lo que estas opciones están desmarcada y en Never, respectivamente.\nHistory: La misma historia (je) que en el caso anterior. ¿Quieres que tu historial de comandos ejecutados se guarde, aún si no guardas el .RData? ¿Quieres que se remuevan los duplicados? Por las mismas razones que antes también las tengo desmarcadas.\n\nGraphics\n\nBackend a Cairo. Simplemente es con qué se están graficando las cosas. ¡ES INDISPENSABLE QUE TENGAS INSTALADO xquartz SI ESTÁS EN macOS/LINUX!\n\n\nAppearance\n\nZoom: ¿Qué tan grandes quieres todos los elementos de la ventana? Para mi trabajo personal, y dependiendo de la resolución del monitor donde se encuentre la ventana, esta oscila entre 100% y 125%, para este curso está en 175-200%\nEditor font y Editor font size: Tipo y tamaño de letra. Personalmente recomiendo no cambiar el tipo de letra.\nEditor theme: Cambia el color de fondo y los colores de realce de la sintaxis. Usualmente trabajo por las noches, por lo que prefiero un tema con fondo obscuro como Tomorrow Night Bright, pero puedes buscar el que tú quieras.\n\nPane Layout\n\nAquí se muestran los cuatro paneles de la ventana de RStudio. Personalmente prefiero tener los dos elementos que más utilizo lado a lado y no uno encima del otro. ¿La razón? El código crece hacia abajo, entonces el espacio vertical tiende a ser más importante que el espacio horizontal. Es decir, que en el panel superior derecho pongo la consola, y en el panel inferior izquierdo el ambiente de trabajo.\n\n\nEl resto de opciones son más específicas, por lo que recomiendo no tocarlas salvo que sepas qué estás moviendo y con qué objetivo. Todo se puede revertir, pero no hay necesidad de fomentar dolores de cabeza."
  },
  {
    "objectID": "c02_intro_rs.html#preámbulo",
    "href": "c02_intro_rs.html#preámbulo",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "3.1 Preámbulo",
    "text": "3.1 Preámbulo\nEl primer elemento es el preámbulo, que mencionamos está en formato YAML y que está contenido entre ---. YAML es un formato de serialización de datos legible por humanos. ¿En castellano? Una lista con niveles de pares de claves:valores que definen los metadatos de nuestro documento. En nuestro ejemplo tenemos:\n---\ntitle: \"Untitled\"\n---\nEs decir, el título que aparecerá en el reporte es \"Untitled\", tal y como vimos en la vista previa. Esto no tiene mucho sentido, así que cambiémoslo por \"Mi primerQuarto\" y añadamos una nueva entrada para el autor, tal que:\n---\ntitle: \"Mi primer `Quarto`\"\nauthor: \"Tu nombre\"\n---\nOtro elemento que usualmente se agrega en el preámbulo es el formato de salida del documento renderizado; es decir, ya presentado para compartir/imprimir. Mi recomendación es exportar a archivos HTML, salvo que vayas a imprimir el documento (PDF), necesites paginación (PDF de nuevo) o que por alguna desafortunada razón necesites un archivo MS Word. Un HTML lo declaramos tal que:\n---\ntitle: \"Mi primer `Quarto`\"\nauthor: \"Tu nombre\"\nformat:\n  html:\n    code-fold: true\n---\nNotarás algunas cosas. La primera es que html está indentado; es decir, no comienza en la misma posición que format. Esto es para indicar que html pertenece a format, al igual que code-fold pertenece a html. La siguiente es, justamente, que agregamos a la lista la entrada code-fold. Esta es una opción que indica si queremos que el código sea colapsable mediante un botón en el archivo final. En este caso, la indicamos como true, por lo que así será. Si no lo quisiéramos así indicaríamos false. Si renderizamos nuestro documento ahora tendremos:\n\n\n\nFigure 3.1: Primer Quarto renderizado\n\n\nSi tienes curiosidad por saber qué características YAML dieron lugar al libro de acompañamiento, puedes revisar el archivo _Quarto.yml."
  },
  {
    "objectID": "c02_intro_rs.html#markdown",
    "href": "c02_intro_rs.html#markdown",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "3.2 Markdown",
    "text": "3.2 Markdown\nPasando el preámbulo tenemos una sección de texto libre, con algunas anotaciones para el formato del texto. Estas anotaciones están hechas en lenguaje markdown. Markdown es un “lenguaje de programación para textos” y permite hacer cosas bastante interesantes. Las anotaciones más básicas son:\n\nEncabezados y secciones: #, ##, ###, ####, etc.\n*Itálicas* : Itálicas\n**Itálicas**: Negritas\n`Código`: Código\nHipervínculos: [Google](https://www.google.com): Google\n$y_i = \\alpha + \\beta*x_i + \\epsilon$: \\(y_i = \\alpha + \\beta*x_i + \\epsilon\\)\n\nPuedes hacer listas numeradas, como la anterior, o listas sin numerar:\n\nElemento\nOtro elemento\n\nE, incluso, puedes hacer listas anidadas añadiendo una indentación de doble tabulación a los elementos anidados:\n\nIntroducción a RStudio y Quarto\n\nR vs. RStudio\nIDE RStudio\n\n\nEn el archivo .qmd este capítulo puedes ver cómo añadí las capturas de la ventana de RStudio. Añadir imágenes es básicamente el mismo procedimiento que con un enlace, solo añadiendo el operador ! antes. Por ejemplo, la siguiente línea añade el logo de R desde su dirección oficial, le asigna el pie de foto “Logo R” y una etiqueta interna que se puede utilizar para referencias cruzadas (Figure 3.2) con @fig-logoR :\n![Logo `R`](https://www.r-project.org/logo/Rlogo.png){#fig-logoR}\n\n\n\nFigure 3.2: Logo R"
  },
  {
    "objectID": "c02_intro_rs.html#referencias-y-citas",
    "href": "c02_intro_rs.html#referencias-y-citas",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "3.3 Referencias y citas",
    "text": "3.3 Referencias y citas\nPodemos agregar referencias, siempre y cuando estas estén contenidas en un archivo .bib como el archivo references.bib que está en este directorio y, por supuesto, referenciarlas en el texto (e.g. Knuth 1984). Si estás viendo la página web con este material, pasa tu cursor sobre la cita y notarás como aparece la información bibliográfica completa. Este archivo .bib está compuesto por entradas en formato bibTeX, heredado del hermano mayor de Markdown: LaTeX. La sintaxis básica es la siguiente:\n@TIPO{CLAVE,\n      author = {},\n      year = {},\n      title = {}}\nLos campos adicionales dependerán del TIPO de referencia que se esté añadiendo. Si quieres ver algunas de las opciones más comunes, te recomiendo revisar esta página. Para incluir una referencia cruzada lo único que tienes que hacer es: @CLAVE. Si tomamos como ejemplo el artículo de Knuth de 1984 sobre la programación literal sería @Knuth_1984 para una referencia en el texto, Knuth (1984), o [@Knuth_1984] para una referencia dentro de paréntesis (Knuth 1984). En cualquiera de los dos casos, si estás viendo el material renderizado, asegúrate de pasar el cursor sobre las citas, y verás que aparece la referencia bibliográfica completa. Para agregar la lista de referencias al final del texto, debes de agregar el siguiente divisor y asegurarte de tener un encabezado de referencias al final del documento:\n::: {#refs}\n:::\n\n\n\n\n\n\nNote\n\n\n\nYo construyo mis archivos .bib a mano, pero no es necesario. Si quieres pasar de un listado de referencias que ya tienes en Word puedes considerar text2bib o Edifix (1. OJO con las opciones; 2. Edifix es de pago). Si quieres una interfaz gráfica para manejar tus archivos .bib, puedes considerar JabRef. Finalmente, gestores de referencias como Mendeley o ReadCube Papers permiten exportar las referencias en formato bib."
  },
  {
    "objectID": "c02_intro_rs.html#consideraciones-sobre-quarto",
    "href": "c02_intro_rs.html#consideraciones-sobre-quarto",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "3.4 Consideraciones sobre Quarto",
    "text": "3.4 Consideraciones sobre Quarto\nAunque Quarto es extremadamente potente y flexible, es importante tener presente algunas cosas. La primera es que NO hay manera de que en esta sesión yo pueda explicarte con lujo de detalle todas las funciones, para eso prefiero dirigirte a la (bastante extensa) guía de Quarto. Otra consideración es que, aunque puedes exportar tus documentos como PDF, Word o ePUB u otros, mi recomendación es que siempre que tengas la libertad exportes a un HTML, que es un poco más permisivo con líneas de código muy largas, o al mostrar tablas con muchas columnas. Si NECESITAS un PDF, asegúrate de tener instalada alguna distribución de LaTeX o, si no quieres la instalación completa, cuando menos asegurarte de haber instalado TinyTeX como sugerimos en la sesión de preparación, de lo contrario NO podrás exportar tus reportes a PDF."
  },
  {
    "objectID": "c02_intro_rs.html#ejercicio",
    "href": "c02_intro_rs.html#ejercicio",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "3.5 Ejercicio",
    "text": "3.5 Ejercicio\nUtilizando Quarto genera un documento HTML con tabla de contenidos en el que te presentes. Las características son:\n\nTítulo: tu nombre\nIncluye tu correo electrónico en el preámbulo\nIncluye las secciones:\n\nGrado académico e institución de procedencia\nMotivación para tomar el curso\nExpectativas sobre el curso (¿hay alguna técnica particular que quieras aprender/revisar?)\nLibro(s) favorito(s) (como cita(s) en el texto, incluyendo la(s) referencia(s) completa(s) al final del documento)\nUna captura de pantalla con tu ventana de RStudio. No importa si es con los ajustes por defecto, si la pusiste igual a la mía, o si pusiste un tema con colores estridentes."
  },
  {
    "objectID": "c02_intro_rs.html#qué-sigue",
    "href": "c02_intro_rs.html#qué-sigue",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "3.6 ¿Qué sigue?",
    "text": "3.6 ¿Qué sigue?\nEn esta sesión revisamos muy someramente el poder de RStudio y Quarto, limitándonos a las funciones más indispensables y que se utilizan de manera cotidiana, pero hay mucho más por ver. Proyectos dentro de RStudio, elaborar libros/páginas web/tesis o incluso artículos científicos con formato editorial según los requerimientos de algunas revistas, solo por mencionar algunos.\nPor otra parte, una de las ventajas poco conocidas de trabajar con archivos de texto simple (.R, .Rmd o .qmd), al menos en el área de ciencias biológicas, es el poder aprovechar al máximo sistemas de gestión de versiones, incluyendo por supuesto al más famoso: git. Muy posiblemente te hayas encontrado en algún momento con GitHub, que no era otra cosa mas que un almacén público de repositorios git. Ahora es un servidor capaz de mantener servicios simples en ejecución o, incluso, alojar páginas web (la página web de acompañamiento de este curso es un ejemplo), por lo que te recomiendo que le eches un ojo al funcionamiento de ambos (git y GitHub), y que revises la integración de git en RStudio. Personalmente utilizo solo la línea de comandos, pero es una herramienta más dentro de nuestro IDE y que puede resultarte más intuitiva."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bioestadística Aplicada con R y RStudio",
    "section": "",
    "text": "¡Hola! Te doy la bienvenida al curso Bioestadística Aplicada con R y RStudio, ofertado por Dr. Plancton.\nEste es el libro de acompañamiento del curso. Aquí encontrarás tanto la teoría como el código que se aborda en el curso, dispuestos en una manera que facilita su lectura, y cuyo objetivo es simplemente proveer una versión lista para ser revisada en cualquier momento, sin necesidad de iniciar RStudio. Cada sección del libro tiene enlaces a los videos correspondientes, en caso de que prefieras ver y escuchar la explicación.\nTen en cuenta que puede existir un desfase entre el material del libro y los videos. La razón es que el material se actualizará para mejorar el contenido, la entrega o la explicación siempre que sea posible, lo cual es fácil de hacer en el libro y las libretas con el código, pero no en los videos; sin embargo, en el momento en el que el desfase sea lo suficientemente grande, también se actualizarán los videos de las secciones correspondientes.\n\n\nEl objetivo de este curso es que seas capaz no solo de implementar distintas técnicas de análisis de datos utilizando R, sino que también puedas ser crítico con tus resultados y que minimices, en la medida de lo posible, el sesgo algorítmico. En este curso aprenderás los fundamentos detrás de las pruebas vistas, en donde abordaremos la teoría desde un punto de vista práctico, buscando que puedas formarte una intuición propia. También trataremos de desmitificar el valor de p y, sobre todo, cómo no interpretarlo. En las partes más abstractas te adentrarás en el aprendizaje automatizado, y verás que hay vida más allá del \\(R^2\\) (regresiones) y la exactitud (clasificaciones).\nUno de los errores más comunes al enseñar estadística con R es tratar de enseñar ambas cosas al mismo tiempo. En este curso, R es solo un medio y no un fin; es decir, no es un curso de programación en R tanto como es un curso de ciencia de datos aplicada; sin embargo, hay una amplia introducción al lenguaje al inicio, y espero que el explicar línea por línea el código te permita familiarizarte con el lenguaje. Dicho esto, el curso fue diseñado para que personas con nulo o muy poco conocimiento de programación en general puedan seguirlo, y siempre podrás contactarnos en caso de que no hayamos explicado algo adecuadamente.\n\n\n\nSi bien es cierto que puedes utilizar y acceder a todo el material del curso desde esta página, te recomiendo encarecidamente unirte al servidor de Discord utilizando tu enlace único (enviado a tu correo al registrarte), pues ahí podrás interactuar no solamente con tus compañeros y compañeras, sino también con tu profesor. Un último comentario, NO es necesario que instales el cliente de Discord en tu computadora o dispositivo móvil, aunque si lo haces podrás recibir las notificaciones sobre modificaciones que se hagan al material."
  },
  {
    "objectID": "c08_descriptiva.html",
    "href": "c08_descriptiva.html",
    "title": "8  Estadística descriptiva",
    "section": "",
    "text": "En una investigación reunimos datos con el objetivo de obtener alguna conclusión o predicción. Pues bien comencemos definiendo un dato como una representación puntual de la realidad. Son un solo valor, sea una sola medición, un promedio, una desviación estándar, una proporción de sexos, etc, y el conjunto de datos de un mismo atributo medidos en distintos individuos nos dan una variable. Es decir, en nuestros conjuntos de datos cada valor es un dato, y cada columna (usualmente) es una variable. ¿Por qué es importante conocer esto? Porque hay distintos tipos de variables, los cuales definen cómo es que vamos a graficar y tratar esos datos:\n\nCualitativas: hacen referencia a las cualidades de nuestros individuos, y tienen dos escalas:\n\nNominal: hace referencia a categorías en las que no hay un orden o distintas importancias. Ejemplos pueden el sexo o el color.\nOrdinal: aquí hay un órden, y un ejemplo muy claro son las encuestas: 0 es nunca, 1 es casi nunca, 2 es ocasionalmente, 3 es casi siempre y 4 es siempre. Aunque son categorías bien definidas, 2 < 3 y 3 < 4. No son cuantitativas porque las respuestas están sujetas a la interpretación personal, pero descartar el órden en el análisis sería un error.\n\nCuantitativas, que hacen referencia a atributos cuantificables de manera objetiva. Hay dos tipos, cada uno con dos escalas.\n\nTipos:\n\nDiscretas: Son solo números enteros. Un ejemplo cotidiano es la edad, que usualmente la expresamos en años. No vamos por la vida diciendo tengo 18.5 años o 18 años con 6 meses, solo decimos tengo 18 años.\nContinuas: Es el caso contrario, son números fraccionarios. Se les denomina continuas porque hay un número infinito de valores posibles entre un valor y el otro, un ejemplo es la temperatura (35.1ºC, 100 K, etc.)\n\nEscalas:\n\nIntervalo: La escala de intervalo es aquella en donde el 0 NO es absoluto o, mejor dicho, donde el 0 es arbitrario. La temperatura expresada en grados centígrados es un ejemplo claro, 0ºC no indica ausencia de movimiento molecular, solo toma como referencia arbitraria el punto de congelación del agua.\nRazón: Aquí el 0 sí es absoluto y representa la ausencia del atributo en cuestión. La longitud es un ejemplo, si algo tiene longitud 0 más bien no tiene longitud, o si algo tiene una temperatura de 0 K quiere decir que no tiene movimiento molecular (~-273.15ºC).\n\n\n\nAlgo que es muy importante tener siempre bien presente es que, aún cuando existen herramientas y técnicas que nos permiten procesar múltiples variables, en cualquier procedimiento de ciencia de datos es INDISPENSABLE que los datos sean de excelente calidad y, sobre todo, que sean adecuados para responder la pregunta que nos interesa, lo cual nos debe de llevar, invariablemente, a preguntarnos “¿qué datos debo de obtener?” O, en otras palabras, “¿qué debo medir?” Una frase que se me quedó marcada de mis clases de la licenciatura es “La investigación inicia y termina en el escritorio del investigador”; es decir, no salimos a hacer trabajo de campo y a registrar todo lo que se nos atraviese, caso contrario podemos terminar en una conclusión como “los bebés son traídos por cigüeñas”, la cual tiene una anécdota bastante divertida.\nSituémonos en"
  },
  {
    "objectID": "c05_ggplot2.html#visualización-de-datos",
    "href": "c05_ggplot2.html#visualización-de-datos",
    "title": "5  Principios de visualización de datos y ggplot2",
    "section": "5.2 Visualización de datos",
    "text": "5.2 Visualización de datos\n\n\n\nFigure 5.1: Calidad de gráficos en artículos científicos (xkcd)\n\n\nTenemos una gran variedad de razones y objetivos para los cuales necesitamos o recurrimos a visualizaciones de datos (solo visualizaciones a partir de aquí), algunas de ellas son:\n\nExplorar nuestros datos\nElaborar reportes con nuestros análisis\nComunicar hallazgos gráficamente\n\nSoportar resultados en una publicación\nPresentar a un público no especializado\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIndependientemente de para qué hagamos la visualización, lo cierto es que es algo que merece mucha dedicación y que, en realidad, va más allá de hacer un simple gráfico: la visualización de datos nos permite contar una historia.\n\n\nSi obviamos no tenemos cuidado al hacer nuestras visualizaciones procedimiento podemos terminar con un gráfico como el siguiente:\n\n\n\nFigure 5.2: Gráfico “por defecto” en Statistica\n\n\n¿Qué tiene de malo y cómo podemos mejorarlo? Esa es la pregunta que vamos a responder en esta sesión, replanteándola como ¿qué debo tener en cuenta para hacer una buena visualización?, y para lo cual seguiremos algunas heurísticas que nos ayudarán a ser conscientes de qué elementos incluiremos en el gráfico y cuáles no.\n\n\n\n\n\n\nNote\n\n\n\n¿Qué es una heurística? Es una guía que vamos a seguir hasta que encontremos algo mejor; es decir, las recomendaciones que vamos a revisar son, al final del día, eso: recomendaciones. No tienes ninguna obligación de seguirlas, ni mi objetivo es imponer estas ideas, sino hacer que seas consciente de todo lo que implica una visualización de datos.\n\n\n\n5.2.1 Cairo y su rueda\nLa primera heurística que vamos a revisar es la rueda de Cairo (2012). Alberto es una de las figuras más relevantes en el área de la visualización de datos, y una de las muchas heurísticas que propone es considerar la siguiente rueda:\n\n\n\nFigure 5.3: Rueda de Cairo\n\n\nEsta rueda no es una guía tal cual, sino más bien una herramienta que nos permite evaluar las compensaciones que debemos hacer al realizar nuestras visualizaciones. La rueda nos muestra seis ejes que hacen referencia a distintas características de una visualización:\n\nAbstracción-Figuración: Este primer eje refiere a qué tipo de gráfico estamos utilizando. ¿Tenemos un gráfico abstracto como un gráfico de barras, dispersión, etc.? O, por el contrario, tenemos un dibujo que describe exactamente el proceso (gráfico figurativo).\nFuncionalidad-Decoración: Esta es bastante auto-explicativa, y hace referencia a qué tantos elementos decorativos forman la visualización.\nDensidad-Ligereza: Refiere al número de elementos que conforman la visualización o, en otras palabras, a qué tan cargado está nuestro gráfico.\nDimensionalidad: Refiere al número de variables que se incluyen en el gráfico o, puesto de otra forma, a cuántas partes de la historia queremos narrar con un mismo gráfico. No es lo mismo hacer un gráfico de dispersión en el que los puntos sean todos del mismo color a hacer uno donde los puntos estén coloreados según una tercera variable.\nOriginalidad-Familiaridad: Refiere a si los elementos utilizados son familiares para el observador o son elementos nuevos. Una forma fácil de entender este eje es poner lado a lado un gráfico de frecuencias y un gráfico de densidad. Ambos cumplen con el mismo objetivo (uno es más adecuado para variables continuas), pero es bastante probable que los gráficos de frecuencias te sean más familiares.\nRedundancia-Novedad: Referente al número de elementos que ayudan a soportar una misma parte de la historia. Un ejemplo sería tener un gráfico de frecuencias para distintas clases, donde cada barra tiene un color distinto (como en la Figure 5.6). Ahí tanto las clases en el eje x como el color de las barras nos indican que son cosas diferentes.\n\nSi analizamos un poco la distribución de las características, los gráficos que tiendan más a estar en la mitad superior de la rueda son más complejos y profundos que los de la parte baja. De hecho, el mismo Cairo menciona que los científicos e ingenieros prefieren una rueda como esta:\n\n\n\nFigure 5.4: Rueda preferida por científicos e ingenieros\n\n\nMientras que los artistas, diseñadores gráficos y periodistas preferirían una esta otra:\n\n\n\nFigure 5.5: Rueda preferida por diseñadores gráficos\n\n\n¿Esto quiere decir que forzosamente debamos de hacer gráficos abstractos, con muchos elementos “originales” pero mínimas decoraciones, que representen múltiples variables y que no sean redundantes? PARA NADA. Recuerda, esto es solo una heurística, y el hacia dónde te inclines en cada eje dependerá de qué objetivo tengas con tu visualización, a quién vaya dirigida e, incluso, en qué medio va a ser observada.\n\n5.2.1.1 Minard y la (fallida) invasión Napoleónica\nPara cerrar con esta heurística házme un favor y observa con atención el siguiente gráfico:\n{fig-minard}\nEvidentemente es un gráfico muy cargado de información, pero es también considerado por muchos como la “mejor visualización que se ha creado”. ¿Cuántos elementos lo conforman y qué parte de la historia cuentan?\n\n\n\n5.2.2 Tufte y sus tintas\nAhora hablemos de una heurística propuesta por una de las figuras seminales en la visualización de datos: Edward Tufte. Él propone que una buena visualización debería tener una alta proporción de tinta de datos a tinta total, donde él define a la tinta de datos como la tinta gastada para imprimir el núcleo del gráfico; es decir, la información mínima necesaria para transmitir el mensaje, mientras que la tinta total es, como el nombre sugiere, la cantidad de tinta empleada para imprimir el gráfico completo. ¿Qué implica una alta proporción de tinta de datos a tinta total? Que reduzcamos lo más posible el número de elementos en el gráfico.\n\n5.2.2.1 Darkhorse Analytics: Data looks better naked\nPara esta parte sigamos el ejemplo de Darkhorse Analytics, en el cual se mejora la siguiente figura:\n\n\n\nFigure 5.6: Gráfico aparentemente inofensivo (Calorías por 100g de alimento)\n\n\nEl gráfico así como está presentado puede encajar en mayor o menor medida con tus gustos, pero lo cierto es que es un gráfico con una gran cantidad de elementos. Bajo la heurística de las tintas de Tufte quitar es mejorar, así que vayamos elemento a elemento. El primero es el color de fondo. No entraré en el debate de si el color es bonito o no, sino más bien quiero que te preguntes ¿qué me dice el color de fondo sobre lo que se está graficando? La respuesta es: nada; por lo tanto, hay que eliminarlo:\n\n\n\nFigure 5.7: ¿Realmente es necesario el color de fondo?\n\n\nEl siguiente elemento son, en realidad, varios. La visualización muestra el número de calorías por 100g de distintos alimentos. Eso aparece repetido en el título, el título del eje x, el título del eje y y, tal vez de forma menos obvia, en la acotación de colores y las etiquetas del eje x. ¿Qué hacer? Una posible solución Es reducir el título a “calorías por 100g”. ¿100 g de qué? de lo que tenemos en las etiquetas del eje x. Esto nos permite no solo reducir el texto en el título, sino también eliminar los títulos de ambos ejes y la acotación:\n\n\n\n¿Calorías por 100 g de qué?\n\n\nYa “adelgazamos” nuestro gráfico, pero aún podemos continuar. El siguiente elemento son las cuadrículas que delimitan el área del gráfico y el área de graficado. Nuevamente la pregunta es ¿nos dicen algo sobre las calorías de los alimentos? Y nuevamente la respuesta es no. Aunado a esto, desde un punto de vista psicológico, el tener esas delimitaciones puede “limita” la imaginación del observador. Estés o no de acuerdo con este último punto, no cambia el que no aportan nada, así que podemos quitarlas:\n\n\n\n¿Libertad?\n\n\nPuede que estés pensando que hasta este punto ya eliminamos muchas cosas, pero aún hay un par de elementos más. El primero son los colores de las barras. Al igual que la acotación son un elemento redundante que manda el mensaje de que estamos tratando con cosas diferentes, pero eso ya está definido claramente en el eje x. En este caso sería más interesante resaltar alguna categoría en particular, tal vez para responder a la pregunta ¿qué tan calóricos son estos alimentos en relación al tocino?, lo que nos permitiría resaltar al tocino en rojo si ponemos a las demás en un color “neutro” como el gris:\n\n\n\n¿Más o menos calorías que el tocino?\n\n\n¿Esto es todo? Aún no. Tenemos en las barras un elemento derivado de las décadas de los 80s-90s cuando se masificó el uso de las computadoras y los modelos tridimensionales: las sombras y el volumen de las barras. Realmente no aportan nada a la narrativa, sino que solo “cargan” más el gráfico, así que también las eliminamos:\n\n\n\nUn look más minimalista\n\n\nEn este punto hay algo que destaca tanto o incluso más que las barras: el texto del título y de las etiquetas del eje y. Evidentemente no podemos eliminarlos porque ya no sabríamos qué es lo que representa el gráfico, pero lo que sí podemos hacer es cambiar las negritas por gris claro, con lo cual cambiamos el punto de anclaje de la figura a la barra roja con el tocino:\n\n\n\n¡Tocino!\n\n\nAhora ya estamos muy cerca, pero hay algo que se ve fuera de lugar. Ese “algo” está relacionado con el eje y: las etiquetas y las líneas guía. En este punto seguramente me dirás “si quitamos esos elementos ya no vamos a saber”qué tanto es tantito” o cuántas calorías tiene cada cosa”, y tendrías la razón, pero podemos sustituirlo poniendo directamente el número de calorías por 100g de cada alimento sobre su barra, lo cual resulta en un gráfico no solo más simple sino también más preciso:\n\n\n\nFigure 5.8: ¿Cuántas calorías tienes?\n\n\nSi comparas esta última visualización con la ?fig-100g-orig notarás que hubo un cambio notable. El gráfico nuevo es más simple, más fácil de leer e incluso más preciso que el primero, con todo y que tiene muchos menos elementos.\n¿Con esto quiero decir que siempre debamos de tomar esta aproximación minimalista? No, para nada. De hecho, hay casos en los cuales el tener muchos elementos visuales puede ayudar a llamar la atención del lector, a expensas de la precisión del gráfico. Tomemos el siguiente ejemplo:\n\n\n\nFigure 5.9: Precios monstruosas\n\n\nAmbos gráficos presentan exactamente la misma información, pero estarás de acuerdo conmigo en que el dibujo con el monstruo es mucho más llamativo que el simple gráfico de barras, lo cual lo hace más adecuado para el medio en el que fue distribuido: una revista/periódico. Evidentemente no es compatible con una publicación científica, pero si presentas el segundo gráfico es bastante probable que la gente no voltee a verlo.\n\n\n\n5.2.3 Cairo y sus principios\nEsta siguiente heurística también fue propuesta por Cairo, y son cinco sencillos principios que debemos de seguir para llevar a una visualización altamente efectiva. El primero es el principio de funcionalidad, en el que los elementos del gráfico deben de ayudar a transmitir la historia que estamos contando. Volvamos a la ?fig-100g-orig. Las barras, sus colores y la acotación eran funcionales, pero no lo eran el color del fondo o las cuadrículas de graficado.\nEl segundo principio es el de veracidad. Este es auto-explicativo, pero es posiblemente el más importante de todos: que los datos presentados sean veraces, y que sean presentados de una forma veraz o, en otras palabras: NO CUCHAREAR DATOS NI SU APARIENCIA. Ejemplos de visualizaciones donde este principio no se cumple abundan en los medios de comunicación, algunas veces sin que sea el objetivo, pero muchas otras intencionalmente para forzar una narrativa. Un caso particular es la ?fig-eleclies, en donde tenemos el gráfico presentado en los medios de comunicación durante las elecciones entre Nicolás Maduro y Henrique Capriles. En apariencia la diferencia en votos era gigantesca, acrecentado no solo por la diferencia de alturas de los cilindros, sino también por ser figuras tridimensionales. Si los seres humanos somos malos juzgando áreas (razón por la que no se recomienda hacer gráficos de pastel), somos peores aún juzgando volúmenes.\n\n\n\nA que no me alcanzas\n\n\nVolviendo a la diferencia de alturas, aquí hay una “trampa” más: el eje y se encuentra truncado. ¿Qué tanto? Lo suficiente para que una diferencia de 1.59% se vea como una ventaja abrumadora de Maduro sobre Capriles. ¿Cómo se vería el gráfico si se presentara de forma veraz? Bastante menos dramático, eso es seguro:\n\n\n\nTú y yo no somos tan diferentes\n\n\nRecuerda: no porque estemos contando una historia tenemos porque forzar una narrativa o solo mostrar lo que nos conviene. Nuevamente, ejemplos como este abundan en los medios de comunicación, y aquí puedes ver algunos otros.\nEl tercer principio es el de belleza. También es autoexplicativo: que el gráfico sea “bonito”. El problema con este principio es que es sumamente subjetivo. Lo que puede ser bonito para mi puede no serlo para ti, y viceversa, pero podemos valernos de las dos heurísticas anteriores para llegar a un gráfico que sea atractivo y, sobre todo, legible.\nSi estos tres principios se cumplen y van de la mano, llegamos de forma automática al cuarto: el principio de comprensibilidad. Cairo menciona que una visualización comprensible es aquella que permite que el lector/observador pueda ver el gráfico, analizarlo y que pueda tener un momento de “¡EUREKA!”, sin que nosotros describamos el gráfico.\n\n\n5.2.4 Del dicho al hecho hay mucho trecho\nEstas son algunas de las consideraciones más básicas que debemos de tener al realizar una visualización de datos, pero no son las únicas. Te recomiendo leer el artículo de (Rougier_2014?), el cual tiene otras guías para mejorar nuestras figuras. Ahora bien, una cosa es conocer la teoría, pero de nada sirve si no podemos llevarlo a la práctica, y es aquí donde entra ggplot2."
  },
  {
    "objectID": "c05_ggplot2.html#ejercicio",
    "href": "c05_ggplot2.html#ejercicio",
    "title": "5  Principios de visualización de datos y ggplot2",
    "section": "5.4 Ejercicio",
    "text": "5.4 Ejercicio\nAjusta la visualización de los datos mpg para que pueda ser publicable en una revista científica (de tu interés) y responde:\n\n¿Qué elementos quitarías?\n¿Qué elementos cambiarías?\n¿Qué elementos agregarías?\n¿Crees que en su estado actual cumple con los criterios de Tufte y Cairo que revisamos en clase? (Explica tu respuesta).\n\nNOTA: En vez de los datos mpg puedes utilizar datos propios o los datos de pingüinos de Palmer.\n\n\n\n\nCairo, A. 2012. The Functional Art. Berkeley, USA: New Riders, Pearson Education.\n\n\nWilkinson, L. 2005. The Grammar of Graphics. Statistics and Computing. USA: Springer."
  },
  {
    "objectID": "c04_tidyverse.html",
    "href": "c04_tidyverse.html",
    "title": "4  Introducción a tidyverse",
    "section": "",
    "text": "En la sesión anterior mencionamos que hay un “paquete de paquetes” que da lugar a un “dialecto” dentro de R: tidyverse, pero no especifiqué a qué me refería con ello. Pues bien, mientras que en R base los procedimientos los realizamos línea a línea, generando a veces una gran cantidad de objetos intermedios o sobreescribiendo los existentes, tidyverse está basado en el paradigma funcional de la programación, con una “gramática” (sintaxis) distinta, muy similar a lo que veremos en ggplot2. De hecho, ggplot2 es un paquete del tidyverse, por lo que el “dialecto” tidy comparte la filosofía declarativa y fomenta la “encadenación” de comandos. A muchas personas les gusta más la forma tidy, a otras les gusta más trabajar con R base. En lo personal soy partidario de que utilices lo que más te acomode, siempre y cuando lo que hagas tenga sentido, pero más de esto cerca del final de la sesión.\nEste nuevo dialecto fue creado con un objetivo en particular: la ciencia de datos. Como tal, cuenta con una gran cantidad de librerías (y por lo tanto funciones) especializadas para realizar operaciones rutinarias. ¿Quieres realizar gráficos? En la siguiente sesión hablaremos de ggplot2. ¿Quieres hacer “manipulación” (ojo, no cuchareo) de datos? Aquí veremos algnas funciones de dplyr. ¿Quieres trabajar con procesamiento de cadenas de caractér? Para esto está stringr. ¿Quieres herramientas para programación funcional? Ve hacia purrr (sí, triple r). readxl es otra librería con la que ya estás familiarizado y que forma parte del tidyverse. ¿Tienes un problema en el que que necesitas manejar fechas? lubridate puede ser una opción. Puedes conocer todos los paquetes que forman el tidyverse con:\n\ntidyverse::tidyverse_packages(include_self = T)\n\n [1] \"broom\"         \"cli\"           \"crayon\"        \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"readr\"        \n[21] \"readxl\"        \"reprex\"        \"rlang\"         \"rstudioapi\"   \n[25] \"rvest\"         \"stringr\"       \"tibble\"        \"tidyr\"        \n[29] \"xml2\"          \"tidyverse\"    \n\n\nA partir de aquí, el cómo aprovecharlos depende mucho de el problema que tengas entre manos, pero la idea general es la misma: utilizar una gramática declarativa para llegar a la solución. Veamos en qué consiste con un ejemplo cotidiano: obtener el promedio de una variable para varios grupos.\n\n\nVeamos un ejemplo en el cual calcularemos la longitud de pico promedio para cada especie de pingüino, según los datos de palmerpenguins. Primero, carguemos los datos:\n\ndatos1 <- palmerpenguins::penguins\n\nAhora, obtengamos los promedios con la función aggregate, tal y como vimos en la sesión anterior:\n\naggregate(bill_length_mm~species, data = datos1, FUN = mean)\n\n\n\n  \n\n\n\nAhora repliquémoslo con tidyverse, particularmente con las funciones group_by y summarise (o summarize) de la librería dplyr:\n\nlibrary(dplyr)\n\ndatos1 |>\n  group_by(species) |>\n  summarise(mbill_l = mean(bill_length_mm, na.rm = T))\n\n\n\n  \n\n\n\nNotarás que el resultado es exactamente el mismo, aunque la forma de hacerlo es diferente. Descompongámosla paso a paso para ver qué es lo que está pasando:\n\nlibrary(dplyr): cargamos la librería dplyr, la cual contiene las funciones que nos interesa aplicar: group_by y summarise.\nLlamamos directamente a nuestros datos (datos1) y utilizamos un operador que no habíamos visto: |>. Este es el operador pipe, el cual pasa lo que está a la izquierda de él como el primer argumento de lo que está a la derecha de él. Esto puede sonar confuso, pero la instrucción datos1 |> group_by(sp) es equivalente a group_by(datos1, sp). Podemos ver al operador pipe como su nombre sugiere: una tubería que manda la información de un lado hacia otro.\ngroup_by(sp): Como te mencionaba, tidy es un poco más explícito que R base. Mientras que el argumento con la fórmula en aggregate indica cómo se van a agrupar los datos, aquí primero los agrupamos y después aplicamos la función que nos interesa. group_by hace justamente eso, agrupar nuestros datos, nada más, nada menos. El argumento principal de esta función es la(s) columnas bajo las cuales queremos agrupar nuestros datos. En este caso solo es una (sp), por lo que la pasamos directamente.\nNuevamente utilizamos el operador |>. Hasta este punto hemos pasado los datos1 a la función group_by(sp), por lo que ya están agrupados por especie, pero falta aplicar la función mean() para obtener el promedio, entonces volvemos a encadenar hacia la función summarise(). Esta función recibe una serie de pares nombres de columnas y funciones a aplicar. En este caso, estamos generando una columna llamada mbill_l que contiene los promedios de la columna bill_length_mm de los datos1.\n\n\n\n\n\n\n\nImportant\n\n\n\nSi revisas documentación “antigua” sobre tidyverse (previa a R 4.1, de hecho), notarás que el operador pipe es %>% en vez de |>. El resultado es el mismo y, de hecho, a partir de R 4.1 puedes seleccionar cuál utilizar en las preferencias de RStudio. En el curso utilizaremos |> por ser el operador pipe nativo de R, el cual fue introducido (como te imaginarás) en R 4.1.\n\n\n¿Abstracto? Sin duda. ¿Útil? También. ¿Más explícito que R base con aggregate? Debatible. Lo que no es debatible es que esta notación brilla especialmente en cierto tipo de problemas. Pensemos que nos interesa conocer el promedio de las longitudes de picos por especie para cada isla. Intenta hacerlo con R base y te darás cuenta de que no es tan intuitivo, salvo que estés familiarizado con el uso de fórmulas. ¿En tidy? Solamente hay que agregar la nueva variable de agrupamiento a group_by:\n\ndatos1 |>\n  group_by(species, island) |>\n  summarise(mbill_l = mean(bill_length_mm,\n                           na.rm = T))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n\n\n  \n\n\n\nAhora tenemos un tibble (funcionalmente equivalente a un data.frame) con tres columnas, en donde se da el promedio para cada combinación de las variables de agrupamiento. ¿A que es más sencillo que intentar hacerlo con R base?. Esto último no es del todo cierto, pues hay una forma muy sencilla de hacerlo con aggregate(), pero encontrar una manera es parte de tu tarea, así que no arruinaré la diversión.\n\n\n\n\n\n\nNote\n\n\n\nCon esto no quiero deciro que tidy sea mejor que R base o viceversa, solamente que son dos aproximaciones, cada una con sus propias ventajas y desventajas. Por un lado, R base puede llegar a ser más compacto, pero tidy tiende a ser más explícito. Por supuesto, también hay casos en los que lo contrario es verdad.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nHay ocasiones en las cuales querrás evitar el uso de tidyverse, y una de ellas es al crear nuevas librerías. ¿La razón? Puedes crear un conflicto de dependencias si no lo manejas con cuidado. Otra es que es sumamente complicado depurar errores.\n\n\nTe habrás dado cuenta de que hasta este momento no hemos asignado nuestros resultados a ningún objeto. Esto se debe a dos razones. La primera, y tal vez la que pasa por tu cabeza, es que de esta manera podemos mostrar los resultados más rápidamente, y sí, pero el trasfondo está en la segunda razón: La asignación sigue un sentido opuesto al encadenamiento. Mientras que con |> la información fluye de izquierda a derecha, con <- la información fluye de derecha a izquierda. Quise, entonces, que primero te acostumbraras al flujo de información con pipe, pues asignar el resultado a un objeto es lo mismo que hemos hecho hasta ahora:\n\ngmeans <- datos1 |>\n          group_by(species, island) |>\n          summarise(mbill_l = mean(bill_length_mm,\n                                   na.rm = T))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\ngmeans\n\n\n\n  \n\n\n\n\n\n\nEn la sesión anterior nos familiarizamos con máscaras booleanas y la función subset. tidy tiene su propia aproximación. Pensemos que queremos quedarnos solo con los pingüinos provenientes de Biscoe. Con subset:\n\nsubset(datos1, island == \"Biscoe\")\n\n\n\n  \n\n\n\nMientras que con tidy:\n\ndatos1 |> filter(island == \"Biscoe\")\n\n\n\n  \n\n\n\nLa notación no es tan diferente como en el caso anterior, y el resultado es el mismo. ¿Cuál utilizar? Depende totalmente de la preferencia de cada quien. A diferencia del caso anterior, subset no se vuelve tan compleja conforme vamos escalando en complejidad, y la equivalencia entre aproximaciones con filter se mantiene. Veamos qué pasa si obtenemos SOLO los pingüinos Adelie de Biscoe. Nuevamente, con subset:\n\nsubset(datos1, species == \"Adelie\" & island == \"Biscoe\")\n\n\n\n  \n\n\n\nCon tidy:\n\ndatos1 |> filter(species == \"Adelie\" & island == \"Biscoe\")\n\n\n\n  \n\n\n\n¿Por qué empezar con un ejemplo tan “complejo” como el caso anterior? Para dejar “lo peor” al inicio, y a partir de ahí las cosas puedan fluir un poco mejor.\n\n\n\nOtra tarea cotidiana que vimos en la sesión anterior fue el añadir nuevas columnas a nuestro data.frame. Pensemos que tiene sentido obtener el “área” que utiliza el pico, la cual obtendríamos multiplicando bill_length_mm y bill_depth_mm. Este producto lo almacenaríamos en una nueva columna llamada bill_area. En R base:\n\ndatos1[\"bill_area\"] <- datos1$bill_length_mm * datos1$bill_depth_mm\ndatos1$bill_area\n\n  [1]  731.17  687.30  725.40      NA  708.31  809.58  692.42  768.32  617.21\n [10]  848.40  646.38  653.94  723.36  818.32  730.06  651.48  735.30  879.75\n [19]  632.96  989.00  691.74  704.99  689.28  691.42  667.36  667.17  755.16\n [28]  724.95  704.94  765.45  659.65  673.32  703.10  773.01  618.80  827.12\n [37]  776.00  780.70  725.68  760.18  657.00  750.72  666.00  868.77  625.30\n [46]  744.48  780.90  708.75  644.40  896.76  700.92  757.89  626.50  819.00\n [55]  624.45  770.04  682.50  763.28  605.90  718.16  603.33  871.43  639.20\n [64]  748.02  622.44  748.80  575.10  785.01  595.94  810.92  636.50  730.48\n [73]  681.12  865.62  621.25  791.80  687.12  721.68  582.82  804.11  595.12\n [82]  755.04  689.96  680.94  663.94  838.39  707.85  686.34  735.36  731.32\n [91]  642.60  743.91  581.40  716.76  626.26  771.12  708.66  745.55  532.91\n[100]  799.20  626.50  820.00  603.20  756.00  704.94  750.33  663.92  764.00\n[109]  647.70  820.80  628.65  925.68  702.69  822.90  819.72  781.41  656.20\n[118]  764.65  606.90  764.46  622.64  746.46  683.40  765.90  559.68  771.40\n[127]  682.88  759.45  666.90  793.80  689.15  827.52  680.80  693.75  670.56\n[136]  719.25  623.00  808.02  610.50  710.63  687.42  698.32  497.55  691.90\n[145]  626.64  729.30  729.12  673.44  640.80  684.18  615.60  767.75  608.52\n[154]  815.00  686.67  760.00  690.20  627.75  662.84  714.51  580.22  720.72\n[163]  560.33  788.90  623.35  706.64  668.68  774.01  567.00  747.84  669.90\n[172]  735.37  717.86  653.95  674.25  731.54  561.99  696.11  636.35  717.00\n[181]  689.26  765.00  723.69  607.76  653.95 1013.20  726.68  788.92  583.62\n[190]  768.12  598.40  764.59  584.99  793.60  620.61  744.00  802.95  606.04\n[199]  632.45  802.95  597.17  714.16  661.72  683.85  649.44  751.50  669.60\n[208]  693.00  608.82  682.50  626.40  771.12  625.14  688.38  635.23  852.51\n[217]  650.36  836.64  665.28  801.90  617.70  760.50  715.50  723.84  751.92\n[226]  688.20  696.00  777.60  674.50  832.93  623.76  741.28  711.95  819.00\n[235]  692.04  795.00  619.62  878.84  624.96  728.46  665.00  885.70  712.50\n[244]  892.62  659.75  796.95  654.15  797.56  780.52  684.74  696.96  843.15\n[253]  727.50  950.30  731.60  736.50  652.74  753.48  612.99  843.72  606.20\n[262]  726.31  767.60  791.82  661.20  839.45  651.42  881.60  698.65  790.56\n[271]  646.64      NA  669.24  791.28  668.96  803.39  832.35  975.00  984.96\n[280]  848.98 1043.46  804.56  839.02  933.66  869.40 1020.87  829.48 1049.51\n[289]  813.10  941.20  784.89  989.80 1006.00 1032.40  863.04  895.44  733.52\n[298]  848.75  717.12  981.64  835.93  988.00  929.20  940.50  825.92 1056.00\n[307]  678.94 1127.36  709.75  958.80  924.42  798.00  871.08 1076.40  778.54\n[316] 1064.65  955.50  808.50  972.19  773.50  911.11  939.80  896.79  960.40\n[325]  963.05  861.54  788.84  976.60  790.61  998.79  735.25  981.36  750.32\n[334]  981.07  943.76  884.64 1012.05  772.20  776.90 1104.84  787.35  902.72\n[343]  965.20  938.74\n\n\nAhora hagámoslo con tidy, pero primero reestablezcamos el objeto datos1:\n\ndatos1 <- palmerpenguins::penguins\n\nY ahora hagamos la operación con tidy:\n\ndatos1 <- datos1 |> \n          mutate(bill_area = bill_length_mm * bill_depth_mm)\ndatos1 |> select(bill_area)\n\n\n\n  \n\n\n\nEvidentemente, los resultados son los mismos, lo cual me lleva directamente a la siguiente sección."
  },
  {
    "objectID": "c04_tidyverse.html#por-qué-no-enseñar-tidy-desde-el-inicio",
    "href": "c04_tidyverse.html#por-qué-no-enseñar-tidy-desde-el-inicio",
    "title": "4  Introducción a tidyverse",
    "section": "4.2 ¿Por qué no enseñar tidy desde el inicio?",
    "text": "4.2 ¿Por qué no enseñar tidy desde el inicio?\nSi tidy se acomodó a tu forma de ver las cosas, o si se te hizo más fácil de leer, es probable que te preguntes por qué no me salté R base para entrar directamente a tidy. Además de incrementar las horas del curso (broma), fue porque (pedagógicamente) tidy puede introducir ciertas barreras para quienes se van introduciendo a R. Matloff (2020) hace una excelente y extensiva recopilación de las razones por las cuales enseñar solo tidy (o solo R base) es una mala idea, así que te recomiendo leas su opinión; sin embargo, me gustaría darte mi perspectiva. Te adelanto: si no tienes experiencia en programación, el paradigma de tidy supone una curva de aprendizaje más alta que solo R base (solo R a partir de aquí) y, tal vez más importante, no es necesario casarse con uno u otro.\n\n4.2.1 tidy es más complejo\nComo habrás notado en esta sesión, tidy es, escencialmente, más complejo que R. Esto no es una falla en el diseño, sino que tiene que ver con la filosofía de la aproximación: generar código que sea más fácilmente leíble por seres humanos. Sin duda alguna, el utilizar data |> group_by() |> summarise() puede parecer menos críptico o más “entendible” que solo aggregate(formula, data, FUN); sin embargo, esto se debe a que ya conocías qué es una librería y cómo cargarla, qué es una función y qué es un argumento, pero aún así hubo que explicar qué es encadenamiento de operaciones/funciones y el operador pipe y también tuvimos que entender que la información fluye de izquierda a derecha al encadenar y de derecha a izquierda al asignar.\nSi esto no fuera suficiente, el utilizar pipes puede complicar demasiado las cosas al querer depurar errores. ¿La razón? Es una capa más de abstracción. Mientras que cuando aprendemos R es común generar objetos intermedios con los resultados y ver sus salidas (o detectar errores en cada paso), en tidy esto tiende a no ser el caso. ¿Qué obtienes si solo aplicas group_by() en el ejemplo anterior? (i.e., no aplicas summarise()). El ejemplo que vimos es relativamente sencillo pero, en la medida que los problemas se van haciendo más complejos, es fácil perder la pista de qué sale de una función y entra a otra.\nEn mi opinión esto no es un problema TAN grande como pudiera parecer. Tomemos de ejemplo a Python, el lenguaje de programación reconocido como el más intuitivo. Al utilizarlo, el encadenamiento y uso de pipes es cotidiano y, aún más, preferido. En este sentido, tidyverse me recuerda mucho a la funcionalidad que de pandas en Python pero, al igual que aquí, lo correcto es aproximarse primero a Python base y luego pensar en aprender pandas. En mi opinión, el problema real (quitando la capa de abstracción) es en realidad dos problemas: uno relacionado con la filosofía de tidy y otro con quienes enseñamos R.\n\n\n4.2.2 tidy limita tus opciones\nUn ejemplo de esto está en esta misma clase. ¿Cómo obtendríamos los promedios de datos agrupados a dos niveles? Dejé el ejercicio “en el tintero” (es parte de tu tarea para esta sesión) pero, si solo te hubiera enseñado tidy, no podrías pensar en ciclos, el operador $ o cualquier otra forma de indización. ¿La razón? tidy no está enfocado a tratar con vectores individuales, aborrece el uso de ciclos y tampoco sigue las notaciones básicas de indización. Recuerda: en programación siempre es mejor tener más herramientas a tu disposición. Esta limitación la podemos probar rápidamente si queremos extraer los elementos 10:25 de la columna sex de los datos1. Con R base:\n\ndatos1$sex[10:25]\n\n [1] <NA>   <NA>   <NA>   female male   male   female female male   female\n[11] male   female male   female male   male  \nLevels: female male\n\n\n¿Con tidy? Realmente no hay una función que permita hacerlo. Podemos extraer la columna sex utilizando la función select:\n\ndatos1 |> select(sex)\n\n\n\n  \n\n\n\nPero si queremos indizar el resultante obtenemos un error:\n\ndatos1 |> select(sex)[10:25]\n\nError: function '[' not supported in RHS call of a pipe\n\n\n¿La alternativa? Primero indizar datos1 y luego utilizar select. Esto, como ves aquí abajo, funciona, pero hubiera sido mucho más fácil solo utilizar R base, sin mencionar que en tidy “puro” esta solución no es aceptable.\n\ndatos1[10:25,] |> select(sex)\n\n\n\n  \n\n\n\nPor otra parte, hay una falta de consistencia interna derivada de una estrategia publicitaria (tal vez) un poco mal llevada. ggplot2 no surgió dentro del tidyverse, sino que fue incluído después. Si bien es cierto que la filosofía es similar (i.e., una estructura declarativa), el cómo funcionan es completamente diferente. Una de las máximas de tidyverse (sin ggplot2) es que todo lo que entra o lo que sale es un data.frame (o tibble), mientras que en ggplot2 entra un data.frame y sale una lista. De hecho, más adelante veremos cómo podemos utilizar ciclos para automatizar la generación de gráficos, pero esto va en contra de la filosofía de tidy y no sería posible si nos hubiéramos enfocado únicamente en ella.\n\n\n4.2.3 Los ponentes somos necios\nEl mayor problema al que nos enfrentamos al aprender algún lenguaje de programación (y en muchas otras cosas) es que estamos sujetos a los prejuicios y preferencias de la persona que nos está enseñando. Al aprender a manejar nuestro tío amante de los autos nos va a decir que la transmisión manual (estándar) es mejor que la automática, pero nuestro papá, quien ve los carros solo como un medio de transporte, nos va a decir que con la automática es suficiente. ¿Cuál es mejor? Para variar, la respuesta es: “depende”. ¿De qué? De la situación en la que nos encontremos. En ciudad tener una transmisión manual puede ser muy cansado, pero puede darnos un mayor control en una carretera con un descenso empinado y muchas curvas.\nEn el problema R base vs. tidy es lo mismo. Hay ponentes “puristas” en ambos sentidos: personas que creen que tidy debería considerarse sacrilegio, y personas que creen que R base es obsoleto, arcaico, y que debería de caer en desuso. No te conviertas en ninguno de ellos y mejor toma lo mejor de ambos.\n\n\n4.2.4 tidy expande tus horizontes\nEn mi opinión, lo que te acabo de exponer son los problemas principales de enseñar solo tidy y, de acuerdo con Matloff (2020), las razones por las cuales enseñar una mezcla de ambos es la mejor opción. Aprender R base nos permite resolver problemas que en tidy sería muy largo, mientras que tidy nos permite simplificar procedimientos que serían más complicados en R base. Otra ventaja de tidy es que permite unificar procesos bajo una misma sintaxis.\nUn ejemplo de esto lo tenemos en el aspecto de aprendizaje automatizado. Si te pones a revisar tutoriales/referencias sobre aprendizaje automatizado es muy probable que te encuentres con un montón de librerías (una por problema), funciones dedicadas y sintáxis que son específicas a la técnica que quieras aplicar. Teníamos/tenemos un excelente intento de solventar este problema: caret. Funcionaba bien en el sentido de que permitía conjuntar una gran diversidad de técnicas de aprendizaje automatizado en un mismo entorno, unificadas en un mismo estilo. Utilizando solo caret podríamos ir desde el preprocesamiento de los datos hasta el entrenamiento y validación de nuestros modelos. ¿El problema? Las pocas funciones que forman su esqueleto se volvieron sumamente complejas, algunas de ellas con 30 o más argumentos. El equipo de posit se ha puesto el mismo desafío, y su solución es tidymodels. A diferencia de caret es altamente modular, pero mantiene la intención de unificar el flujo de trabajo en una misma estructura. Tal vez yendo en contra de nuestro consejo, la mayor parte de nuestros procedimientos de aprendizaje automatizado los realizaremos bajo tidymodels, pero haremos referencia a las librerías y funciones involucradas en cada paso. Para ejemplificar, realicemos una regresión lineal simple entre la longitud y la profundidad del pico de los pingüinos.\nEn R base lo podemos hacer en una sola línea, llamando a la función lm con una fórmula y unos datos:\n\nlm(bill_length_mm~bill_depth_mm, data = datos1)\n\n\nCall:\nlm(formula = bill_length_mm ~ bill_depth_mm, data = datos1)\n\nCoefficients:\n  (Intercept)  bill_depth_mm  \n      55.0674        -0.6498  \n\n\nEn tidymodels es un poco más complejo:\n\nlibrary(tidymodels)\n\nlinear_reg() |>\n  set_engine(\"lm\") |> \n  set_mode(\"regression\") |> \n  fit(bill_length_mm~bill_depth_mm, data = datos1)\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = bill_length_mm ~ bill_depth_mm, data = data)\n\nCoefficients:\n  (Intercept)  bill_depth_mm  \n      55.0674        -0.6498  \n\n\n¿Por qué utilizar tidymodels entonces? Eso lo dejaremos para las sesiones en las que hablemos de aprendizaje automatizado, pero verás que toma mucho sentido en el momento en el que empiezas a hacer particiones entrenamiento/prueba, optimización mediante validación cruzada, preprocesamiento de datos, evaluación, y demás tareas necesarias. Lo único que te diré en este punto es que el poder homogeneizar todos estos procedimientos en un solo estilo de trabajo simplifica las cosas."
  },
  {
    "objectID": "c04_tidyverse.html#conclusión",
    "href": "c04_tidyverse.html#conclusión",
    "title": "4  Introducción a tidyverse",
    "section": "4.3 Conclusión",
    "text": "4.3 Conclusión\nAunque tidy puede llegar a verse más elegante o moderno que R base, no es un substituto total. Aunque R base te permite resolver los mismos problemas que tidy, a veces no es tan intuitivo. ¿Solución? No casarse con ninguno de los dos y exprimirlos lo mejor posible. ¿Tu problema se resuelve más rápidamente con tidy? Úsalo. ¿R base se presta mejor? Aprovéchalo. Recuerda, R (como cualquier otro lenguaje de programación) es una caja de herramientas en la cual debes de buscar la que mejor se adapte al problema o pregunta que quieras responder.\nEsto es todo para esta sesión, nos vemos en la siguiente para hablar sobre teoría y buenas prácticas para la visualización de datos."
  },
  {
    "objectID": "c04_tidyverse.html#ejercicio",
    "href": "c04_tidyverse.html#ejercicio",
    "title": "4  Introducción a tidyverse",
    "section": "4.4 Ejercicio",
    "text": "4.4 Ejercicio\n\nUtilizando R base obtén los promedios de las longitudes de picos de los pingüinos de palmerpenguins para cada especie en cada isla. OJO: Hay al menos dos formas de hacerlo, una muy simple y una más rebuscada. No importa cuál realices, el objetivo es que te rompas la cabeza un rato ;).\nUtilizando tidy (dplyr), y en una sola cadena, filtra los datos para la isla Biscoe, crea una columna que tenga cada valor de la masa corporal menos la media global de esa columna, y luego obtén el promedio de esta columna para cada especie.\nRealiza la misma operación del punto 2 con R base. Algunas funciones que puedes tomar en cuenta para estos dos puntos son subset, filter, mutate, aggregate, summarise y/o for.\nOpcionalmente puedes intentar mezclar ambos procedimientos para llegar al mismo resultado.\n¿Qué opción se te hizo más sencilla? ¿tidy, R base o una combinación de las dos?\n\n\n\n\n\nMatloff, N. 2020. “Teaching R in a Kinder, Gentler, More Effective Manner: Teach Base-R, Not Just the Tidyverse.” https://github.com/matloff/TidyverseSkeptic?fbclid=IwAR0b_e0fWGfFe1exc_VwJUh4TGLtOxoEb4h3YJv6BOCbybSdVBNp6T2xJIU."
  },
  {
    "objectID": "c07_muestreo.html",
    "href": "c07_muestreo.html",
    "title": "7  Introducción al muestreo",
    "section": "",
    "text": "En una investigación reunimos datos con el objetivo de obtener alguna conclusión o predicción. Pues bien comencemos definiendo un dato como una representación puntual de la realidad. Son un solo valor, sea una sola medición, un promedio, una desviación estándar, una proporción de sexos, etc, y el conjunto de datos de un mismo atributo medidos en distintos individuos nos dan una variable. Es decir, en nuestros conjuntos de datos cada valor es un dato, y cada columna (usualmente) es una variable. ¿Por qué es importante conocer esto? Porque hay distintos tipos de variables, los cuales definen cómo es que vamos a graficar y tratar esos datos:\n\nCualitativas: hacen referencia a las cualidades de nuestros individuos, y tienen dos escalas:\n\nNominal: hace referencia a categorías en las que no hay un orden o distintas importancias. Ejemplos pueden el sexo o el color.\nOrdinal: aquí hay un órden, y un ejemplo muy claro son las encuestas: 0 es nunca, 1 es casi nunca, 2 es ocasionalmente, 3 es casi siempre y 4 es siempre. Aunque son categorías bien definidas, 2 < 3 y 3 < 4. No son cuantitativas porque las respuestas están sujetas a la interpretación personal, pero descartar el órden en el análisis sería un error.\n\nCuantitativas, que hacen referencia a atributos cuantificables de manera objetiva. Hay dos tipos, cada uno con dos escalas.\n\nTipos:\n\nDiscretas: Son solo números enteros. Un ejemplo cotidiano es la edad, que usualmente la expresamos en años. No vamos por la vida diciendo tengo 18.5 años o 18 años con 6 meses, solo decimos tengo 18 años.\nContinuas: Es el caso contrario, son números fraccionarios. Se les denomina continuas porque hay un número infinito de valores posibles entre un valor y el otro, un ejemplo es la temperatura (35.1ºC, 100 K, etc.)\n\nEscalas:\n\nIntervalo: La escala de intervalo es aquella en donde el 0 NO es absoluto o, mejor dicho, donde el 0 es arbitrario. La temperatura expresada en grados centígrados es un ejemplo claro, 0ºC no indica ausencia de movimiento molecular, solo toma como referencia arbitraria el punto de congelación del agua.\nRazón: Aquí el 0 sí es absoluto y representa la ausencia del atributo en cuestión. La longitud es un ejemplo, si algo tiene longitud 0 más bien no tiene longitud, o si algo tiene una temperatura de 0 K quiere decir que no tiene movimiento molecular (~-273.15ºC).\n\n\n\nAlgo que es muy importante tener siempre bien presente es que, aún cuando existen herramientas y técnicas que nos permiten procesar múltiples variables, en cualquier procedimiento de ciencia de datos es INDISPENSABLE que los datos sean de excelente calidad y, sobre todo, que sean adecuados para responder la pregunta que nos interesa, lo cual nos debe de llevar, invariablemente, a preguntarnos “¿qué datos debo de obtener?” O, en otras palabras, “¿qué debo medir?” Una frase que se me quedó marcada de mis clases de la licenciatura es “La investigación inicia y termina en el escritorio del investigador”; es decir, no salimos a hacer trabajo de campo y a registrar todo lo que se nos atraviese, caso contrario podemos terminar en una conclusión como “los bebés son traídos por cigüeñas”, la cual tiene una anécdota bastante divertida.\nSituémonos en"
  }
]