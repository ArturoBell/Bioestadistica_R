) +
geom_vline(xintercept = 1.96,
colour = rgb(118,78,144, maxColorValue = 255),
linetype = "dashed"
) +
geom_point(aes(x = z, y = 0),
color = robs$color, alpha = 0.3) +
scale_y_continuous(breaks = NULL) +
scale_x_continuous(breaks = c(-3, -1.96, -1, 0, 1, 1.96, 3),
labels = as.character(c(-3, -1.96, -1, 0, 1, 1.96, 3))
) +
annotate("text", x = 3, y = 0.5,
label = paste("# sign = ",
length(robs$color[robs$color == "firebrick"]), "/", n),
colour = "firebrick"
)
robs.plot
set.seed(45)
n <- 1000
a.corr <- (0.05/n)/2
sig.lev <- abs(qnorm(a.corr))
robs <- data.frame(z = rnorm(n))
robs["color"] <- ifelse(robs$z < -sig.lev | robs$z > sig.lev, "firebrick", "deepskyblue4")
rcor.plot <- ggplot(data = robs, aes(z)) +
geom_density(color = "deepskyblue4") +
blank_theme() +
labs(title = "Observaciones aleatorias a un nivel de significancia de 0.05",
subtitle = "Bandas indican límites del LS corregido",
caption = paste(n, " datos simulados"),
x = "Z",
y = element_blank()
) +
geom_vline(xintercept = -sig.lev,
colour = rgb(118,78,144, maxColorValue = 255),
linetype = "dashed"
) +
geom_vline(xintercept = sig.lev,
colour = rgb(118,78,144, maxColorValue = 255),
linetype = "dashed"
) +
geom_point(aes(x = z, y = 0),
color = robs$color, alpha = 0.3) +
scale_y_continuous(breaks = NULL) +
scale_x_continuous(breaks = c(-3, -1.96, -1, 0, 1, 1.96, 3),
labels = as.character(c(-3, -1.96, -1, 0, 1, 1.96, 3))
) +
annotate("text", x = 2.5, y = 0.5,
label = paste("# sign = ",
length(robs$color[robs$color == "firebrick"]), "/", n),
colour = "firebrick"
)
rcor.plot
mili <- read.csv("milipedos.csv")
str(mili)
norm.mili <- data.frame(grupo = NA, n = NA, W = NA, p = NA)
cols <- colnames(mili)[1:2]
especies <- as.character(unique(mili$Especie))
sexos <- as.character(unique(mili$Sexo))
for (i in 1:length(cols)) {# Cicla entre las columnas indicadas
if (i == 1) { # Si es la primera columna:
for (j in 1:length(especies)) { # Cicla entre los valores de la columa Especies
shap <- shapiro.test(mili$Ala[mili[cols[i]] == especies[j]])
norm.mili[j,] <- c(especies[j],
length(mili$Ala[mili[cols[i]] == especies[j]]),
round(shap$statistic, 2),
round(shap$p.value, 2)
)
}
}
if (i == 2) { # Si es la segunda columna
for (k in 1:length(sexos)) { # Cicla entre los valores de la columna Sexo
shap <- shapiro.test(mili$Ala[mili[cols[i]] == sexos[k]])
norm.mili[j+k,] <- c(sexos[k], # Sexo de la iteración
length(mili$Ala[mili[cols[i]] == sexos[k]]), # Tamaño de muestra para esa iteración
round(shap$statistic, 2), #
round(shap$p.value, 2)
)
}
}
}
norm.mili
# Dado que los datos se ajustaron a una distribución normal podemos utilizar la prueba de Bartlett
bartlett.test(Ala~Sexo, data = mili)
bartlett.test(Ala~Especie, data = mili)
# Verificamos con la prueba de Levene
library(car)
leveneTest(Ala~Sexo, data = mili)
leveneTest(Ala~Especie, data = mili)
library(rcompanion)
library(FSA)
scheirerRayHare(Ala ~ Especie + Sexo, data = mili)
dunnTest(Ala~Especie, data = mili, method = "bonferroni")
res.mili <- aov(Ala~Especie * Sexo, data = mili)
summary(res.mili)
TukeyHSD(res.mili)$Especie
inter.plot <- ggplot(data = mili, aes(x = Sexo, y = Ala, color = Sexo)) +
geom_violin() + geom_boxplot(width = 0.1) +
facet_wrap(~Especie) +
blank_theme(1.61) +
labs(title = "Gráfico de interacción de la [Ala] (mg/100 ml) en milípedos",
subtitle = "Especie + Sexo",
x = element_blank(),
y = element_blank(),
caption = "Datos: milipedos.csv")
inter.plot
espec.plot <- ggplot(data = mili, aes(x = Especie, y = Ala, color = Especie)) +
geom_violin() + geom_boxplot(width = 0.1) +
blank_theme() +
labs(title = "Gráfico de interacción de la [Ala] (mg/100 ml) en milípedos",
subtitle = "Especie",
x = element_blank(),
y = element_blank(),
caption = "Datos: milipedos.csv")
espec.plot
sexos.plot <- ggplot(data = mili, aes(x = Sexo, y = Ala, color = Sexo)) +
geom_violin() + geom_boxplot(width = 0.1) +
blank_theme() +
labs(title = "Gráfico de interacción de la [Ala] (mg/100 ml) en milípedos",
subtitle = "Especie",
x = element_blank(),
y = element_blank(),
caption = "Datos: milipedos.csv")
sexos.plot
straw <- read.csv("strawberry.csv")
head(straw)
str(straw)
summary(straw)
straw$Tratamiento <- factor(LETTERS[straw$Tratamiento])
straw$Rep <- factor(letters[straw$Rep])
head(straw)
head(iris)
str(iris)
summary(iris)
library(MVN)
mvn(iris, subset = "Species", mvnTest = "mardia", desc = F)$multivariateNormality
mvn(iris, subset = "Species", mvnTest = "hz", desc = F)$multivariateNormality
mvn(iris, subset = "Species", mvnTest = "royston", desc = F)$multivariateNormality
library(vegan)
dist.mat <- vegdist(iris[,1:4], method = "bray", type = c("median"))
groups <- as.character(iris$Species)
disp.mv <- betadisper(dist.mat, group = groups, type = "median") # Realizar el procedimiento
disp.mv
anova(disp.mv) # Prueba de hipótesis
mod.HSD <- TukeyHSD(disp.mv)
mod.HSD <- data.frame(mod.HSD$group, comp = dimnames(mod.HSD$group)[[1]])
mod.HSD
versicolor <- subset(iris, (Species == "versicolor"))[,1:4]
virginica <- subset(iris, (Species == "virginica"))[,1:4]
versi.virg <- subset(iris, (Species == "versicolor") | (Species == "virginica"))
library(Hotelling)
hot.t2 <- hotelling.test(x = virginica, y = versicolor)
hot.t2
t.test(Sepal.Length~Species, versi.virg)
t.test(Sepal.Width~Species, versi.virg)
t.test(Petal.Length~Species, versi.virg)
t.test(Petal.Width~Species, versi.virg)
model <- lm(cbind(Sepal.Length, Petal.Length, Sepal.Width, Petal.Width)~Species, data = iris)
Manova(model, test.statistic = "Wilks")
res.man <- manova(cbind(Sepal.Length, Petal.Length, Sepal.Width, Petal.Width)~Species, data = iris)
summary(res.man)
summary.aov(res.man)
TukeyHSD(aov(Sepal.Length~Species, data = iris))
library(gridExtra)
sepall.plot <- ggplot(data = iris, aes(x = Species, y = Sepal.Length, colour = Species)) +
geom_violin() +
geom_boxplot(width = 0.1) +
blank_theme(1/1.61) +
labs(title = "Sepal length",
x = element_blank(),
y = element_blank())
sepalw.plot <- ggplot(data = iris, aes(x = Species, y = Sepal.Width, colour = Species)) +
geom_violin() +
geom_boxplot(width = 0.1) +
blank_theme(1/1.61) +
labs(title = "Sepal width",
x = element_blank(),
y = element_blank())
petall.plot <- ggplot(data = iris, aes(x = Species, y = Petal.Length, colour = Species)) +
geom_violin() +
geom_boxplot(width = 0.1) +
blank_theme(1/1.61)+
labs(title = "Petal length",
x = element_blank(),
y = element_blank())
petalw.plot <- ggplot(data = iris, aes(x = Species, y = Petal.Width, colour = Species)) +
geom_violin() +
geom_boxplot(width = 0.1) +
blank_theme(1/1.61)+
labs(title = "Sepal width",
x = element_blank(),
y = element_blank())
grid.arrange(sepall.plot, sepalw.plot, petall.plot, petalw.plot)
library(GGally)
coord.plot <- ggparcoord(iris,
columns = 1:4,
groupColumn = 5,
showPoints = T,
scale = "std",
order = "anyClass",
alphaLines = 0.5) +
blank_theme(1/1.61) +
labs(title = "Gráfico de coordenadas paralelas",
subtitle = "Valores escalados",
y = element_blank(),
x = element_blank(),
caption = "Datos: Iris")
coord.plot
set.seed(1)
n <- 100
tr <- rbinom(100, 1, 0.5)
y <- 1 + tr + rnorm(n, 0, 3)
s <- sample(tr, length(tr), FALSE)
diff(by(y, s, mean))
dist <- data.frame(f = unname(replicate(2000, diff(by(y, sample(tr, length(tr), FALSE), mean)))))
permut.plot <- ggplot(data = dist, aes(f)) +
geom_density(color = "deepskyblue4", fill = "deepskyblue3", alpha = 0.5) +
geom_vline(xintercept = 1.3, colour = rgb(118,78,144, maxColorValue = 255)) +
blank_theme() +
labs(title = "Resultados de un experimento permutacional",
subtitle = "Distribución de las diferencias entre dos grupos",
caption = "Datos simulados",
x = element_blank(),
y = element_blank())
permut.plot
dist.mat <- vegdist(iris[,1:4], method = "euclidean") # Matriz de distancias
grps <- iris[,5] # Es un data.frame que contiene los distintos niveles de agrupamiento, anidados o no
adonis2(dist.mat~iris$Sepal.Length*iris$Sepal.Width+iris$Petal.Length*iris$Petal.Width, data = grps, permutations = 999)
plot(betadisper(dist.mat, grps), hull = F, ellipse= T)
iris.mds <- metaMDS(dist.mat, distance = "euclidean", k = 2, trace = F)
mds.dims <- data.frame(NMDS1 = iris.mds$points[,1], NMDS2 = iris.mds$points[,2])
mds.plot.data <- cbind(mds.dims, iris)
# Extraemos las correlaciones de cada factor con cada dimensión reducida (flechas)
fit <- envfit(iris.mds, iris)
arrow <- data.frame(fit$vectors$arrows, R = fit$vectors$r, P = fit$vectors$pvals)
arrow["Variable"] <- rownames(arrow)
arrow.p <-subset(arrow, P <= 0.05)
mds.plot <- ggplot(mds.plot.data, aes(NMDS1, NMDS2)) +
geom_point(aes(color = Species), alpha = 0.7) +
stat_ellipse(aes(fill = Species), type = "t", size = 1, geom = "polygon", alpha = 0.2) +
labs(title = "Escalamiento Multidimensional no métrico (NMDS)",
subtitle = paste('Estrés =',round(iris.mds$stress,3)),
caption = "Datos: Iris") +
blank_theme() + theme(legend.position = "right") +
geom_segment(data = arrow.p,
aes(x=0, y=0, xend = NMDS1, yend = NMDS2, lty = Variable),
arrow = arrow(length = unit(.2, "cm")*arrow.p$R) #Flechas escaladas según su R^2
)
mds.plot
crime.df <- read.csv("crime.csv")[,-1]
#str(crime.df)
crime.lm <- lm(ViolentCrimesPerPop~., data = crime.df)
summary(crime.lm)
#coef(crime.lm)
library(caret)
library(caTools)
set.seed(1111)
sample <- sample.split(crime.df$ViolentCrimesPerPop, SplitRatio = .75)
train <- subset(crime.df, sample == TRUE)
test <- subset(crime.df, sample == FALSE)
train.crime.lm <- lm(ViolentCrimesPerPop~., data = train)
summary(train.crime.lm)$r.squared
pred <- predict.lm(train.crime.lm, test[,1:88])
R2(pred, test$ViolentCrimesPerPop)*100
X_train <- train[,1:88]
y_train <- train$ViolentCrimesPerPop
X_test <- test[,1:88]
y_test <- test$ViolentCrimesPerPop
preProc <- preProcess(X_train, method = c("center", "scale"))
X_train_s <- predict(preProc, X_train)
X_test_s <- predict(preProc, X_test)
library(glmnet)
cv.ridge. <- cv.glmnet(as.matrix(X_train_s), y_train, alpha = 0, type.measure = "mse")
lambdamin <- cv.ridge.$lambda.min #Contiene el valor de lambda que otorga el menor valor de error
lambdamin
ridge.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 0, lambda = lambdamin)
print(ridge.lm)
#coef(ridge.lm) # Imprime los coeficientes de la regresión
ridge.pred <- predict(ridge.lm, as.matrix(X_test_s))
R2(ridge.pred, y_test)*100
for (lambda in c(0, 0.5, 1, 2, 3, 5, 10, 20, 50, round(lambdamin,2))) {
ridge.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 0, lambda = lambda, standardize = F, standardize.response = F)
ridge.pred <- predict(ridge.lm, as.matrix(X_test_s))
print(paste("lambda = ", lambda,
"; Variables restantes:", round(ridge.lm$df, 2),
"; R^2 entrenamiento = ", round(ridge.lm$dev.ratio,2),
"; R^2 prueba = ", round(R2(ridge.pred, y_test),2)))
}
cv.lasso <- cv.glmnet(as.matrix(X_train_s), y_train, alpha = 1, type.measure = "mse")
lambdamin <- cv.lasso$lambda.min #Contiene el valor de lambda que otorga el menor valor de error
lambdamin
lasso.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 1, lambda = lambdamin)
print(lasso.lm)
#coef(lasso.lm) # Imprime los coeficientes de la regresión
lasso.pred <- predict(lasso.lm, as.matrix(X_test_s))
R2(lasso.pred, y_test)*100
for (lambda in c(0, 0.5, 1, 2, 3, 5, 10, 20, 50, round(lambdamin,2))) {
lasso.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 1, lambda = lambda, standardize = F, standardize.response = F)
lasso.pred <- predict(lasso.lm, as.matrix(X_test_s))
print(paste("lambda = ", lambda,
"; Variables restantes:", round(lasso.lm$df, 2),
"; R^2 entrenamiento = ", round(lasso.lm$dev.ratio,2),
"; R^2 prueba = ", round(R2(lasso.pred, y_test),2)))
}
library(corrplot)
corrplot(cor(crime.df), type = "upper")
e2 <- read.table("E2.txt")
e2
e2 <- read.table("E2.txt", header = T)
e2
e2.lm <- lm(Y~., data = e2)
summary(e2.lm)
e2 <- read.table("E2.txt", header = T)
set.seed(1111)
sample <- sample.split(e2$Y, SplitRatio = .75)
train <- subset(e2, sample == TRUE)
test <- subset(e2, sample == FALSE)
train.crime.lm <- lm(ViolentCrimesPerPop~., data = train)
train.e2.lm <- lm(Y~., data = train)
summary(train.e2.lm)$r.squared*100
pred <- predict.lm(train.e2.lm, test[,1:88])
e2
train.e2.lm <- lm(Y~., data = train)
summary(train.e2.lm)$r.squared*100
pred <- predict.lm(train.e2.lm, test[,-5])
R2(pred, test$Y)*100
e2 <- read.table("E2.txt", header = T)
sample <- sample.split(e2$Y, SplitRatio = .75)
train <- subset(e2, sample == TRUE)
test <- subset(e2, sample == FALSE)
train.e2.lm <- lm(Y~., data = train)
summary(train.e2.lm)$r.squared*100
pred <- predict.lm(train.e2.lm, test[,-5])
R2(pred, test$Y)*100
e2 <- read.csv("hatco.csv")
sample <- sample.split(e2$X1, SplitRatio = .75)
train <- subset(e2, sample == TRUE)
test <- subset(e2, sample == FALSE)
train.e2.lm <- lm(Y~., data = train)
train.e2.lm <- lm(X1~., data = train)
summary(train.e2.lm)$r.squared*100
pred <- predict.lm(train.e2.lm, test[,-5])
train.e2.lm <- lm(X1~., data = train)
summary(train.e2.lm)$r.squared*100
pred <- predict.lm(train.e2.lm, test[,-1])
R2(pred, test$X1)*100
mlm.fit <- lm(X1~., data = e2)
mlm.fit$fitted.values
?geom_smooth
mlm.fit <- lm(X1~., data = e2)
mlm.data <- data.frame(x = e2$X1, y = unname(mlm.fit$fitted.values))
e2$X1
unname(mlm.fit$fitted.values)
mlm.fit <- lm(X1~., data = e2)
mlm.data <- data.frame(x = e2$X1, y = predict(mlm.fit, e2$X1))
predict(mlm.fit, e2$X1)
mlm.fit <- lm(X1~., data = e2)
mlm.data <- data.frame(x = e2$X1, y = predict(mlm.fit, e2[,-1]))
mlm.plot <- ggplot(data = mlm.data, aes(x, y)) + geom_point() + geom_smooth()
mlm.plot
?geom_smooth
mlm.fit <- lm(X1~., data = e2)
mlm.data <- data.frame(x = e2$X1, y = predict(mlm.fit, e2[,-1]))
mlm.plot <- ggplot(data = mlm.data, aes(x, y)) + geom_point() + geom_smooth(, method = "lm")
mlm.plot
summary(e2)
e2 <- read.csv("hatco.csv")
sample <- sample.split(e2$X1, SplitRatio = .75)
train <- subset(e2, sample == TRUE)
test <- subset(e2, sample == FALSE)
summary(e2)
e2 <- read.csv("hatco.csv")
sample <- sample.split(e2$ventas, SplitRatio = .75)
train <- subset(e2, sample == TRUE)
test <- subset(e2, sample == FALSE)
e2
train.e2.lm <- lm(ventas~., data = train)
summary(train.e2.lm)$r.squared*100
pred <- predict.lm(train.e2.lm, test[,-11])
R2(pred, test$X1)*100
train.e2.lm <- lm(ventas~., data = train)
summary(train.e2.lm)$r.squared*100
pred <- predict.lm(train.e2.lm, test[,-11])
R2(pred, test$ventas)*100
mlm.fit <- lm(X1~., data = e2)
mlm.data <- data.frame(x = e2$X1, y = predict(mlm.fit, e2[,-1]))
mlm.plot <- ggplot(data = mlm.data, aes(x, y)) + geom_point() + geom_smooth(, method = "lm")
mlm.fit <- lm(X1~., data = e2)
mlm.data <- data.frame(x = e2$X1, y = predict(mlm.fit, e2[,-1]))
mlm.plot <- ggplot(data = mlm.data, aes(x, y)) + geom_point() + geom_smooth(method = "lm")
mlm.plot
mlm.fit <- lm(X1~., data = e2)
mlm.data <- data.frame(x = e2$ventas, y = predict(mlm.fit, e2[,-11]))
mlm.fit <- lm(ventas~., data = e2)
mlm.data <- data.frame(x = e2$ventas, y = predict(mlm.fit, e2[,-11]))
mlm.plot <- ggplot(data = mlm.data, aes(x, y)) + geom_point() + geom_smooth(method = "lm")
mlm.plot
e2 <- read.table("E2.txt", header = T)
sample <- sample.split(e2$ventas, SplitRatio = .75)
e2 <- read.table("E2.txt", header = T)
sample <- sample.split(e2$Y, SplitRatio = .75)
train <- subset(e2, sample == TRUE)
test <- subset(e2, sample == FALSE)
e2
train.e2.lm <- lm(Y~., data = train)
summary(train.e2.lm)$r.squared*100
pred <- predict.lm(train.e2.lm, test[,-5])
R2(pred, test$ventas)*100
train.e2.lm <- lm(Y~., data = train)
summary(train.e2.lm)$r.squared*100
pred <- predict.lm(train.e2.lm, test[,-5])
R2(pred, test$Y)*100
mlm.fit <- lm(Y~., data = e2)
mlm.data <- data.frame(x = e2$Y, y = predict(mlm.fit, e2[,-5]))
mlm.plot <- ggplot(data = mlm.data, aes(x, y)) + geom_point() + geom_smooth(method = "lm")
mlm.fit <- lm(Y~., data = e2)
mlm.data <- data.frame(x = e2$Y, y = predict(mlm.fit, e2[,-5]))
mlm.plot <- ggplot(data = mlm.data, aes(x, y)) + geom_point() +
geom_smooth(method = "lm") +
labs(title = "Gráfico de dispersión de valores de Y observados y predichos",
subtitle = "Bandas indican el intervalo de confianza de la regresión al 95%",
caption = "Datos: E2.txt")
mlm.plot
mlm.fit <- lm(Y~X1+X2, data = e2)
mlm.data <- data.frame(x = e2$Y, y = predict(mlm.fit, e2[,-c(3:5)]))
mlm.plot <- ggplot(data = mlm.data, aes(x, y)) + geom_point() +
geom_smooth(method = "lm") +
labs(title = "Gráfico de dispersión de valores de Y observados y predichos",
subtitle = "Bandas indican el intervalo de confianza de la regresión al 95%",
caption = "Datos: E2.txt")
mlm.plot
mlm.fit <- lm(Y~X1, data = e2)
mlm.data <- data.frame(x = e2$Y, y = predict(mlm.fit, e2[,-c(2:5)]))
mlm.data <- data.frame(obs = y_test, pred = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(obs, pred)) + geom_point() + geom_smooth(method = "lm")
mlm.data <- data.frame(obs = y_test, pred = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(obs, pred)) + geom_point() + geom_smooth(method = "lm")
mlm.plot
mlm.data <- data.frame(obs = y_test, pred = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(x = obs, y =  pred)) + geom_point() + geom_smooth(method = "lm")
mlm.plot
lasso.pred
mlm.data <- data.frame(obs = y_test, s0 = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(x = obs, y =  s0)) + geom_point() + geom_smooth(method = "lm")
mlm.plot
coef(lasso.lm)
rownames(coef(lasso.lm))
mlm.data <- data.frame(obs = y_test, s0 = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(x = obs, y =  s0)) +
geom_point() +
geom_smooth(method = "lm", colour = rgb(118,78,144, maxColorValue = 255)) +
labs(caption = "Datos simulados. El área gris representa el intervalo de confianza de la regresión al 95%",
subtitle = paste("Modelo ajustado: v2 = ",
paste(coef(lasso.lm)$s0, "X_i", sep = "*")))
mlm.data <- data.frame(obs = y_test, s0 = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(x = obs, y =  s0)) +
geom_point() +
geom_smooth(method = "lm", colour = rgb(118,78,144, maxColorValue = 255)) +
labs(caption = "Datos simulados. El área gris representa el intervalo de confianza de la regresión al 95%",
subtitle = paste("Modelo ajustado: v2 = ",
paste(coef(lasso.lm)["s0"], "X_i", sep = "*")))
mlm.data <- data.frame(obs = y_test, s0 = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(x = obs, y =  s0)) +
geom_point() +
geom_smooth(method = "lm", colour = rgb(118,78,144, maxColorValue = 255)) +
labs(caption = "Datos simulados. El área gris representa el intervalo de confianza de la regresión al 95%",
subtitle = paste("Modelo ajustado: v2 = ",
paste(coef(lasso.lm), "X_i", sep = "*")))
mlm.plot
mlm.data <- data.frame(obs = y_test, s0 = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(x = obs, y =  s0)) +
geom_point() +
geom_smooth(method = "lm", colour = rgb(118,78,144, maxColorValue = 255)) +
labs(title = "Gráfico de dispersión de datos observados y predichos",
caption = "Datos simulados. \n El área gris representa el intervalo de confianza de la regresión al 95%",
subtitle = paste("Modelo ajustado: v2 = ",
paste(coef(lasso.lm), "X_i", sep = "*")))
mlm.plot
mlm.data <- data.frame(obs = y_test, s0 = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(x = obs, y =  s0)) +
geom_point() +
geom_smooth(method = "lm", colour = rgb(118,78,144, maxColorValue = 255)) +
labs(title = "Gráfico de dispersión de datos observados y predichos",
caption = "Datos simulados. \n El área gris representa el intervalo de confianza de la regresión al 95%")
mlm.plot
mlm.data <- data.frame(obs = y_test, s0 = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(x = obs, y =  s0)) +
geom_point() +
geom_smooth(method = "lm", colour = rgb(118,78,144, maxColorValue = 255)) +
labs(title = "Gráfico de dispersión de datos observados y predichos",
caption = "Datos simulados. \n El área gris representa el intervalo de confianza de la regresión al 95%") +
blank_theme()
mlm.plot
mlm.data <- data.frame(obs = y_test, s0 = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(x = obs, y =  s0)) +
geom_point() +
geom_smooth(method = "lm", colour = rgb(118,78,144, maxColorValue = 255)) +
labs(title = "Gráfico de dispersión de datos observados y predichos",
caption = "Datos simulados. \n El área gris representa el intervalo de confianza de la regresión al 95%",
x = "",
y = "") +
blank_theme()
mlm.plot
mlm.data <- data.frame(obs = y_test, s0 = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(x = obs, y =  s0)) +
geom_point() +
geom_smooth(method = "lm", colour = rgb(118,78,144, maxColorValue = 255)) +
labs(title = "Gráfico de dispersión de datos observados y predichos",
caption = "Datos simulados. \n El área gris representa el intervalo de confianza de la regresión al 95%",
x = "",
y = "") +
blank_theme()
mlm.plot
