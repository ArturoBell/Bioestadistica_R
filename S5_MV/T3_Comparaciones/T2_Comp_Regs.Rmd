---
title: "Hipótesis Múltiples y Multivariadas"
author: "Arturo Bell Enríquez García"
output: 
  html_notebook:
    toc: yes
  
---

## Funciones personalizadas

```{r}

# Tema personalizado
blank_theme <- function(aspect.ratio = 1/1.61){
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank(),
        axis.line = element_blank(),
        aspect.ratio = aspect.ratio,
        axis.ticks = element_blank(),
        text = element_text(colour = "gray50"), # Eliminar
        legend.position = "none"
        )
}

```


# Múltiples hipótesis: FWER
## Corrección de Bonferroni

La probabilidad de encontrarnos con al menos un error de tipo 1 al realizar múltiples comparaciones independientes incrementa a una tasa de $1-(1-\alpha)^m$, donde m es el número de comparaciones. Grafiquemos este cambio:


```{r}
library(ggplot2)

error <- data.frame(m = 1:20)
error["P_alpha"] <- 1 - (1-0.05)^error$m

error.rate <- ggplot(data = error, aes(m, P_alpha)) + 
              geom_line(color = rgb(118,78,144, maxColorValue = 255)) +
              scale_y_continuous(breaks = NULL) +
              scale_x_continuous(breaks = c(1, 2, 5, 10, 20)) +
              expand_limits(y = c(0,1)) +
              blank_theme() +
              geom_hline(yintercept = 0.05, colour = "deepskyblue4", linetype = "dashed") +
              geom_hline(yintercept = 0.5, colour = "firebrick", linetype = "dashed", alpha = 0.5) +
              geom_hline(yintercept = 1, colour = "firebrick", linetype = "dashed", alpha = 0.5) +
              annotate("text", x = 0, y = 0.08, label = "0.05", colour = "deepskyblue4", alpha = 0.5) + 
              annotate("text", x = 0, y = 0.53, label = "0.5", colour = "firebrick", alpha = 0.5) +
              annotate("text", x = 0, y = 0.97, label = "1", colour = "firebrick", alpha = 0.5) +
              labs(title = "P(error) al incrementar el número de pruebas (m)",
                   subtitle = bquote({1 - (1- alpha)^m}),
                   x = element_blank(),
                   y = element_blank(),
                   caption = "King & Eckersley (2019)"
                   )

error.rate
```

Ahora apliquemos la corrección de Bonferroni, dada por $\alpha/m$, de modo que la ecuación anterior queda formulada como: $1-(1-\alpha/m)^m$

```{r}
error["P_bonf"] <- 1 - (1-(0.05/error$m))^error$m

error.corr <- ggplot(data = error, aes(m, P_bonf)) + 
              geom_line(color = rgb(118,78,144, maxColorValue = 255)) +
              scale_y_continuous(breaks = NULL) +
              scale_x_continuous(breaks = c(1, 2, 5, 10, 20)) +
              expand_limits(y = c(0.04, 0.06)) +
              blank_theme() +
              geom_hline(yintercept = 0.05, colour = "deepskyblue4", linetype = "dashed") +
              geom_hline(yintercept = 0.04, colour = "lightslategray", linetype = "dashed", alpha = 0.5) +
              geom_hline(yintercept = 0.06, colour = "lightslategray", linetype = "dashed", alpha = 0.5) +
              annotate("text", x = 0, y = 0.0505, label = "0.05", colour = "deepskyblue4", alpha = 0.5) + 
              annotate("text", x = 0, y = 0.0405, label = "0.04", colour = "lightslategray", alpha = 0.5) +
              annotate("text", x = 0, y = 0.0595, label = "0.06", colour = "lightslategray", alpha = 0.5) +
              labs(title = "P(error) al corregir según el número de pruebas (m)",
                   subtitle = bquote({1 - (1- (alpha/m))^m}),
                   x = element_blank(),
                   y = element_blank(),
                   caption = "King & Eckersley (2019)"
                   )

error.corr
```

```{r}
set.seed(45)
n <- 1000
robs <- data.frame(z = rnorm(n))
robs["color"] <- ifelse(robs$z < -1.96 | robs$z > 1.96, "firebrick", "deepskyblue4")

robs.plot <- ggplot(data = robs, aes(z)) + 
             geom_density(color = "deepskyblue4") + 
             blank_theme() + 
             labs(title = "Observaciones aleatorias a un nivel de significancia de 0.05",
                  subtitle = "Bandas indican límites del LS   ",
                  caption = paste(n, " datos simulados"),
                  x = "Z",
                  y = element_blank()
                  ) +
             geom_vline(xintercept = -1.96, 
                        colour = rgb(118,78,144, maxColorValue = 255), 
                        linetype = "dashed"
                        ) +
             geom_vline(xintercept = 1.96, 
                        colour = rgb(118,78,144, maxColorValue = 255), 
                        linetype = "dashed"
                        ) +
             geom_point(aes(x = z, y = 0), 
                        color = robs$color, alpha = 0.3) +
             scale_y_continuous(breaks = NULL) +
             scale_x_continuous(breaks = c(-3, -1.96, -1, 0, 1, 1.96, 3), 
                                labels = as.character(c(-3, -1.96, -1, 0, 1, 1.96, 3))
                                ) +
             annotate("text", x = 3, y = 0.5, 
                      label = paste("# sign = ", 
                                    length(robs$color[robs$color == "firebrick"]), "/", n),
                      colour = "firebrick"
                      )

robs.plot
```

```{r}
set.seed(45)
n <- 1000
a.corr <- (0.05/n)/2
sig.lev <- abs(qnorm(a.corr))
robs <- data.frame(z = rnorm(n))
robs["color"] <- ifelse(robs$z < -sig.lev | robs$z > sig.lev, "firebrick", "deepskyblue4")

rcor.plot <- ggplot(data = robs, aes(z)) + 
             geom_density(color = "deepskyblue4") + 
             blank_theme() + 
             labs(title = "Observaciones aleatorias a un nivel de significancia de 0.05",
                  subtitle = "Bandas indican límites del LS corregido",
                  caption = paste(n, " datos simulados"),
                  x = "Z",
                  y = element_blank()
                  ) +
             geom_vline(xintercept = -sig.lev, 
                        colour = rgb(118,78,144, maxColorValue = 255), 
                        linetype = "dashed"
                        ) +
             geom_vline(xintercept = sig.lev, 
                        colour = rgb(118,78,144, maxColorValue = 255), 
                        linetype = "dashed"
                        ) +
             geom_point(aes(x = z, y = 0), 
                        color = robs$color, alpha = 0.3) +
             scale_y_continuous(breaks = NULL) +
             scale_x_continuous(breaks = c(-3, -1.96, -1, 0, 1, 1.96, 3), 
                                labels = as.character(c(-3, -1.96, -1, 0, 1, 1.96, 3))
                                ) +
             annotate("text", x = 2.5, y = 0.5, 
                      label = paste("# sign = ", 
                                    length(robs$color[robs$color == "firebrick"]), "/", n),
                      colour = "firebrick"
                      )

rcor.plot
```

## ANOVA Sheirer-Ray-Hare

Carguemos los datos
```{r}
mili <- read.csv("milipedos.csv")
str(mili)
```

Realicemos la prueba de normalidad para cada nivel de cada variable:
```{r}
norm.mili <- data.frame(grupo = NA, n = NA, W = NA, p = NA)
cols <- colnames(mili)[1:2]
especies <- as.character(unique(mili$Especie))
sexos <- as.character(unique(mili$Sexo))

for (i in 1:length(cols)) {# Cicla entre las columnas indicadas
  if (i == 1) { # Si es la primera columna:
    for (j in 1:length(especies)) { # Cicla entre los valores de la columa Especies
      shap <- shapiro.test(mili$Ala[mili[cols[i]] == especies[j]])
      norm.mili[j,] <- c(especies[j], 
                         length(mili$Ala[mili[cols[i]] == especies[j]]), 
                         round(shap$statistic, 2), 
                         round(shap$p.value, 2)
                         )
    }
  }
  if (i == 2) { # Si es la segunda columna
    for (k in 1:length(sexos)) { # Cicla entre los valores de la columna Sexo
      shap <- shapiro.test(mili$Ala[mili[cols[i]] == sexos[k]])
      norm.mili[j+k,] <- c(sexos[k], # Sexo de la iteración
                           length(mili$Ala[mili[cols[i]] == sexos[k]]), # Tamaño de muestra para esa iteración
                           round(shap$statistic, 2), # 
                           round(shap$p.value, 2)
                           )
    }
  }
}

norm.mili
```
Comprobemos la homocedasticidad:
```{r}
# Dado que los datos se ajustaron a una distribución normal podemos utilizar la prueba de Bartlett
bartlett.test(Ala~Sexo, data = mili)
bartlett.test(Ala~Especie, data = mili)
```
```{r}
# Verificamos con la prueba de Levene
library(car)
leveneTest(Ala~Sexo, data = mili)
leveneTest(Ala~Especie, data = mili)
```

Realicemos la prueba Scheirer-Ray-Hare:
```{r}
library(rcompanion)
library(FSA)

scheirerRayHare(Ala ~ Especie + Sexo, data = mili)
```


```{r}
dunnTest(Ala~Especie, data = mili, method = "bonferroni")
```

Bajo este criterio, las diferencias parecieran no ser significativas. Apliquemos entonces el ANOVA de dos vías paramétrico y veamos qué encontramos:

```{r}
res.mili <- aov(Ala~Especie * Sexo, data = mili)
summary(res.mili)
```
¡SORPRESA! Ahora encontramos diferencias en ambos niveles, aunque no se encontró una interacción entre los factores. Realicemos la prueba HSD de Tukey para analizar las diferencias a cada nivel.

```{r}
TukeyHSD(res.mili)$Especie
```

Veamos ahora estos resultados de manera gráfica utilizando un gráfico de interacción:

```{r}
inter.plot <- ggplot(data = mili, aes(x = Sexo, y = Ala, color = Sexo)) + 
              geom_violin() + geom_boxplot(width = 0.1) + 
              facet_wrap(~Especie) + 
              blank_theme(1.61) +
              labs(title = "Gráfico de interacción de la [Ala] (mg/100 ml) en milípedos",
                   subtitle = "Especie + Sexo",
                   x = element_blank(),
                   y = element_blank(),
                   caption = "Datos: milipedos.csv")
inter.plot
```
La variable Especie sola
```{r}
espec.plot <- ggplot(data = mili, aes(x = Especie, y = Ala, color = Especie)) + 
              geom_violin() + geom_boxplot(width = 0.1) + 
              blank_theme() +
              labs(title = "Gráfico de interacción de la [Ala] (mg/100 ml) en milípedos",
                   subtitle = "Especie",
                   x = element_blank(),
                   y = element_blank(),
                   caption = "Datos: milipedos.csv")
espec.plot
```
La variable sexo sola
```{r}
sexos.plot <- ggplot(data = mili, aes(x = Sexo, y = Ala, color = Sexo)) + 
              geom_violin() + geom_boxplot(width = 0.1) + 
              blank_theme() +
              labs(title = "Gráfico de interacción de la [Ala] (mg/100 ml) en milípedos",
                   subtitle = "Especie",
                   x = element_blank(),
                   y = element_blank(),
                   caption = "Datos: milipedos.csv")
sexos.plot
```

### Ejercicio opcional:
Realizar un ANOVA Scheirer-Ray-Hare con la base de datos strawberry ([Horst *et al.* 2005](https://doi.org/10.1094/pd-89-1195)). Una base de datos multivariada con medidas de peso, % de Botrytis, % de otras epecies fúngicas y una evaluación de Phomopsis en las hojas para 4 tratamientos con 3 réplicas cada uno.
```{r}
straw <- read.csv("strawberry.csv")
head(straw)
str(straw)
summary(straw)
```

Hay un par de elementos con los cuales hay que tener cuidado: 1) las variables tratamiento y réplica son variables categóricas y fueron detectadas como variables de enteros, 2) la variable Eval está en escala *ordinal* no en escala de intervalo o de razón, por lo cual queda automáticamente descartada para pruebas paramétricas. Corrijamos entonces el punto 1:

```{r}
straw$Tratamiento <- factor(LETTERS[straw$Tratamiento])
straw$Rep <- factor(letters[straw$Rep])
head(straw)
```

# Comparaciones Multivariadas
## Datos para comparaciones Mv:
1. Base de datos iris. Medidas de 4 variables cuantitativas para 50 flores de cada especie de *Iris*: *setosa*, *versicolor* y *virginica*. Al explorarla vemos que todo está en orden, las cuatro variables cuantitativas fueron detectadas como tal y la única variable categórica fue asignada correctamente
```{r}
head(iris)
str(iris)
summary(iris)
```


## Prueba $T^2$ de Hotelling
Es una extensión multivariada de la prueba T de Student; por lo tanto, es una prueba paramétrica. Comparemos si las especies *versicolor* y *virginica* son iguales. Para ello es importante revisar los supuestos del análisis:

### Normalidad
```{r}
library(MVN)
mvn(iris, subset = "Species", mvnTest = "mardia", desc = F)$multivariateNormality
```
```{r}
mvn(iris, subset = "Species", mvnTest = "hz", desc = F)$multivariateNormality
```
```{r}
mvn(iris, subset = "Species", mvnTest = "royston", desc = F)$multivariateNormality
```

### Igualdad de dispersión multivariada
Al aplicar la prueba global vemos que al parecer no hay diferencias importantes en las dispersiones multivariadas
```{r}
library(vegan)
dist.mat <- vegdist(iris[,1:4], method = "bray", type = c("median"))
groups <- as.character(iris$Species)
disp.mv <- betadisper(dist.mat, group = groups, type = "median") # Realizar el procedimiento
disp.mv
anova(disp.mv) # Prueba de hipótesis
```
La prueba post-hoc confirma los resultados
```{r}
mod.HSD <- TukeyHSD(disp.mv)
mod.HSD <- data.frame(mod.HSD$group, comp = dimnames(mod.HSD$group)[[1]])
mod.HSD
```

### Comparación Multivariada:
Extraemos dos grupos a comparar
```{r}
versicolor <- subset(iris, (Species == "versicolor"))[,1:4]
virginica <- subset(iris, (Species == "virginica"))[,1:4]

versi.virg <- subset(iris, (Species == "versicolor") | (Species == "virginica"))
```

Aplicamos la prueba:
```{r}
library(Hotelling)
hot.t2 <- hotelling.test(x = virginica, y = versicolor)
hot.t2
```

Al parecer, los promedios de las mediciones multivariadas son diferentes.

### Comparaciones univariadas
Realizaremos 4 comparaciones univariadas ¿tiene sentido aplicar una corrección de Bonferroni? Algo a notar es que la prueba aplicada en este caso es la prueba de Welch; es decir, una prueba bajo el supuesto de desigualdad de varianzas (muestras heterocedásticas). Para aplicar la prueba T de Student solo hay que agregar el argumento `equal.var = TRUE` a la función.

```{r}
t.test(Sepal.Length~Species, versi.virg)
```

```{r}
t.test(Sepal.Width~Species, versi.virg)
```

```{r}
t.test(Petal.Length~Species, versi.virg)
```

```{r}
t.test(Petal.Width~Species, versi.virg)
```

## Análisis Multivariado de la Varianza
Extensión Multivariada del Análisis de la Varianza; por lo tanto es el equivalente a una prueba $T^2$ de Hotelling con más de dos grupos (al igual que el ANOVA con respecto a la prueba t de Student)

Ahora apliquemos la prueba utilizando la función `Manova()` de la librería `car`

```{r}
model <- lm(cbind(Sepal.Length, Petal.Length, Sepal.Width, Petal.Width)~Species, data = iris)
Manova(model, test.statistic = "Wilks")
```

```{r}
# La forma por defecto de R, con la traza de Pillai
res.man <- manova(cbind(Sepal.Length, Petal.Length, Sepal.Width, Petal.Width)~Species, data = iris)
summary(res.man)
```
```{r}
summary.aov(res.man)
```

La prueba post-hoc es una prueba HSD de Tukey por cada variable. 

```{r}
TukeyHSD(aov(Sepal.Length~Species, data = iris))
```
Veamos un gráfico de violín para cada variable de cada especie:
```{r}
library(gridExtra)

sepall.plot <- ggplot(data = iris, aes(x = Species, y = Sepal.Length, colour = Species)) + 
               geom_violin() + 
               geom_boxplot(width = 0.1) + 
               blank_theme(1/1.61) +
               labs(title = "Sepal length",
                    x = element_blank(),
                    y = element_blank())
sepalw.plot <- ggplot(data = iris, aes(x = Species, y = Sepal.Width, colour = Species)) + 
               geom_violin() + 
               geom_boxplot(width = 0.1) + 
               blank_theme(1/1.61) +
               labs(title = "Sepal width",
                    x = element_blank(),
                    y = element_blank())
petall.plot <- ggplot(data = iris, aes(x = Species, y = Petal.Length, colour = Species)) + 
               geom_violin() + 
               geom_boxplot(width = 0.1) + 
               blank_theme(1/1.61)+
               labs(title = "Petal length",
                    x = element_blank(),
                    y = element_blank())
petalw.plot <- ggplot(data = iris, aes(x = Species, y = Petal.Width, colour = Species)) + 
               geom_violin() + 
               geom_boxplot(width = 0.1) + 
               blank_theme(1/1.61)+
               labs(title = "Sepal width",
                    x = element_blank(),
                    y = element_blank())

grid.arrange(sepall.plot, sepalw.plot, petall.plot, petalw.plot)
```


O veamos un gráfico de coordenadas paralelas, el cual nos permite analizar las mediciones de cada variable de cada individuo en un mismo gráfico:

```{r}
library(GGally)
coord.plot <- ggparcoord(iris, 
                         columns = 1:4, 
                         groupColumn = 5, 
                         showPoints = T, 
                         scale = "std", 
                         order = "anyClass", 
                         alphaLines = 0.5) + 
               blank_theme(1/1.61) +
               labs(title = "Gráfico de coordenadas paralelas",
                    subtitle = "Valores escalados",
                    y = element_blank(),
                    x = element_blank(),
                    caption = "Datos: Iris")
coord.plot
```

## Análisis Permutacional Multivariado de la Varianza:
Los pasos a seguir son básicamente los mismos que los que seguimos para realizar la prueba de homogeneidad de matrices de dispersión. Este supuesto es, debido a la aproximación permutacional, (posiblemente) el supuesto más importante para esta prueba. Es importante notar que existe una corrección para grupos con varianzas no homogéneas.

```{r}
set.seed(1)
n <- 100
tr <- rbinom(100, 1, 0.5)
y <- 1 + tr + rnorm(n, 0, 3)

s <- sample(tr, length(tr), FALSE)
diff(by(y, s, mean))

dist <- data.frame(f = unname(replicate(2000, diff(by(y, sample(tr, length(tr), FALSE), mean)))))
```

```{r}
permut.plot <- ggplot(data = dist, aes(f)) + 
               geom_density(color = "deepskyblue4", fill = "deepskyblue3", alpha = 0.5) + 
               geom_vline(xintercept = 1.3, colour = rgb(118,78,144, maxColorValue = 255)) + 
               blank_theme() +
               labs(title = "Resultados de un experimento permutacional",
                    subtitle = "Distribución de las diferencias entre dos grupos",
                    caption = "Datos simulados",
                    x = element_blank(),
                    y = element_blank())
permut.plot
```

Apliquemos entonces la prueba. Para ello lo primero será calcular la matriz de distancias (de no pasar una matriz de distancias a la prueba hará por default la distancia de Bray-Curtis)

```{r}
dist.mat <- vegdist(iris[,1:4], method = "euclidean") # Matriz de distancias
grps <- iris[,5] # Es un data.frame que contiene los distintos niveles de agrupamiento, anidados o no
```

Ahora podemos aplicar el PERMANOVA. De los resultados podemos observar que la principal división entre especies está dada por la longitud del sépalo, seguida por el ancho. Las cuatro variables explican el 100% del espacio multivariado ($R^2$ de los residuales = 0)
```{r}
adonis2(dist.mat~iris$Sepal.Length*iris$Sepal.Width+iris$Petal.Length*iris$Petal.Width, data = grps, permutations = 999)
```

Veamos la dispersión multivariada (**Mañana veremos PCA**)
```{r}
plot(betadisper(dist.mat, grps), hull = F, ellipse= T)
```

Podemos utilizar también un Escalamiento Multi-Dimensional No Paramétrico. Esta técnica es similar al PCA en el sentido de que proyecta un espacio altamente dimensional a un espacio con menos dimensiones (k), tratando de preservar las distancias entre cada punto. En pocas palabras, es una "hoja" o "lámina" de pocas dimensiones dentro de un espacio altamente dimensional.

```{r}
iris.mds <- metaMDS(dist.mat, distance = "euclidean", k = 2, trace = F)
mds.dims <- data.frame(NMDS1 = iris.mds$points[,1], NMDS2 = iris.mds$points[,2])

mds.plot.data <- cbind(mds.dims, iris)

# Extraemos las correlaciones de cada factor con cada dimensión reducida (flechas)
fit <- envfit(iris.mds, iris)
arrow <- data.frame(fit$vectors$arrows, R = fit$vectors$r, P = fit$vectors$pvals)
arrow["Variable"] <- rownames(arrow)

arrow.p <-subset(arrow, P <= 0.05)
```

Posteriormente podemos graficarlo. El "estrés" representa la fidelidad con respecto al espacio original; entre más alto sea, mayores serán las deformaciones (menor fue el éxito de preservar las distancias). En general, valores de estrés menores a 0.1 se consideran aceptables, menores a 0.05 como una buena representación y por encima de 0.3 indican una "ordenación" arbitraria. En nuestro gráfico, el estrés de 0.02 indica que la representación es fidedigna, que la mayor división entre especies se da en el eje x (usualmente) y que las variables más relacionadas con esa separación son la longitud y el ancho del pétalo, lo cual corresponde perfectamente con lo encontrado por el PERMANOVA.

```{r}
mds.plot <- ggplot(mds.plot.data, aes(NMDS1, NMDS2)) +
            geom_point(aes(color = Species), alpha = 0.7) +
            stat_ellipse(aes(fill = Species), type = "t", size = 1, geom = "polygon", alpha = 0.2) + 
            labs(title = "Escalamiento Multidimensional no métrico (NMDS)",
                 subtitle = paste('Estrés =',round(iris.mds$stress,3)),
                 caption = "Datos: Iris") +
            blank_theme() + theme(legend.position = "right") +
            geom_segment(data = arrow.p, 
                         aes(x=0, y=0, xend = NMDS1, yend = NMDS2, lty = Variable), 
                         arrow = arrow(length = unit(.2, "cm")*arrow.p$R) #Flechas escaladas según su R^2
                         )

mds.plot
```

# Regresiones multivariadas

## Regresión Lineal Múltiple

Para esta sección utilizaremos los datos de la base `crime.csv`. Esta base contiene información relacionada con actos criminales (88 variables) y la variable que nos interesa predecir es el # de crímenes/población (columna ViolentCrimesPerPop). Apliquemos un modelo de regresión lineal múltiple incluyendo todas las variables, sin dividir los datos en entrenamiento-prueba y sin escalarlos. Tampoco filtraremos los datos para evitar una fuga de información (es un ejemplo)
```{r}
crime.df <- read.csv("crime.csv")[,-1]
#str(crime.df)
```

```{r}
crime.lm <- lm(ViolentCrimesPerPop~., data = crime.df)
summary(crime.lm)
#coef(crime.lm)
```

Veamos qué pasa ahora si aplicamos este mismo modelo realizando la división entrenamiento-prueba.

### Evaluación, el PROBLEMA del exceso de dimensionalidad y el sobreajuste:
Para realizar la división utilizaremos la función `sample.split()` de librería caTools:

```{r}
library(caret)
library(caTools)
set.seed(1111)
sample <- sample.split(crime.df$ViolentCrimesPerPop, SplitRatio = .75)
train <- subset(crime.df, sample == TRUE)
test <- subset(crime.df, sample == FALSE)
```

Ajustemos el modelo de entrenamiento:
```{r}
train.crime.lm <- lm(ViolentCrimesPerPop~., data = train)
summary(train.crime.lm)$r.squared*100

```

Evaluemos el desempeño en los datos de prueba. La advertencia es resultado de utilizar un modelo con demasiadas variables.
```{r}
pred <- predict.lm(train.crime.lm, test[,1:88]) 
R2(pred, test$ViolentCrimesPerPop)*100
```

De estos resultados vemos que el modelo está claramente sobreajustado, ya que el $R^2$ del modelo de prueba es prácticamente 15% menor al de entrenamiento. Tomando esto en consideración, 1) escalemos los datos y b) apliquemos los modelos regularizados.

Para hacer las cosas más organizadas, primero dividamos ambos sets de datos en dos objetos: uno con las variables independientes y otro con la variable dependiente:

```{r}
X_train <- train[,1:88]
y_train <- train$ViolentCrimesPerPop

X_test <- test[,1:88]
y_test <- test$ViolentCrimesPerPop
```

Ahora estandaricemos las variables dependientes:
```{r}
preProc <- preProcess(X_train, method = c("center", "scale"))
X_train_s <- predict(preProc, X_train)
X_test_s <- predict(preProc, X_test)
```


## Regularización L2: Regresión Ridge

Apliquemos la regresión al set de entrenamiento. Debido a que el valor de penalización ($\alpha$ en la clase, $\lambda$ en glmnet) es "arbitrario", podemos utilizar validación cruzada para encontrar el valor que mejor se ajuste a nuestros datos. La validación cruzada consiste en hacer k particiones entrenamiento-prueba de los datos, ajustar un modelo para cada k para cada valor del parámetro que sea de nuestro interés, promediar el valor de error de cada iteración y quedarnos con el valor del parámetro que haya logrado el menor valor de nuestra medida de error. En la librería `glmnet` esto se hace con la función `cv.glmnet`, la cual recibe como argumentos una matriz de variables independientes, un vector con variables dependientes, un valor de alpha que será 0 para regresión Ridge, 1 para Lasso y algún intermedio para red elástica (no la veremos en el curso) y el tipo de medida de error, en este caso MSE.

```{r}
library(glmnet)
cv.ridge. <- cv.glmnet(as.matrix(X_train_s), y_train, alpha = 0, type.measure = "mse")
lambdamin <- cv.ridge.$lambda.min #Contiene el valor de lambda que otorga el menor valor de error
lambdamin
```
Ajustemos entonces el modelo regularizado con ese valor de lambda. (Df representa el número de coeficientes no negativos, %Dev = R^2). 
```{r}
ridge.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 0, lambda = lambdamin)
print(ridge.lm)
#coef(ridge.lm) # Imprime los coeficientes de la regresión
```
Vemos que el valor de R2 es ligeramente menor al caso anterior; sin embargo, ganamos un poco de poder predictivo en el modelo de prueba:
```{r}
ridge.pred <- predict(ridge.lm, as.matrix(X_test_s))
R2(ridge.pred, y_test)*100
```

Veamos cómo afecta el valor de lambda:

```{r}
for (lambda in c(0, 0.5, 1, 2, 3, 5, 10, 20, 50, round(lambdamin,2))) {
  
  ridge.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 0, lambda = lambda, standardize = F, standardize.response = F)
  ridge.pred <- predict(ridge.lm, as.matrix(X_test_s))
  
  print(paste("lambda = ", lambda, 
              "; Variables restantes:", round(ridge.lm$df, 2), 
              "; R^2 entrenamiento = ", round(ridge.lm$dev.ratio,2), 
              "; R^2 prueba = ", round(R2(ridge.pred, y_test),2)))
  
}
```

Vemos que no diferencias con respecto al primer caso. Apliquemos la regresión Lasso:

## Regularización L1: Regresión Lasso
```{r}
cv.lasso <- cv.glmnet(as.matrix(X_train_s), y_train, alpha = 1, type.measure = "mse")
lambdamin <- cv.lasso$lambda.min #Contiene el valor de lambda que otorga el menor valor de error
lambdamin
```
Ajustemos entonces el modelo regularizado con ese valor de lambda. (Df representa el número de coeficientes no negativos, %Dev = R^2). 
```{r}
lasso.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 1, lambda = lambdamin)
print(lasso.lm)
#coef(lasso.lm) # Imprime los coeficientes de la regresión
```
Vemos que el valor de R2 no es muy diferente al caso anterior, aunque ahora únicamente tenemos 18 coeficientes ≠ 0
```{r}
lasso.pred <- predict(lasso.lm, as.matrix(X_test_s))
R2(lasso.pred, y_test)*100
```
En los datos de prueba tampoco hubo mucha diferencia. Veamos cómo cambia esto al modificar el valor de lambda:

```{r}
for (lambda in c(0, 0.5, 1, 2, 3, 5, 10, 20, 50, round(lambdamin,2))) {
  
  lasso.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 1, lambda = lambda, standardize = F, standardize.response = F)
  lasso.pred <- predict(lasso.lm, as.matrix(X_test_s))
  
  print(paste("lambda = ", lambda, 
              "; Variables restantes:", round(lasso.lm$df, 2), 
              "; R^2 entrenamiento = ", round(lasso.lm$dev.ratio,2), 
              "; R^2 prueba = ", round(R2(lasso.pred, y_test),2)))
  
}
```

De lo anterior podemos ver que un modelo lineal puede no ser la mejor de las opciones; además, no corroboramos ninguno de los supuestos de la regresión y con una cantidad tan alta de variables es muy posible que muchas estén altamente correlacionadas:
```{r}
library(corrplot)
corrplot(cor(crime.df), type = "upper")
```
La visualización de los resultados se realiza casi a la par que la evaluación, en el sentido de que se grafican los valores observados vs. predichos por el modelo.

```{r}
mlm.data <- data.frame(obs = y_test, s0 = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(x = obs, y =  s0)) + 
            geom_point() + 
            geom_smooth(method = "lm", colour = rgb(118,78,144, maxColorValue = 255)) +
            labs(title = "Gráfico de dispersión de datos observados y predichos",
                 caption = "Datos simulados. \n El área gris representa el intervalo de confianza de la regresión al 95%",
                 x = "",
                 y = "") +
            blank_theme()
mlm.plot
```


