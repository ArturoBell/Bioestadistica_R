---
title: "Regresiones Lineales Múltiples"
author: "M. en C. Arturo Bell Enríquez García"
output: 
  distill::distill_article:
    toc: true
    toc_float: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(R.options = list(width = 80))
```

**[VIDEO](https://youtu.be/Kb8CwFgC9Zs)**

## Funciones personalizadas

```{r}
# Tema personalizado
blank_theme <- function(aspect.ratio = 1/1.61){
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank(),
        axis.line = element_blank(),
        aspect.ratio = aspect.ratio,
        axis.ticks = element_blank(),
        text = element_text(colour = "gray50"), # Eliminar
        legend.position = "none"
        )
}
```

## Regresión Lineal Múltiple

Para esta sección utilizaremos los datos de la base `crime.csv`. El objetivo será predecir la tasa de crimenes/poblacion a partir de otras 88 variables:

La variable que nos interesa predecir es el la columna `ViolentCrimesPerPop`). Apliquemos un modelo de regresión lineal múltiple incluyendo todas las variables, sin dividir los datos en entrenamiento-prueba y sin escalarlos. Tampoco filtraremos los datos para evitar una fuga de información:

```{r}
dr.df <- read.csv("data/crime.csv")[,-c(1)]
head(dr.df)
```

```{r}
dr.lm <- lm(ViolentCrimesPerPop~., data = dr.df)
summary(dr.lm)
```

```{r}
summary(dr.df$RentQrange)
```


Veamos qué pasa ahora si aplicamos este mismo modelo realizando la división entrenamiento-prueba.

#### Evaluación, el PROBLEMA del exceso de dimensionalidad y el sobreajuste:
Para realizar la división utilizaremos la función `sample.split()` de librería caTools:

```{r}
library(caret)
library(caTools)
set.seed(1111)
sample <- sample.split(dr.df$ViolentCrimesPerPop, SplitRatio = .75)
train <- subset(dr.df, sample == TRUE)
test <- subset(dr.df, sample == FALSE)
```

Ajustemos el modelo de entrenamiento:

```{r}
train.dr.lm <- lm(ViolentCrimesPerPop~., data = train)
summary(train.dr.lm)$r.squared*100
```

Evaluemos el desempeño en los datos de prueba.

```{r}
pred <- predict.lm(train.dr.lm, test[,1:88]) 
R2(pred, test$ViolentCrimesPerPop)*100
```

De estos resultados vemos que el modelo está sobreajustado, ya que el $R^2$ del modelo de prueba menor al de entrenamiento. Tomando esto en consideración, 1) escalemos los datos y b) apliquemos los modelos regularizados.

Para hacer las cosas más organizadas, primero dividamos ambos sets de datos en dos objetos: uno con las variables independientes y otro con la variable dependiente:

```{r}
X_train <- train[,1:88]
y_train <- train$ViolentCrimesPerPop
X_test <- test[,1:88]
y_test <- test$ViolentCrimesPerPop
```

Ahora estandaricemos las variables dependientes:

```{r}
preProc <- preProcess(X_train, method = c("center", "scale"))
X_train_s <- predict(preProc, X_train)
X_test_s <- predict(preProc, X_test)
```

## Regularización L2: Regresión Ridge

Apliquemos la regresión al set de entrenamiento. Debido a que el valor de penalización ($\alpha$ en la clase, $\lambda$ en glmnet) es "arbitrario", podemos utilizar validación cruzada para encontrar el valor que mejor se ajuste a nuestros datos. La validación cruzada consiste en hacer k particiones entrenamiento-prueba de los datos, ajustar un modelo para cada k para cada valor del parámetro que sea de nuestro interés, promediar el valor de error de cada iteración y quedarnos con el valor del parámetro que haya logrado el menor valor de nuestra medida de error. En la librería `glmnet` esto se hace con la función `cv.glmnet`, la cual recibe como argumentos una matriz de variables independientes, un vector con variables dependientes, un valor de alpha que será 0 para regresión Ridge, 1 para Lasso y algún intermedio para red elástica (no la veremos en el curso) y el tipo de medida de error, en este caso MSE.

```{r}
library(glmnet)
cv.ridge <- cv.glmnet(as.matrix(X_train_s), y_train, alpha = 0, type.measure = "mse")
# Valor de lambda que otorga el menor valor de error
lambdamin <- cv.ridge$lambda.min 
lambdamin
```

Ajustemos entonces el modelo regularizado con ese valor de lambda. (Df representa el número de coeficientes no negativos, $\%Dev = R^2$).

```{r}
ridge.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 0, lambda = lambdamin)
print(ridge.lm)
coef(ridge.lm) # Imprime los coeficientes de la regresión
```

Vemos que el valor de R2 es ligeramente menor al caso anterior; sin embargo, ganamos un poco de poder predictivo en el modelo de prueba:

```{r}
ridge.pred <- predict(ridge.lm, as.matrix(X_test_s))
R2(ridge.pred, y_test)*100
```

Veamos cómo afecta el valor de lambda:

```{r}
for (lambda in c(0, 0.5, 1, 2, 3, 5, 10, 20, 50, round(lambdamin,2))) {
  
  ridge.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 0,
                     lambda = lambda, standardize = F,
                     standardize.response = F)
  
  ridge.pred <- predict(ridge.lm, as.matrix(X_test_s))
  
  print(paste("lambda = ", lambda, 
              "; Variables restantes:", round(ridge.lm$df, 2), 
              "; R^2 entrenamiento = ", round(ridge.lm$dev.ratio,2), 
              "; R^2 prueba = ", round(R2(ridge.pred, y_test),2)))
  
}
```

Vemos que sí hay diferencias con respecto al primer caso. Apliquemos la regresión Lasso:

## Regularización L1: Regresión Lasso
```{r}
cv.lasso <- cv.glmnet(as.matrix(X_train_s),
                      y_train, alpha = 1,
                      type.measure = "mse")

# Valor de lambda que otorga el menor valor de error
lambdamin <- cv.lasso$lambda.min
lambdamin
```

Ajustemos entonces el modelo regularizado con ese valor de lambda. (Df representa el número de coeficientes no cero, $\%Dev = R^2$).

```{r}
lasso.lm <- glmnet(as.matrix(X_train_s), y_train, alpha = 1, 
                   ambda = lambdamin)
print(lasso.lm)
coef(lasso.lm) # Imprime los coeficientes de la regresión
```

Vemos que el valor de R2 no es muy diferente al caso anterior, aunque ahora únicamente tenemos 18 coeficientes ≠ 0

```{r}
lasso.pred <- predict(lasso.lm, as.matrix(X_test_s))
R2(lasso.pred, y_test)*100
```

En los datos de prueba tampoco hubo mucha diferencia. Veamos cómo cambia esto al modificar el valor de lambda:

```{r}
for (lambda in c(0, 0.5, 1, 2, 3, 5, 10, 20, 50, round(lambdamin,2))) {
  
  lasso.lm <- glmnet(as.matrix(X_train_s), y_train,
                     alpha = 1, lambda = lambda,
                     standardize = F, standardize.response = F)
  
  lasso.pred <- predict(lasso.lm, as.matrix(X_test_s))
  
  print(paste("lambda = ", lambda, 
              "; Variables restantes:", round(lasso.lm$df, 2), 
              "; R^2 entrenamiento = ", round(lasso.lm$dev.ratio,2), 
              "; R^2 prueba = ", round(R2(lasso.pred, y_test),2)))
  
}
```

De lo anterior podemos ver que un modelo lineal puede no ser la mejor de las opciones; además, no corroboramos ninguno de los supuestos de la regresión y con una cantidad tan alta de variables es muy posible que muchas estén altamente correlacionadas:

```{r}
library(corrplot)
corrplot(cor(dr.df), method = "ellipse", type = "upper")
```

Podemos también hacer una matriz similar, aunque utilizando gráficos de dispersión:

```{r, fig.height=10, fig.width=10}
library(GGally)
#pairs <- ggpairs(dr.df, progress = F)
pairs
```

La visualización de los datos se hace en parte junto con la evaluación de la regresión, en el sentido de que solo podemos ver la relación entre los datos observados y predichos por el modelo

```{r}
mlm.data <- data.frame(obs = y_test, s0 = predict(lasso.lm, as.matrix(X_test_s)))
mlm.plot <- ggplot(data = mlm.data, aes(x = obs, y =  s0)) + 
            geom_point() + 
            geom_smooth(method = "lm", colour = rgb(118,78,144, maxColorValue = 255)) +
            labs(title = "Gráfico de dispersión de datos observados y predichos",
                 subtitle = sprintf("R2e: %.2f | R2p: %.2f",
                                    round(lasso.lm$dev.ratio,2), 
                                    round(R2(lasso.pred, y_test),2)),
                 caption = "Datos de prueba",
                 x = "",
                 y = "") +
            theme_bw()
mlm.plot
```

## Ingeniería de variables
Aplicamos un PCA para generar nuevas variables que contengan el efecto de las variables originales y que sean ortogonales:

```{r}
library(factoextra)
library(FactoMineR)

X_train_pca <- FactoMineR::PCA(X_train, graph = F, ncp = length(X_train), scale.unit = F)
X_pca_train <- predict(X_train_pca, X_train)$coord
X_pca_test <- predict(X_train_pca, X_test)$coord
```

Evaluemos las correlaciones de los nuevos predictores con nuestra variable de interés y extraigamos aquellas que tengan correlaciones significativas (≠0):

```{r}
#library(Hmisc)
c_mat <- as.data.frame(cor(cbind(X_pca_train, y_train)))$y_train
p_mat <-  as.data.frame(Hmisc::rcorr(cbind(X_pca_train, y_train))$P)$y_train
p_mat <- data.frame(y_train = p_mat[is.na(p_mat) == F], CP = colnames(X_pca_train))
sig_cps <- p_mat$CP[p_mat$y_train <= 0.05]
sig_cps
```

Filtramos nuestros datos:

```{r}
X_filt_train <- X_pca_train[,sig_cps]
X_filt_test <- X_pca_test[,sig_cps]
filt_train <- data.frame(X_filt_train, y_train)
```


Realicemos la regresión múltiple:

```{r}
pca_lm <- train(y_train~.,
                data = filt_train,
                method = "lm")
summary(pca_lm)
```

Los resultados son similares en los datos de entrenamiento, veamos qué pasa con los datos de prueba:

```{r}
pca_tpreds <- predict(pca_lm, as.data.frame(X_filt_test))
round(R2(pca_tpreds, y_test), 2)
```

Los resultados también son similares a aquellos de la regresión Lasso. La conclusión que podemos generar es que un modelo lineal como este puede no ser la mejor opción para estos datos. ¿Cómo más podríamos mejorarlo?

## Ejercicio 1

1. Realiza una regresión Lasso con los CPs. ¿Cuántas variables se mantienen?¿Cambia el desempeño de los modelos?
2. Realiza los diagnósticos de las regresiones Ridge, Lasso y la regresión con CP. ¿Cuál está mejor ajustada? (Performance)
3. Aplica un GLM con las variables restantes en la regresión Lasso. ¿Qué familia utilizas para el error? ¿El ajuste mejora o se mantiene igual?

## Ejercicio 2

El objetivo es predecir la edad de individuos de abulón a partir de mediciones corporales de los mismos utilizando algún modelo lineal. Puedes también utilizar algún modelo no lineal, si es de tu interés. 

Los datos para entrenar los modelos se encuentran [aquí](https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv). Las columnas corresponden a:
- Longitud del organismo,
- Diámetro del organismo,
- Altura del organismo,
- Peso entero,
- Peso sin concha,
- Peso de las vísceras,
- Peso de la cáscara,
- Edad (años)

Los puntos a tener en cuenta son:

1) Identificar si es necesario hacer algún procesamiento a los datos y, de ser así, aplicarlo.
2) ¿Es necesario, prudente y válido incluir todas las variables en el modelo?
3) A partir del punto anterior, construir el/los modelos de regresión. ¿Es necesario utilizar un modelo penalizado/regularizado?
4) Evaluar si los modelos están sobre o sub ajustados.
5) Analizar los gráficos diagnósticos de la regresión (recuerda que todos son construidos a partir de los residuales y los valores a predecir) y evaluar la bondad de ajuste de los modelos y evaluar su calidad (e.g., ¿Son los residuales normales y homocedásticos?).
6) Una vez mejorado el modelo lo más posible (i.e., escalando los valores, eliminando variables o generando nuevas (e.g. ACP)), crea un nuevo modelo con TODAS las observaciones.
7) Predice los valores de edad de los [datos de prueba](https://storage.googleapis.com/download.tensorflow.org/data/abalone_test.csv). ¿Cuál es el valor de MSE y $R^2$ alcanzado por el modelo?
8) Tomando en cuenta estos resultados, ¿el modelo ajustado final se encuentra bien ajustado, sobreajustado o infraajustado?

## Datos:

El código de las siguientes celdas permite descargar los datos directamente a R desde una URL:

### Entrenamiento
```{r, results='hide'}
train_d <- paste0("https://storage.googleapis.com/",
                  "download.tensorflow.org/data/abalone_train.csv")
download <- RCurl::getURL(train_d)
train <- read.csv(text = download, header = F)
colnames(train) <- c("Long", "Diam", "Alt", "PesoEnt",
                     "PesoDesc", "PesoVisc", "PesoCasc", "Edad")
head(train)
```

```{r, echo = FALSE}
rmarkdown::paged_table(head(train))
```

### Prueba
```{r, results='hide'}
test_d <- paste0("https://storage.googleapis.com/",
                 "download.tensorflow.org/data/abalone_test.csv")
download <- RCurl::getURL(test_d)
test <- read.csv(text = download, header = F)
colnames(test) <- c("Long", "Diam", "Alt", "PesoEnt", "PesoDesc",
                    "PesoVisc", "PesoCasc", "Edad")
head(test)
```
```{r, echo = FALSE}
rmarkdown::paged_table(head(test))
```
