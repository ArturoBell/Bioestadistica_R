[
  {
    "objectID": "c1x_clasificacion.html",
    "href": "c1x_clasificacion.html",
    "title": "5  Aprendizaje supervisado: Clasificación",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\n\n\niris.plot <- ggplot(iris, aes(x = Species, y = Petal.Length)) +\n             geom_point(color = \"dodgerblue4\", alpha = 0.8) +\n             theme_bw()\niris.plot\n\n\n\n\nEl primer paso es separar nuestros datos en datos de entreenamiento y prueba, lo cual podemos hacer con las funciones initial_split, training y testing de la librería rsample:\n\nset.seed(123)\niris_split <- initial_split(iris, strata = Species)\niris_train <- training(iris_split)\niris_test <- testing(iris_split)\n\nLuego, construimos una receta para el preprocesamiento de los datos:\n\nLe damos a la receta (recipe()) la fórmula y los datos de entrenamiento\nAñadimos un paso para centrar los datos numéricos. Recuerda, solo estamos poniendo todos los valores numéricos en la misma escala\n\nEl objeto iris_prep sigue los pasos a seguir para el preprocesamiento de los datos (por ello receta) y obtiene los parámetros con los que se van a preprocesar los datos, mientras que juiced obtiene los datos procesados.\n\niris_rec <- recipe(Species~., data = iris_train) |> \n            step_center(all_numeric())\niris_prep <- iris_rec |> prep()\njuiced <- juice(iris_prep)\n\nAhora podemos especificar el modelo de bosques aleatorios, donde ajustaremos sus hiperparámetros:mtry (el número máximo de predictores por árbol), min_n (el número de observaciones necesarias para seguir dividiendo los datos) y trees (el número de árboles en el ensemble). Después especificamos que es un bosque para clasificación, y por último le indicamos que utilice la librería ranger para construir el bosque:\n\ntune_spec <- rand_forest(mtry = tune(),\n                         trees = tune(),\n                         min_n = tune()) |> \n             set_mode(\"classification\") |>\n             set_engine(\"ranger\")\n\nFinalmente, formamos un flujo de trabajo que contenga ambos pasos: la receta de preprocesamiento y el modelo\n\ntune_wf <- workflow() |> \n           add_recipe(iris_rec) |> \n           add_model(tune_spec)\n\nAhora sí, podemos ajustar nuestros hiper-parámetros. Primero, asignemos un confjunto de remuestreos para la validación cruzada, construidos a partir de los datos de entrenamiento:\n\nset.seed(0)\niris_fold <- vfold_cv(iris_train)\n\nLuego establezcamos el procesamiento en paralelo para hacer el procedimiento más rápido. En este primer proceso vamos a escoger 20 puntos aleatorios para guiar nuestra búsqueda y no abusar de la fuerza bruta para resolver el problema:\n\ndoParallel::registerDoParallel(cores = 6)\ntune_res <- tune_grid(tune_wf,\n                      resamples = iris_fold,\n                      grid = 20)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\nVeamos nuestros AUCs:\n\ntune_res |> collect_metrics() |> \n            filter(.metric == \"roc_auc\") |> \n            select(mean, min_n, mtry, trees) |>\n            pivot_longer(min_n:trees,\n                         values_to = \"value\",\n                         names_to = \"parameter\") |> \n            ggplot(aes(value, mean, color = parameter)) +\n            geom_point(show.legend = F) +\n            facet_wrap(~parameter, scales = \"free_x\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bioestadística Aplicada con R y RStudio",
    "section": "",
    "text": "¡Hola! Te doy la bienvenida al curso Bioestadística Aplicada con R y RStudio, ofertado por Dr. Plancton.\nEste es el libro de acompañamiento del curso. Aquí encontrarás tanto la teoría como el código que se aborda en el curso, dispuestos en una manera que facilita su lectura, y cuyo objetivo es simplemente proveer una versión lista para ser revisada en cualquier momento, sin necesidad de iniciar RStudio. Cada sección del libro tiene enlaces a los videos correspondientes, en caso de que prefieras ver y escuchar la explicación.\nTen en cuenta que puede existir un desfase entre el material del libro y los videos. La razón es que el material se actualizará para mejorar el contenido, la entrega o la explicación siempre que sea posible, lo cual es fácil de hacer en el libro y las libretas con el código, pero no en los videos; sin embargo, en el momento en el que el desfase sea lo suficientemente grande, también se actualizarán los videos de las secciones correspondientes.\n\n\nEl objetivo de este curso es que seas capaz no solo de implementar distintas técnicas de análisis de datos utilizando R, sino que también puedas ser crítico con tus resultados y que minimices, en la medida de lo posible, el sesgo algorítmico. En este curso aprenderás los fundamentos detrás de las pruebas vistas, en donde abordaremos la teoría desde un punto de vista práctico, buscando que puedas formarte una intuición propia. También trataremos de desmitificar el valor de p y, sobre todo, cómo no interpretarlo. En las partes más abstractas te adentrarás en el aprendizaje automatizado, y verás que hay vida más allá del \\(R^2\\) (regresiones) y la exactitud (clasificaciones).\nUno de los errores más comunes al enseñar estadística con R es tratar de enseñar ambas cosas al mismo tiempo. En este curso, R es solo un medio y no un fin; es decir, no es un curso de programación en R tanto como es un curso de ciencia de datos aplicada; sin embargo, hay una amplia introducción al lenguaje al inicio, y espero que el explicar línea por línea el código te permita familiarizarte con el lenguaje. Dicho esto, el curso fue diseñado para que personas con nulo o muy poco conocimiento de programación en general puedan seguirlo, y siempre podrás contactarnos en caso de que no hayamos explicado algo adecuadamente.\n\n\n\nSi bien es cierto que puedes utilizar y acceder a todo el material del curso desde esta página, te recomiendo encarecidamente unirte al servidor de Discord utilizando tu enlace único (enviado a tu correo al registrarte), pues ahí podrás interactuar no solamente con tus compañeros y compañeras, sino también con tu profesor. Un último comentario, NO es necesario que instales el cliente de Discord en tu computadora o dispositivo móvil, aunque si lo haces podrás recibir las notificaciones sobre modificaciones que se hagan al material."
  },
  {
    "objectID": "s1_biolcdatos.html",
    "href": "s1_biolcdatos.html",
    "title": "Biología como Ciencia de Datos",
    "section": "",
    "text": "En esta sección del curso comenzarás reflexionando sobre el cómo se han aplicado tradicionalmente las técnicas estadísticas a los problemas biológicos, y cómo esta aproximación puede no ser óptima. Después, te introducirás a R utilizando RStudio y terminarás con una introducción a los conceptos básicos detrás de la visualización de datos."
  },
  {
    "objectID": "s0_preparacion.html",
    "href": "s0_preparacion.html",
    "title": "Preparación",
    "section": "",
    "text": "Antes de entrar al contenido del curso es necesario asegurarnos de que tengas instalados todos los programas y extensiones requeridos. Aunque los pasos son los mismos para todos los casos (i.e., descargar el instalador, ejecutarlo, y dar click en aceptar/continuar), puedes (en raras ocasiones) encontrarte con algunos contratiempos que son específicos al sistema operativo en el que te encuentres:"
  },
  {
    "objectID": "s0_preparacion.html#r",
    "href": "s0_preparacion.html#r",
    "title": "Preparación",
    "section": "R",
    "text": "R\nEvidentemente, lo primero que deberás instalar es R. Puedes encontrar el instalador de la versión más reciente para tu sistema operativo en CRAN (The Comprehensive R Archive Network).\nSimplemente da click en el enlace al servidor más cercano a tu ubicación, por ejemplo https://cran.itam.mx/.\nDespués simplemente descarga la versión que corresponde a tu sistema operativo.\nIndependientemente del sistema operativo que utilices, la instalación consiste en ejecutar el instalador y seguir los pasos indicados en su ventana, dando click en aceptar y continuar según sea necesario."
  },
  {
    "objectID": "s0_preparacion.html#rstudio",
    "href": "s0_preparacion.html#rstudio",
    "title": "Preparación",
    "section": "RStudio",
    "text": "RStudio\nUna vez instalado R podemos instalar RStudio. Más adelante veremos cuál es la diferencia entre ambos, pero por el momento piensa en RStudio como una ventana para R. Primero, dirígete a https://posit.co/download/rstudio-desktop/.\n\n\n\n\n\n\nNote\n\n\n\n¿Por qué el enlace para descargar RStudio es de posit? En octubre del 2022 la empresa se volvió posit. Aquí puedes leer más al respecto, pero el resumen es que el nombre de la empresa cambió, pero el nombre de su ambiente integrado de desarrollo (IDE, RStudio) se mantendrá igual.\n\n\nEn la sección All Installers ubica tu sistema operativo y descarga el instalador correspondiente\nUna vez descargado, ejecuta el instalador y sigue los pasos que aparecen en pantalla."
  },
  {
    "objectID": "s0_preparacion.html#quarto-y-tinytex",
    "href": "s0_preparacion.html#quarto-y-tinytex",
    "title": "Preparación",
    "section": "Quarto y tinytex",
    "text": "Quarto y tinytex\nCon estas dos instalaciones sería más que suficiente para empezar a trabajar, sin embargo, podemos ir más allá y utilizar RStudio para crear reportes, artículos científicos, libros (incluyendo tesis), páginas web, presentaciones, y más. Esto solía (y puede) hacerse con librerías como rmarkdown, distilled o bookdown; sin embargo, tenemos la siguiente generación: Quarto. En el curso veremos una introducción para hacer reportes y, de hecho, este material de acompañamiento (libro y página web) fueron escritos en documentos Quarto. Al igual que en los casos anteriores, dirígete a la página de descargas y descarga e instala la versión correspondiente a tu sistema operativo.\n\n\n\n\n\n\nImportant\n\n\n\nNO verás un ejecutable (acceso directo) después de que se haya realizado la instalación. Para utilizar Quarto necesitaremos de a) la línea de comandos o b) RStudio. Debajo de los enlaces de descarga hay más información sobre cómo utilizarlo, incluyendo detalles para su integración con VS Code, Jupyter y en un editor de textos (línea de comandos). Puedes explorarlos, aunque aquí verás los detalles correspondientes.\n\n\nAdicional a Quarto, y si deseas exportar tus reportes a archivos PDF, es necesario instalar una distribución de LaTeX. Si ya cuentas con alguna, puedes saltarte este paso, de lo contrario puedes o realizar la instalación completa o simplemente instalar TinyTeX desde aquí. Si optas por instalar TinyTeX y no tienes nada de experiencia con R, te recomiendo seguir los pasos de su página una vez que hayas pasado por el tema 3 Bases de R. No te preocupes, hay un recordatorio al final de la sesión."
  },
  {
    "objectID": "s0_preparacion.html#xquartz",
    "href": "s0_preparacion.html#xquartz",
    "title": "Preparación",
    "section": "xquartz",
    "text": "xquartz"
  },
  {
    "objectID": "s0_preparacion.html#developer-command-line",
    "href": "s0_preparacion.html#developer-command-line",
    "title": "Preparación",
    "section": "developer command line",
    "text": "developer command line"
  },
  {
    "objectID": "c02_intro_rs.html",
    "href": "c02_intro_rs.html",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "",
    "text": "En la sesión anterior hablamos de cómo la ciencia de datos nos proveé de las herramientas que necesitamos para poder extraer conclusiones sensibles desde nuestros datos; sin embargo, el análisis de nuestros datos va (o debería ir) mucho más allá de aplicar una prueba estadística y dar a conocer el valor de p correspondiente. El análisis de datos es un proceso, y como científicos debemos de ser capaces de reportar ese proceso de una manera ordenada, transparente y reproducible. Es ahí donde entran RStudio y Quarto (la evolución de RMarkdown), así que antes de entrar propiamente al lenguaje de programación R, hablemos de cómo realizar reportes y cómo podemos aprovechar al máximo la interface que provee RStudio. Te adelanto: si lo utilizas adecuadamente, RStudio (en conjunto con Quarto) puede ser el lugar donde escribas tu tesis, por muy inverosímil que parezca. De hecho, este sitio fue construido utilizando ambas cosas. Sin más preámbulo, comencemos por hablar de qué es RStudio."
  },
  {
    "objectID": "c02_intro_rs.html#r-vs.-rstudio",
    "href": "c02_intro_rs.html#r-vs.-rstudio",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "2.1 R vs. RStudio",
    "text": "2.1 R vs. RStudio\nAntes de volar y pretender formar un sitio web o una tesis, comencemos hablando de RStudio. En la sección de preparación instalamos tres cosas diferentes: R, RStudio, y Quarto. Olvidemos a este último por un momento y centrémonos en los dos primeros. R es un lenguaje de programación. Como tal, se ejecuta en consola, ya sea el terminal (macOS/Linux) o el interpretador de comandos cmd en Windows. Lo único que veremos si abrimos/ejecutamos R per-se es una ventana como la siguiente:\n\n\n\nFigure 2.1: Consola de R (R GUI)\n\n\nEs decir, solamente veremos nuestra consola, compuesta por una descripción de la versión de R que estamos utilizando y un prompt (el símbolo >) que nos presiona a darle a la computadora una instrucción. Más allá de ser una interfaz extremadamente simple, no está pensada para el desarrollo de reportes como los que nosotros realizamos. No podemos escribir texto libre, ni tampoco podemos guardar nuestro progreso. Para eso habría que abrir un script, pero hay una mejor alternativa que nos permite hacer eso y mucho más: RStudio. Por el momento hasta aquí vamos a llegar con R, pero no te preocupes, le vamos a dedicar mucho más tiempo posteriormente."
  },
  {
    "objectID": "c02_intro_rs.html#el-ide-rstudio",
    "href": "c02_intro_rs.html#el-ide-rstudio",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "2.2 El IDE RStudio",
    "text": "2.2 El IDE RStudio\nMientras que R es un lenguaje de programación ejecutable en consola, RStudio es un ambiente gráfico de desarrollo (IDE). ¿Qué significa? Que es una interfaz gráfica que nos permite no solo ejecutar nuestro código línea a línea, sino que también incluye otros páneles que nos facilitan enormemente la existencia y, además, abre otras puertas para la creación de documentos como este libro. Vayamos por partes.\n\n2.2.1 La ventana de RStudio\nAl abrir RStudio por primera vez te vas a topar con una ventana como la siguiente:\n\n\n\nFigure 2.2: Ventana de RStudio\n\n\nYa sé, ya sé, no se ve mucho más amable que la ventana de R. Es más, se ve mucho más intimidante porque ahora tenemos la consola y otros 3 espacios. Al ser un IDE, RStudio incluye elementos gráficos para todo lo que pudiéramos llegar a necesitar mientras desarrollamos nuestros análisis, entonces vamos a descomponer esta ventana panel por panel, de arriba a abajo y de izquierda a derecha.\n\n2.2.1.1 El editor\nEl primer panel es el editor:\n\n\n\nFigure 2.3: Editor en RStudio\n\n\nEste es, como el nombre sugiere, un editor de textos, que no debemos de confundir con procesador de palabras (i.e., Word o similares). En él vamos a poder escribir sripts o libretas que contengan la serie de pasos que realizamos durante nuestro análisis. Cada una de las pestañas en este panel es siempre un documento de texto simple, independientemente de si es un script o una libreta. Esto tiene varias ventajas, pero la más importante es que nos podemos llevar esos archivos a cualquier computadora y estar bastante seguros de que podremos, cuando menos, ver su contenido y editarlo sin preocuparnos por problemas de compatibilidad entre versiones del software o, peor aún, sistemas operativos (*ejem* Word *ejem*). Estos archivos de texto simple pueden, dependiendo del tipo de archivo, enviar instrucciones a R.\n\n\n2.2.1.2 La consola\nEl siguiente panel es la consola:\n\n\n\nFigure 2.4: Consola en RStudio\n\n\nEste panel es, literalmente, lo que veíamos al abrir R en sí mismo; es decir, un espacio donde tenemos nuestro prompt y donde se ejecutarán nuestras instrucciones o líneas de comandos. Notarás que hay otras tres pestañas: una llamada Terminal, y otra llamada Background Jobs. Estas son interfaces a la terminal del sistema y a los trabajos que estemos ejecutando en segundo plano. Nuestra interacción con estas dos pestañas va a ser limitada, salvo que realicemos algo muy especializado. En el curso solo entraremos ocasionalmente al Terminal.\n\n\n2.2.1.3 ¿Reportes como scripts?\nAntes de pasar al siguiente panel es importante hablar de los scripts, las libretas, e intentar hacer un poco de labor de convencimiento. Si has tenido un acercamiento previo a R/RStudio, es bastante probable que trabajar con scripts te sea familiar. Si no es así, un script de R es un archivo de texto con extensión .R en el que ponemos nuestro código línea a línea. Pensemos en un ejercicio en el que queremos primero sumar 1 y 1, y luego 2 y 2. Nuestro script en RStudio se vería así:\n\n\n\nFigure 2.5: Script en el editor\n\n\nSolo tenemos el código, no tenemos los resultados. ¿La razón? Aún no le hemos dicho a la computadora que queremos que las ejecute. ¿Cómo le decimos? Tenemos dos formas:\n\nEjecutar el script línea a línea, para lo que debemos posicionar nuestro cursor (dar click) sobre la línea a ejecutar, utilizar el atajo de teclado CMD + R en macOS/Linux o CTRL + R en Windows, o dar click sobre el botón Run que está cerca de la esquina superior derecha del panel.\nEjecutar el script completo, para lo que seleccionaríamos todo su contenido y utilizaríamos el mismo atajo de teclado o botón que antes.\n\nSea cual sea la opción que hayas escogido, la salida (el resultado) aparecerá en la consola:\n\n\n\nFigure 2.6: Script ejecutado en consola\n\n\n¿Cuál es el problema? El primero es que en el momento en el que cerremos RStudio esos resultados se van a perder, salvo que los hayamos guardado manualmente en algún lugar. El segundo tiene que ver con una falta de unificación: el código (las sumas) están por un lado, mientras que los resultados están en otro que, además, es volátil. El tercero se deriva de los dos anteriores: falta de legibilidad y reproducibilidad. No podemos hacer el reporte al mismo tiempo en que analizamos los datos y, si en algún momento volvemos al script, debemos de ejecutarlo todo nuevamente para ver los resultados. Suena engorroso, ¿no? Un cuarto problema es que no tenemos descripciones de nuestros resultados. Si ya has trabajado con estos archivos me vas a decir “para eso existen los comentarios”, a lo que yo te respondería que no, los comentarios no son para eso. Si no has trabajado con R ni ningún otro lenguaje de programación te preguntarás qué es un comentario. Bien, un comentario es un fragmento de texto no ejecutable; es decir, es algo que podemos escribir y pasarle a la consola pero que no se va a ejecutar. En R estos están dados por el operador #. Agreguemos un comentario a nuestro script con la palabra “Sumas” y ejecutémoslo todo nuevamente:\n\n\n\nFigure 2.7: Script con comentarios ejecutado en consola\n\n\nComo esperábamos, en la consola no hay una salida asociada a la instrucción # Sumas, por lo tanto puedo usar esos comentarios para describir mis resultados, ¿no? La respuesta es, como en muchas otras cosas, depende. O, mejor dicho, de que se puede, se puede, que debamos hacerlo, es otra historia. Los comentarios tienen la función de describir muy brevemente qué intención tiene el código, no escribir párrafos completos con el reporte de los resultados. Comentarios válidos son agregar al inicio del script quién lo escribió, qué hace el código contenido en él, un medio de contacto, y breves descripciones de qué se hace en cada línea, sin repetir el código en texto simple (no decir # Suma 1 y 1 si el código es 1+1, por ejemplo). Existe otro gran problema el cuál no es obvio en este ejercicio, pero que tiene que ver con la carga de datos en archivos dentro de nuestra computadora (archivos .csv o .xlsx, por ejemplo), pero eso lo veremos en un tema posterior. Por el momento veamos una alternativa que resuelve todos estos problemas.\n\n\n2.2.1.4 Libretas y reportes: Quarto\nAquí es donde entran Quarto y las libretas. Al instalar Quarto no instalamos un programa per-se, sino que instalamos una extensión a RStudio que es, y cito textualmente, “un sistema de publicación científica y técnica de código abierto construido sobre Pandoc”, que permite, citando nuevamente: i) crear contenido dinámico no solo con R sino con otros lenguajes de programación; ii) escribir documentos como texto plano; iii) publicar artículos, reportes, presentaciones, sitios web, blogs y libros de alta calidad en formatos HTML, PDF, MS Word, ePUB; y iv) escribir con markdown científico, incluyendo ecuaciones, citas, referencias cruzadas, páneles de figuras, anotaciones, diseños avanzados y más. ¿A que ya suena mejor que los scripts? Sin ir más lejos, todo el material que utilizaremos en este curso fue escrito en RStudio utilizando Quarto, y puedes ver la versión final en el sitio web de acompañamiento. Debido a que explicar Quarto es un tema que merece le dediquemos tiempo y estar más arriba que un subtema de IDE RStudio, vamos a dejarlo de lado por el momento, solo revisemos cómo crear un nuevo documento y las diferencias fundamentales con los scritps. Para crear un documento podemos ir a la barra de herramientas -> File -> New file -> Quarto document, o utilizar el botón correspondiente en la ventana de RStudio:\n\n\n\nFigure 2.8: Nuevo documento Quarto\n\n\nAl darle click nos va a aparecer la siguiente ventana para personalizar el documento:\n\n\n\nFigure 2.9: Opciones documento Quarto\n\n\nAquí añadirás el título de tu documento y opcionalmente el autor. Por el momento dejaremos todo lo demás tal y como está y daremos click en Create, lo que abrirá una pestaña nueva en el editor:\n\n\n\nFigure 2.10: Opciones documento Quarto\n\n\nLa pestaña se parece al contenido de un script, la única diferencia es un texto contenido entre ---. A esta parte la podemos identificar como el preámbulo del documento, y es un fragmento de nuestro documento escrito en formato YAML ¿Qué es eso y con qué se come? No te preocupes ahorita por eso, solo necesitas saber ahorita que vamos a desarrollar nuestro trabajo debajo del preámbulo. En la Figure 2.11 puedes ver un ejemplo básico de un documento Quarto con el código de nuestras sumas.\n\n\n\nFigure 2.11: Un documento Quarto básico\n\n\nUn ejemplo más claro del potencial de Quarto es, nuevamente, el material de este curso. Pero sigamos explorando la ventana de RStudio\n\n\n\n2.2.2 El ambiente de trabajo\nEl siguiente panel es lo que se conoce como el ambiente de trabajo (workspace), que nos da un listado de las cosas que le hemos dado a R para que recuerde (objetos). En la siguiente sesión hablaremos largo y tendido de esto, pero veamos un ejemplo donde, utilizando la consola, le digamos a R que recuerde el resultado de la suma 1 + 1, asignándolo a una referencia que arbitráriamente llamaré suma:\n\n\n\nFigure 2.12: Guardar un resultado en la consola\n\n\nDos cosas: 1) La asignación se hizo con el operador <-. Esto es sumamente importante, en R guardamos cosas utilizando ese operador y no =. 2) Al ejecutar la línea no obtuvimos el resultado. Esto es porque solo le dijimos que lo recordara, que lo anotara en un post-it, si quieres, no que nos lo mostrara. Si queremos que nos lo muestre solo tenemos que llamarlo por su nombre (ejecutar en la consola):\n\n\n\nFigure 2.13: Imprimir el resultado\n\n\n¿Qué tiene que ver esto con el ambiente de trabajo? Pues ahora ya no está vacío, ya tenemos una entrada en la lista, en donde se muestra el nombre del objeto y su valor. Conforme vayamos creando más objetos, más entradas tendrá esa lista. Prueba a crear un objeto que contenga el texto \"Hola mundo\" (ojo a las comillas) y dar click en su nombre en el ambiente de trabajo. ¿Qué ocurre?\n\n\n2.2.3 El ambiente gráfico\nEl último panel corresponde al ambiente gráfico. Este panel junta varios elementos a los que es más fácil acceder visualmente. La primera pestaña es un explorador de archivos. puedes dar click a cada carpeta para ver sus elementos, crear nuevas carpetas, y mucho más. En este curso no lo utilizaremos más que como una referencia visual de dónde están ubicados nuestros archivos.\n\n\n\nFigure 2.14: Explorador de archivos\n\n\nLa siguiente pestaña nos muestra la serie de gráficos que hemos ido generando. Podemos ejecutar en la consola el comando plot(cars) y verás que el gráfico se muestra en esta pestaña.\n\n\n\nFigure 2.15: Gráfico en el ambiente gráfico\n\n\nEn la siguiente pestaña encontraremos un listado de las librerías/paqueterías que tenemos instaladas, sus versiones, una breve descripción de para qué son, así como botones para instalarlas o actualizarlas.\n\n\n\nFigure 2.16: Paquetes\n\n\nDespués tenemos la pestaña de ayuda. Aquí podemos ver, valga la redundancia, ayuda sobre R, pero también sobre funciones en las que estemos interesados. Si queremos ver la ayuda de una función FUN vamos a utilizar el comando ?FUN, tal que:\n\n\n\nFigure 2.17: ¡Ayuda!\n\n\nEn la siguiente pestaña tenemos un visor (Viewer), donde tendremos vistas previas de los documentos RMarkdown o Quarto con los que estemos trabajando. Tomando como ejemplo el documento que generamos antes, le daremos click al botón Render con la flecha azul, lo que da como resultado la vista previa en Viewer\n\n\n\nFigure 2.18: Documento Quarto y su renderizado\n\n\nLa última pestaña es un visor de presentaciones, el cual no utilizaremos en este curso.\n\n\n2.2.4 Personalizando RStudio\nComo todo IDE, podemos personalizar la apariencia de RStudio. Para hacerlo simplemente ve a la barra de herramientas, Tools -> Global Options. Te aparecerá la siguiente ventana\n\n\n\nFigure 2.19: Ventana de ajustes\n\n\nVamos a revisar algunas de las opciones que te recomiendo tener presentes. Puedes hacer los cambios y aplicarlos todos juntos al final con el botón Apply:\n\nGeneral\n\nBasic\n\nWorkspace: Restore .RData into workspace at startup & Save workspace to .RData on exit. ¿Quieres que cada que cierres RStudio todos los objetos de tu espacio de trabajo se guarden en un archivo, y que esos mismos se carguen la siguiente vez que abras RStudio? Personalmente no es algo con lo que esté de acuerdo, porque más frecuentemente que no vas a querer un ambiente limpio, por lo que estas opciones están desmarcada y en Never, respectivamente.\nHistory: La misma historia (je) que en el caso anterior. ¿Quieres que tu historial de comandos ejecutados se guarde, aún si no guardas el .RData? ¿Quieres que se remuevan los duplicados? Por las mismas razones que antes también las tengo desmarcadas.\n\nGraphics\n\nBackend a Cairo. Simplemente es con qué se están graficando las cosas. ¡ES INDISPENSABLE QUE TENGAS INSTALADO xquartz SI ESTÁS EN macOS/LINUX!\n\n\nAppearance\n\nZoom: ¿Qué tan grandes quieres todos los elementos de la ventana? Para mi trabajo personal, y dependiendo de la resolución del monitor donde se encuentre la ventana, esta oscila entre 100% y 125%, para este curso está en 175-200%\nEditor font y Editor font size: Tipo y tamaño de letra. Personalmente recomiendo no cambiar el tipo de letra.\nEditor theme: Cambia el color de fondo y los colores de realce de la sintaxis. Usualmente trabajo por las noches, por lo que prefiero un tema con fondo obscuro como Tomorrow Night Bright, pero puedes buscar el que tú quieras.\n\nPane Layout\n\nAquí se muestran los cuatro paneles de la ventana de RStudio. Personalmente prefiero tener los dos elementos que más utilizo lado a lado y no uno encima del otro. ¿La razón? El código crece hacia abajo, entonces el espacio vertical tiende a ser más importante que el espacio horizontal. Es decir, que en el panel superior derecho pongo la consola, y en el panel inferior izquierdo el ambiente de trabajo.\n\n\nEl resto de opciones son más específicas, por lo que recomiendo no tocarlas salvo que sepas qué estás moviendo y con qué objetivo. Todo se puede revertir, pero no hay necesidad de fomentar dolores de cabeza."
  },
  {
    "objectID": "c02_intro_rs.html#entra-a-quarto",
    "href": "c02_intro_rs.html#entra-a-quarto",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "2.3 Entra a Quarto",
    "text": "2.3 Entra a Quarto\nAhora sí, podemos dedicarle nuestra atención a Quarto. Antes mencioné que era un sistema para la creación de documentos científicos y técnicos, que se instala aparte de R y RStudio (lo hicimos ya en la sesión anterior), y que es sumamente flexible. Vimos también un ejemplo de cómo crear un documento Quarto y un poco de cómo interactuar con él. Ahora entremos a todos los detalles. Retomemos nuestro documento de ejemplo (Figure 2.11).\n\n2.3.1 Preámbulo\nEl primer elemento es el preámbulo, que mencionamos está en formato YAML y que está contenido entre ---. YAML es un formato de serialización de datos legible por humanos. ¿En castellano? Una lista con niveles de pares de claves:valores que definen los metadatos de nuestro documento. En nuestro ejemplo tenemos:\n---\ntitle: \"Untitled\"\n---\nEs decir, el título que aparecerá en el reporte es \"Untitled\", tal y como vimos en la vista previa. Esto no tiene mucho sentido, así que cambiémoslo por \"Mi primer Quarto\" y añadamos una nueva entrada para el autor, tal que:\n---\ntitle: \"Mi primer Quarto\"\nauthor: \"Tu nombre\"\n---\nOtro elemento que usualmente se agrega en el preámbulo es el formato de salida del documento renderizado; es decir, ya presentado para compartir/imprimir. Mi recomendación es exportar a archivos HTML, salvo que vayas a imprimir el documento (PDF), necesites paginación (PDF de nuevo) o que por alguna desafortunada razón necesites un archivo MS Word. Un HTML lo declaramos tal que:\n---\ntitle: \"Mi primer Quarto\"\nauthor: \"Tu nombre\"\nformat:\n  html:\n    code-fold: true\n---\nNotarás algunas cosas. La primera es que html está indentado; es decir, no comienza en la misma posición que format. Esto es para indicar que html pertenece a format, al igual que code-fold pertenece a html. La siguiente es, justamente, que agregamos a la lista la entrada code-fold. Esta es una opción que indica si queremos que el código sea colapsable mediante un botón en el archivo final. En este caso, la indicamos como true, por lo que así será. Si no lo quisiéramos así indicaríamos false. Si renderizamos nuestro documento ahora tendremos:\n\n\n\nFigure 2.20: Primer Quarto renderizado\n\n\nSi tienes curiosidad por saber qué características YAML dieron lugar al libro de acompañamiento, puedes revisar el archivo _quarto.yml.\n\n\n2.3.2 Markdown\nPasando el preámbulo tenemos una sección de texto libre, con algunas anotaciones para el formato del texto. Estas anotaciones están hechas en lenguaje markdown. Markdown es un “lenguaje de programación para textos” y permite hacer cosas bastante interesantes. Las anotaciones más básicas son:\n\nEncabezados y secciones: #, ##, ###, ####, etc.\n*Itálicas* : Itálicas\n**Itálicas**: Negritas\n`Código`: Código\nHipervínculos: [Google](https://www.google.com): Google\n$y_i = \\alpha + \\beta*x_i + \\epsilon$: \\(y_i = \\alpha + \\beta*x_i + \\epsilon\\)\n\nPuedes hacer listas numeradas, como la anterior, o listas sin numerar:\n\nElemento\nOtro elemento\n\nE, incluso, puedes hacer listas anidadas añadiendo una indentación de doble tabulación a los elementos anidados:\n\nIntroducción a RStudio y Quarto\n\nR vs. RStudio\nIDE RStudio\n\n\nEn el archivo .qmd este capítulo puedes ver cómo cómo añadir imágenes, pero es básicamente el mismo procedimiento que con un enlace, salvo el añadir el operador ! antes. Por ejemplo, esta línea añade el logo de R desde su dirección oficial, le asigna el pie de foto “Logo R” y una etiqueta interna que se puede utilizar para referencias cruzadas (Figure 2.21) con @fig-logoR :\n![Logo `R`](https://www.r-project.org/logo/Rlogo.png){#fig-logoR}\n\n\n\nFigure 2.21: Logo R\n\n\n\n\n2.3.3 Referencias y citas\nPodemos agregar referencias, siempre y cuando estas estén contenidas en un archivo .bib como el archivo references.bib que está en este directorio y, por supuesto, referenciarlas en el texto (e.g. knuth84?). Si estás viendo la página web con este material, pasa tu cursor sobre la cita y notarás como aparece la información bibliográfica completa. Este archivo .bib está compuesto por entradas en formato bibTeX, heredado del hermano mayor de Markdown: LaTeX. La sintaxis básica es la siguiente:\n@TIPO{CLAVE,\n      author = {},\n      year = {},\n      title = {}}\nLos campos adicionales dependerán del TIPO de referencia que se esté añadiendo y si quieres ver todas las posibilidades te recomiendo revisar esta página. Para incluir una referencia cruzada lo único que tienes que hacer es: @CLAVE. Si tomamos como ejemplo el artículo de Knuth de 1984 sobre la programación literal sería @Knuth_1984 para una referencia en el texto, Knuth (1984), o [@Knuth_1984] para una referencia dentro de paréntesis (Knuth 1984). En cualquiera de los dos casos, si estás viendo el material renderizado, asegúrate de pasar el cursor sobre las citas, y verás que aparece toda la referencia bibliográfica. Para agregar la lista de referencias al final del texto, debes de agregar: el siguiente divisor debajo de un encabezado de referencias:\n::: {#refs}\n:::\n\n\n2.3.4 Consideraciones sobre Quarto\nAunque Quarto es extremadamente potente y flexible, es importante tener presente algunas cosas. La primera es que NO hay manera de que en esta sesión yo pueda explicarte con lujo de detalle todas las funciones, para eso prefiero dirigirte a la (bastante extensa) guía de Quarto. Otra consideración es que, aunque puedes exportar tus documentos como PDF, Word o ePUB u otros, mi recomendación es que siempre que tengas la libertad exportes a un HTML, que es un poco más permisivo con líneas de código muy largas, o al mostrar tablas con muchas columnas. Si NECESITAS un PDF asegúrate de tener instalada alguna distribución de LaTeX o, si no quieres la instalación completa, cuando menos asegurarte de haber instalado tinytex como lo hicimos en la sesión de preparación, de lo contrario NO podrás exportar tus reportes a PDF."
  },
  {
    "objectID": "c02_intro_rs.html#ejercicio",
    "href": "c02_intro_rs.html#ejercicio",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "3.5 Ejercicio",
    "text": "3.5 Ejercicio\nUtilizando Quarto genera un documento HTML con tabla de contenidos en el que te presentes. Las características son:\n\nTítulo: tu nombre\nIncluye tu correo electrónico en el preámbulo\nIncluye las secciones:\n\nGrado académico e institución de procedencia\nMotivación para tomar el curso\nExpectativas sobre el curso (¿hay alguna técnica particular que quieras aprender/revisar?)\nLibro(s) favorito(s) (como cita(s) en el texto, incluyendo la(s) referencia(s) completa(s) al final del documento)\nUna captura de pantalla con tu ventana de RStudio. No importa si es con los ajustes por defecto, si la pusiste igual a la mía, o si pusiste un tema con colores estridentes."
  },
  {
    "objectID": "c03_bases_r.html",
    "href": "c03_bases_r.html",
    "title": "3  Bases de R",
    "section": "",
    "text": "En la sesión anterior hablamos de RStudio como una interfaz gráfica a R, pero no fuimos más allá de decir que R es un lenguaje de programación que se ejecuta en consola. Pues bien, R es, y cito textualmente, “un lenguaje y ambiente para la computación estadística y la creación de gráficos”. ¿En castellano? Es un lenguaje creado especialmente para procedimientos estadísticos y el graficado de datos. Es un software libre, por lo que además de ser gratuito es auditable (i.e., cualquiera puede revisar el código fuente), “cualquiera” puede contribuir (ojo a las comillas). En su código fuente base (R base) incluye diversos algoritmos, modelos y distribuciones de probabilidad, aunque también es fácilmente extensible por medio de paquetes o librerías.\nEn este punto me dirás “Ok, Arturo, de acuerdo con lo que dices, pero ¿por qué se ha vuelto tan popular en análisis bioestadísticos?” Pues tiene que ver con varios factores. El primero es que es un lenguaje de alto nivel; es decir, está hecho para ser leído por humanos y no por computadoras. El segundo es que es interactivo, por lo que podemos ir modificando el código y ver su salida en tiempo real sin necesidad de compilar primero el código. El tercer"
  },
  {
    "objectID": "c03_bases_r.html#objetos",
    "href": "c03_bases_r.html#objetos",
    "title": "3  Bases de R",
    "section": "3.2 Objetos",
    "text": "3.2 Objetos\nR es un lenguaje en el cual domina el paradigma de la programación orientada a objetos; i.e., en R todo es un objeto. El método de creación es el mismo para todos los casos: utilizar el símbolo de asignación <- (atajo de teclado alt -). Como ejemplo, creemos un objeto que contenga el texto “¡Hola Mundo!”:\n\ntexto <- \"¡Hola mundo!\"\n\nNotarás que no hubo salida ni en la libreta ni en la consola. Esto quiere decir que el objeto fue creado satisfactoriamente, y ahora podemos acceder o utilizar ese texto llamando al objeto texto:\n\ntexto\n\n[1] \"¡Hola mundo!\"\n\n\n\n3.2.1 Consideraciones\nAunque podemos poner virtualmente cualquier nombre a nuestros objetos, es necesario que tengamos algunas cosas en cuenta:\n\nNo empezar nombres de objetos con números.\nNo utilizar nombres de funciones u otros objetos creados anteriormente: enmascaramiento (funciones) o sobre-escritura (variables)\nEvitar empezar con punto (.), pues el objeto queda oculto del ambiente de trabajo\nUtilizar nombres cortos, pero lo más descriptivos posibles (amundsen_plot >> plot)\nSe pueden utilizar _ o . dentro del nombre (como separadores, por ejemplo). La guía de estilo de R sugiere el uso de _, aunque la guía de estilo de Google para R sugiere el uso de CamelCase (AmundsenPlot). Lo más importante para uso personal/interno es ser consistente y evitar mezclar estilos."
  },
  {
    "objectID": "c03_bases_r.html#librerías-y-funciones",
    "href": "c03_bases_r.html#librerías-y-funciones",
    "title": "3  Bases de R",
    "section": "3.3 Librerías y funciones",
    "text": "3.3 Librerías y funciones\nAunque en R predomina el paradigma de la programación orientada a objetos, también podemos hacer uso del paradigma funcional de la programación; es decir, podemos construir nuestros programas mediante la aplicación y construcción de funciones. Aunque en este momento te suene poco intuitivo o como si estuviéramos comenzando por el final, vamos a comenzar con las funciones, para después hablar de los tipos de objetos que tenemos, pues resulta que para crear cierto tipo de objetos necesitamos utilizar funciones.\n\n3.3.1 Funciones\nLas funciones representan una serie de métodos para obtener un resultado, para utilizarlas emplearemos la estructura fun(arg1, arg2, ..., argn), donde arg*representa un argumento; es decir, un elemento “pasado” a la función para regular sus procesos. El ejemplo más simple, y con el cuál ya hemos estado en contacto, es la función print():\n\nprint(\"¡Hola Mundo!\")\n\n[1] \"¡Hola Mundo!\"\n\n\nEsta función “imprime” un resultado en pantalla, pero puede ser utilizada para mucho más que para imprimir texto. A final de cuentas, este mismo resultado lo podemos obtener simplemente poniendo el texto en la consola. ¿Qué puede hacer la función? Eso lo podemos ver consultando la ayuda de la función, utilizando el operador ? antes del nombre, tal que:\n\n?print\n\nTe darás cuenta que no tenemos una salida en la libreta, lo cuál es normal, pues la ayuda tiene su propio espacio en el ambiente gráfico. Si estuviéramos trabajando solo con la línea de comandos en el terminal, ahí sí veríamos la salida en la consola. Una de las partes más importantes de la documentación de ayuda es que tenemos los argumentos de la función; es decir, qué necesita la función para realizar su trabajo, así como el papel de cada uno de estos elementos.\nPor otra parte, cuando declaramos una función los llamaremos parámetros. Para declarar una función generaremos una variable cuyo nombre será el nombre “llamable” de la función, a la cual asignaremos el cuerpo de la función utilizando function(parámetros){cuerpo}. Para ejemplificar, creemos una función para calcular la media aritmética de un conjunto de números x:\n\nmedia.arit <- function(x){\n  # Mejora: Trabajo con NAs\n  suma <- sum(x)\n  n <- length(x)\n  return(suma/n)\n}\n\nmedia.arit(1:5)\n\n[1] 3\n\n\n¿Cuándo declarar una función? Cuando tengamos un flujo de trabajo que consista de exactamente los mismos pasos con posibles pequeñas variaciones, el cuál aplicaremos de manera continua. De hecho, uno de los productos que obtendremos de estas reuniones será un script con las funciones relacionadas con los análisis tróficos IIR, PSIRI, gráficos de Amundsen, etc. para que puedan ser utilizados de manera sencilla, repetitiva, y consistente.\nPor último, debido a que un gran número de funciones son altamente regulables (cuentan con un gran número de parámetros), te recomiendo hacer uso extensivo (excesivo) de la ayuda (?fun) para que obtengas de primera mano el conocimiento sobre su objetivo, sus entradas, su salida y, en consecuencia, ayudarte a prevenir o solucionar errores.\n\n\n3.3.2 Librerías\nAfortunadamente para nostros, muchas de las técnicas o procedimientos que realizamos ya fueron programados por alguien con más experiencia, y usualmente compilados en una librería de R. Hay una gran cantidad de librerías disponibles, algunas instalables directamente desde CRAN (R), mientras que otras son instalables desde repositorios públicos como GitHub. Por lo general, la gran mayoría las instalaremos desde R, utilizando la función install.packages(\"package\", dependencies = T). Esta función buscará la versión más reciente del paquete solicitado y la descargará e instalará para que pueda ser utilizada por nosotros. Un ejemplo:\ninstall.packages(\"tidyverse\", dependencies = T)\nEsta línea descargará el paquete tidyverse, que es un “súper” paquete formado por muchos otros paquetes que forman un “dialecto” dentro de R. Por el momento no te preocupes por eso, solo lo instalamos para evitarnos muchas descargas independientes de paquetes que pueden llegar a serte extremadamente útiles, tal como ggplot2. Es importante mencionar que una cosa es instalar la librería y otra cosa es utilizar la librería, para lo cual necesitamos de la función library(package), tal que:\n\nlibrary(ggplot2)\n\nUna vez que hicimos esto ya podemos utilizar TODAS las funciones que forman parte de la librería. ¿Y si solo quiero utilizar una función particular? En ese caso puedes utilizar el operador ::. Probemos viendo la ayuda de la función str_extract de la librería stringr que forma parte del tidyverse:\n\n?stringr::str_extract\n\nAhora que sabemos qué es una función, qué es una librería y cómo utilizarlos, vayamos a explorar el otro tipo de objetos: las variables."
  },
  {
    "objectID": "c03_bases_r.html#variables",
    "href": "c03_bases_r.html#variables",
    "title": "3  Bases de R",
    "section": "3.4 Variables",
    "text": "3.4 Variables\nA diferencia de una función en la cual almacenamos series de pasos para obtener un resultado, una variable nos permite almacenar todo lo demás: resultados, números, texto, tablas, e incluso otras variables. Su declaración la vimos arriba: con el símbolo de asignación (<-). Para imprimir el resultado en pantalla podemos llamar a la variable o utilizar la función print(var):\n\nvar <- 1:5\nprint(var)\n\n[1] 1 2 3 4 5"
  },
  {
    "objectID": "c03_bases_r.html#tipos-de-variables",
    "href": "c03_bases_r.html#tipos-de-variables",
    "title": "3  Bases de R",
    "section": "3.5 Tipos de variables",
    "text": "3.5 Tipos de variables\nExisten dos tipos de variables, los cuales a su vez se subdividen en otros tipos. Para conocer el tipo de una variable utilizamos la función typeof(var), mientras que las funciones is.*() nos permiten probar si una variable es de un tipo en específico (e.g. is.character(var)).\n\n3.5.1 Datos\nLas variables que contienen un solo elemento se conocen como datos:\n\nCharacter: Cadena de caracteres, indicadas por comillas dobles o sencillas:\n\n\nchar <- \"a\"\ntypeof(char)\n\n[1] \"character\"\n\n\n\nInteger: Números enteros, indicados por la letra “L” después del número:\n\n\ninteger <- 5L\ntypeof(integer)\n\n[1] \"integer\"\n\n\n\nDouble: Fracciones, también conocidos como floating points:\n\n\ndbl <- 7/5\ntypeof(dbl)\n\n[1] \"double\"\n\n\n\nLogical: Valor lógico o booleano. Solo puede tomar dos valores: TRUE o FALSE o sus abreviaturas T o F\n\n\nbool <- is.double(dbl)\nprint(paste('valor: ', bool))\n\n[1] \"valor:  TRUE\"\n\nprint(paste('tipo: ', typeof(bool)))\n\n[1] \"tipo:  logical\"\n\n\n\nComplex: Números complejos, con una parte real y una imaginaria:\n\n\ncomp.n <- 8+3i\ntypeof(comp.n)\n\n[1] \"complex\"\n\n\n\n\n3.5.2 Estructuras/arreglos\nLas estructuras son colecciones de valores, cada una con sus propiedades y sus métodos de acceso a los valores que las conforman (indexación/indización):\n\n3.5.2.1 Vector\nLa estructura más básica. Una colección unidimensional de elementos. Las funciones para crearlos son: c(), la cual combina una serie de elementos en un vector (mismo tipo) o una lista (diferentes tipos); vector(mode, length): genera un vector “vacío” con longitud (número de elementos) length y tipo de datos 'mode'.\n\nvect.1 <- c(1:5)\nvect.2 <- vector(mode = 'double', length = 5)\nprint(vect.1)\n\n[1] 1 2 3 4 5\n\nprint(vect.2)\n\n[1] 0 0 0 0 0\n\n\nPara indexar un vector utilizamos: var[i], donde i representa la posición del (los) elemento(s) de interés:\n\nprint(vect.1[4])\n\n[1] 4\n\nprint(vect.1[2:3])\n\n[1] 2 3\n\n\n\n\n3.5.2.2 Factor\nRepresentan variables categoricas. Contienen los valores de la variable así como los valores posibles que puede tomar (niveles). Se crean con la función factor(x, levels, labels), donde x representa los valores de la variable, levels representa los posibles niveles y labels (opcional) representan etiquetas de cada nivel:\n\nfact.1 <- factor(x = c('a', 'b', 'c'), \n                 levels = c('a', 'b', 'c', 'd', 'e'))\nfact.1\n\n[1] a b c\nLevels: a b c d e\n\n\n\n\n3.5.2.3 Matrix\nUna estructura bidimensional (columnas/renglones). Se generan utilizando la función matrix(data, nrow, ncol, byrow), donde data representa la colección de objetos que formarán la matriz, nrow y ncol el número de renglones y columnas, respectivamente, y byrow si se llenará por renglones (FALSE) o por columnas (TRUE, por defecto)\n\nmat.1 <- matrix(c(T, F, F, T), nrow = 2, ncol = 2)\nmat.1\n\n      [,1]  [,2]\n[1,]  TRUE FALSE\n[2,] FALSE  TRUE\n\n\nPara indexar una matriz utilizaremos también corchetes; sin embargo, indicaremos el par renglón,columna donde se ubica el elemento:\n\nprint(mat.1[1,1])\n\n[1] TRUE\n\nprint(mat.1[2,1])\n\n[1] FALSE\n\n\nSi quisieramos indexar toda una dimensión (renglón o columna), utilizaríamos el mismo método, dejando en blanco la dimensión contraria; es decir, si nos interesa una columna, dejaremos en blanco el número de renglón y si nos interesa un renglón dejaremos en blanco el número de columna:\n\nprint(mat.1[,2])\n\n[1] FALSE  TRUE\n\nprint(mat.1[1,])\n\n[1]  TRUE FALSE\n\n\nOJO: print(mat.1[c(1,1)]) NO da la diagonal de la matriz, esa la obtenemos con diag(mat1), sino que repite 2 veces el primer elemento de la matriz\n\nmat.1[c(2,1),1]\n\n[1] FALSE  TRUE\n\n\n\n\n3.5.2.4 DataFrame\nEl DataFrame es la estructura con la que más comúnmente estaremos en contacto. Es una tabla completa que, a diferencia de la matriz, contiene nombres de columnas. Tiene dos particularidades que hay que considerar: 1) todos los elementos que forman a cada columna deberán ser del mismo tipo y 2) El número de renglones de todas las columnas debe de ser el mismo. Se crean utilizando la función data.frame(col.name = data, ...):\n\ndf.1 <- data.frame(col.a = c(0:5), \n                   col.b = c(20:25), \n                   col.c = c(15:20))\n# Nota: Si no se indica el nombre de las columnas este será asignado automáticamente\ndf.1\n\n\n\n  \n\n\n\nExisten distintos modos de indexar un DataFrame. El primero de ellos var$col.name:\n\ndf.1$col.a\n\n[1] 0 1 2 3 4 5\n\n\nEjercicio renglones 1 y 4 de la columna c:\n\ndf.1$col.c[c(1,4)]\n\n[1] 15 18\n\n\nComo vemos, este modo de indexación extrae la columna completa en forma de un vector, por lo que si queremos accesar un valor en particular solo habrá que utilizar ese método de indexación:\n\ndf.1$col.b[4]\n\n[1] 23\n\n\nFinalmente, también podemos utilizar el método de indexación de matrices, recordando que se especifica el par renglón, columna:\n\ndf.1[4,2]\n\n[1] 23\n\n\nEsta es la estructura con la que más debemos de familiarizarnos, pues la mayor parte de nuestros datos los representamos en ella. ¿Siempre debemos de ingresar los datos manualmente? Para nada, tenemos todo un abanico de funciones que nos permiten cargar datos directamente de archivos, pero eso lo veremos más adelante.\n\n\n3.5.2.5 List\nLas listas son una colección de cualquier combinación de datos o estructuras, incluyendo otras listas:\n\nl.1 <- list(df.1, mat.1, vect.1)\nprint(l.1)\n\n[[1]]\n  col.a col.b col.c\n1     0    20    15\n2     1    21    16\n3     2    22    17\n4     3    23    18\n5     4    24    19\n6     5    25    20\n\n[[2]]\n      [,1]  [,2]\n[1,]  TRUE FALSE\n[2,] FALSE  TRUE\n\n[[3]]\n[1] 1 2 3 4 5\n\n\nEn la salida de arriba vemos el método de indexación: var[[i]][j,k], donde i representa el número de objeto en la lista y j,k el par renglón,columna (de aplicar). En el caso de DataFrames podemos seguir utilizando el operador $ para utilizar los noombres de columnas:\n\nl.1[[1]]$col.a[6]\n\n[1] 5\n\n\nAhora que hemos hablado de todos los tipos de estructuras, y antes de encaminarnos hacia los procesos de automatización, hablemos de cómo cargar nuestros datos en R.\nEjercicios:\n\nl.1[[2]][2,2]\n\n[1] TRUE\n\nl.1[[3]][5]\n\n[1] 5\n\nl.1[[1]]$col.b[3:4]\n\n[1] 22 23\n\nl.1[[1]]$col.a[c(6,1)]\n\n[1] 5 0"
  },
  {
    "objectID": "c03_bases_r.html#carga-de-datos",
    "href": "c03_bases_r.html#carga-de-datos",
    "title": "3  Bases de R",
    "section": "3.6 Carga de datos",
    "text": "3.6 Carga de datos\nEl cómo carguemos nuestros datos depende de varios factores: a) el formato del archivo en el que estén archivados, b) el cómo esté acomodada la información, c) qué necesitemos para hacer los análisis posteriores. El ejemplo más simple es cargar un archivo de texto separado por comas, en el cuál las comas separan las columnas y los saltos de línea los renglones. Tomemos como ejemplo el archivo \"datos1.csv\":\n\ndatos1 <- read.table(\"datos/datos1.csv\", sep = \",\", header = T)\n\nPodemos verificar la información obteniendo el encabezado del data.frame:\n\nhead(datos1)\n\n\n\n  \n\n\n\nLos archivos separados por comas son uno de los formatos más comunes, por lo que R cuenta con una función dedicada (la función read.table() con valores predefinidos):\n\ndatos1 <- read.csv(\"datos/datos1.csv\")\nhead(datos1)\n\n\n\n  \n\n\n\nAquí todo se cargó sin ningún problema porque el archivo estaba listo para ser leído, pero esto no siempre es el caso. Por ejemplo, los datos pueden estar en la segunda hoja de un archivo Excel, la cuál tiene 5 renglones de encabezado dando una descripción de los datos y en el renglón 6 están dispuestos los nombres de las variables. Además, sabemos que vamos a realizar un análisis de agrupamientos jerárquicos (clúster), el cuál requiere que los nombres de los individuos estén marcados en los nombres de los renglones (Ver archivo datos2.xlsx):\n\ndatos2 <- read.table(\"datos/datos2.xlsx\")\n\nEsto, evidentemente, da un error, pues le dimos a la función read.table() un archivo que no es de texto simple, sino un Excel.\nVamos entonces por partes:\n\nFormato: es un archivo Excel, por lo que hay que utilizar una función que permita leer ese tipo de archivo. En nuestro caso utilizaremos la función readxl::read_xlsx(). Aquí no obtendremos ningún error, pues el tipo de archivo es el correcto. Lo único que obtenemos es un mensaje (New names:) que nos diría a qué columnas se les asignó nombres nuevos (y cuáles).\n\n\ndatos2 <- readxl::read_xlsx(\"datos/datos2.xlsx\")\n\nNew names:\n• `Lp14-C` -> `Lp14-C...94`\n• `Lp14-C` -> `Lp14-C...109`\n\n\nPero, ¿qué pasa si leemos el encabezado? Resulta que la función cargó la primera hoja del excel, cuando en realidad nosotros queríamos la segunda\n\nhead(datos2)\n\n\n\n  \n\n\n\nNecesitamos entonces indicar explícitamente que queremos se cargue la segunda hoja:\n\ndatos2 <- readxl::read_xlsx(\"datos/datos2.xlsx\", sheet = 2)\n\nNew names:\n• `` -> `...2`\n• `` -> `...3`\n• `` -> `...4`\n• `` -> `...5`\n• `` -> `...6`\n• `` -> `...7`\n• `` -> `...8`\n• `` -> `...9`\n• `` -> `...10`\n• `` -> `...11`\n• `` -> `...12`\n• `` -> `...13`\n• `` -> `...14`\n• `` -> `...15`\n• `` -> `...16`\n• `` -> `...17`\n• `` -> `...18`\n• `` -> `...19`\n• `` -> `...20`\n• `` -> `...21`\n• `` -> `...22`\n• `` -> `...23`\n• `` -> `...24`\n• `` -> `...25`\n• `` -> `...26`\n• `` -> `...27`\n• `` -> `...28`\n• `` -> `...29`\n• `` -> `...30`\n• `` -> `...31`\n• `` -> `...32`\n• `` -> `...33`\n• `` -> `...34`\n• `` -> `...35`\n• `` -> `...36`\n• `` -> `...37`\n• `` -> `...38`\n• `` -> `...39`\n• `` -> `...40`\n• `` -> `...41`\n• `` -> `...42`\n• `` -> `...43`\n• `` -> `...44`\n• `` -> `...45`\n• `` -> `...46`\n• `` -> `...47`\n• `` -> `...48`\n• `` -> `...49`\n• `` -> `...50`\n\nhead(datos2)\n\n\n\n  \n\n\n\n\nSaltar renglones: Ya tenemos la hoja que nos interesa, el problema es que cargó el encabezado como renglones con observaciones, por lo que hay que saltarlos:\n\n\ndatos2 <- readxl::read_xlsx(\"datos/datos2.xlsx\",\n                            sheet = 2,\n                            skip = 5)\nhead(datos2)"
  },
  {
    "objectID": "c03_bases_r.html#operaciones-comunes",
    "href": "c03_bases_r.html#operaciones-comunes",
    "title": "3  Bases de R",
    "section": "3.7 Operaciones comunes",
    "text": "3.7 Operaciones comunes\nComo ya vimos, no siempre vamos a obtener la información en el formato que necesitamos. Aunque podemos solventar algunas de estas carencias durante la carga de los archivos, a veces necesitamos “masajear” los datos o “manipularlos” para llevarlos a lo que las funciones que nos interesan nos piden. Tomemos como ejemplo los datos de la hoja número 1 del archivo datos2.xlsx:\n\ndatos3 <- readxl::read_xlsx(\"datos/datos2.xlsx\", sheet = 1)\n\nNew names:\n• `Lp14-C` -> `Lp14-C...94`\n• `Lp14-C` -> `Lp14-C...109`\n\nhead(datos3)\n\n\n\n  \n\n\n\n\n3.7.1 Transposición\nEn estos datos las presas están en los renglones, y los individuos de los depredadores en las columnas. Aunque esta disposición no tiene fundamentalmente nada de malo, normalmente las instancias (observaciones individuales/réplicas) están en los renglones, y las variables (presas) en las columnas. Es necesario entonces tranponer los datos. Esto lo podemos hacer de manera sencilla con la función t():\n\nhead(t(datos3))\n\n      [,1]              [,2]          [,3]           [,4]       \nPrey  \"Alpheus_lottini\" \"Alpheus_spp\" \"Alpheus_umbo\" \"Amphipods\"\nCu1-C \"0\"               \"0\"           \"0\"            \"0\"        \nCu2-C \"0\"               \"4\"           \"0\"            \"0\"        \nCu3-C \"0\"               \"0\"           \"0\"            \"0\"        \nCz1-C \" 0\"              \" 0\"          \" 0\"           \" 6\"       \nAr1-C \"0\"               \"0\"           \"0\"            \"0\"        \n      [,5]                [,6]               [,7]                   \nPrey  \"Apogon_retrosella\" \"Appendicularians\" \"Axoclinus_nigricaudis\"\nCu1-C \"0\"                 \"0\"                \"0\"                    \nCu2-C \"0\"                 \"0\"                \"0\"                    \nCu3-C \"0\"                 \"0\"                \"0\"                    \nCz1-C \" 0\"                \" 0\"               \" 0\"                   \nAr1-C \"0\"                 \"0\"                \"0\"                    \n      [,8]                   [,9]           [,10]                            \nPrey  \"Bittium_cerralvoense\" \"Chaetognaths\" \"Cirripedia_Chthamalus_anisopoma\"\nCu1-C \"0\"                    \"0\"            \"0\"                              \nCu2-C \"0\"                    \"0\"            \"0\"                              \nCu3-C \"0\"                    \"0\"            \"0\"                              \nCz1-C \" 0\"                   \" 0\"           \" 0\"                             \nAr1-C \"0\"                    \"0\"            \"0\"                              \n      [,11]                           [,12]                               \nPrey  \"Cladocerans_Penila_avirostris\" \"Cladocerans_Pseudovadne_tergestina\"\nCu1-C \"0\"                             \"0\"                                 \nCu2-C \"0\"                             \"0\"                                 \nCu3-C \"0\"                             \"0\"                                 \nCz1-C \" 0\"                            \" 0\"                                \nAr1-C \"0\"                             \"0\"                                 \n      [,13]                     [,14]                        [,15]            \nPrey  \"Copepods_Acartia_clausi\" \"Copepods_Calanus_pacificus\" \"Epitonium_canna\"\nCu1-C \"9\"                       \"0\"                          \"0\"              \nCu2-C \"0\"                       \"0\"                          \"0\"              \nCu3-C \"0\"                       \"0\"                          \"0\"              \nCz1-C \" 8\"                      \" 0\"                         \" 0\"             \nAr1-C \"0\"                       \"0\"                          \"0\"              \n      [,16]       [,17]          [,18]                     [,19]     \nPrey  \"Fish_eggs\" \"foraminifera\" \"Gnathophyllum_panamense\" \"Hidrozoa\"\nCu1-C \"0\"         \"0\"            \"0\"                       \"0\"       \nCu2-C \"0\"         \"0\"            \"2\"                       \"0\"       \nCu3-C \"0\"         \"0\"            \"0\"                       \"0\"       \nCz1-C \"13\"        \" 0\"           \" 0\"                      \" 0\"      \nAr1-C \"0\"         \"0\"            \"0\"                       \"0\"       \n      [,20]            [,21]                         [,22]                    \nPrey  \"Ichtyoplankton\" \"Larvae_crustaceans_megalopa\" \"larvae_crustaceans_zoea\"\nCu1-C \"6\"              \"0\"                           \"0\"                      \nCu2-C \"0\"              \"0\"                           \"0\"                      \nCu3-C \"0\"              \"0\"                           \"0\"                      \nCz1-C \" 0\"             \" 0\"                          \" 0\"                     \nAr1-C \"0\"              \"0\"                           \"0\"                      \n      [,23]                [,24]                 [,25]   [,26]               \nPrey  \"Liomera_cinctimana\" \"Litiopa_melanostoma\" \"Mysid\" \"Mytella_arciformis\"\nCu1-C \"0\"                  \"0\"                   \"0\"     \"0\"                 \nCu2-C \"0\"                  \"0\"                   \"0\"     \"0\"                 \nCu3-C \"0\"                  \"0\"                   \"0\"     \"0\"                 \nCz1-C \" 0\"                 \" 0\"                  \" 0\"    \" 0\"                \nAr1-C \"0\"                  \"0\"                   \"0\"     \"0\"                 \n      [,27]                 [,28]                 [,29]                \nPrey  \"Mytella_tumbezensis\" \"Nanocassiope_polita\" \"Nyctiphanes_simplex\"\nCu1-C \"0\"                   \"0\"                   \"0\"                  \nCu2-C \"0\"                   \"0\"                   \"0\"                  \nCu3-C \"0\"                   \"0\"                   \"0\"                  \nCz1-C \" 0\"                  \" 0\"                  \" 0\"                 \nAr1-C \"0\"                   \"0\"                   \"0\"                  \n      [,30]       [,31]      [,32]             [,33]               \nPrey  \"Ostracods\" \"Otoliths\" \"Palaemon_ritter\" \"Panopeus_purpureus\"\nCu1-C \"0\"         \"0\"        \"0\"               \"0\"                 \nCu2-C \"0\"         \"0\"        \"0\"               \"0\"                 \nCu3-C \"0\"         \"0\"        \"2\"               \"0\"                 \nCz1-C \" 0\"        \" 0\"       \" 0\"              \" 0\"                \nAr1-C \"0\"         \"0\"        \"0\"               \"0\"                 \n      [,34]                      [,35]              [,36]           \nPrey  \"Parviturbo_acuticostatus\" \"Parviturbo_erici\" \"Parviturbo_spp\"\nCu1-C \"0\"                        \"0\"                \"0\"             \nCu2-C \"0\"                        \"0\"                \"0\"             \nCu3-C \"0\"                        \"0\"                \"0\"             \nCz1-C \" 0\"                       \" 0\"               \" 0\"            \nAr1-C \"0\"                        \"0\"                \"0\"             \n      [,37]       [,38]              [,39]                   [,40]            \nPrey  \"Pteropods\" \"Quadrella_nitida\" \"Tagelus_californianus\" \"Tegula_globulus\"\nCu1-C \"0\"         \"0\"                \"0\"                     \"0\"              \nCu2-C \"0\"         \"0\"                \"0\"                     \"0\"              \nCu3-C \"0\"         \"0\"                \"0\"                     \"0\"              \nCz1-C \" 0\"        \" 0\"               \" 0\"                    \" 0\"             \nAr1-C \"0\"         \"0\"                \"0\"                     \"0\"              \n      [,41]            [,42]           [,43]                [,44]             \nPrey  \"Tegula_mariana\" \"Tellina_coani\" \"Trapezia_bidentata\" \"Trapezia_formosa\"\nCu1-C \"0\"              \"0\"             \"0\"                  \"0\"               \nCu2-C \"0\"              \"0\"             \"0\"                  \"0\"               \nCu3-C \"0\"              \"0\"             \"0\"                  \"0\"               \nCz1-C \" 0\"             \" 0\"            \" 0\"                 \" 0\"              \nAr1-C \"2\"              \"0\"             \"0\"                  \"0\"               \n      [,45]          [,46]              [,47]          [,48]     \nPrey  \"Trapezia_spp\" \"Ulva_dactylifera\" \"Ulva_lactuca\" \"Ulva_spp\"\nCu1-C \"0\"            \"0\"                \"0\"            \"0\"       \nCu2-C \"0\"            \"0\"                \"0\"            \"0\"       \nCu3-C \"0\"            \"0\"                \"0\"            \"0\"       \nCz1-C \" 0\"           \" 0\"               \" 0\"           \" 0\"      \nAr1-C \"0\"            \"0\"                \"0\"            \"0\"       \n      [,49]                                \nPrey  \"UOM (Unidentified Organic Material)\"\nCu1-C \"0\"                                  \nCu2-C \"0\"                                  \nCu3-C \"0\"                                  \nCz1-C \" 0\"                                 \nAr1-C \"0\"                                  \n\n\nEsto logró nuestro objetivo, aunque con un pequeño gran problema: toda la información es texto. ¿Por qué? Resulta que las columnas solo pueden contener datos de un solo tipo, por lo que al tener el texto de las especies presa todas las columnas son transformadas a cadenas de caracter. ¿Qué podemos hacer? Transponer los datos en tres pasos.\n\n\n3.7.2 “Rebanadas” (slices)\nEl primer paso es separar los nombres de las presas de los datos de los depredadores:\n\nprey <- datos3$Prey\nhead(prey)\n\n[1] \"Alpheus_lottini\"   \"Alpheus_spp\"       \"Alpheus_umbo\"     \n[4] \"Amphipods\"         \"Apogon_retrosella\" \"Appendicularians\" \n\ncounts <- datos3[,2:ncol(datos3)]\nhead(counts)\n\n\n\n  \n\n\n\nTransponer la matriz de conteos:\n\ncountst <- t(counts)\nhead(countst)\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\nCu1-C    0    0    0    0    0    0    0    0    0     0     0     0     9\nCu2-C    0    4    0    0    0    0    0    0    0     0     0     0     0\nCu3-C    0    0    0    0    0    0    0    0    0     0     0     0     0\nCz1-C    0    0    0    6    0    0    0    0    0     0     0     0     8\nAr1-C    0    0    0    0    0    0    0    0    0     0     0     0     0\nPs1-C    0    0    0    0    0    0    0    0    0     0     0     0     0\n      [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]\nCu1-C     0     0     0     0     0     0     6     0     0     0     0     0\nCu2-C     0     0     0     0     2     0     0     0     0     0     0     0\nCu3-C     0     0     0     0     0     0     0     0     0     0     0     0\nCz1-C     0     0    13     0     0     0     0     0     0     0     0     0\nAr1-C     0     0     0     0     0     0     0     0     0     0     0     0\nPs1-C     0     0     0     0     0     0     0     0     0     0     0     0\n      [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37]\nCu1-C     0     0     0     0     0     0     0     0     0     0     0     0\nCu2-C     0     0     0     0     0     0     0     0     0     0     0     0\nCu3-C     0     0     0     0     0     0     2     0     0     0     0     0\nCz1-C     0     0     0     0     0     0     0     0     0     0     0     0\nAr1-C     0     0     0     0     0     0     0     0     0     0     0     0\nPs1-C     0     0     0    15     0     0     0     0     0     0     0     0\n      [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49]\nCu1-C     0     0     0     0     0     0     0     0     0     0     0     0\nCu2-C     0     0     0     0     0     0     0     0     0     0     0     0\nCu3-C     0     0     0     0     0     0     0     0     0     0     0     0\nCz1-C     0     0     0     0     0     0     0     0     0     0     0     0\nAr1-C     0     0     0     2     0     0     0     0     0     0     0     0\nPs1-C     0     0     0     0     0     0     0     0     0     0     0     0\n\n\n\n\n3.7.3 Cambiar nombres de columnas\nPara acceder o asignar los nombres de las columnas o renglones de arreglos bidimensionales podemos utilizar los atributos colnames(data) y rownames(data):\n\ncolnames(countst) <- prey\nhead(countst)\n\n      Alpheus_lottini Alpheus_spp Alpheus_umbo Amphipods Apogon_retrosella\nCu1-C               0           0            0         0                 0\nCu2-C               0           4            0         0                 0\nCu3-C               0           0            0         0                 0\nCz1-C               0           0            0         6                 0\nAr1-C               0           0            0         0                 0\nPs1-C               0           0            0         0                 0\n      Appendicularians Axoclinus_nigricaudis Bittium_cerralvoense Chaetognaths\nCu1-C                0                     0                    0            0\nCu2-C                0                     0                    0            0\nCu3-C                0                     0                    0            0\nCz1-C                0                     0                    0            0\nAr1-C                0                     0                    0            0\nPs1-C                0                     0                    0            0\n      Cirripedia_Chthamalus_anisopoma Cladocerans_Penila_avirostris\nCu1-C                               0                             0\nCu2-C                               0                             0\nCu3-C                               0                             0\nCz1-C                               0                             0\nAr1-C                               0                             0\nPs1-C                               0                             0\n      Cladocerans_Pseudovadne_tergestina Copepods_Acartia_clausi\nCu1-C                                  0                       9\nCu2-C                                  0                       0\nCu3-C                                  0                       0\nCz1-C                                  0                       8\nAr1-C                                  0                       0\nPs1-C                                  0                       0\n      Copepods_Calanus_pacificus Epitonium_canna Fish_eggs foraminifera\nCu1-C                          0               0         0            0\nCu2-C                          0               0         0            0\nCu3-C                          0               0         0            0\nCz1-C                          0               0        13            0\nAr1-C                          0               0         0            0\nPs1-C                          0               0         0            0\n      Gnathophyllum_panamense Hidrozoa Ichtyoplankton\nCu1-C                       0        0              6\nCu2-C                       2        0              0\nCu3-C                       0        0              0\nCz1-C                       0        0              0\nAr1-C                       0        0              0\nPs1-C                       0        0              0\n      Larvae_crustaceans_megalopa larvae_crustaceans_zoea Liomera_cinctimana\nCu1-C                           0                       0                  0\nCu2-C                           0                       0                  0\nCu3-C                           0                       0                  0\nCz1-C                           0                       0                  0\nAr1-C                           0                       0                  0\nPs1-C                           0                       0                  0\n      Litiopa_melanostoma Mysid Mytella_arciformis Mytella_tumbezensis\nCu1-C                   0     0                  0                   0\nCu2-C                   0     0                  0                   0\nCu3-C                   0     0                  0                   0\nCz1-C                   0     0                  0                   0\nAr1-C                   0     0                  0                   0\nPs1-C                   0     0                  0                   0\n      Nanocassiope_polita Nyctiphanes_simplex Ostracods Otoliths\nCu1-C                   0                   0         0        0\nCu2-C                   0                   0         0        0\nCu3-C                   0                   0         0        0\nCz1-C                   0                   0         0        0\nAr1-C                   0                   0         0        0\nPs1-C                   0                  15         0        0\n      Palaemon_ritter Panopeus_purpureus Parviturbo_acuticostatus\nCu1-C               0                  0                        0\nCu2-C               0                  0                        0\nCu3-C               2                  0                        0\nCz1-C               0                  0                        0\nAr1-C               0                  0                        0\nPs1-C               0                  0                        0\n      Parviturbo_erici Parviturbo_spp Pteropods Quadrella_nitida\nCu1-C                0              0         0                0\nCu2-C                0              0         0                0\nCu3-C                0              0         0                0\nCz1-C                0              0         0                0\nAr1-C                0              0         0                0\nPs1-C                0              0         0                0\n      Tagelus_californianus Tegula_globulus Tegula_mariana Tellina_coani\nCu1-C                     0               0              0             0\nCu2-C                     0               0              0             0\nCu3-C                     0               0              0             0\nCz1-C                     0               0              0             0\nAr1-C                     0               0              2             0\nPs1-C                     0               0              0             0\n      Trapezia_bidentata Trapezia_formosa Trapezia_spp Ulva_dactylifera\nCu1-C                  0                0            0                0\nCu2-C                  0                0            0                0\nCu3-C                  0                0            0                0\nCz1-C                  0                0            0                0\nAr1-C                  0                0            0                0\nPs1-C                  0                0            0                0\n      Ulva_lactuca Ulva_spp UOM (Unidentified Organic Material)\nCu1-C            0        0                                   0\nCu2-C            0        0                                   0\nCu3-C            0        0                                   0\nCz1-C            0        0                                   0\nAr1-C            0        0                                   0\nPs1-C            0        0                                   0\n\n\n\n\n3.7.4 Transformaciones\nEl resultado de las operaciones anteriores es una matriz; sin embargo, podemos pasarlo a un data.frame:\n\ncountst <- as.data.frame(countst)\nhead(countst)\n\n\n\n  \n\n\n\n\n\n3.7.5 Añadir vectores como columnas\nAhora tenemos un data.frame; sin embargo, tenemos las claves como nombres de los renglones y, según qué querramos realizar, podemos necesitar que estas formen su propia columna. Una forma de hacerlo es: 1) extraer los nombres de los renglones y 2) añadirlos como una columna adicional:\n\nkeys <- rownames(countst)\ncountst <- cbind(keys, countst)\nhead(countst)"
  },
  {
    "objectID": "c03_bases_r.html#operadores-lógicos",
    "href": "c03_bases_r.html#operadores-lógicos",
    "title": "3  Bases de R",
    "section": "3.8 Operadores lógicos",
    "text": "3.8 Operadores lógicos\nLos operadores lógicos nos sirven para hacer comparaciones y obtener un resultado booleano (T o F). Los más comunes son: 1. cond1|cond2: Condicional “O”. T si se cumple alguna de las dos condiciones\n\nc <- 5L\nis.integer(c)|is.double(c)\n\n[1] TRUE\n\n\n\ncond1&cond2: Condicional “Y”. T si se cumplen ambas condiciones\n\n\nis.integer(c)&(c>3)\n\n[1] TRUE\n\n\n\n<, >: Comparaciones, menor qué o mayor qué\n\n\nprint(c<10)\n\n[1] TRUE\n\nprint(c>5)\n\n[1] FALSE\n\n\n\n<=, >=: Comparaciones, menor o igual qué; mayor o igual qué.\na!=b: Desigualdad, T si a es diferente de b\n\n\nc!=5\n\n[1] FALSE"
  },
  {
    "objectID": "c03_bases_r.html#automatización",
    "href": "c03_bases_r.html#automatización",
    "title": "3  Bases de R",
    "section": "3.9 Automatización",
    "text": "3.9 Automatización\nEl primer paso de la automatización es generar funciones que te permitan realizar la misma acción múltiples veces y no cometer algún error en dichas repeticiones. Esta práctica se deriva de una de las máximas más importantes en programación: “Don’t repeat yourself” (DRY, no te repitas a ti mismo); es decir, dejar que la computadora haga las repeticiones por sí mismas. En la práctica, esto implica no estar copiando y pegando el mismo bloque de código una y otra vez y luego modificarlo manualmente, sino que escribirlo solo una vez y luego decirle a la computadora que repita esa acción n veces, modificando algún(os) argumento(s), o que cambie el comportamiento en función de si se cumple o no una condición en nuestros datos. En ese caso, las estructuras de control son nuestras mejores aliadas.\n\n3.9.1 Ciclos for\nHay distintas formas de realizar la repetición de acciones, pero hoy introduciremos únicamente los ciclos for por ser los más probables a ser requeridos. Un ciclo for consta de cuatro elementos:\nfor (variable in vector) {action}\n\nLa estructura de control for, evidentemente\nUna variable que hace las veces de un marcador de posición; es decir, la utilizaremos para indicar en dónde se van a sustituir los valores que queremos ciclar\nLos valores que ciclaremos, contenidos en un vector\nLa acción a realizar\n\nComo muchas otras cosas, es más fácil entenderlo utilizando algunos ejemplos. El primero de ellos es simplemente imprimir la secuencia de números del 1 al 10. Aunque podemos escribir 10 veces la función print e ir cambiando el número, es mucho más sencillo:\n\nfor (i in 1:10) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n\n\n¿Qué fue lo que hizo la computadora? Utilizó la función print() para mostrarnos el contenido de i, el cuál es el iésimo elemento de la secuencia 1:10. En otras palabras, si es la segunda vuelta que da, imprimirá el número 2, si es la séptima imprimirá 7, y así hasta que termine con todos los elementos en la secuencia. Ahora, sumemos 2 a cada número de la secuencia:\n\nfor (i in 1:10) {\n  print(i+2)\n}\n\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n[1] 11\n[1] 12\n\n\nAl igual que en el caso anterior, tomó uno por uno los valores (de forma secuencial), le añadió 2 y luego mostró el resultado en pantalla. Este tipo de estructuras son sumamente útiles, pues no solo nos ahorran errores, sino también tiempo de ejecución. Sobra decir que no es la única manera de hacer este tipo de ciclos, ni tampoco es la más rápida. Tenemos algo que se conocen como funciones vectorizadas.\n\n\n3.9.2 Familia de funciones apply()\nPodemos entender la vectorización como la aplicación de una función a cada elemento de un vector (igual que el ciclo for), aunque procesando todo el vector “al mismo tiempo”. Esta última parte no es estrictamente verdad, aunque lo cierto es que son más rápidas que los ciclos for tradicionales. En R tenemos toda una gama de funciones que hacen justo eso, la familia apply y sus relacionadas, compuesta por las funciones:\n\napply\nlapply\nsapply\ntapply\nmapply\nby\naggregate\n\nTodas estas funciones manipulan porciones de datos como matrices, arreglos, listas o data frames de forma repetitiva. Básicamente nos permiten evitar el uso explícito de un ciclo for. Toman como argumento una lista, matriz o data frame y le aplican una función con uno o más argumentos adicionales. Esta función puede ser:\n\nUna función de agregación, por ejemplo la media o la suma\nFunciones de transformaciones o para extraer sub-conjuntos\nOtras funciones vectorizadas, que dan como resultado estructuras más complejas como listas, vectores, matrices o arreglos. Pero basta de cháchara, ¿cómo y cuándo debemos de utilizarlas? La respuesta depende totalmente de la estructura de los datos y el formato de salida que se necesite. Veamos algunos casos de uso:\n\n\n3.9.2.1 apply()\nEsta es la función “madre” de las demás, la cual opera sobre arreglos. Para simplicidad, vamos a limitarnos a arreglos bi-dimensionales como las matrices o data.frames. La sintaxis para su uso es apply(X, MARGIN, FUN, ...), donde X es el arreglo, MARGIN es el márgen sobre el cuál va a actuar la función; es decir, si queremos que la aplique a cada renglón (MARGIN = 1) o a cada columna (MARGIN = 2), y FUN es el nombre de la función a aplicar (puede ser cualquiera, incluso una función definida por nosotros).\nPodemos pensar en obtener la suma o el promedio de cada columna de nuestro data.frame con las presas utilizando un ciclo, o podemos utilizar apply, tal que:\n\nsums <- apply(datos2[,2:ncol(datos2)], 2, sum)\nsums\n\n                    Alpheus_lottini                         Alpheus_spp \n                                  4                                  12 \n                       Alpheus_umbo                           Amphipods \n                                  9                                  44 \n                  Apogon_retrosella                    Appendicularians \n                                  5                                   5 \n              Axoclinus_nigricaudis                Bittium_cerralvoense \n                                  2                                  35 \n                       Chaetognaths     Cirripedia_Chthamalus_anisopoma \n                                 50                                   5 \n      Cladocerans_Penila_avirostris  Cladocerans_Pseudovadne_tergestina \n                                 34                                 171 \n            Copepods_Acartia_clausi          Copepods_Calanus_pacificus \n                                390                                  50 \n                    Epitonium_canna                           Fish_eggs \n                                  3                                  96 \n                       foraminifera             Gnathophyllum_panamense \n                                205                                  11 \n                           Hidrozoa                      Ichtyoplankton \n                                  1                                 153 \n        Larvae_crustaceans_megalopa             larvae_crustaceans_zoea \n                                 22                                  17 \n                 Liomera_cinctimana                 Litiopa_melanostoma \n                                 13                                  13 \n                              Mysid                  Mytella_arciformis \n                                  5                                   2 \n                Mytella_tumbezensis                 Nanocassiope_polita \n                                  1                                   2 \n                Nyctiphanes_simplex                           Ostracods \n                                549                                  76 \n                           Otoliths                     Palaemon_ritter \n                                  2                                   2 \n                 Panopeus_purpureus            Parviturbo_acuticostatus \n                                  4                                   1 \n                   Parviturbo_erici                      Parviturbo_spp \n                                  3                                   2 \n                          Pteropods                    Quadrella_nitida \n                                  8                                   1 \n              Tagelus_californianus                     Tegula_globulus \n                                  2                                  22 \n                     Tegula_mariana                       Tellina_coani \n                                 20                                   3 \n                 Trapezia_bidentata                    Trapezia_formosa \n                                  2                                   6 \n                       Trapezia_spp                    Ulva_dactylifera \n                                  4                                  35 \n                       Ulva_lactuca                            Ulva_spp \n                                158                                  78 \nUOM (Unidentified Organic Material) \n                                 20 \n\n\n\n\n3.9.2.2 aggregate()\nOtra función extremadamente útil es la función aggregate(). Esta función nos permite aplicar una función a distintos grupos. Un escenario clásico es obtener el promedio de una variable para cada grupo, por ejemplo el promedio de conteos de quetognatos. La forma “tradicional” es: aggregate(x, by, FUN), donde x es el objeto R a agrupar, by es una lista con los grupos y FUN es la función a aplicar; sin embargo, podemos utilizar una notación más compacta utilizando una formula: aggregate(forumla, data, FUN). Las fórmulas en R son objetos sumamente útiles y que se utilizan para una gran diversidad de cosas. Su estructura es: Y ~ X, y se lee “Y con respecto a X”. En nuestro caso particular:\n\naggregate(Chaetognaths~sp, data = datos1, FUN = mean)\n\n\n\n  \n\n\n\n\n\n\n3.9.3 Condicionales\nOk, ahora conocemos una manera de aplicar una función a una serie de elementos, pero que pasa si queremos aplicarla de manera condicionada; es decir, si queremos solo imprimir los números mayores a 5, por ejemplo. Eso es justo de lo que se tratan los condicionales, particularmente if, else, e ifelse. La lógica detrás de ellos es sumanmente simple: si se cumple una condición, realiza una acción, si no se cumple, realiza otra (o no realices nada). Comencemos con if. Su estructura es: if(condition){action T}, que notarás es básicamente la descripción que dimos, solo que sin una acción en caso de que no se cumpla la condición. Un ejemplo sería proporcionar un número y que nos diga si es mayor a 5:\n\nx <- 6\nif (x>5) {print(\"x es mayor a 5\")}\n\n[1] \"x es mayor a 5\"\n\n\n¿Y si no se cumple la condición? Veamos qué pasa:\n\nx <- 1\nif (x>5) {print(\"x es mayor a 5\")}\n\nR no nos da ninguna salida, pues no sabe qué hacer. Una forma de decirle es utilizando el complemento de if, else, que nos permite establecer una acción secundaria:\n\nif (x>5) {print(\"x es mayor a 5\")\n  }else{print(\"x no es mayor a 5\")}\n\n[1] \"x no es mayor a 5\"\n\n\nUna notación mucho más compacta para este tipo de casos es utilizar la función ifelse(condition, action T, action F):\n\nx <- 4\nifelse(x > 5,\n       \"x es mayor a 5\",\n       \"x no es mayor a 5\")\n\n[1] \"x no es mayor a 5\"\n\n\nEl resultado fue el mismo que el anterior, pero qué pasa si tenemos más de dos escenarios, que, por ejemplo, nos interesara decir si el número es mayor, menor o igual a 5. Veamos primero lo que sucede si establecemos que x sea 5:\n\nx <- 5\nifelse(x > 5,\n       \"x es mayor a 5\",\n       \"x no es mayor a 5\")\n\n[1] \"x no es mayor a 5\"\n\n\nLa computadora no hizo nada mal, 5 no es mayor a 5. En otros lenguajes de programación añadiríamos una estructura llamada elif, pero en R solo hay que añadir otro(s) if. Mientras que else aplica para todos los casos donde la condición no se cumpla, estos if secundarios nos permiten establecer condiciones adicionales para cuando la condición principal no se cumpla. Volviendo a nuestro problema con x = 5:\n\nx <- 4\nif (x > 5) {\n  print(\"x es mayor a 5\")\n}\n\nif (x == 5) {\n  print(\"x es 5\")\n}else{print(\"x es menor a 5\")}\n\n[1] \"x es menor a 5\"\n\n\nAhora sí cubrimos todas nuestras bases para este problema de comparación. Como te imaginarás, el siguiente paso lógico es mezclar for e if o, mejor dicho, anidarlos:\n\nx <- 1:10\n\nfor (i in x) {\n  if (i > 5) {\n    print(\"x es mayor a 5\")\n  }\n  if (i == 5) {\n    print(\"x es 5\")\n  }else{print(\"x es menor a 5\")}\n}\n\n[1] \"x es menor a 5\"\n[1] \"x es menor a 5\"\n[1] \"x es menor a 5\"\n[1] \"x es menor a 5\"\n[1] \"x es 5\"\n[1] \"x es mayor a 5\"\n[1] \"x es menor a 5\"\n[1] \"x es mayor a 5\"\n[1] \"x es menor a 5\"\n[1] \"x es mayor a 5\"\n[1] \"x es menor a 5\"\n[1] \"x es mayor a 5\"\n[1] \"x es menor a 5\"\n[1] \"x es mayor a 5\"\n[1] \"x es menor a 5\"\n\n\nCon esto también quiero decir que podemos anidar ciclos for, tal que:\n\nx <- 1:5\ny <- 100:105\n\nfor (i in x) {\n  for (j in y) {\n    print(c(i,j))\n  }\n}\n\n[1]   1 100\n[1]   1 101\n[1]   1 102\n[1]   1 103\n[1]   1 104\n[1]   1 105\n[1]   2 100\n[1]   2 101\n[1]   2 102\n[1]   2 103\n[1]   2 104\n[1]   2 105\n[1]   3 100\n[1]   3 101\n[1]   3 102\n[1]   3 103\n[1]   3 104\n[1]   3 105\n[1]   4 100\n[1]   4 101\n[1]   4 102\n[1]   4 103\n[1]   4 104\n[1]   4 105\n[1]   5 100\n[1]   5 101\n[1]   5 102\n[1]   5 103\n[1]   5 104\n[1]   5 105"
  },
  {
    "objectID": "c03_bases_r.html#ejercicios",
    "href": "c03_bases_r.html#ejercicios",
    "title": "3  Bases de R",
    "section": "3.10 Ejercicios",
    "text": "3.10 Ejercicios\n\n¿Qué es un objeto?\n¿Cuál es la diferencia entre una variable y una función?\n¿Qué es una librería? ¿Qué pasa si utilizas la función ggplot() sin haber cargado la librería ggplot2?\n¿Cuál es la diferencia entre un dato y una estructura?\nCarga los datos1.csv y añade un renglón adicional con los totales para cada columna.\nCarga los datos1.csv y obten una tabla con los conteos promedio de cada presa para cada especie (aggregate/apply o ciclos).\nCombina el ciclo for anidado del último ejemplo con un condicional, en el cuál se imprima si la suma de ambos números (i, j) es mayor, menor o igual a 105."
  },
  {
    "objectID": "c04_ggplot2.html",
    "href": "c04_ggplot2.html",
    "title": "4  Principios de visualización de datos y ggplot2",
    "section": "",
    "text": "Como seres humanos, con una tendencia a encontrar el camino que ofrezca una menor resistencia (otra forma de decir que somos flojos), usualmente resumimos una realidad altamente compleja utilizando distintas estrategias. Si yo te pido que me digas “qué es una orca” puedes darme una descripción textual del tipo “las orcas son mamíferos del orden Cetartiodactyla”, una descripción numérica en forma de mediciones (Longitud: 6-8 m) o medidas de tendencia central/dispersión (Peso máximo: 5.5 toneladas), pero usualmente preferimos medios audiovisuales como un dibujo, un video o, en el caso de la investigación y el tema principal de hoy, gráficos."
  },
  {
    "objectID": "c04_ggplot2.html#datos-y-variables",
    "href": "c04_ggplot2.html#datos-y-variables",
    "title": "4  Principios de visualización de datos y ggplot2",
    "section": "4.2 Datos y variables",
    "text": "4.2 Datos y variables\nEn una investigación reunimos datos que después representamos con gráficos. Pues bien comencemos definiendo un dato como una representación puntual de la realidad. Son un solo valor, sea una sola medición, un promedio, una desviación estándar, una proporción de sexos, etc, y el conjunto de datos de un mismo atributo medidos en distintos individuos nos dan una variable. Es decir, en nuestros conjuntos de datos cada valor es un dato, y cada columna (usualmente) es una variable. ¿Por qué es importante conocer esto? Porque hay distintos tipos de variables, los cuales definen cómo es que vamos a graficar y tratar esos datos:\n\nCualitativas: hacen referencia a las cualidades de nuestros individuos, y tienen dos escalas:\n\nNominal: hace referencia a categorías en las que no hay un orden o distintas importancias. Ejemplos pueden el sexo o el color.\nOrdinal: aquí hay un órden, y un ejemplo muy claro son las encuestas: 0 es nunca, 1 es casi nunca, 2 es ocasionalmente, 3 es casi siempre y 4 es siempre. Aunque son categorías bien definidas, 2 < 3 y 3 < 4. No son cuantitativas porque las respuestas están sujetas a la interpretación personal, pero descartar el órden en el análisis sería un error.\n\nCuantitativas, que hacen referencia a atributos cuantificables de manera objetiva. Hay dos tipos, cada uno con dos escalas.\n\nTipos:\n\nDiscretas: Son solo números enteros. Un ejemplo cotidiano es la edad, que usualmente la expresamos en años. No vamos por la vida diciendo tengo 18.5 años o 18 años con 6 meses, solo decimos tengo 18 años.\nContinuas: Es el caso contrario, son números fraccionarios. Se les denomina continuas porque hay un número infinito de valores posibles entre un valor y el otro, un ejemplo es la temperatura (35.1ºC, 100 K, etc.)\n\nEscalas:\n\nIntervalo: La escala de intervalo es aquella en donde el 0 NO es absoluto o, mejor dicho, donde el 0 es arbitrario. La temperatura expresada en grados centígrados es un ejemplo claro, 0ºC no indica ausencia de movimiento molecular, solo toma como referencia arbitraria el punto de congelación del agua.\nRazón: Aquí el 0 sí es absoluto y representa la ausencia del atributo en cuestión. La longitud es un ejemplo, si algo tiene longitud 0 más bien no tiene longitud, o si algo tiene una temperatura de 0 K quiere decir que no tiene movimiento molecular (~-273.15ºC).\n\n\n\nAlgo que es muy importante tener siempre bien presente es que, aún cuando existen herramientas y técnicas que nos permiten procesar múltiples variables, en cualquier procedimiento de ciencia de datos es INDISPENSABLE que los datos sean de excelente calidad y, sobre todo, que sean adecuados para responder la pregunta que nos interesa, lo cual nos debe de llevar, invariablemente, a preguntarnos “¿qué datos debo de obtener?” O, en otras palabras, “¿qué debo medir?” Una frase que se me quedó marcada de mis clases de la licenciatura es “La investigación inicia y termina en el escritorio del investigador”; es decir, no salimos a hacer trabajo de campo y a registrar todo lo que se nos atraviese, caso contrario podemos terminar en una conclusión como “los bebés son traídos por cigüeñas”, la cual tiene una anécdota bastante divertida"
  },
  {
    "objectID": "c04_ggplot2.html#introducción-a-ggplot2",
    "href": "c04_ggplot2.html#introducción-a-ggplot2",
    "title": "4  Principios de visualización de datos y ggplot2",
    "section": "4.3 Introducción a ggplot2",
    "text": "4.3 Introducción a ggplot2\nAntes de comenzar una visualización es necesario saber qué queremos responder con ella. En este caso, utilizaremos la base de datos mpg incluída en ggplot2. El primer paso es, entonces, conocer la información que contiene. Para ello guardaremos la base en una variable que llamaremos df1:\n\nlibrary(ggplot2)\n\ndf1 <- ggplot2::mpg\ndf1\n\n\n\n  \n\n\n\nUna manera rápida de tener una idea de cómo está dispuesta una base de datos es utilizando la función head(var). Esta nos mostrará solo las primeras instancias (renglones) del data.frame que estemos analizando. En la tabla inferior podemos ver que se trata de una base de datos sobre automóviles y que las columnas representan: el fabricante, el modelo, el desplazamiento de combustible (litros), el año del modelo, el número de cilindros, el tipo de transmisión, el tipo de tracción, los consumos en ciudad y autopista (en millas por galón, mpg), el tipo de combustible que utilizan y la clase a la que pertenencen. También nos plantearemos el objetivo de eliminar la mayor cantidad de elementos posibles hasta solo tener el esqueleto y de ahí agregar algunos elementos que favorezcan la interpretación.\n\nhead(df1)\n\n\n\n  \n\n\n\n\n4.3.1 ggplot() + ...\nA partir de esta información podemos tratar de responder si existe una relación apreciable entre el consumo de combustible (por ejemplo en autopista) y el desplazamiento del motor, considerando la clase del vehículo. Para atender a esta pregunta utilizaremos un gráfico de dispersión, con el desplazamiento en el eje x, el consumo en el eje y y la clase indicada por los colores de los puntos. Ahora que tenemos claro qué queremos visualizar y cómo lo vamos a visualizar podemos empezar a graficar. El primer paso es inicializar el espacio de graficado con la función ggplot() y pasarle los parámetros estéticos utilizando la función aes(x, y, colour). Es importante mencionar que en este momento aparecerá únicamente el espacio de graficado en blanco. Esto es normal, ya que únicamente definimos el “qué”, pero no el “cómo”.\n\nggplot(data = df1, aes(x = displ, y = cty, colour = class))\n\n\n\n\nYa que inicializamos el espacio gráfico podemos agregar la información que nos interesa. Para facilitar la construcción paso a paso y evitar el repetir código innecesariamente podemos almacenar la gráfica completa en una variable (por ejemplo plot2) e ir añadiendo capas (operador +) posteriormente. Para ver un gráfico guardado en una variable simplemente hay que llamar a esa variable. La primera capa que agregaremos será la que indicará el tipo de gráfico que deseamos (nombrados como geom_*), en este caso un gráfico de dispersión:\n\nplot1 <- ggplot(data = df1, aes(x = displ, y = hwy, colour = class)) +\n         geom_point()\nplot1 # Imprime el gráfico\n\n\n\n\nAhora sí tenemos la información que necesitamos y podríamos comenzar a describir el gráfico, pero en realidad hay demasiados elementos que son innecesarios y otros que son poco informativos en su estado actual (etiquetas de ejes), entonces trabajemos uno por uno. Para modificar las etiquetas de los ejes podemos utilizar las funciones xlab() y ylab() como capas separadas; sin embargo, podemos modificar todas las etiquetas y títulos en un mismo paso utilizando la función labs(title, x, y, caption, colour, ...).\n\nplot2 <- plot1 + labs(x = \"Desplazamiento (l)\",\n                      y = 'Consumo (mpg)',\n                      colour = 'Clase',\n                      title = \n                        'Tamaño del motor y Rendimiento de combustible',\n                      subtitle = 'Consumo en carretera',\n                      caption = 'Datos: ggplot2::mpg')\nplot2\n\n\n\n\n\n\n4.3.2 Tema de ggplot2\nAhora que está claro cuáles son las variables que estamos mostrando podemos empezar a modificar la estética. Recordemos que debemos mantener la relación datos/tinta lo más alta posible, y uno de los elementos más prevalentes del gráfico es el fondo gris con todo y cuadrículas. Para modificar esos elementos tenemos que modificar el “tema” de la gráfica, que no es otra cosa mas que utilizar una función que nos permita modificar en una sola línea la estética general del gráfico. Los temas se encuentran señalados con el nombre theme_*. Probemos con theme_minimal():\n\nplot2 + theme_minimal()\n\n\n\n\nLogramos eliminar el fondo gris y de paso las “espinas” (líneas de los ejes) y ahora el gráfico está en mucho mejor condición para ser presentado; sin embargo aún podemos ir más lejos. El objetivo de esta gráfica no es ver los detalles precisos de la información, si no extraer la información más relevante, por lo que la cuadrícula es un elemento que no aporta nada a la visualización. Para retirarla utilizaremos la función theme(), la cual permite modificar el aspecto de todos los elementos del gráfico. En realidad, las funciones theme_*() son aplicaciones de theme() con diferentes valores por defecto, por lo que podemos replicar el efecto de theme_minimal() e incluir otras modificaciones. Otra función muy útil para este procedimiento es la función element_blank(), la cual le indica a ggplot2 que no debe mostrar ese elemento. Otra cuestión importante que debemos de considerar es la relación de aspecto. Debido a que esta puede modificar enormemente la percepción de los datos, su selección no es algo trivial. En general, la proporción áurea (1:1.61) es un buen punto de partida y en series de tiempo es la proporción que menos deforma los datos. Una proporción cuadrada tiene sentido únicamente en aquellos casos en los que ambos ejes tengan la misma magnitud de variación y procuraremos que el eje más largo sea aquel con la variación más pequeña. En este caso, la variación del eje y (5 a 45) es mucho mayor que la del eje x (1.5 a 7), por lo cual una proporción cuadrada no sería una buena alternativa. En su lugar, utilicemos la proporción áurea. El último elemento que eliminaremos aquí son las marcas de los ejes, ya que realmente no aportan demasiada información.\n\nplot2 <- plot2 + \n         # Eliminamos la cuadrícula menor\n         theme(panel.grid.minor = element_blank(),\n               # Eliminamos la cuadrícula mayor\n               panel.grid.major = element_blank(),\n               # Eliminamos el color de fondo\n               panel.background = element_blank(),\n               # Eliminamos las líneas de los ejes\n               axis.line = element_blank(),\n               # Eliminamos la leyenda\n               legend.key = element_blank(),\n               # Cambiamos la relación de aspecto\n               aspect.ratio = 1/1.61,\n               # Eliminamos las marcas de los ejes\n               axis.ticks = element_blank()\n                       )\nplot2\n\n\n\n\n\n\n4.3.3 Personalizar los ejes\nAhora que nos deshicimos del fondo, la cuadrícula y las líneas y marcas de los ejes podemos trabajar en los valores de los ejes. Una de las mejores maneras de hacerlo es utilizando las funciones scale_x_*() o scale_y_*(), sustituyendo el * por continuous o discrete dependiendo del tipo de variable con el que estemos trabajando. En este caso, eliminaremos por completo las marcas del eje y y dejaremos únicamente los desplazamientos más comunes en el eje x.\n\nplot2 <- plot2 + scale_x_continuous(breaks = c(1.8, 2.5, 5, 7)) +\n                 scale_y_continuous(breaks = NULL)\nplot2\n\n\n\n\n\n\n4.3.4 Añadir líneas de referencia\nAhora que nos deshicimos de los valores del eje la gráfica ya no es entendible debido a que no sabemos cuál es la orientación o la escala de los datos. Una alternativa es añadir un par de líneas de referencia. Esto lo haremos con la función geom_hline(), la cual nos permite añadir líneas horizontales a través de todo el gráfico que cruzan al eje y en una posición que nosotros determinamos:\n\n# Valores de referencia como el mínimo, la media y\n# el máximo de los consumos\n\nrefs <- c(round(min(df1$hwy),0),\n          round(mean(df1$hwy),0),\n          round(max(df1$hwy),0))\n\n# Líneas de referencia, una verde para el mejor consumo,\n# una gris para el consumo promedio y una roja para el peor consumo\nplot2 <- plot2 + geom_hline(yintercept = refs[1],\n                            colour = 'firebrick', alpha = 0.5,\n                            linetype = 'dashed') +\n                 geom_hline(yintercept = refs[2],\n                            colour = 'lightslategrey', alpha = 0.5,\n                            linetype = 'dashed') +\n                 geom_hline(yintercept = refs[3],\n                            colour = 'forestgreen', alpha = 0.5,\n                            linetype = 'dashed')\nplot2\n\n\n\n\nAhora el gráifico ya cuenta nuevamente con un sentido de dimensión, pero no tenemos los valores de referencia, entonces habrá que poner esas anotaciones con la función geom_text(), utilizando como valores de posición en y los mismos que las líneas de referencia + un pequeño valor:\n\n# Líneas de referencia con los mismos colores\nplot2 <- plot2 + annotate('text', x = 1.3, y = refs[1]+1, \n                          label = as.character(refs[1]),\n                          colour = 'firebrick') +\n                 annotate('text', x = 1.3, y = refs[2]+1,\n                          label = as.character(refs[2]),\n                          colour = 'lightslategrey') +\n                 annotate('text', x = 1.3, y = refs[3]+1,\n                          label = as.character(refs[3]),\n                          colour = 'forestgreen')\nplot2\n\n\n\n\nCon esta última modificación terminamos de explorar algunas de las funciones más básicas e importantes para personalizar los elementos que más impactan en una visualización, pero antes de terminar de discutir este punto me gustaría terminar el objetivo que nos propusimos al inicio de sacar información de la gráfica. En general, existe una tendencia a que el consumo de combustible incremente conforme incrementa el desplazamiento, lo cual es de esperarse, ya que el desplazamiento es una medida de el volumen máximo de combustible que puede entrar al motor en un momento dado; sin embargo, podemos también observar que, independientemente del desplazamiento, las SUVs y pickups tienden a tener los peores rendimientos de combustible, mientras que los subcompactos tienden al otro extremo. Podemos también analizar a los vehículos de dos plazas y ver que aún cuando tienen desplazamientos altos, sus rendimientos son mejores que los de las SUVs.\n\n\n4.3.5 Conclusión y ejercicio\nEn cuanto a la parte visual, se podría argumentar que esta visualización final no es tan precisa como la primera, que algún elemento podría embellecerse, o que podriamos eliminar la leyenda y poner etiquetas de texto en algunos puntos para indicar las clases. Todos estos argumentos y muchos otros serían válidos ya que la estética es algo subjetivo; sin embargo, las decisiones que tomemos deberán estar en función del medio de distribución de la visualización (no es lo mismo una página web que en un medio impreso, por ejemplo) y sobre todo del público objetivo. Esta visualización en particular funciona para los fines didácticos que tenía en mente, es adecuada para una presentación de resultados de manera electrónica como este video, pero no es una visualización adecuada para una publicación científica. Tomando eso en cuenta, te sugiero hacer el ejercicio de transformarla para cumplir con ese objetivo, ¿qué elementos quitarías? ¿qué elementos cambiarías? ¿qué elementos agregarías? ¿crees que en su estado actual cumple con los criterios de Tufte y Cairo que revisamos la clase anterior?\nPara finalizar la clase te presento la visualización inicial y la final, una junto a la otra, para ver en dónde comenzamos, dónde terminamos y cómo llegamos hasta aquí. También te sugiero revises y descargues el PDF de esta página, que es un acordeón donde se encuentran los gráficos y funciones más comunes. Más adelante revisaremos algunos de ellos pero es un recurso que vale la pena tener a la mano.\nEsto es todo para esta clase. ¡Nos vemos en la siguiente!\n\n\n\n\n\n\n\n\n\n\n\n4.3.5.1 Gráfico final\n\n# Valores de referencia para utilizar en la gráfica\nrefs <- c(round(min(df1$hwy),0),  # Valor mínimo = peor consumo\n          round(mean(df1$hwy),0), # Valor promedio\n          round(max(df1$hwy),0))  # Valor máximo = mejor consumo\n\n# Objeto con todos los pasos para llegar a la gráfica final\n# Inicializamos el espacio gráfico\nfinal.plot <- ggplot(data = df1, aes(x = displ, y = hwy,\n                                     colour = class)) +\n              # Gráfico de dispersión\n              geom_point() +\n              # Establecemos los títulos, subtítulos y un pie de foto\n              labs(x = 'Desplazamiento (l)',\n                   y = 'Consumo (mpg)',\n                   colour = 'Clase',\n                   title = 'Tamaño del motor y Rendimiento de combustible',\n                   subtitle = 'Consumo en carretera',\n                   caption = 'Datos: ggplot2::mpg'\n                   ) +\n              #Eliminamos la cuadrícula menor\n              theme(panel.grid.minor = element_blank(),\n                    #Eliminamos la cuadrícula mayor\n                    panel.grid.major = element_blank(),\n                    #Eliminamos el color de fondo\n                    panel.background = element_blank(),\n                    #Eliminamos las líneas de ejes\n                    axis.line = element_blank(),\n                    #Eliminamos el fondo de la leyenda\n                    legend.key = element_blank(),\n                    #Establecemos la rel. de aspecto\n                    aspect.ratio = 1/1.61,\n                    #Eliminamos las marcas de los ejes\n                    axis.ticks = element_blank(),\n                    #Cambiamos el tipo de letra\n                    text = element_text(family = 'Times',\n                                        colour = 'gray50')\n                    ) + \n              # Reducimos las divisiones del eje ex a 4 valores\n              scale_x_continuous(breaks = c(1.8, 2.5, 5, 7)) +\n              # Eliminamos las divisiones del eje y\n              scale_y_continuous(breaks = NULL) +\n              # Añadimos una línea roja en el peor consumo\n              geom_hline(yintercept = refs[1],\n                         colour = 'firebrick', alpha = 0.5, \n                         linetype = 'dashed') +\n              # Añadimos una línea gris en el consumo promedio\n              geom_hline(yintercept = refs[2],\n                         colour = 'lightslategrey', alpha = 0.5, \n                         linetype = 'dashed') +\n              # Añadimos una línea verde en el mejor consumo\n              geom_hline(yintercept = refs[3],\n                         colour = 'forestgreen', alpha = 0.5,\n                         linetype = 'dashed') +\n              # Etiqueta del peor consumo\n              annotate('text', x = 1.3, y = refs[1]+1,\n                       label = as.character(refs[1]),\n                       colour = 'firebrick') +\n              #Etiqueta del consumo promedio\n              annotate('text', x = 1.3, y = refs[2]+1,\n                       label = as.character(refs[2]),\n                       colour = 'lightslategrey') +\n              # Etiqueta del mejor consumo\n              annotate('text', x = 1.3, y = refs[3]+1,\n                       label = as.character(refs[3]),\n                       colour = 'forestgreen') \n              \nfinal.plot\n\n\n\n\n\n\n\n4.3.6 Extras\nAunque estas modificaciones no necesariamente forman parte del proceso necesario para la visualización que era de nuestro interés, sí que son rutinarias, por lo que vale la pena echarles un ojo.\n\n4.3.6.1 Colores de puntos\nModificar los colores de los puntos. Podemos utilizar la función randomColor(n) de la librería con el mismo nombre. Esta función solamente recibe el número de colores que queremos y los generará de manera aleatoria:\n\naleat <- randomcoloR::randomColor(7)\nfinal.plot + scale_color_manual(name = \"Clase\", values = aleat)\n\n\n\n\nPodemos también especificar una paleta predefinida, utilizando la capa scale_color_brewer():\n\nfinal.plot + scale_color_brewer(type = \"seq\", palette = \"Paired\")\n\n\n\n\nOtra opción es directamente pasar un vector con los nombres de los colores que sean de nuestro interés:\n\ncolor_names <- c(\"red\", \"blue\", \"yellow\", \"black\",\n                 \"dodgerblue\", \"pink\", \"gray\")\nfinal.plot + scale_color_manual(name = \"Clase\", values = color_names)\n\n\n\n\n\n\n4.3.6.2 Tamaño de los puntos\nPara modificar el tamaño de los puntos solamente hay que agregar el argumento size a la capa geom_point, en el cuál indicaremos qué tamaños tomarán los puntos. Puede ser un solo valor:\n\nfinal.plot + geom_point(size = 0.1)\n\n\n\n\nO también a partir de una columna de la base de datos (dividida entre 5 para no obtener únicamente “manchas”):\n\nfinal.plot + geom_point(size = df1$hwy/5)\n\n\n\n\n\n\n4.3.6.3 Tipografías y Exportación de gráficos\nEl manejo de las tipografías en R es un poco especial, por ello usualmente recomiendo generar el gráfico en R, exportarlo como PDF (cairo_pdf(\"filename.pdf\", width, height, family)) y agregar las cursivas donde sea necesario; sin embargo, un paquete que puede resultar especialmente útil es ggtext. Este añade un nuevo “elemento” de texto que recibe formato Markdown (element_markdown()); es decir, podemos agregar itálicas o negritas. Para poder utilizarlo, sin embargo, es necesario modificar ligeramente nuestros datos de antemano. Para facilitarnos las cosas agregaremos una nueva columna a df1 que contenga las clases en itálicas y extraeremos los valores únicos (algo más eficiente sería hacerlo al revés, pero es más lógico de esta manera):\n\ndf1$clase <- paste0(\"*\",df1$class,\"*\")\nclases <- unique(df1$clase)\n\nFinalmente lo agregaremos a la gráfica. ¡OJO! Es necesario modificar el tema para que entienda el formato markdown:\n\nif(!require(ggtext)) {install.packages(\"ggtext\", dependencies = T)}\n\nLoading required package: ggtext\n\nfinal.plot + scale_color_discrete(name = \"Clase\",labels = clases) +\n             theme(legend.text = ggtext::element_markdown())\n\n\n\n\nCon este elemento podemos modificar también fracciones de cualquier texto de nuestra gráfica, por ejemplo carretera en negritas:\n\nfinal.plot + labs(subtitle = \"Consumo en **carretera**\") +\n             theme(plot.subtitle = ggtext::element_markdown())\n\n\n\n\nMezclando ambas modificaciones:\n\nfinal.plot + scale_color_discrete(name = \"Clase\",labels = clases) +\n             labs(subtitle = \"Consumo en **carretera**\") +\n             theme(plot.subtitle = ggtext::element_markdown(),\n                   legend.text = ggtext::element_markdown())"
  },
  {
    "objectID": "s0_preparacion.html#instalaciones-opcionales",
    "href": "s0_preparacion.html#instalaciones-opcionales",
    "title": "Preparación",
    "section": "Instalaciones “opcionales”",
    "text": "Instalaciones “opcionales”\nAdicionalmente, te recomiendo encarecidamente (por no decir te solicito) que instales, dependiendo de tu sistema operativo, algunas herramientas. Tienes la descripción de cada una, así como desde donde realizar su instalación:\n\nWindows: Rtools. Esta es una serie de herramientas que nunca vas a ver cuando se utilicen, pero que son un dolor de cabeza si no cuentas con ellas y tienes la pésima fortuna de necesitar compilar un paquete desde su código fuente, o la dicha de querer publicar un paquete. A final de cuentas permiten justamente eso, administrar esas ejecuciones. Solía ser parte de la instalación de R en Windows, pero ya no es así, por lo que recomiendo la instales siguiendo las instrucciones oficiales (selecciona la versión más nueva de Rtools disponible).\nmacOS: xquartz. R es un lenguaje con un enfoque muy fuerte hacia la generación de gráficos, lo cual permite hacer visualizaciones de muy alta calidad. Desafortunadamente, algunas cosas se apoyan del sistema de ventanas X.Org X Window System y que, de no estar disponible, pueden dar algunos dolores de cabeza. Apple solía incluir una implementación en la aplicación X11 en las versiones de OS X 10.5 a 10.7, pero ya no en sistemas más modernos. Es ahí donde entra el proyecto XQuartz. El instalador está disponible en la página del proyecto.\nmacOS: Xcode Command Line Tools. Si bien es cierto que macOS juega un papel importante en algunos círculos de desarrollo de software, no incluye algunas herramientas necesarias para el mismo objetivo que Rtools en Windows: compilar desde fuente. En este caso, hay dos formas de instalar lo que necesitamos, ambas provistas por Apple: a) Instalar el entorno de desarrollo Xcode (40 GB) o, mi recomendación si no desarrollas aplicaciones para SOs de Apple, b) instalar las herramientas de línea de comando. Xcode lo puedes instalar directamente desde tu App Store, mientras que las herramientas de línea de comando desde el Terminal con el comando xcode-select --install. Puedes abrir el terminal utilizando Spotlight (CMD + espacio), o ejecutando su aplicación, ubicada en Aplicaciones -> Utilidades\n\nUna vez instalado todo esto estás más que listo para avanzar con el programa del curso. Recuerda que si tuviste algún problema siempre puedes contactarme en el servidor de Discord del curso."
  },
  {
    "objectID": "c01_biolcdatos.html",
    "href": "c01_biolcdatos.html",
    "title": "1  Ciencia de datos y biología",
    "section": "",
    "text": "Para comenzar, hablaremos un poco sobre lo que conocemos como estadística. El origen de esta disciplina se encuentra en la necesidad de los gobiernos de conocer cuál es el estado de su población, de ahí su raíz etimológica “relativo al Estado”. Sin embargo, en la actualidad, existen diversas definiciones y opiniones sobre lo que representa. Hay quienes mencionan que “es la primera de las ciencias inexactas”, mientras otros la consideran como “La ciencia que nos permite cambiar nuestras ideas ante la incertidumbre”. Si bien es cierto que estas visiones son en apariencia muy diferentes, ambas son perspectivas bastante válidas: la primera hace referencia a la relativa facilidad con la que se pueden manipular los datos o las pruebas (intencionalmente o no) para llegar al resultado que nosotros deseemos y la segunda a que nos permite tomar decisiones aún sin conocer en su totalidad un fenómeno. Si deseas leer sobre algunos mitos y realidades de la estadística, sigue este enlace.\nUna definición más formal es la de la Real Academia de la Lengua Española: “Rama de la matemática que utiliza grandes conjuntos de datos numéricos para obtener inferencias basadas en el cálculo de probabilidades”. De esta definición podemos retomar algunas ideas claves: la primera es que es una rama de la matemática, por lo cual los problemas que analicemos deben de seguir un razonamiento lógico y los procedimientos y resultados deben de ser expresados sin ambigüedades. La siguiente es que requiere de grandes conjuntos de datos, lo cual hace referencia a un tema que será abordado más adelante en el curso: la representatividad. Por último, podemos también reconocer su objetivo, el cual es permitirnos obtener conclusiones a partir de este conjunto de datos. A partir de esta definición podemos considerar a la bioestadística como la aplicación de la estadística a problemas biológicos, desde la estimación del tamaño poblacional de una especie, comparaciones de tallas entre sitios de muestreo, modelar el crecimiento corporal, entre muchas otras.\nLlegados a este punto, quiero introducir otro concepto: la ciencia de datos. En pocas palabras, esta estudia los métodos para extraer información sobre los datos y, en última instancia, facilitar la toma de decisiones. Sus objetivos son i) describir los datos, comparar entre grupos/poblaciones/clases, ordenar o clasificar observaciones y, en última instancia, predecir un resultado futuro a partir de los datos con las que se cuenta.\nAl igual que con la definición de estadística, existen distintas definiciones y visiones, pero por el momento analicemos este diagrama que nos habla sobre las habilidades de un individuo realizando un procedimiento a sus datos y cuál sería el resultado:\n\nConsideremos las habilidades de hackeo como habilidades de programación y el conocimiento técnico necesario para la aplicación de distintas técnicas de análisis de datos, a la experiencia como el conocimiento que el individuo tenga sobre el fenómeno que está analizando y al conocimiento sobre matemáticas y estadística como el conocimiento teórico sobre las técnicas que está aplicando.\nEn la intersección de las habilidades de hackeo y la experiencia se encuentra una “zona de peligro”, la cual también podemos definir como el área de la “caja negra”, es decir, el área en la que se aplican pruebas y métodos sin conocer sus fundamentos y las conclusiones o inferencias están en función de la experiencia y los prejuicios de quien las realice, sin considerar su pertinencia.\nPor otra parte, en la intersección de la experiencia y el conocimiento de estadística se encuentra la investigación tradicional; es decir, existe un conocimiento teórico sobre las pruebas que se están aplicando y la experiencia para poder realizar inferencias sobre los datos considerando las limitaciones, fortalezas y debilidades de las técnicas; sin embargo, la visión sobre el problema se encuentra normalmente limitada a las pruebas tradicionales, lo cual a su vez limita el tipo de análisis y preguntas que se puedan resolver.\nEn la intersección de las habilidades de hackeo y el conocimiento sobre estadística se encuentra la disciplina del “aprendizaje automatizado”, algo que discutiremos más profundamente en la sección de Técnicas Multivariadas, pero que hace referencia al extraer relaciones entre los datos de manera eficiente, independientemente de si estas relaciones son causales o no.\nFinalmente, en el centro, recibiendo entradas de las tres áres encontramos a la ciencia de datos. Tomando esto en consideración, te propongo hacer un ejercicio de reflexión sobre la pertinencia de aproximarnos a los problemas biológicos de una manera más flexible, eficiente, informada y que considere también la experiencia del investigador, más allá del modo tradicional e inamovible que nos ha llevado a pensar de manera incorrecta que la falta de significancia estadística es falta de significancia biológica o viceversa. ¿Es esto un problema muy grave? Esa pregunta la dejaremos para un tema donde es más adecuado abordarla: pruebas de hipótesis, en especial al hablar sobre los usos y abusos del famosísimo (¿o infame?) valor de p.\n\nCon esta idea terminamos la primera clase del curso. Nos vemos en la siguiente para familiarizarnos con RStudio y cómo elaborar reportes utilizando Quarto."
  },
  {
    "objectID": "c02_intro_rs.html#preámbulo",
    "href": "c02_intro_rs.html#preámbulo",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "3.1 Preámbulo",
    "text": "3.1 Preámbulo\nEl primer elemento es el preámbulo, que mencionamos está en formato YAML y que está contenido entre ---. YAML es un formato de serialización de datos legible por humanos. ¿En castellano? Una lista con niveles de pares de claves:valores que definen los metadatos de nuestro documento. En nuestro ejemplo tenemos:\n---\ntitle: \"Untitled\"\n---\nEs decir, el título que aparecerá en el reporte es \"Untitled\", tal y como vimos en la vista previa. Esto no tiene mucho sentido, así que cambiémoslo por \"Mi primerQuarto\" y añadamos una nueva entrada para el autor, tal que:\n---\ntitle: \"Mi primer `Quarto`\"\nauthor: \"Tu nombre\"\n---\nOtro elemento que usualmente se agrega en el preámbulo es el formato de salida del documento renderizado; es decir, ya presentado para compartir/imprimir. Mi recomendación es exportar a archivos HTML, salvo que vayas a imprimir el documento (PDF), necesites paginación (PDF de nuevo) o que por alguna desafortunada razón necesites un archivo MS Word. Un HTML lo declaramos tal que:\n---\ntitle: \"Mi primer `Quarto`\"\nauthor: \"Tu nombre\"\nformat:\n  html:\n    code-fold: true\n---\nNotarás algunas cosas. La primera es que html está indentado; es decir, no comienza en la misma posición que format. Esto es para indicar que html pertenece a format, al igual que code-fold pertenece a html. La siguiente es, justamente, que agregamos a la lista la entrada code-fold. Esta es una opción que indica si queremos que el código sea colapsable mediante un botón en el archivo final. En este caso, la indicamos como true, por lo que así será. Si no lo quisiéramos así indicaríamos false. Si renderizamos nuestro documento ahora tendremos:\n\n\n\nFigure 3.1: Primer Quarto renderizado\n\n\nSi tienes curiosidad por saber qué características YAML dieron lugar al libro de acompañamiento, puedes revisar el archivo _Quarto.yml."
  },
  {
    "objectID": "c02_intro_rs.html#markdown",
    "href": "c02_intro_rs.html#markdown",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "3.2 Markdown",
    "text": "3.2 Markdown\nPasando el preámbulo tenemos una sección de texto libre, con algunas anotaciones para el formato del texto. Estas anotaciones están hechas en lenguaje markdown. Markdown es un “lenguaje de programación para textos” y permite hacer cosas bastante interesantes. Las anotaciones más básicas son:\n\nEncabezados y secciones: #, ##, ###, ####, etc.\n*Itálicas* : Itálicas\n**Itálicas**: Negritas\n`Código`: Código\nHipervínculos: [Google](https://www.google.com): Google\n$y_i = \\alpha + \\beta*x_i + \\epsilon$: \\(y_i = \\alpha + \\beta*x_i + \\epsilon\\)\n\nPuedes hacer listas numeradas, como la anterior, o listas sin numerar:\n\nElemento\nOtro elemento\n\nE, incluso, puedes hacer listas anidadas añadiendo una indentación de doble tabulación a los elementos anidados:\n\nIntroducción a RStudio y Quarto\n\nR vs. RStudio\nIDE RStudio\n\n\nEn el archivo .qmd este capítulo puedes ver cómo añadí las capturas de la ventana de RStudio. Añadir imágenes es básicamente el mismo procedimiento que con un enlace, solo añadiendo el operador ! antes. Por ejemplo, la siguiente línea añade el logo de R desde su dirección oficial, le asigna el pie de foto “Logo R” y una etiqueta interna que se puede utilizar para referencias cruzadas (Figure 3.2) con @fig-logoR :\n![Logo `R`](https://www.r-project.org/logo/Rlogo.png){#fig-logoR}\n\n\n\nFigure 3.2: Logo R"
  },
  {
    "objectID": "c02_intro_rs.html#referencias-y-citas",
    "href": "c02_intro_rs.html#referencias-y-citas",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "3.3 Referencias y citas",
    "text": "3.3 Referencias y citas\nPodemos agregar referencias, siempre y cuando estas estén contenidas en un archivo .bib como el archivo references.bib que está en este directorio y, por supuesto, referenciarlas en el texto (e.g. Knuth 1984). Si estás viendo la página web con este material, pasa tu cursor sobre la cita y notarás como aparece la información bibliográfica completa. Este archivo .bib está compuesto por entradas en formato bibTeX, heredado del hermano mayor de Markdown: LaTeX. La sintaxis básica es la siguiente:\n@TIPO{CLAVE,\n      author = {},\n      year = {},\n      title = {}}\nLos campos adicionales dependerán del TIPO de referencia que se esté añadiendo. Si quieres ver algunas de las opciones más comunes, te recomiendo revisar esta página. Para incluir una referencia cruzada lo único que tienes que hacer es: @CLAVE. Si tomamos como ejemplo el artículo de Knuth de 1984 sobre la programación literal sería @Knuth_1984 para una referencia en el texto, Knuth (1984), o [@Knuth_1984] para una referencia dentro de paréntesis (Knuth 1984). En cualquiera de los dos casos, si estás viendo el material renderizado, asegúrate de pasar el cursor sobre las citas, y verás que aparece la referencia bibliográfica completa. Para agregar la lista de referencias al final del texto, debes de agregar el siguiente divisor y asegurarte de tener un encabezado de referencias al final del documento:\n::: {#refs}\n:::\n\n\n\n\n\n\nNote\n\n\n\nYo construyo mis archivos .bib a mano, pero no es necesario. Si quieres pasar de un listado de referencias que ya tienes en Word puedes considerar text2bib o Edifix (1. OJO con las opciones; 2. Edifix es de pago). Si quieres una interfaz gráfica para manejar tus archivos .bib, puedes considerar JabRef. Finalmente, gestores de referencias como Mendeley o ReadCube Papers permiten exportar las referencias en formato bib."
  },
  {
    "objectID": "c02_intro_rs.html#consideraciones-sobre-quarto",
    "href": "c02_intro_rs.html#consideraciones-sobre-quarto",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "3.4 Consideraciones sobre Quarto",
    "text": "3.4 Consideraciones sobre Quarto\nAunque Quarto es extremadamente potente y flexible, es importante tener presente algunas cosas. La primera es que NO hay manera de que en esta sesión yo pueda explicarte con lujo de detalle todas las funciones, para eso prefiero dirigirte a la (bastante extensa) guía de Quarto. Otra consideración es que, aunque puedes exportar tus documentos como PDF, Word o ePUB u otros, mi recomendación es que siempre que tengas la libertad exportes a un HTML, que es un poco más permisivo con líneas de código muy largas, o al mostrar tablas con muchas columnas. Si NECESITAS un PDF, asegúrate de tener instalada alguna distribución de LaTeX o, si no quieres la instalación completa, cuando menos asegurarte de haber instalado TinyTeX como sugerimos en la sesión de preparación, de lo contrario NO podrás exportar tus reportes a PDF."
  },
  {
    "objectID": "c02_intro_rs.html#qué-sigue",
    "href": "c02_intro_rs.html#qué-sigue",
    "title": "2  Introducción a RStudio y Quarto",
    "section": "3.6 ¿Qué sigue?",
    "text": "3.6 ¿Qué sigue?\nEn esta sesión revisamos muy someramente el poder de RStudio y Quarto, limitándonos a las funciones más indispensables y que se utilizan de manera cotidiana, pero hay mucho más por ver. Proyectos dentro de RStudio, elaborar libros/páginas web/tesis o incluso artículos científicos con formato editorial según los requerimientos de algunas revistas, solo por mencionar algunos.\nPor otra parte, una de las ventajas poco conocidas de trabajar con archivos de texto simple (.R, .Rmd o .qmd), al menos en el área de ciencias biológicas, es el poder aprovechar al máximo sistemas de gestión de versiones, incluyendo por supuesto al más famoso: git. Muy posiblemente te hayas encontrado en algún momento con GitHub, que no era otra cosa mas que un almacén público de repositorios git. Ahora es un servidor capaz de mantener servicios simples en ejecución o, incluso, alojar páginas web (la página web de acompañamiento de este curso es un ejemplo), por lo que te recomiendo que le eches un ojo al funcionamiento de ambos (git y GitHub), y que revises la integración de git en RStudio. Personalmente utilizo solo la línea de comandos, pero es una herramienta más dentro de nuestro IDE y que puede resultarte más intuitiva."
  },
  {
    "objectID": "s02_herrbasic.html",
    "href": "s02_herrbasic.html",
    "title": "Herramientas básicas para el análisis de datos",
    "section": "",
    "text": "En esta sección del curso comenzarás a adentrarte a la estadística, abordando primero el concepto más importante: la probabilidad. Después escalarás a la teoría del muestreo, revisarás cómo describir tus datos (tanto numérica como gráficamente) y por último cómo probar si tu evidencia puede dejar en ridículo a una (ridícula) hipótesis de nulidad."
  },
  {
    "objectID": "s01_biolcdatos.html",
    "href": "s01_biolcdatos.html",
    "title": "Biología como Ciencia de Datos",
    "section": "",
    "text": "En esta sección del curso comenzarás reflexionando sobre el cómo se han aplicado tradicionalmente las técnicas estadísticas a los problemas biológicos, y cómo esta aproximación puede no ser óptima. Después, te introducirás a RStudio, la elaboración de reportes con Quarto y posteriormente las bases del lenguaje R. Como última parte de esta sección, revisarás los conceptos y consideraciones básicas detrás de la visualización de datos."
  },
  {
    "objectID": "s02_fundan.html",
    "href": "s02_fundan.html",
    "title": "Fundamentos del análisis de datos",
    "section": "",
    "text": "En esta sección del curso comenzarás a adentrarte a la estadística, abordando primero el concepto más importante: la probabilidad. Después escalarás a la teoría del muestreo, revisarás cómo describir tus datos (tanto numérica como gráficamente) y por último cómo probar si tu evidencia puede dejar en ridículo a una (ridícula) hipótesis de nulidad."
  },
  {
    "objectID": "s03_noparnolin.html",
    "href": "s03_noparnolin.html",
    "title": "Técnicas no paramétricas y modelación no lineal",
    "section": "",
    "text": "En esta sección del curso te adentrarás en las caras “opuestas” a las técnicas que has revisado hasta ahora; es decir, explorarás casos en los cuales no puedes o debes de aplicar una prueba paramétrica, así como casos en los cuales no asumirás que tus variables tienen una relación lineal, ni tampoco necesitas cumplir con el supuesto de normalidad."
  },
  {
    "objectID": "s04_mv.html",
    "href": "s04_mv.html",
    "title": "Técnicas Multivariadas",
    "section": "",
    "text": "En esta sección del curso llegarás al punto de máxima abstracción y te adentrarás en diversas técnicas que te permitirán obtener conclusiones a partir de datos multivariados. Comenzarás analizando las relaciones entre tus variables mediante matrices de varianzas/covarianzas, formarás agrupaciones, compararás las mediciones multivariadas entre grupos, realizarás clasificaciones y, por último, realizarás regresiones múltiples y verás cómo controlar la complejidad de tus modelos."
  },
  {
    "objectID": "c16_clasif.html",
    "href": "c16_clasif.html",
    "title": "16  Aprendizaje supervisado: Clasificación",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\n\n\niris.plot <- ggplot(iris, aes(x = Species, y = Petal.Length)) +\n             geom_point(color = \"dodgerblue4\", alpha = 0.8) +\n             theme_bw()\niris.plot\n\n\n\n\nEl primer paso es separar nuestros datos en datos de entreenamiento y prueba, lo cual podemos hacer con las funciones initial_split, training y testing de la librería rsample:\n\nset.seed(123)\niris_split <- initial_split(iris, strata = Species)\niris_train <- training(iris_split)\niris_test <- testing(iris_split)\n\nLuego, construimos una receta para el preprocesamiento de los datos:\n\nLe damos a la receta (recipe()) la fórmula y los datos de entrenamiento\nAñadimos un paso para centrar los datos numéricos. Recuerda, solo estamos poniendo todos los valores numéricos en la misma escala\n\nEl objeto iris_prep sigue los pasos a seguir para el preprocesamiento de los datos (por ello receta) y obtiene los parámetros con los que se van a preprocesar los datos, mientras que juiced obtiene los datos procesados.\n\niris_rec <- recipe(Species~., data = iris_train) |> \n            step_center(all_numeric())\niris_prep <- iris_rec |> prep()\njuiced <- juice(iris_prep)\n\nAhora podemos especificar el modelo de bosques aleatorios, donde ajustaremos sus hiperparámetros:mtry (el número máximo de predictores por árbol), min_n (el número de observaciones necesarias para seguir dividiendo los datos) y trees (el número de árboles en el ensemble). Después especificamos que es un bosque para clasificación, y por último le indicamos que utilice la librería ranger para construir el bosque:\n\ntune_spec <- rand_forest(mtry = tune(),\n                         trees = tune(),\n                         min_n = tune()) |> \n             set_mode(\"classification\") |>\n             set_engine(\"ranger\")\n\nFinalmente, formamos un flujo de trabajo que contenga ambos pasos: la receta de preprocesamiento y el modelo\n\ntune_wf <- workflow() |> \n           add_recipe(iris_rec) |> \n           add_model(tune_spec)\n\nAhora sí, podemos ajustar nuestros hiper-parámetros. Primero, asignemos un confjunto de remuestreos para la validación cruzada, construidos a partir de los datos de entrenamiento:\n\nset.seed(0)\niris_fold <- vfold_cv(iris_train)\n\nLuego establezcamos el procesamiento en paralelo para hacer el procedimiento más rápido. En este primer proceso vamos a escoger 20 puntos aleatorios para guiar nuestra búsqueda y no abusar de la fuerza bruta para resolver el problema:\n\ndoParallel::registerDoParallel(cores = 6)\ntune_res <- tune_grid(tune_wf,\n                      resamples = iris_fold,\n                      grid = 20)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\nVeamos nuestros AUCs:\n\ntune_res |> collect_metrics() |> \n            filter(.metric == \"roc_auc\") |> \n            select(mean, min_n, mtry, trees) |>\n            pivot_longer(min_n:trees,\n                         values_to = \"value\",\n                         names_to = \"parameter\") |> \n            ggplot(aes(value, mean, color = parameter)) +\n            geom_point(show.legend = F) +\n            facet_wrap(~parameter, scales = \"free_x\")"
  },
  {
    "objectID": "c04_tidyverse.html",
    "href": "c04_tidyverse.html",
    "title": "4  Introducción a tidyverse",
    "section": "",
    "text": "En la sesión anterior mencionamos que hay un “paquete de paquetes” que da lugar a un “dialecto” dentro de R: tidyverse, pero no especifiqué a qué me refería con ello. Pues bien, mientras que en R base los procedimientos los realizamos línea a línea, generando a veces una gran cantidad de objetos intermedios o sobreescribiendo los existentes, tidyverse proveé de un paradigma diferente, con una “gramática” (sintaxis) distinta, muy similar a lo que veremos en ggplot2. De hecho, ggplot2 es un paquete del tidyverse, por lo que el “dialecto” tidy comparte la filosofía declarativa y fomenta la “encadenación” de comandos. A muchas personas les gusta más la forma tidy, a otras les gusta más trabajar con R base. En lo personal soy partidario de que utilices lo que más te acomode, siempre y cuando lo que hagas tenga sentido, pero más de esto cerca del final de la sesión.\nEste nuevo dialecto fue creado con un objetivo en particular: la ciencia de datos. Como tal, cuenta con una gran cantidad de librerías (y por lo tanto funciones) especializadas para realizar operaciones rutinarias. ¿Quieres realizar gráficos? En la siguiente sesión hablaremos de ggplot2. ¿Quieres hacer “manipulación” (ojo, no cuchareo) de datos? Aquí veremos algnas funciones de dplyr. ¿Quieres trabajar con procesamiento de cadenas de caractér? Para esto está stringr. ¿Quieres herramientas para programación funcional? Ve hacia purrr (sí, triple r). readxl es otra librería con la que ya estás familiarizado y que forma parte del tidyverse. ¿Tienes un problema en el que que necesitas manejar fechas? lubridate puede ser una opción. Puedes conocer todos los paquetes que forman el tidyverse con:\n\ntidyverse::tidyverse_packages(include_self = T)\n\n [1] \"broom\"         \"cli\"           \"crayon\"        \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"readr\"        \n[21] \"readxl\"        \"reprex\"        \"rlang\"         \"rstudioapi\"   \n[25] \"rvest\"         \"stringr\"       \"tibble\"        \"tidyr\"        \n[29] \"xml2\"          \"tidyverse\"    \n\n\nA partir de aquí, el cómo aprovecharlos depende mucho de el problema que tengas entre manos, pero la idea general es la misma: utilizar una gramática declarativa para llegar a la solución. Veamos en qué consiste con un ejemplo cotidiano: obtener el promedio de una variable para varios grupos.\n\n\nVeamos un ejemplo en el cual calcularemos la longitud de pico promedio para cada especie de pingüino, según los datos de palmerpenguins. Primero, carguemos los datos:\n\ndatos1 <- palmerpenguins::penguins\n\nAhora, obtengamos los promedios con la función aggregate, tal y como vimos en la sesión anterior:\n\naggregate(bill_length_mm~species, data = datos1, FUN = mean)\n\n\n\n  \n\n\n\nAhora repliquémoslo con tidyverse, particularmente con las funciones group_by y summarise (o summarize) de la librería dplyr:\n\nlibrary(dplyr)\n\ndatos1 |>\n  group_by(species) |>\n  summarise(mbill_l = mean(bill_length_mm, na.rm = T))\n\n\n\n  \n\n\n\nNotarás que el resultado es exactamente el mismo, aunque la forma de hacerlo es diferente. Descompongámosla paso a paso para ver qué es lo que está pasando:\n\nlibrary(dplyr): cargamos la librería dplyr, la cual contiene las funciones que nos interesa aplicar: group_by y summarise.\nLlamamos directamente a nuestros datos (datos1) y utilizamos un operador que no habíamos visto: |>. Este es el operador pipe, el cual pasa lo que está a la izquierda de él como el primer argumento de lo que está a la derecha de él. Esto puede sonar confuso, pero la instrucción datos1 |> group_by(sp) es equivalente a group_by(datos1, sp). Podemos ver al operador pipe como su nombre sugiere: una tubería que manda la información de un lado hacia otro.\ngroup_by(sp): Como te mencionaba, tidy es un poco más explícito que R base. Mientras que el argumento con la fórmula en aggregate indica cómo se van a agrupar los datos, aquí primero los agrupamos y después aplicamos la función que nos interesa. group_by hace justamente eso, agrupar nuestros datos, nada más, nada menos. El argumento principal de esta función es la(s) columnas bajo las cuales queremos agrupar nuestros datos. En este caso solo es una (sp), por lo que la pasamos directamente.\nNuevamente utilizamos el operador |>. Hasta este punto hemos pasado los datos1 a la función group_by(sp), por lo que ya están agrupados por especie, pero falta aplicar la función mean() para obtener el promedio, entonces volvemos a encadenar hacia la función summarise(). Esta función recibe una serie de pares nombres de columnas y funciones a aplicar. En este caso, estamos generando una columna llamada mbill_l que contiene los promedios de la columna bill_length_mm de los datos1.\n\n\n\n\n\n\n\nImportant\n\n\n\nSi revisas documentación “antigua” sobre tidyverse (previa a R 4.1, de hecho), notarás que el operador pipe es %>% en vez de |>. El resultado es el mismo y, de hecho, a partir de R 4.1 puedes seleccionar cuál utilizar en las preferencias de RStudio; sin embargo, utilizaremos |> por ser el operador pipe nativo de R, el cual fue introducido (como te imaginarás) en R 4.1.\n\n\n¿Abstracto? Sin duda. ¿Útil? También. ¿Más explícito que R base con aggregate? Debatible. Lo que no es debatible es que esta notación brilla especialmente en cierto tipo de problemas. Pensemos que nos interesa conocer el promedio de las longitudes de picos por especie para cada isla. Intenta hacerlo con R base y te darás cuenta de que no es tan intuitivo, salvo que estés familiarizado con el uso de fórmulas. ¿En tidy? Solamente hay que agregar la nueva variable de agrupamiento a group_by:\n\ndatos1 |>\n  group_by(species, island) |>\n  summarise(mbill_l = mean(bill_length_mm,\n                           na.rm = T))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n\n\n  \n\n\n\nAhora tenemos un tibble (funcionalmente equivalente a un data.frame) con tres columnas, en donde se da el promedio para cada combinación de las variables de agrupamiento. ¿A que es más sencillo que intentar hacerlo con R base?\n\n\n\n\n\n\nNote\n\n\n\nCon esto no quiero deciro que tidy sea mejor que R base o viceversa, solamente que son dos aproximaciones, cada una con sus propias ventajas y desventajas. Por un lado, R base puede llegar a ser más compacto, pero tidy tiende a ser más explícito. Por supuesto, también hay casos en los que lo contrario es verdad.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nHay ocasiones en las cuales querrás evitar el uso de tidyverse, y una de ellas es al crear nuevas librerías. ¿La razón? Puedes crear un conflicto de dependencias si no lo manejas con cuidado. Otra es que es sumamente complicado depurar errores.\n\n\nTe habrás dado cuenta de que hasta este momento no hemos asignado nuestros resultados a ningún objeto. Esto se debe a dos razones. La primera, y tal vez la que pasa por tu cabeza, es que de esta manera podemos mostrar los resultados más rápidamente, y sí, pero el trasfondo está en la segunda razón: La asignación sigue un sentido opuesto al encadenamiento. Mientras que con |> la información fluye de izquierda a derecha, con <- la información fluye de derecha a izquierda. Quise, entonces, que primero te acostumbraras al flujo de información con pipe, pues asignar el resultado a un objeto es lo mismo que hemos hecho hasta ahora:\n\ngmeans <- datos1 |>\n          group_by(species, island) |>\n          summarise(mbill_l = mean(bill_length_mm,\n                                   na.rm = T))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\ngmeans\n\n\n\n  \n\n\n\n\n\n\nEn la sesión anterior nos familiarizamos con máscaras booleanas y la función subset. tidy tiene su propia aproximación. Pensemos que queremos quedarnos solo con los pingüinos provenientes de Biscoe. Con subset:\n\nsubset(datos1, island == \"Biscoe\")\n\n\n\n  \n\n\n\nMientras que con tidy:\n\ndatos1 |> filter(island == \"Biscoe\")\n\n\n\n  \n\n\n\nLa notación no es tan diferente como en el caso anterior, y el resultado es el mismo. ¿Cuál utilizar? Depende totalmente de la preferencia de cada quien. A diferencia del caso anterior, subset no se vuelve tan compleja conforme vamos escalando en complejidad, y la equivalencia entre aproximaciones con filter se mantiene. Veamos qué pasa si obtenemos SOLO los pingüinos Adelie de Biscoe. Nuevamente, con subset:\n\nsubset(datos1, species == \"Adelie\" & island == \"Biscoe\")\n\n\n\n  \n\n\n\nCon tidy:\n\ndatos1 |> filter(species == \"Adelie\" & island == \"Biscoe\")\n\n\n\n  \n\n\n\n¿Por qué empezar con un ejemplo tan “complejo” como el caso anterior? Para dejar “lo peor” al inicio, y a partir de ahí las cosas puedan fluir un poco mejor.\n\n\n\nOtra tarea cotidiana que vimos en la sesión anterior fue el añadir nuevas columnas a nuestro data.frame. Pensemos que tiene sentido obtener el “área” que utiliza el pico, la cual obtendríamos multiplicando bill_length_mm y bill_depth_mm. Este producto lo almacenaríamos en una nueva columna llamada bill_area. En R base:\n\ndatos1[\"bill_area\"] <- datos1$bill_length_mm * datos1$bill_depth_mm\ndatos1$bill_area\n\n  [1]  731.17  687.30  725.40      NA  708.31  809.58  692.42  768.32  617.21\n [10]  848.40  646.38  653.94  723.36  818.32  730.06  651.48  735.30  879.75\n [19]  632.96  989.00  691.74  704.99  689.28  691.42  667.36  667.17  755.16\n [28]  724.95  704.94  765.45  659.65  673.32  703.10  773.01  618.80  827.12\n [37]  776.00  780.70  725.68  760.18  657.00  750.72  666.00  868.77  625.30\n [46]  744.48  780.90  708.75  644.40  896.76  700.92  757.89  626.50  819.00\n [55]  624.45  770.04  682.50  763.28  605.90  718.16  603.33  871.43  639.20\n [64]  748.02  622.44  748.80  575.10  785.01  595.94  810.92  636.50  730.48\n [73]  681.12  865.62  621.25  791.80  687.12  721.68  582.82  804.11  595.12\n [82]  755.04  689.96  680.94  663.94  838.39  707.85  686.34  735.36  731.32\n [91]  642.60  743.91  581.40  716.76  626.26  771.12  708.66  745.55  532.91\n[100]  799.20  626.50  820.00  603.20  756.00  704.94  750.33  663.92  764.00\n[109]  647.70  820.80  628.65  925.68  702.69  822.90  819.72  781.41  656.20\n[118]  764.65  606.90  764.46  622.64  746.46  683.40  765.90  559.68  771.40\n[127]  682.88  759.45  666.90  793.80  689.15  827.52  680.80  693.75  670.56\n[136]  719.25  623.00  808.02  610.50  710.63  687.42  698.32  497.55  691.90\n[145]  626.64  729.30  729.12  673.44  640.80  684.18  615.60  767.75  608.52\n[154]  815.00  686.67  760.00  690.20  627.75  662.84  714.51  580.22  720.72\n[163]  560.33  788.90  623.35  706.64  668.68  774.01  567.00  747.84  669.90\n[172]  735.37  717.86  653.95  674.25  731.54  561.99  696.11  636.35  717.00\n[181]  689.26  765.00  723.69  607.76  653.95 1013.20  726.68  788.92  583.62\n[190]  768.12  598.40  764.59  584.99  793.60  620.61  744.00  802.95  606.04\n[199]  632.45  802.95  597.17  714.16  661.72  683.85  649.44  751.50  669.60\n[208]  693.00  608.82  682.50  626.40  771.12  625.14  688.38  635.23  852.51\n[217]  650.36  836.64  665.28  801.90  617.70  760.50  715.50  723.84  751.92\n[226]  688.20  696.00  777.60  674.50  832.93  623.76  741.28  711.95  819.00\n[235]  692.04  795.00  619.62  878.84  624.96  728.46  665.00  885.70  712.50\n[244]  892.62  659.75  796.95  654.15  797.56  780.52  684.74  696.96  843.15\n[253]  727.50  950.30  731.60  736.50  652.74  753.48  612.99  843.72  606.20\n[262]  726.31  767.60  791.82  661.20  839.45  651.42  881.60  698.65  790.56\n[271]  646.64      NA  669.24  791.28  668.96  803.39  832.35  975.00  984.96\n[280]  848.98 1043.46  804.56  839.02  933.66  869.40 1020.87  829.48 1049.51\n[289]  813.10  941.20  784.89  989.80 1006.00 1032.40  863.04  895.44  733.52\n[298]  848.75  717.12  981.64  835.93  988.00  929.20  940.50  825.92 1056.00\n[307]  678.94 1127.36  709.75  958.80  924.42  798.00  871.08 1076.40  778.54\n[316] 1064.65  955.50  808.50  972.19  773.50  911.11  939.80  896.79  960.40\n[325]  963.05  861.54  788.84  976.60  790.61  998.79  735.25  981.36  750.32\n[334]  981.07  943.76  884.64 1012.05  772.20  776.90 1104.84  787.35  902.72\n[343]  965.20  938.74\n\n\nAhora hagámoslo con tidy, pero primero reestablezcamos el objeto datos1:\n\ndatos1 <- palmerpenguins::penguins\n\nY ahora hagamos la operación con tidy:\n\ndatos1 <- datos1 |> \n          mutate(bill_area = bill_length_mm * bill_depth_mm)\ndatos1$bill_area\n\n  [1]  731.17  687.30  725.40      NA  708.31  809.58  692.42  768.32  617.21\n [10]  848.40  646.38  653.94  723.36  818.32  730.06  651.48  735.30  879.75\n [19]  632.96  989.00  691.74  704.99  689.28  691.42  667.36  667.17  755.16\n [28]  724.95  704.94  765.45  659.65  673.32  703.10  773.01  618.80  827.12\n [37]  776.00  780.70  725.68  760.18  657.00  750.72  666.00  868.77  625.30\n [46]  744.48  780.90  708.75  644.40  896.76  700.92  757.89  626.50  819.00\n [55]  624.45  770.04  682.50  763.28  605.90  718.16  603.33  871.43  639.20\n [64]  748.02  622.44  748.80  575.10  785.01  595.94  810.92  636.50  730.48\n [73]  681.12  865.62  621.25  791.80  687.12  721.68  582.82  804.11  595.12\n [82]  755.04  689.96  680.94  663.94  838.39  707.85  686.34  735.36  731.32\n [91]  642.60  743.91  581.40  716.76  626.26  771.12  708.66  745.55  532.91\n[100]  799.20  626.50  820.00  603.20  756.00  704.94  750.33  663.92  764.00\n[109]  647.70  820.80  628.65  925.68  702.69  822.90  819.72  781.41  656.20\n[118]  764.65  606.90  764.46  622.64  746.46  683.40  765.90  559.68  771.40\n[127]  682.88  759.45  666.90  793.80  689.15  827.52  680.80  693.75  670.56\n[136]  719.25  623.00  808.02  610.50  710.63  687.42  698.32  497.55  691.90\n[145]  626.64  729.30  729.12  673.44  640.80  684.18  615.60  767.75  608.52\n[154]  815.00  686.67  760.00  690.20  627.75  662.84  714.51  580.22  720.72\n[163]  560.33  788.90  623.35  706.64  668.68  774.01  567.00  747.84  669.90\n[172]  735.37  717.86  653.95  674.25  731.54  561.99  696.11  636.35  717.00\n[181]  689.26  765.00  723.69  607.76  653.95 1013.20  726.68  788.92  583.62\n[190]  768.12  598.40  764.59  584.99  793.60  620.61  744.00  802.95  606.04\n[199]  632.45  802.95  597.17  714.16  661.72  683.85  649.44  751.50  669.60\n[208]  693.00  608.82  682.50  626.40  771.12  625.14  688.38  635.23  852.51\n[217]  650.36  836.64  665.28  801.90  617.70  760.50  715.50  723.84  751.92\n[226]  688.20  696.00  777.60  674.50  832.93  623.76  741.28  711.95  819.00\n[235]  692.04  795.00  619.62  878.84  624.96  728.46  665.00  885.70  712.50\n[244]  892.62  659.75  796.95  654.15  797.56  780.52  684.74  696.96  843.15\n[253]  727.50  950.30  731.60  736.50  652.74  753.48  612.99  843.72  606.20\n[262]  726.31  767.60  791.82  661.20  839.45  651.42  881.60  698.65  790.56\n[271]  646.64      NA  669.24  791.28  668.96  803.39  832.35  975.00  984.96\n[280]  848.98 1043.46  804.56  839.02  933.66  869.40 1020.87  829.48 1049.51\n[289]  813.10  941.20  784.89  989.80 1006.00 1032.40  863.04  895.44  733.52\n[298]  848.75  717.12  981.64  835.93  988.00  929.20  940.50  825.92 1056.00\n[307]  678.94 1127.36  709.75  958.80  924.42  798.00  871.08 1076.40  778.54\n[316] 1064.65  955.50  808.50  972.19  773.50  911.11  939.80  896.79  960.40\n[325]  963.05  861.54  788.84  976.60  790.61  998.79  735.25  981.36  750.32\n[334]  981.07  943.76  884.64 1012.05  772.20  776.90 1104.84  787.35  902.72\n[343]  965.20  938.74\n\n\nEvidentemente, los resultados son los mismos, lo cual me lleva directamente a la siguiente sección."
  },
  {
    "objectID": "c04_tidyverse.html#promedios-de-grupos-aggregate-vs-group_by-summarise",
    "href": "c04_tidyverse.html#promedios-de-grupos-aggregate-vs-group_by-summarise",
    "title": "4  Introducción a tidyverse",
    "section": "4.2 Promedios de grupos: aggregate vs group_by() |> summarise()",
    "text": "4.2 Promedios de grupos: aggregate vs group_by() |> summarise()\nVeamos un ejemplo en el cual calcularemos la longitud de pico promedio para cada especie de pingüino, según los datos de palmerpenguins. Primero, carguemos los datos:\n\ndatos1 <- palmerpenguins::penguins\n\nAhora, obtengamos los promedios con la función aggregate, tal y como vimos en la sesión anterior:\n\naggregate(bill_length_mm~species, data = datos1, FUN = mean)\n\n\n\n  \n\n\n\nAhora repliquémoslo con tidyverse, particularmente con las funciones group_by y summarise (o summarize) de la librería dplyr:\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndatos1 |> group_by(species) |> summarise(mbill_l = mean(bill_length_mm, na.rm = T))\n\n\n\n  \n\n\n\nNotarás que el resultado es exactamente el mismo, aunque la forma de hacerlo es diferente. Descompongámosla paso a paso para ver qué es lo que está pasando:\n\nlibrary(dplyr): cargamos la librería dplyr, la cual contiene las funciones que nos interesa aplicar: group_by y summarise.\nLlamamos directamente a nuestros datos (datos1) y, en vez de aplicar las funciones como fun(datos1), aparece un operador que no habíamos visto: |>. Este es el operador pipe, el cual pasa lo que está a la izquierda de él como primer argumento de lo que está a la derecha de él. Esto puede sonar confuso, pero la instrucción datos1 |> group_by(sp) da el mismo resultado que daría group_by(datos1, sp). Podemos ver al operador pipe como su nombre sugiere: una tubería que manda la información de un lado hacia otro.\ngroup_by(sp): Como te mencionaba, tidy es un poco más explícito que R base. Mientras que el argumento con la fórmula en aggregate indica cómo se van a agrupar los datos, aquí primero los agrupamos y después aplicamos la función que nos interesa. group_by hace justamente eso, agrupar nuestros datos, nada más, nada menos. El argumento principal de esta función es la(s) columnas bajo las cuales queremos agrupar nuestros datos. En este caso solo es una (sp), por lo que la pasamos directamente.\nNuevamente utilizamos el operador |>. Hasta este punto hemos pasado los datos1 a la función group_by(sp), por lo que ya están agrupados por especie, pero falta aplicar la función mean() para obtener el promedio, entonces volvemos a encadenar hacia la función summarise(). Esta función recibe una serie de pares nombres de columnas y funciones a aplicar. En este caso, estamos generando una columna llamada mbill_l que contiene los promedios de la columna bill_length_mm de los datos1.\n\n\n\n\n\n\n\nImportant\n\n\n\nSi revisas documentación “antigua” sobre tidyverse (previa a R 4.1, de hecho), notarás que el operador pipe es %>% en vez de |>. El resultado es el mismo y, de hecho, a partir de R 4.1 puedes seleccionar cuál utilizar en las preferencias; sin embargo, utilizaremos |> por ser el operador pipe nativo de R, el cual fue introducido (como te imaginarás) en R 4.1.\n\n\n¿Abstracto? Sin duda. ¿Útil? También.¿Más explícito que R base con aggregate? Debatible. En este sentido, esta notación brilla especialmente con problemas más complejos. Pensemos que nos interesa conocer el promedio de las longitudes de picos por especie por isla. Intenta hacerlo con R base y te darás cuenta de que no es tan intuitivo. ¿En tidy? Solamente hay que agregar la nueva variable de agrupamiento a group_by:\n\ndatos1 |> group_by(species, island) |> summarise(mbill_l = mean(bill_length_mm, na.rm = T))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n\n\n  \n\n\n\nAhora tenemos un tibble (funcionalmente equivalente a un data.frame) con tres columnas, en donde se da el promedio para cada combinación de las variables de agrupamiento. ¿A que es más sencillo que intentar hacerlo con R base?\n\n\n\n\n\n\nNote\n\n\n\nCon esto no quiero deciro que tidy sea mejor que R base o viceversa, solamente que son dos aproximaciones, cada una con sus propias ventajas y desventajas. Por un lado, R base puede llegar a ser más compacto, pero tidy tiende a ser más explícito. Por supuesto, hay casos en los que lo contrario es verdad, así que mi consejo es: no te cierres a utilizar solo R base o solo tidy, tal vez en el otro “lado” haya una manera más sencilla/compacta o lógica de hacer las cosas.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nHay ocasiones en las cuales querrás evitar el uso de tidyverse, y una de ellas es al crear nuevas librerías. ¿La razón? Puedes crear un conflicto de dependencias si no lo manejas con cuidado.\n\n\nTe habrás dado cuenta de que hasta este momento no hemos asignado nuestros resultados a ningún objeto. Esto se debe a dos razones. La primera, y tal vez la que pasa por tu cabeza, es que de esta manera podemos mostrar los resultados más rápidamente, y sí, pero el trasfondo está en la segunda razón: La asignación sigue un sentido opuesto al encadenamiento. Mientras que con |> la información fluye de izquierda a derecha, con <- la información fluye de derecha a izquierda. Quise, entonces, primero presentarte"
  },
  {
    "objectID": "c04_tidyverse.html#por-qué-no-enseñar-tidy-desde-el-inicio",
    "href": "c04_tidyverse.html#por-qué-no-enseñar-tidy-desde-el-inicio",
    "title": "4  Introducción a tidyverse",
    "section": "4.2 ¿Por qué no enseñar tidy desde el inicio?",
    "text": "4.2 ¿Por qué no enseñar tidy desde el inicio?\nSi tidy se acomodó a tu forma de ver las cosas, o si se te hizo más fácil de leer, es probable que te preguntes por qué no me salté R base para entrar directamente a tidy. Además de incrementar las horas del curso (broma), fue porque (pedagógicamente) tidy puede introducir ciertas barreras para quienes se van introduciendo a R. Matloff (2020) hace una excelente y extensiva recopilación de las razones por las cuales enseñar solo tidy (o solo R base) es una mala idea, así que te recomiendo leas su opinión; sin embargo, me gustaría darte mi perspectiva. Te adelanto: si no tienes experiencia en programación, el paradigma de tidy supone una curva de aprendizaje más alta que solo R base (solo R a partir de aquí) y, tal vez más importante, no es necesario casarse con uno u otro.\n\n4.2.1 tidy es más complejo\nComo habrás notado en esta sesión, tidy es, escencialmente, más complejo que R. Esto no es una falla en el diseño, sino que tiene que ver con la filosofía de la aproximación: generar código que sea más fácilmente leíble por seres humanos. Sin duda alguna, el utilizar data |> group_by() |> summarise() puede parecer menos críptico o más “entendible” que solo aggregate(formula, data, FUN); sin embargo, esto se debe a que ya conocías qué es una librería y cómo cargarla, qué es una función y qué es un argumento, pero aún así hubo que explicar qué es encadenamiento de operaciones/funciones y el operador pipe y también tuvimos que entender que la información fluye de izquierda a derecha al encadenar y de derecha a izquierda al asignar.\nSi esto no fuera suficiente, el utilizar pipes puede complicar demasiado las cosas al querer depurar errores. ¿La razón? Es una capa más de abstracción. Mientras que cuando aprendemos R es común generar objetos intermedios con los resultados y ver sus salidas (o detectar errores en cada paso), en tidy esto tiende a no ser el caso. ¿Qué obtienes si solo aplicas group_by() en el ejemplo anterior? (i.e., no aplicas summarise()). El ejemplo que vimos es relativamente sencillo pero, en la medida que los problemas se van haciendo más complejos, es fácil perder la pista de qué sale de una función y entra a otra.\nEn mi opinión esto no es un problema TAN grande como pudiera parecer. Tomemos de ejemplo a Python, el lenguaje de programación reconocido como el más intuitivo. Al utilizarlo, el encadenamiento y uso de pipes es cotidiano y, aún más, preferido. En este sentido, tidyverse me recuerda mucho a la funcionalidad que de pandas en Python pero, al igual que aquí, lo correcto es aproximarse primero a Python base y luego pensar en aprender pandas. En mi opinión, el problema real (quitando la capa de abstracción) es en realidad dos problemas: uno relacionado con la filosofía de tidy y otro con quienes enseñamos R.\n\n\n4.2.2 tidy limita tus opciones\nUn ejemplo de esto está en esta misma clase. ¿Cómo obtendríamos los promedios de datos agrupados a dos niveles? Dejé el ejercicio “en el tintero” (es parte de tu tarea para esta sesión) pero, si solo te hubiera enseñado tidy, no podrías pensar en ciclos, el operador $ o cualquier otra forma de indización. ¿La razón? tidy no está enfocado a tratar con vectores individuales, aborrece el uso de ciclos y tampoco sigue las notaciones básicas de indización. Recuerda: en programación siempre es mejor tener más herramientas a tu disposición. Esta limitación la podemos probar rápidamente si queremos extraer los elementos 10:25 de la columna sex de los datos1. Con R base:\n\ndatos1$sex[10:25]\n\n [1] <NA>   <NA>   <NA>   female male   male   female female male   female\n[11] male   female male   female male   male  \nLevels: female male\n\n\n¿Con tidy? Realmente no hay una función que permita hacerlo. Podemos extraer la columna sex utilizando la función select:\n\ndatos1 |> select(sex)\n\n\n\n  \n\n\n\nPero si queremos indizar el resultante obtenemos un error:\n\ndatos1 |> select(sex)[10:25]\n\nError: function '[' not supported in RHS call of a pipe\n\n\n¿La alternativa? Primero indizar datos1 y luego utilizar select. Esto, como ves aquí abajo, funciona, pero hubiera sido mucho más fácil solo utilizar R base.\n\ndatos1[10:25,] |> select(sex)\n\n\n\n  \n\n\n\nPor otra parte, hay una falta de consistencia interna derivada de una estrategia publicitaria (tal vez) un poco mal llevada. ggplot2 no surgió dentro del tidyverse, sino que fue incluído después. Si bien es cierto que la filosofía es similar (i.e., una estructura declarativa), el cómo funcionan es completamente diferente. Una de las máximas de tidyverse (sin ggplot2) es que todo lo que entra o lo que sale es un data.frame (o tibble), mientras que en ggplot2 entra un data.frame y sale una lista. De hecho, más adelante veremos cómo podemos utilizar ciclos para automatizar la generación de gráficos, pero esto va en contra de la filosofía de tidy y no sería posible si nos hubiéramos enfocado únicamente en ella.\n\n\n4.2.3 Los ponentes somos necios\nEl mayor problema al que nos enfrentamos al aprender algún lenguaje de programación (y en muchas otras cosas) es que estamos sujetos a los prejuicios y preferencias de la persona que nos está enseñando. Al aprender a manejar nuestro tío amante de los autos nos va a decir que la transmisión manual (estándar) es mejor que la automática, pero nuestro papá, quien ve los carros solo como un medio de transporte, nos va a decir que con la automática es suficiente. ¿Cuál es mejor? Para variar, la respuesta es: “depende”. ¿De qué? De la situación en la que nos encontremos. En ciudad tener una transmisión manual puede ser muy cansado, pero puede darnos un mayor control en una carretera con un descenso empinado y muchas curvas.\nEn el problema R base vs. tidy es lo mismo. Hay ponentes “puristas” en ambos sentidos: personas que creen que tidy debería considerarse sacrilegio, y personas que creen que R base es obsoleto, arcaico, y que debería de caer en desuso. No te conviertas en ninguno de ellos y mejor ve tidy como una expansión de R base.\n\n\n4.2.4 tidy expande tus horizontes\nEn mi opinión, lo que te acabo de exponer son los problemas principales de enseñar solo tidy y, de acuerdo con Matloff (2020), las razones por las cuales enseñar una mezcla de ambos es la mejor opción. Aprender R base nos permite resolver problemas que en tidy sería muy largo, mientras que tidy nos permite simplificar procedimientos que serían más complicados en R base. Otra ventaja de tidy es que permite unificar procesos bajo una misma sintaxis.\nUn ejemplo de esto lo tenemos en el aspecto de aprendizaje automatizado. Si te pones a revisar tutoriales/referencias sobre aprendizaje automatizado es muy probable que te encuentres con un montón de librerías (una por problema), funciones dedicadas y sintáxis que son específicas a la técnica que quieras aplicar. Teníamos/tenemos un excelente intento de solventar este problema: caret. Funcionaba bien en el sentido de que permitía conjuntar una gran diversidad de técnicas de aprendizaje automatizado en un mismo entorno, unificadas en una misma sintaxis. Utilizando solo caret podíamos ir desde el preprocesamiento de los datos hasta el entrenamiento y validación de nuestros modelos. ¿El problema? Las pocas funciones que forman su esqueleto se volvieron sumamente complejas, algunas de ellas con 30 o más argumentos. El equipo de posit se ha puesto el mismo desafío, y su solución es tidymodels. A diferencia de caret es altamente modular, pero mantiene la intención de unificar el flujo de trabajo en una misma estructura. Tal vez yendo en contra de nuestro consejo, la mayor parte de nuestros procedimientos de aprendizaje automatizado los realizaremos bajo tidymodels, pero haremos referencia a las librerías y funciones involucradas en cada paso. Para ejemplificar, realicemos una regresión lineal simple entre la longitud y la profundidad del pico de los pingüinos.\nEn R base es tan simple como llamar a la función lm con una fórmula y unos datos:\n\nlm(bill_length_mm~bill_depth_mm, data = datos1)\n\n\nCall:\nlm(formula = bill_length_mm ~ bill_depth_mm, data = datos1)\n\nCoefficients:\n  (Intercept)  bill_depth_mm  \n      55.0674        -0.6498  \n\n\nEn tidymodels se requieren más líneas:\n\nlibrary(tidymodels)\n\nlinear_reg() |>\n  set_engine(\"lm\") |> \n  set_mode(\"regression\") |> \n  fit(bill_length_mm~bill_depth_mm, data = datos1)\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = bill_length_mm ~ bill_depth_mm, data = data)\n\nCoefficients:\n  (Intercept)  bill_depth_mm  \n      55.0674        -0.6498  \n\n\n¿Por qué utilizar tidymodels entonces? Eso lo dejaremos para las sesiones en las que hablemos de aprendizaje automatizado, pero verás que toma mucho sentido en el momento en el que quieres hacer particiones entrenamiento/prueba, optimización mediante validación cruzada, preprocesamiento de datos, etc."
  },
  {
    "objectID": "c04_tidyverse.html#ejercicio",
    "href": "c04_tidyverse.html#ejercicio",
    "title": "4  Introducción a tidyverse",
    "section": "4.4 Ejercicio",
    "text": "4.4 Ejercicio\n\nUtilizando R base obtén los promedios de las longitudes de picos de los pingüinos de palmerpenguins para cada especie en cada isla. OJO: Hay al menos dos formas de hacerlo, una muy simple y una más rebuscada. No importa cuál realices, el objetivo es que te rompas la cabeza un rato ;).\nUtilizando tidy (dplyr), y en una sola cadena, filtra los datos para la isla Biscoe, crea una columna que tenga cada valor de la masa corporal menos la media global de esa columna, y luego obtén el promedio de esta columna para cada especie.\nRealiza la misma operación del punto 2 con R base. Algunas funciones que puedes tomar en cuenta para estos dos puntos son subset, filter, mutate, aggregate, summarise y/o for.\nOpcionalmente puedes intentar mezclar ambos procedimientos para llegar al mismo resultado.\n¿Qué opción se te hizo más sencilla? ¿tidy, R base o una combinación de las dos?\n\n\n\n\n\nMatloff, N. 2020. “Teaching R in a Kinder, Gentler, More Effective Manner: Teach Base-R, Not Just the Tidyverse.” https://github.com/matloff/TidyverseSkeptic?fbclid=IwAR0b_e0fWGfFe1exc_VwJUh4TGLtOxoEb4h3YJv6BOCbybSdVBNp6T2xJIU."
  },
  {
    "objectID": "c04_tidyverse.html#conclusión",
    "href": "c04_tidyverse.html#conclusión",
    "title": "4  Introducción a tidyverse",
    "section": "4.3 Conclusión",
    "text": "4.3 Conclusión\nAunque tidy puede llegar a verse más elegante o moderno que R base, no es un substituto, por lo que tampoco debes de casarte con ninguno de los dos. ¿Tu problema se resuelve más rápidamente con tidy? Úsalo. ¿R base se presta mejor? Aprovéchalo. Recuerda, R es una caja de herramientas en la cual debes de buscar la que mejor se adapte al problema o pregunta que quieras responder.\nEsto es todo para esta sesión, nos vemos en la siguiente para hablar sobre teoría y buenas prácticas para la visualización de datos."
  },
  {
    "objectID": "c05_ggplot2.html",
    "href": "c05_ggplot2.html",
    "title": "5  Principios de visualización de datos y ggplot2",
    "section": "",
    "text": "Como seres humanos, con una tendencia a encontrar el camino que ofrezca una menor resistencia (otra forma de decir que somos flojos), usualmente resumimos una realidad altamente compleja utilizando distintas estrategias. Si yo te pido que me digas “qué es una orca” puedes darme una descripción textual del tipo “las orcas son mamíferos del orden Cetartiodactyla”, una descripción numérica en forma de mediciones (Longitud: 6-8 m) o medidas de tendencia central/dispersión (Peso máximo: 5.5 toneladas), pero usualmente preferimos medios audiovisuales como un dibujo, un video o, en el caso de la investigación y el tema principal de hoy, gráficos."
  },
  {
    "objectID": "c05_ggplot2.html#datos-y-variables",
    "href": "c05_ggplot2.html#datos-y-variables",
    "title": "5  Principios de visualización de datos y ggplot2",
    "section": "5.2 Datos y variables",
    "text": "5.2 Datos y variables\nEn una investigación reunimos datos que después representamos con gráficos. Pues bien comencemos definiendo un dato como una representación puntual de la realidad. Son un solo valor, sea una sola medición, un promedio, una desviación estándar, una proporción de sexos, etc, y el conjunto de datos de un mismo atributo medidos en distintos individuos nos dan una variable. Es decir, en nuestros conjuntos de datos cada valor es un dato, y cada columna (usualmente) es una variable. ¿Por qué es importante conocer esto? Porque hay distintos tipos de variables, los cuales definen cómo es que vamos a graficar y tratar esos datos:\n\nCualitativas: hacen referencia a las cualidades de nuestros individuos, y tienen dos escalas:\n\nNominal: hace referencia a categorías en las que no hay un orden o distintas importancias. Ejemplos pueden el sexo o el color.\nOrdinal: aquí hay un órden, y un ejemplo muy claro son las encuestas: 0 es nunca, 1 es casi nunca, 2 es ocasionalmente, 3 es casi siempre y 4 es siempre. Aunque son categorías bien definidas, 2 < 3 y 3 < 4. No son cuantitativas porque las respuestas están sujetas a la interpretación personal, pero descartar el órden en el análisis sería un error.\n\nCuantitativas, que hacen referencia a atributos cuantificables de manera objetiva. Hay dos tipos, cada uno con dos escalas.\n\nTipos:\n\nDiscretas: Son solo números enteros. Un ejemplo cotidiano es la edad, que usualmente la expresamos en años. No vamos por la vida diciendo tengo 18.5 años o 18 años con 6 meses, solo decimos tengo 18 años.\nContinuas: Es el caso contrario, son números fraccionarios. Se les denomina continuas porque hay un número infinito de valores posibles entre un valor y el otro, un ejemplo es la temperatura (35.1ºC, 100 K, etc.)\n\nEscalas:\n\nIntervalo: La escala de intervalo es aquella en donde el 0 NO es absoluto o, mejor dicho, donde el 0 es arbitrario. La temperatura expresada en grados centígrados es un ejemplo claro, 0ºC no indica ausencia de movimiento molecular, solo toma como referencia arbitraria el punto de congelación del agua.\nRazón: Aquí el 0 sí es absoluto y representa la ausencia del atributo en cuestión. La longitud es un ejemplo, si algo tiene longitud 0 más bien no tiene longitud, o si algo tiene una temperatura de 0 K quiere decir que no tiene movimiento molecular (~-273.15ºC).\n\n\n\nAlgo que es muy importante tener siempre bien presente es que, aún cuando existen herramientas y técnicas que nos permiten procesar múltiples variables, en cualquier procedimiento de ciencia de datos es INDISPENSABLE que los datos sean de excelente calidad y, sobre todo, que sean adecuados para responder la pregunta que nos interesa, lo cual nos debe de llevar, invariablemente, a preguntarnos “¿qué datos debo de obtener?” O, en otras palabras, “¿qué debo medir?” Una frase que se me quedó marcada de mis clases de la licenciatura es “La investigación inicia y termina en el escritorio del investigador”; es decir, no salimos a hacer trabajo de campo y a registrar todo lo que se nos atraviese, caso contrario podemos terminar en una conclusión como “los bebés son traídos por cigüeñas”, la cual tiene una anécdota bastante divertida"
  },
  {
    "objectID": "c05_ggplot2.html#introducción-a-ggplot2",
    "href": "c05_ggplot2.html#introducción-a-ggplot2",
    "title": "5  Principios de visualización de datos y ggplot2",
    "section": "5.3 Introducción a ggplot2",
    "text": "5.3 Introducción a ggplot2\nAntes de comenzar una visualización es necesario saber qué queremos responder con ella. En este caso, utilizaremos la base de datos mpg incluída en ggplot2. El primer paso es, entonces, conocer la información que contiene. Para ello guardaremos la base en una variable que llamaremos df1:\n\nlibrary(ggplot2)\n\ndf1 <- ggplot2::mpg\ndf1\n\n\n\n  \n\n\n\nUna manera rápida de tener una idea de cómo está dispuesta una base de datos es utilizando la función head(var). Esta nos mostrará solo las primeras instancias (renglones) del data.frame que estemos analizando. En la tabla inferior podemos ver que se trata de una base de datos sobre automóviles y que las columnas representan: el fabricante, el modelo, el desplazamiento de combustible (litros), el año del modelo, el número de cilindros, el tipo de transmisión, el tipo de tracción, los consumos en ciudad y autopista (en millas por galón, mpg), el tipo de combustible que utilizan y la clase a la que pertenencen. También nos plantearemos el objetivo de eliminar la mayor cantidad de elementos posibles hasta solo tener el esqueleto y de ahí agregar algunos elementos que favorezcan la interpretación.\n\nhead(df1)\n\n\n\n  \n\n\n\n\n5.3.1 ggplot() + ...\nA partir de esta información podemos tratar de responder si existe una relación apreciable entre el consumo de combustible (por ejemplo en autopista) y el desplazamiento del motor, considerando la clase del vehículo. Para atender a esta pregunta utilizaremos un gráfico de dispersión, con el desplazamiento en el eje x, el consumo en el eje y y la clase indicada por los colores de los puntos. Ahora que tenemos claro qué queremos visualizar y cómo lo vamos a visualizar podemos empezar a graficar. El primer paso es inicializar el espacio de graficado con la función ggplot() y pasarle los parámetros estéticos utilizando la función aes(x, y, colour). Es importante mencionar que en este momento aparecerá únicamente el espacio de graficado en blanco. Esto es normal, ya que únicamente definimos el “qué”, pero no el “cómo”.\n\nggplot(data = df1, aes(x = displ, y = cty, colour = class))\n\n\n\n\nYa que inicializamos el espacio gráfico podemos agregar la información que nos interesa. Para facilitar la construcción paso a paso y evitar el repetir código innecesariamente podemos almacenar la gráfica completa en una variable (por ejemplo plot2) e ir añadiendo capas (operador +) posteriormente. Para ver un gráfico guardado en una variable simplemente hay que llamar a esa variable. La primera capa que agregaremos será la que indicará el tipo de gráfico que deseamos (nombrados como geom_*), en este caso un gráfico de dispersión:\n\nplot1 <- ggplot(data = df1, aes(x = displ, y = hwy, colour = class)) +\n         geom_point()\nplot1 # Imprime el gráfico\n\n\n\n\nAhora sí tenemos la información que necesitamos y podríamos comenzar a describir el gráfico, pero en realidad hay demasiados elementos que son innecesarios y otros que son poco informativos en su estado actual (etiquetas de ejes), entonces trabajemos uno por uno. Para modificar las etiquetas de los ejes podemos utilizar las funciones xlab() y ylab() como capas separadas; sin embargo, podemos modificar todas las etiquetas y títulos en un mismo paso utilizando la función labs(title, x, y, caption, colour, ...).\n\nplot2 <- plot1 + labs(x = \"Desplazamiento (l)\",\n                      y = 'Consumo (mpg)',\n                      colour = 'Clase',\n                      title = \n                        'Tamaño del motor y Rendimiento de combustible',\n                      subtitle = 'Consumo en carretera',\n                      caption = 'Datos: ggplot2::mpg')\nplot2\n\n\n\n\n\n\n5.3.2 Tema de ggplot2\nAhora que está claro cuáles son las variables que estamos mostrando podemos empezar a modificar la estética. Recordemos que debemos mantener la relación datos/tinta lo más alta posible, y uno de los elementos más prevalentes del gráfico es el fondo gris con todo y cuadrículas. Para modificar esos elementos tenemos que modificar el “tema” de la gráfica, que no es otra cosa mas que utilizar una función que nos permita modificar en una sola línea la estética general del gráfico. Los temas se encuentran señalados con el nombre theme_*. Probemos con theme_minimal():\n\nplot2 + theme_minimal()\n\n\n\n\nLogramos eliminar el fondo gris y de paso las “espinas” (líneas de los ejes) y ahora el gráfico está en mucho mejor condición para ser presentado; sin embargo aún podemos ir más lejos. El objetivo de esta gráfica no es ver los detalles precisos de la información, si no extraer la información más relevante, por lo que la cuadrícula es un elemento que no aporta nada a la visualización. Para retirarla utilizaremos la función theme(), la cual permite modificar el aspecto de todos los elementos del gráfico. En realidad, las funciones theme_*() son aplicaciones de theme() con diferentes valores por defecto, por lo que podemos replicar el efecto de theme_minimal() e incluir otras modificaciones. Otra función muy útil para este procedimiento es la función element_blank(), la cual le indica a ggplot2 que no debe mostrar ese elemento. Otra cuestión importante que debemos de considerar es la relación de aspecto. Debido a que esta puede modificar enormemente la percepción de los datos, su selección no es algo trivial. En general, la proporción áurea (1:1.61) es un buen punto de partida y en series de tiempo es la proporción que menos deforma los datos. Una proporción cuadrada tiene sentido únicamente en aquellos casos en los que ambos ejes tengan la misma magnitud de variación y procuraremos que el eje más largo sea aquel con la variación más pequeña. En este caso, la variación del eje y (5 a 45) es mucho mayor que la del eje x (1.5 a 7), por lo cual una proporción cuadrada no sería una buena alternativa. En su lugar, utilicemos la proporción áurea. El último elemento que eliminaremos aquí son las marcas de los ejes, ya que realmente no aportan demasiada información.\n\nplot2 <- plot2 + \n         # Eliminamos la cuadrícula menor\n         theme(panel.grid.minor = element_blank(),\n               # Eliminamos la cuadrícula mayor\n               panel.grid.major = element_blank(),\n               # Eliminamos el color de fondo\n               panel.background = element_blank(),\n               # Eliminamos las líneas de los ejes\n               axis.line = element_blank(),\n               # Eliminamos la leyenda\n               legend.key = element_blank(),\n               # Cambiamos la relación de aspecto\n               aspect.ratio = 1/1.61,\n               # Eliminamos las marcas de los ejes\n               axis.ticks = element_blank()\n                       )\nplot2\n\n\n\n\n\n\n5.3.3 Personalizar los ejes\nAhora que nos deshicimos del fondo, la cuadrícula y las líneas y marcas de los ejes podemos trabajar en los valores de los ejes. Una de las mejores maneras de hacerlo es utilizando las funciones scale_x_*() o scale_y_*(), sustituyendo el * por continuous o discrete dependiendo del tipo de variable con el que estemos trabajando. En este caso, eliminaremos por completo las marcas del eje y y dejaremos únicamente los desplazamientos más comunes en el eje x.\n\nplot2 <- plot2 + scale_x_continuous(breaks = c(1.8, 2.5, 5, 7)) +\n                 scale_y_continuous(breaks = NULL)\nplot2\n\n\n\n\n\n\n5.3.4 Añadir líneas de referencia\nAhora que nos deshicimos de los valores del eje la gráfica ya no es entendible debido a que no sabemos cuál es la orientación o la escala de los datos. Una alternativa es añadir un par de líneas de referencia. Esto lo haremos con la función geom_hline(), la cual nos permite añadir líneas horizontales a través de todo el gráfico que cruzan al eje y en una posición que nosotros determinamos:\n\n# Valores de referencia como el mínimo, la media y\n# el máximo de los consumos\n\nrefs <- c(round(min(df1$hwy),0),\n          round(mean(df1$hwy),0),\n          round(max(df1$hwy),0))\n\n# Líneas de referencia, una verde para el mejor consumo,\n# una gris para el consumo promedio y una roja para el peor consumo\nplot2 <- plot2 + geom_hline(yintercept = refs[1],\n                            colour = 'firebrick', alpha = 0.5,\n                            linetype = 'dashed') +\n                 geom_hline(yintercept = refs[2],\n                            colour = 'lightslategrey', alpha = 0.5,\n                            linetype = 'dashed') +\n                 geom_hline(yintercept = refs[3],\n                            colour = 'forestgreen', alpha = 0.5,\n                            linetype = 'dashed')\nplot2\n\n\n\n\nAhora el gráifico ya cuenta nuevamente con un sentido de dimensión, pero no tenemos los valores de referencia, entonces habrá que poner esas anotaciones con la función geom_text(), utilizando como valores de posición en y los mismos que las líneas de referencia + un pequeño valor:\n\n# Líneas de referencia con los mismos colores\nplot2 <- plot2 + annotate('text', x = 1.3, y = refs[1]+1, \n                          label = as.character(refs[1]),\n                          colour = 'firebrick') +\n                 annotate('text', x = 1.3, y = refs[2]+1,\n                          label = as.character(refs[2]),\n                          colour = 'lightslategrey') +\n                 annotate('text', x = 1.3, y = refs[3]+1,\n                          label = as.character(refs[3]),\n                          colour = 'forestgreen')\nplot2\n\n\n\n\nCon esta última modificación terminamos de explorar algunas de las funciones más básicas e importantes para personalizar los elementos que más impactan en una visualización, pero antes de terminar de discutir este punto me gustaría terminar el objetivo que nos propusimos al inicio de sacar información de la gráfica. En general, existe una tendencia a que el consumo de combustible incremente conforme incrementa el desplazamiento, lo cual es de esperarse, ya que el desplazamiento es una medida de el volumen máximo de combustible que puede entrar al motor en un momento dado; sin embargo, podemos también observar que, independientemente del desplazamiento, las SUVs y pickups tienden a tener los peores rendimientos de combustible, mientras que los subcompactos tienden al otro extremo. Podemos también analizar a los vehículos de dos plazas y ver que aún cuando tienen desplazamientos altos, sus rendimientos son mejores que los de las SUVs.\n\n\n5.3.5 Conclusión y ejercicio\nEn cuanto a la parte visual, se podría argumentar que esta visualización final no es tan precisa como la primera, que algún elemento podría embellecerse, o que podriamos eliminar la leyenda y poner etiquetas de texto en algunos puntos para indicar las clases. Todos estos argumentos y muchos otros serían válidos ya que la estética es algo subjetivo; sin embargo, las decisiones que tomemos deberán estar en función del medio de distribución de la visualización (no es lo mismo una página web que en un medio impreso, por ejemplo) y sobre todo del público objetivo. Esta visualización en particular funciona para los fines didácticos que tenía en mente, es adecuada para una presentación de resultados de manera electrónica como este video, pero no es una visualización adecuada para una publicación científica. Tomando eso en cuenta, te sugiero hacer el ejercicio de transformarla para cumplir con ese objetivo, ¿qué elementos quitarías? ¿qué elementos cambiarías? ¿qué elementos agregarías? ¿crees que en su estado actual cumple con los criterios de Tufte y Cairo que revisamos la clase anterior?\nPara finalizar la clase te presento la visualización inicial y la final, una junto a la otra, para ver en dónde comenzamos, dónde terminamos y cómo llegamos hasta aquí. También te sugiero revises y descargues el PDF de esta página, que es un acordeón donde se encuentran los gráficos y funciones más comunes. Más adelante revisaremos algunos de ellos pero es un recurso que vale la pena tener a la mano.\nEsto es todo para esta clase. ¡Nos vemos en la siguiente!\n\n\n\n\n\n\n\n\n\n\n\n5.3.5.1 Gráfico final\n\n# Valores de referencia para utilizar en la gráfica\nrefs <- c(round(min(df1$hwy),0),  # Valor mínimo = peor consumo\n          round(mean(df1$hwy),0), # Valor promedio\n          round(max(df1$hwy),0))  # Valor máximo = mejor consumo\n\n# Objeto con todos los pasos para llegar a la gráfica final\n# Inicializamos el espacio gráfico\nfinal.plot <- ggplot(data = df1, aes(x = displ, y = hwy,\n                                     colour = class)) +\n              # Gráfico de dispersión\n              geom_point() +\n              # Establecemos los títulos, subtítulos y un pie de foto\n              labs(x = 'Desplazamiento (l)',\n                   y = 'Consumo (mpg)',\n                   colour = 'Clase',\n                   title = 'Tamaño del motor y Rendimiento de combustible',\n                   subtitle = 'Consumo en carretera',\n                   caption = 'Datos: ggplot2::mpg'\n                   ) +\n              #Eliminamos la cuadrícula menor\n              theme(panel.grid.minor = element_blank(),\n                    #Eliminamos la cuadrícula mayor\n                    panel.grid.major = element_blank(),\n                    #Eliminamos el color de fondo\n                    panel.background = element_blank(),\n                    #Eliminamos las líneas de ejes\n                    axis.line = element_blank(),\n                    #Eliminamos el fondo de la leyenda\n                    legend.key = element_blank(),\n                    #Establecemos la rel. de aspecto\n                    aspect.ratio = 1/1.61,\n                    #Eliminamos las marcas de los ejes\n                    axis.ticks = element_blank(),\n                    #Cambiamos el tipo de letra\n                    text = element_text(family = 'Times',\n                                        colour = 'gray50')\n                    ) + \n              # Reducimos las divisiones del eje ex a 4 valores\n              scale_x_continuous(breaks = c(1.8, 2.5, 5, 7)) +\n              # Eliminamos las divisiones del eje y\n              scale_y_continuous(breaks = NULL) +\n              # Añadimos una línea roja en el peor consumo\n              geom_hline(yintercept = refs[1],\n                         colour = 'firebrick', alpha = 0.5, \n                         linetype = 'dashed') +\n              # Añadimos una línea gris en el consumo promedio\n              geom_hline(yintercept = refs[2],\n                         colour = 'lightslategrey', alpha = 0.5, \n                         linetype = 'dashed') +\n              # Añadimos una línea verde en el mejor consumo\n              geom_hline(yintercept = refs[3],\n                         colour = 'forestgreen', alpha = 0.5,\n                         linetype = 'dashed') +\n              # Etiqueta del peor consumo\n              annotate('text', x = 1.3, y = refs[1]+1,\n                       label = as.character(refs[1]),\n                       colour = 'firebrick') +\n              #Etiqueta del consumo promedio\n              annotate('text', x = 1.3, y = refs[2]+1,\n                       label = as.character(refs[2]),\n                       colour = 'lightslategrey') +\n              # Etiqueta del mejor consumo\n              annotate('text', x = 1.3, y = refs[3]+1,\n                       label = as.character(refs[3]),\n                       colour = 'forestgreen') \n              \nfinal.plot\n\n\n\n\n\n\n\n5.3.6 Extras\nAunque estas modificaciones no necesariamente forman parte del proceso necesario para la visualización que era de nuestro interés, sí que son rutinarias, por lo que vale la pena echarles un ojo.\n\n5.3.6.1 Colores de puntos\nModificar los colores de los puntos. Podemos utilizar la función randomColor(n) de la librería con el mismo nombre. Esta función solamente recibe el número de colores que queremos y los generará de manera aleatoria:\n\naleat <- randomcoloR::randomColor(7)\nfinal.plot + scale_color_manual(name = \"Clase\", values = aleat)\n\n\n\n\nPodemos también especificar una paleta predefinida, utilizando la capa scale_color_brewer():\n\nfinal.plot + scale_color_brewer(type = \"seq\", palette = \"Paired\")\n\n\n\n\nOtra opción es directamente pasar un vector con los nombres de los colores que sean de nuestro interés:\n\ncolor_names <- c(\"red\", \"blue\", \"yellow\", \"black\",\n                 \"dodgerblue\", \"pink\", \"gray\")\nfinal.plot + scale_color_manual(name = \"Clase\", values = color_names)\n\n\n\n\n\n\n5.3.6.2 Tamaño de los puntos\nPara modificar el tamaño de los puntos solamente hay que agregar el argumento size a la capa geom_point, en el cuál indicaremos qué tamaños tomarán los puntos. Puede ser un solo valor:\n\nfinal.plot + geom_point(size = 0.1)\n\n\n\n\nO también a partir de una columna de la base de datos (dividida entre 5 para no obtener únicamente “manchas”):\n\nfinal.plot + geom_point(size = df1$hwy/5)\n\n\n\n\n\n\n5.3.6.3 Tipografías y Exportación de gráficos\nEl manejo de las tipografías en R es un poco especial, por ello usualmente recomiendo generar el gráfico en R, exportarlo como PDF (cairo_pdf(\"filename.pdf\", width, height, family)) y agregar las cursivas donde sea necesario; sin embargo, un paquete que puede resultar especialmente útil es ggtext. Este añade un nuevo “elemento” de texto que recibe formato Markdown (element_markdown()); es decir, podemos agregar itálicas o negritas. Para poder utilizarlo, sin embargo, es necesario modificar ligeramente nuestros datos de antemano. Para facilitarnos las cosas agregaremos una nueva columna a df1 que contenga las clases en itálicas y extraeremos los valores únicos (algo más eficiente sería hacerlo al revés, pero es más lógico de esta manera):\n\ndf1$clase <- paste0(\"*\",df1$class,\"*\")\nclases <- unique(df1$clase)\n\nFinalmente lo agregaremos a la gráfica. ¡OJO! Es necesario modificar el tema para que entienda el formato markdown:\n\nif(!require(ggtext)) {install.packages(\"ggtext\", dependencies = T)}\n\nLoading required package: ggtext\n\nfinal.plot + scale_color_discrete(name = \"Clase\",labels = clases) +\n             theme(legend.text = ggtext::element_markdown())\n\n\n\n\nCon este elemento podemos modificar también fracciones de cualquier texto de nuestra gráfica, por ejemplo carretera en negritas:\n\nfinal.plot + labs(subtitle = \"Consumo en **carretera**\") +\n             theme(plot.subtitle = ggtext::element_markdown())\n\n\n\n\nMezclando ambas modificaciones:\n\nfinal.plot + scale_color_discrete(name = \"Clase\",labels = clases) +\n             labs(subtitle = \"Consumo en **carretera**\") +\n             theme(plot.subtitle = ggtext::element_markdown(),\n                   legend.text = ggtext::element_markdown())"
  }
]