---
title: "Ejercicio Salvavidas/Evaluación final"
author: "AGREGA TU NOMBRE"
output: 
  html_notebook:
    toc: yes
---

## Descripción y carga de los datos:

En este ejercicio final (salvavidas) el objetivo será responder a una serie de preguntas utilizando la base de datos `heart.csv`, la cual consiste en 14 columnas:

- edad: edad del individuo
- sexo: 1: hombre, 0: mujer
- tipo_dolor: 1: angina típica; 2: angina atípica, 3: dolor sin angina, 4: sin síntoma
- p_sang_reposo: Presión sanguínea en reposo (mmHg)
- col_suero: Concentración de colesterol en el suero sanguíneo (mg/dl)
- gluc_ayuno: 0 si es menor a 120 mg/dl, 1 si es mayor
- ecg_reposo: 0: normal; 1: anormalidad en la onda ST-T, 2: hipertrofia ventricular izquierda
- frec_card_max: máxima frecuencia cardiaca alcanzada por el individuo. Valor numérico
- angina_induc: ¿El ejercicio indujo angina? 0: no, 1: sí
- depresion_ST:Bajada del segmento T (ST) en ejercicio vs. reposo. Valor numérico
- max_ST_ejercicio: 1: amplitud positiva, 2: plana, 3: amplitud negativa
- vasos_color: número de vasos sanguíneos mayores coloreados por fluoroscopía (1-3)
- thal: Talasemia. 3: normal, 6: defecto corregido, 7 defecto reversible.
- enfermedad: Describe la ausencia (0) o presencia de enfermedades cardiacas (1,2,3,4)

```{r}
col_names = c('edad', 'sexo', 'tipo_dolor', 'p_sang_reposo', 'col_suero', 'gluc_ayuno', 'ecg_reposo', 'frec_card_max', 'angina_induc', 'depresion_ST', 'max_ST_ejercicio', 'vasos_color', 'thal', 'enfermedad')
heart <- read.csv("heart.csv", col.names = col_names)
head(heart)
```


A lo largo de las siguientes secciones encontrarás una serie de preguntas relacionadas con las temáticas vistas a lo largo del curso. De manera general, todas las respuestas deberán contenidas en céldas de código (salvo los casos en los que se solicite una interpretación de los resultados). Además de las celdas incluidas en esta libreta, puedes agregar las que consideres necesarias (una para el procesamiento de los datos y otra para el graficado, por ejemplo.)

## Criterios de evaluación
1. Se deberán de **entregar** ambas versiones de la libreta; es decir, tanto el **archivo .Rmd** (deberá ejecutarse sin errores) como el **archivo .html** (correctamente renderizado). Entregar cada uno representa el 25% de la calificación final (ambos suman el 50%)
2. Las salidas finales del código de cada respuesta deberán a) mostrarse en cada celda (ver ejemplo), b) tener el tipo de objeto indicado y c) contar con las características solicitadas. La falta de cada uno de estos tres criterios implica una penalización del 1/3 respecto a la ponderación de cada pregunta, asumiendo que el resultado sea correcto; es decir, si la conclusión de la pregunta es la correcta, se almacenó en el tipo de objeto solititado (*e.g.* un data.frame), pero no se muestra la salida en la libreta, esa respuesta valdrá 2/3 de su puntuación correspondiente.
3. En los casos en los que apliques una prueba de hipótesis de nulidad se espera que se incluya a) el juego de hipótesis ($H_0$ y $H_A$) y b) la verificación de sus supuestos.
4. Siguiendo con el punto anterior, los resultados de la prueba deberán de **reportarse** en la descripción de manera adecuada (estadístico de prueba(grados de libertad) = X, p = xxx; *e.g.* ANOVA de una vía: $F_{(2,18)} = 13.082$, p = 0.003), con máximo 3 decimales.
5. En los casos en los que apliques una Regresión Lineal (Simple o Múltiple) o un Análisis Discriminante, deberás de verificar si el modelo está o no sobre o infra ajustado, de lo contrario el reactivo será dado por incorrecto.
6. **La nota aprobatoria será 80/100**, lo cual representa el criterio para la obtención de la **constancia**.
7. **Puedes solicitar asesorías** para la resolución de dudas u orientación sobre alguna de las preguntas; SIN EMBARGO, las preguntas deberán de estar bien estructuradas (*i.e.*, no solicitar la clase completa nuevamente). Al igual que en las tareas anteriores, esperamos que tengas la iniciativa de recabar información adicional a la vista en el curso para lograr resolver las distintas preguntas de la manera que mejor consideres posible.
8. Debido a que se establecerá una fecha límite de entrega entre todos, **NO habrá posibilidad de entrega a destiempo** (a menos de que exista un justificante).
9. El modo de entrega será Google Classroom, en el cual se incluirá una copia de estos comentarios. Además, se incluirá una rúbrica en la que se indicará, al igual que aquí, la ponderación de cada pregunta.

#### Diagrama de flujo con respecto a la evaluación de los reactivos:

## Ejemplo:

0. ¿Cuál es el tipo de las variables sexo, angina_inducida, vasos_color, frec_card_max, enfermedad? La respuesta debe de ser un **vector nombrado** cuyos valores son los tipos de la variable. De estas, menciona AL MENOS dos variables que tengan tipo numeric o integer y que en realidad sean variables categóricas (justifica tu respuesta).
```{r}
# INCORRECTO:
#str(heart)

# CORRECTO:
tipos <- c(sexo = typeof(heart$sexo), angina_inducida = typeof(heart$angina_induc), vasos_color = typeof(heart$vasos_color), frec_card_max = typeof(heart$frec_card_max), enfermedad = typeof(heart$enfermedad))
print(tipos)
```

- Las variables que deberían ser categóricas son a) sexo, ya que son hombres o mujeres; b) angina_inducida, ya que es verdadero (1) o falso (2); c) enfermedad, ya que indica la presencia (1, 2, 3, 4) o ausencia (0) de enfermedades cardicas.

## Sección 1: Fundamentos

1. ¿Cuántas observaciones (instancias) hay en la base de datos? La salida deberá de ser un solo número.
```{r}
# Tu código va aquí
length(heart$edad)
dim(heart)[1]
```

2. Estima las medias e intervalos de confianza de las variables para las que tenga sentido hacerlo. Preséntalas en un **DataFrame** cuyas columnas sean: variable, media, IC_i, IC_s
```{r}
# Tu código va aquí
library(Rmisc)
vars <- c("p_sang_reposo", "col_suero", "frec_card_max", "depresion_ST")
no_cat <- heart[,vars]

IC <- data.frame(variable = rep(NA, length(vars)), media = rep(NA, length(vars)), IC_i = rep(NA, length(vars)), IC_s = rep(NA, length(vars)))

for (i in 1:length(vars)) {
  
  IC[i,] <- c(vars[i], round(CI(no_cat[,i])["mean"], 2), round(CI(no_cat[,i])["lower"], 2), round(CI(no_cat[,i])["upper"],2))
}

IC
```

3. Realiza un gráfico de **densidad** (KDE) de la variable `p_sang_reposo`. Sigue las heurísticas vistas en el tema de representaciones de la realidad. ¿Observas alguna tendencia/patrón?
```{r}
# Tu código va aquí
# Tema personalizado
library(ggplot2)
blank_theme <- function(aspect.ratio = 1/1.61){
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank(),
        axis.line = element_blank(),
        aspect.ratio = aspect.ratio,
        axis.ticks = element_blank(),
        text = element_text(colour = "gray50"), # Eliminar
        legend.position = "none"
        )
}
# Graficado
k.dens.plot <- ggplot(data = heart, aes(p_sang_reposo)) + 
               geom_density(color = "deepskyblue4", fill = "deepskyblue4", alpha = 0.5) + 
               geom_vline(xintercept = mean(heart$p_sang_reposo), colour = rgb(118,78,144, maxColorValue = 255)) + 
               blank_theme() +
               labs(title = "Gráfico de densidad de la variable p_sang_reposo",
                    subtitle = "Línea vertical representa la media",
                    caption = "Datos: heart.csv",
                    x = element_blank(),
                    y = element_blank()) +
               scale_y_continuous(breaks = NULL)
k.dens.plot
```
- La variable no es simétrica respecto a su media, con una cola más pesada hacia los valores más altos
4. Realiza un gráfico de *distribución de frecuencias* de la variable `thal`. Sigue las heurísticas vistas en el tema de representaciones de la realidad. ¿Observas alguna tendencia/patrón?¿La cantidad de individuos en cada nivel es similar? 
```{r}
# Tu código va aquí
# Graficado
freque.plot <- ggplot(data = heart, aes(thal)) + 
               geom_bar(colour = NA, fill = "deepskyblue4", alpha = 0.5) +
               blank_theme() +
               labs(title = "Gráfico de distribución de frecuencias de la variable thal",
                    caption = "Datos: heart.csv",
                    x = element_blank(),
                    y = element_blank()) +
               scale_y_continuous(breaks = NULL)
freque.plot
```
- La clase 6 está sub representada, mientras que la clase 3 es la mejor representada.

5. ¿Cuál es la diferencia entre los gráficos de distribución de frecuencias y los histogramas? ¿Cuál es la diferencia entre los gráficos de distribución de frecuencias y los gráficos de densidad? 

- Los gráficos de distribución de frecuencias nos permiten ver cómo están repartidos el número de individuos (altura de las barras) en relación a un intervalo FIJO, mientras que los histogramas tienen amplitudes de clase distintas.

6. ¿Cuál es la ventaja de utilizar un gráfico KDE con respecto a uno de distribución de frecuencias al tratarse de una variable continua?

- Que los intervalos se vuelven infinitesimalmente pequeños, por lo que es una representación más fiel de la distribución.

## Sección 2: Herramientas básicas para el análisis de datos

1. Aplica una prueba t de Student para comparar el colesterol en suero (`colesterol_suero`) entre hombres (sexo = 1) y mujeres (sexo = 0). Integra los resultados en un *vector nombrado* cuyos valores sean `t`, `df`, `p`. ¿Qué concluyes? ¿Hay algún sesgo en la inferencia? ¿Qué representa el IC que nos muestra la salida completa del análisis?
```{r}
library(car)

# Normalidad

s.1 <- shapiro.test(heart$col_suero[heart$sexo == 1])
s.2 <- shapiro.test(heart$col_suero[heart$sexo == 0])
print("Normalidad")
print(paste("Hombres: W = ", round(s.1$statistic, 2), " p = ",round(s.1$p.value, 2)))
print(paste("Mujeres: W = ", round(s.2$statistic, 2), " p = ",round(s.2$p.value, 5)))

# Homocedasticidad
l.1 <- leveneTest(col_suero~as.factor(sexo), data = heart)
print("Homocedasticidad")
print(paste("F = ", round(l.1$`F value`[1],2), 
            "g.l =", l.1$Df[1], ",", l.1$Df[2], 
            "; p = ", round(l.1$`Pr(>F)`[1],3)
            )
      )
# Tu código va aquí
t.res <- t.test(heart$col_suero[heart$sexo == 1], heart$col_suero[heart$sexo == 0])
print("Resultados prueba t")
t.sum <- c(t.res[["statistic"]], t.res[["parameter"]], p = t.res[["p.value"]])
t.sum
```
- Considerando a $\alpha = 0.05$ como el límite absoluto para el error de tipo 1, existen diferencias significativas entre las [colesterol] en suero de hombres y mujeres.
- Debido a que los datos de las mujeres no se ajustan a una distribución normal y que las muestras no son homocedásticas, posiblemente una prueba paramétrica no sea la mejor alternativa.
- Representa el intervalo de confianza del tamaño del efecto que, en este caso, es la diferencia de medias.

2. Aplica un ANOVA de una vía para comparar `frec_card_max` entre los niveles de `tipo_dolor`. Agrupa los resultados en un *vector nombrado* con los valores F_val, gl1, gl2, p. ¿Qué concluyes? ¿Dadas las descripciones de los datos, es coherente realizar esta comparación? ¿Es adecuada la prueba según la naturaleza de los datos? ¿Qué grupos presentaron diferencias significativas según la prueba HSD de Tukey? ¿Es necesario aplicar alguna corrección al valor de p?
```{r}
# Tu código va aquí
s.1 <- shapiro.test(heart$frec_card_max[heart$tipo_dolor == 1])
s.2 <- shapiro.test(heart$frec_card_max[heart$tipo_dolor == 2])
s.3 <- shapiro.test(heart$frec_card_max[heart$tipo_dolor == 3])
s.4 <- shapiro.test(heart$frec_card_max[heart$tipo_dolor == 4])

print("Normalidad")
print(paste("1: W = ", round(s.1$statistic, 2), " p = ",round(s.1$p.value, 2)))
print(paste("2: W = ", round(s.2$statistic, 2), " p = ",round(s.2$p.value, 2)))
print(paste("1: W = ", round(s.3$statistic, 2), " p = ",round(s.3$p.value, 5)))
print(paste("2: W = ", round(s.4$statistic, 2), " p = ",round(s.4$p.value, 2)))

# Homocedasticidad
l.1 <- leveneTest(frec_card_max~as.factor(tipo_dolor), data = heart)
print("Homocedasticidad")
print(paste("F = ", round(l.1$`F value`[1],2), 
            "g.l =", l.1$Df[1], ",", l.1$Df[2], 
            "; p = ", round(l.1$`Pr(>F)`[1],3)
            )
      )

# ANOVA
aov.1 <- aov(frec_card_max~as.factor(tipo_dolor), data = heart)
sum.1 <- summary(aov.1)
aov.res <- c(F_val = (sum.1[[1]]["F value"][1,1]), gl1 = (sum.1[[1]]["Df"][1,1]), gl2 =(sum.1[[1]]["Df"][2,1]), p = (sum.1[[1]]["Pr(>F)"][1,1]))
aov.res
```
- Al menos una de las medias de frec_card_max es significativamente diferente a las demás
- Tiene sentido desde la perspectiva de que un esfuerzo cardiaco alto (alta frecuencia cardiaca) puede llevar a sentir dolor en el pecho, y tal vez diferentes tipos de dolor de pecho estén relacionados con diferentes valores de frecuencia cardiaca máxima
```{r}
TukeyHSD(aov.1)
```
- Las comparaciones significativamente distintas fueron entre los tipos 4-1, 4,2 y 4-3; es decir, que aquellos pacientes que no presentaron ningún tipo de dolor (grupo 4) presentaron valores de frecuencia cardiaca máxima consistentemente menores (intervalos de confianza de las diferencias negativos) a los demás, aunque no hubo diferencias entre aquellos que sí presentaron algún tipo de dolor.
- No es necesario aplicar ninguna corrección ya que la prueba HSD de Tukey fue diseñada con el propósito de mantener bajo control la tasa de error de la familia de pruebas (FWER)

3. ROBERTO ...

## Sección 3: Modelación lineal y GLMs
1. Muestra gráficamente las correlaciones de *PEARSON* entre las variables **no categóricas**. ¿Qué observas? ¿Hay algún par de variables para los cuales sería mejor realizar una correlación de *SPEARMAN*?
```{r}
# Tu código va aquí
library(corrplot)
corrplot(cor(no_cat), method = "ellipse", type = "lower", tl.col = "lightslategray")
```
- La depresión en el segmento T está negativamente correlacionada con la frecuencia cardiaca máxima y positivamente relacionada con la presión sanguínea en reposo
- Ya que ninguna de estas variables es ordinal, el coeficiente de correlación de Spearman es el adecuado.

2. Considerando los resultados del punto anterior, realiza una regresión lineal simple entre las *dos variables MÁS correlacionadas*. ¿Cuáles son los coeficientes de la regresión? ¿Qué concluyes a partir de la pendiente? ¿El modelo describe de manera aceptable la relación entre estas variables? Grafica la regresión con los intervalos de confianza *para el ajuste*. Realiza *al menos* un gráfico diagnóstico de la regresión y describelo brevemente. 
```{r}
# Tu código va aquí
# Entrenamiento-Prueba
library(caTools)
set.seed(111)
samples <- sample.split(no_cat$frec_card_max, SplitRatio = 0.75)
train <- subset(no_cat, samples == TRUE)
test <- subset(no_cat, samples == FALSE)

# Ajuste del modelo lineal simple:
rls <- lm(frec_card_max~depresion_ST, data = train)
summary(rls)
```
- Los coeficientes son: intercepto = 157.14 y pendiente = -7.32
- La línea inicia en 157.14 pulsaciones por minuto y disminuye a una tasa de 7.32 pulsaciones/min por cada unidad de depresión en el segmento T.
- El valor de R2 sugiere que el modelo NO está describiendo adecuadamente la relación entre ambas variables. Tomando en cuenta que el modelo se entrenó a partir de los datos de entrenamiento, podemos concluir que el modelo está infra-ajustado, lo cual es más que evidente al ver el gráfico de dispersión.
```{r}
conf.plot.reg1 <- ggplot(data = train, aes(x = depresion_ST, y = frec_card_max)) +
                  geom_point(color = "deepskyblue4", alpha = 0.4, size = 2) + 
                  geom_smooth(method = lm, colour = rgb(118,78,144, maxColorValue = 255)) +
                  labs(title = "Regresión lineal simple de frec_card_max con respecto a depresion_ST",
                       caption = "Datos: heart.csv. El área gris representa el intervalo de confianza de la regresión al 95%",
                       subtitle = paste("Modelo ajustado: v2 = ", 
                                   round(rls$coefficients[1],2), 
                                   " + ",
                                   round(rls$coefficients[2],2),
                                   "*v1 + e"),
                       x = element_blank(),
                       y = element_blank()) +
                  blank_theme()
conf.plot.reg1
```

```{r}
# Gráfico de residuales
resid.df <- data.frame(train$frec_card_max, train$depresion_ST)
resid.df["ajustados"] <- rls$fitted.values
resid.df["std.resids"] <- rstandard(rls)

resid.plot <- ggplot(data = resid.df, aes(x = ajustados, y = std.resids, colour = std.resids)) + 
              geom_point(size = 3, alpha = 0.5) +
              stat_smooth(method = "loess", colour = rgb(118,78,144, maxColorValue = 255)) + 
              geom_hline(yintercept = 0, col = "red", linetype = "dashed") +
              labs(title = "Gráfico de Residuales",
                   x = "Valores ajustados",
                   y = "Residuales estandarizados") +
              blank_theme() +
              scale_color_gradient2(low = "firebrick", 
                                    midpoint = 0, 
                                    mid = "deepskyblue4", 
                                    high = "firebrick",
                                    breaks = c(-2, 0, 2),
                                    limits = c(-2, 2),
                                    oob = scales::squish)
resid.plot
```
- Ambas variables son heterocedásticas y no normales, ya que es posible visualizar un cono con vértice en el lado izquierdo de la gráfica y una gran cantidad de datos aberrantes.

3. Considerando los resultados del punto 1 de esta sección, realiza un gráfico de dispersión entre las *dos variables MENOS correlacionadas*. De existir una relación aparente, ¿de qué tipo es (monótona o no monótona)? Incluye en el gráfico el valor de la covarianza. ¿Qué concluyes a partir de él? ¿En qué difiere respecto a la correlación?
```{r}
disp.plot <- ggplot(data = no_cat, aes(x = frec_card_max, y = col_suero)) +
             geom_point(color = "deepskyblue4", alpha = 0.4, size = 2) +
             blank_theme() +
             labs(title = "Gráfico de dispersión de col_suero con respecto a frec_card_max",
                  subtitle = paste("Cov = ", round(cov(no_cat$col_suero, no_cat$frec_card_max))),
                  caption = "Datos: heart.csv",
                  x = element_blank(),
                  y = element_blank()) #+
            #scale_y_continuous(limits = c(min(no_cat$col_suero), 400))

disp.plot
```
- No existe una relación evidente entre estas variables, aunque hay una tendencia no monótona.

4. GLM (ROBERTO)
.
.
.

## Sección 4: Estadística no paramétrica y modelación no lineal
1. Realiza la misma comparación que en la pregunta 1 de la sección 2 mediante una prueba U de Mann-Whitney y almacena los resultados en un vector nombrado con los valores de W y p. ¿Cambian los resultados? ¿Con cuál de las dos aproximaciones te quedas? ¿Por qué?
```{r}
 # Tu código va aquí
u.res <- wilcox.test(heart$col_suero[heart$sexo == 1], heart$col_suero[heart$sexo == 0])
print("Resultados prueba U de Mann-Whitney")
u.sum <- c(u.res[["statistic"]], p = u.res[["p.value"]])
u.sum
```
- No cambian los resultados, en el sentido de que a un $\alpha = 0.05$ estricto hay diferencias significativas en las medianas de los grupos.
- Tomando en consideración los resultados de las pruebas de normalidad y homocedasticidad presentados en la sección 1 sería fácil decidirse por la aproximación no paramétrica; sin embargo, la prueba t de Student/Welch es bastante robusta aún en una situación de no normalidad y la prueba t de Welch aplicada fue diseñada para casos en los que las muestras fueran heterocedásticas; por tanto, y en vista de que los resultados no cambian, me quedaría con la aproximación paramétrica.

2. Realiza la misma comparación que en la pregunta 2 de la sección 2 utilizando una aproximación no paramétrica. Guarda los resultados en un vector nombrado cuyos valores sean ji.2, gl, p. ¿Cuál de los dos ANOVAs no paramétricos aplicas y por qué? ¿Cambia la conclusión a la que llegas después de aplicar la prueba? ¿Cuál de las dos consideras como la mejor de las dos aproximaciones (paramétrica o no paramétrica)?
```{r}
# Tu código va aquí
# ANOVA Kruskal-Wallis
kw.1 <- kruskal.test(frec_card_max~as.factor(tipo_dolor), data = heart)

kw.res <- c(ji.2 = unname(kw.1["statistic"]$statistic), gl = unname(kw.1["parameter"]$parameter), p = unname(kw.1["p.value"]$p.value, 10))
kw.res
```

3. Modelación no lineal (ROBERTO)
.
.
.

## Sección 5: Análisis Multivariado
1. Genera un nuevo `data.frame` con cada variable *NO CATEGÓRICA* centrada y escalada. Grafica las distribuciones utilizando un gráfico de densidad (KDE) para cada una. ¿Qué representan los valores del eje x? Si realizaras el mismo gráfico sin las variables sin transformar, ¿esperarías ver alguna diferencia en la forma de la distribución?
```{r}
# Código
library(gridExtra)
no_cat_cen <- as.data.frame(scale(no_cat))

psangr.plot <- ggplot(data = no_cat_cen, aes(p_sang_reposo)) + 
               geom_density(color = "deepskyblue4", fill = "deepskyblue4", alpha = 0.5) + 
               blank_theme() +
               labs(subtitle = "p_sang_reposo escalada",
                    caption = "Datos: heart.csv",
                    x = element_blank(),
                    y = element_blank()) +
               scale_y_continuous(breaks = NULL)

colsue.plot <- ggplot(data = no_cat_cen, aes(col_suero)) + 
               geom_density(color = "deepskyblue4", fill = "deepskyblue4", alpha = 0.5) + 
               blank_theme() +
               labs(subtitle = "col_suero escalada",
                    caption = "Datos: heart.csv",
                    x = element_blank(),
                    y = element_blank()) +
               scale_y_continuous(breaks = NULL)

freccm.plot <- ggplot(data = no_cat_cen, aes(frec_card_max)) + 
               geom_density(color = "deepskyblue4", fill = "deepskyblue4", alpha = 0.5) + 
               blank_theme() +
               labs(subtitle = "frec_card_max escalada",
                    caption = "Datos: heart.csv",
                    x = element_blank(),
                    y = element_blank()) +
               scale_y_continuous(breaks = NULL)

deprst.plot <- ggplot(data = no_cat_cen, aes(depresion_ST)) + 
               geom_density(color = "deepskyblue4", fill = "deepskyblue4", alpha = 0.5) + 
               blank_theme() +
               labs(subtitle = "depresion_ST escalada",
                    caption = "Datos: heart.csv",
                    x = element_blank(),
                    y = element_blank()) +
               scale_y_continuous(breaks = NULL)
grid.arrange(psangr.plot, colsue.plot, freccm.plot, deprst.plot)


```
- Los valores del eje X representan el número de desviaciones estándares con respecto a la media a las que se encuentra un valor
- La distribución de los valores sería la misma, ya que al centrar y escalar las variables NO se modifica la forma de la distribución.

2. Realiza una comparación multivariada en la que incluyas todas las variables **NO CATEGÓRICAS**, considerando a los grupos como los niveles de la variable enfermedad. ¿existen diferencias en las mediciones multivariadas de estos grupos? ¿Cuáles son las dos variables en las que existen mayores diferencias/explican mejor la repartición del espacio multivariado?
```{r}
# Código
nc.enf <- data.frame(no_cat, enfermedad = as.factor(heart$enfermedad))

res.man <- manova(as.matrix(nc.enf[,1:4])~as.factor(nc.enf$enfermedad))
summary.manova(res.man, test = "Wilks")
summary.aov(res.man)
```
```{r}
library(vegan)
dist.mat <- vegdist(nc.enf[,1:4], method = "euclidean")
grps <-as.factor(nc.enf$enfermedad)
adonis2(dist.mat~nc.enf$p_sang_reposo + nc.enf$col_suero + nc.enf$frec_card_max + nc.enf$depresion_ST, data = grps, permutations = 999)
```
- Tanto el MANOVA como el PERMANOVA sugieren diferencias en las mediciones multivariadas; sin embargo, dada la naturaleza sesgada de algunas variables incluidas en el análisis la mejor alternativa es el PERMANOVA. En este sentido, las dos variables más importantes son col_suero y frec_card_max, dados los valores de R2 y de sumas de cuadrados. Ambos contrastes fueron significativos a un $\alpha$ de 0.05; aún corrigiendo al menor número de contrastes (sin interacciones). Se descartan los efectos de interacción debido a que la suma de cuadrados de los residuales es 0.

3. Acompaña el análisis del punto anterior con a) un gráfico de coordenadas paralelas *O* b) un gráfico de NMDS. ¿Concuerda la visualización con los resultados de la prueba del punto anterior?
```{r}
# Código
iris.mds <- metaMDS(dist.mat, distance = "euclidean", k = 2, trace = F)
mds.dims <- data.frame(NMDS1 = iris.mds$points[,1], NMDS2 = iris.mds$points[,2])
mds.plot.data <- cbind(mds.dims, nc.enf)
# Extraemos las correlaciones de cada factor con cada dimensión reducida (flechas)
fit <- envfit(iris.mds, nc.enf)
arrow <- data.frame(fit$vectors$arrows, R = fit$vectors$r, P = fit$vectors$pvals)
arrow["Variable"] <- rownames(arrow)
arrow.p <-subset(arrow, P <= 0.05)

mds.plot <- ggplot(mds.plot.data, aes(NMDS1, NMDS2)) +
            geom_point(aes(color = as.factor(enfermedad)), alpha = 0.7) +
            stat_ellipse(aes(fill = as.factor(enfermedad)), type = "t", size = 1, geom = "polygon", alpha = 0.2) + 
            labs(title = "Escalamiento Multidimensional no métrico (NMDS)",
                 subtitle = paste('Estrés =',round(iris.mds$stress,3)),
                 caption = "Datos: heart.csv") +
            blank_theme() + theme(legend.position = "right") +
            geom_segment(data = arrow.p, 
                         aes(x=0, y=0, xend = NMDS1, yend = NMDS2, lty = Variable), 
                         arrow = arrow(length = unit(.2, "cm")) #Flechas escaladas según su R^2
                         )
mds.plot
```
```{r}
library(GGally)
coord.plot <- ggparcoord(nc.enf, 
                         columns = 1:4, 
                         groupColumn = 5, 
                         showPoints = T, 
                         scale = "std", 
                         order = "anyClass", 
                         alphaLines = 0.5) + 
               blank_theme(1/1.61) +
               labs(title = "Gráfico de coordenadas paralelas",
                    subtitle = "Valores escalados",
                    y = element_blank(),
                    x = element_blank(),
                    caption = "Datos: heart.csv") +
               theme(legend.position = "right")
coord.plot
```
- Aunque ambas pruebas sugirieron diferencias en algunas de las variables, vistas desde el punto de vista multivariado esto no parece ser cierto, ni en términos de distancias (NMDS representan bien las distancias, Estrés menor a 0.1) ni en el gráfico de coordenadas paralelas. Faltaría hacer el análisis univariado para compbrobar.

4. Realiza una regresión lineal múltiple SIN regularizar en la que la variable de respuesta sea el frec_card_max y los predictores sean las variables **NO CATEGÓRICAS** restantes. ¿Cuántas y cuáles variables incluyes en el análisis? ¿Aplicarías un modelo regularizado (Lasso o Ridge)? ¿Cuáles serían las diferencias entre los efectos de ambas regularizaciones? ¿
```{r}
# Código
rlm <- lm(frec_card_max~., data = no_cat_cen) # Variables escaladas debido a la diferencia de magnitudes
sum.rlm <- summary(rlm)
sum.rlm
```
- Se incluyen tres variables: col_suero, frec_card_max y depresion_ST
- Sí aplicaría un modelo regularizado, aunque considerando el caso de una sola variable de la sección 3 (regularizar y solo mantener una variable) no habría ganancias importantes en poder predictivo.
- Las diferencias serían que el modelo Ridge mantendría todos los coeficientes, haciendo aún más pequeños algunos; mientras que, el modelo Lasso posiblemente únicamente extraería un coeficiente diferente de 0.

5. Partiendo de la regresión del punto anterior, guarda en un *data frame* los coeficientes de la regresión (columna coef) y los niveles de significancia de sus pruebas t (columna p). ¿Qué representan estos valores de p? Tomando ese criterio, ¿qué variables fueron las mejores predictoras? ¿existe alguna relación con el gráfico de correlaciones de la sección 3?
```{r}
# Código
coef.df <- data.frame(coef = sum.rlm$coefficients[,1], p = round(sum.rlm$coefficients[,4], 2))
coef.df
```
- La única variable con un coeficiente significativamente diferente de 0 fue depresion_ST, la variable más correlacionada con frec_card_max según el gráfico de correlaciones.

6. Reporta los resultados del ANOVA de la regresión. ¿Qué representa esta prueba de hipótesis? Tomando eso en cuenta, ¿Cómo interpretas estos resultados?

- El ANOVA de la regresión fue significativo a un $\alpha$ de 0.001: $F_{3, 298} = 13.38$, p < 0.001. Esta prueba de hipótesis representa el contraste del modelo contra un modelo nulo; por lo tanto, al menos uno de los coeficientes es significativamente diferente de 0


7. Realiza un Análisis de Funciones Discriminantes considerando todas las variables **NO CATEGÓRICAS** en el que predigas las categorías de la variable enfermedad. A partir de la matriz de confusión, ¿el modelo funciona adecuadamente? ¿cuál es la variable más importante para la primera función discriminante?

```{r}
# Código
library(MASS)
library(caret)
set.seed(111)

nc.enf.ad <- data.frame(no_cat, enfermedad = nc.enf$enfermedad)

# División entrenamiento-prueba

samples <- sample.split(nc.enf.ad$enfermedad, SplitRatio = 0.75)
train <- subset(nc.enf.ad, samples == TRUE)
test <- subset(nc.enf.ad, samples == FALSE)

# Centrado y estandarizado de los datos
pre.pars <- preProcess(train, method = c("center", "scale"))
train.t <- predict(pre.pars, train)
test.t <- predict(pre.pars, test)

# LDA
mod.lda <- lda(enfermedad~., data = train.t)
mod.lda
```
- Tomando en cuenta el resultado de las comparaciones multivariadas no se rechaza el modelo de funciones discriminantes. La varianza explicada por cada función discriminante sugiere que las primeras dos dimensiones explicaron más del 96% de la varianza.
- La variable más importante para la primera función fue depresion_ST

```{r}
confusionMatrix(predict(mod.lda, test.t)$class, test.t$enfermedad)
```
- Al realizar la evaluación a partir de los datos de PRUEBA es posible observar que aunque la clase 0 parece estar siendo clasificada adecuadamente, las clasificaciones no son diferentes de emitir siempre a la clase mayoritaria (p[acc > NIR] = 0.36); por lo tanto, el modelo de funciones discriminantes no está distinguiendo adecuadamente entre las clases. 

8. Codifica la variable enfermedad de modo que solamente tengas dos categorías: 0 (ausencia) y 1 (presencia) y realiza un análisis de Funciones Discriminantes (solo variables no categóricas). ¿Hay mejorías en el desempeño del modelo? ¿Por qué? (toma en consideración los resultados de la comparación multivariada) ¿Cambió la variable más importante?

```{r}
nc.cod <- data.frame(no_cat, enfermedad = nc.enf$enfermedad)
nc.cod$enfermedad <- ifelse(nc.cod$enfermedad == 0, 0, 1)

# División entrenamiento-prueba

samples <- sample.split(nc.cod$enfermedad, SplitRatio = 0.75)
train <- subset(nc.cod, samples == TRUE)
test <- subset(nc.cod, samples == FALSE)

# Centrado y estandarizado de los datos
pre.pars <- preProcess(train[,1:4], method = c("center", "scale"))
train.t <- predict(pre.pars, train[,1:4])
test.t <- predict(pre.pars, test[,1:4])

# LDA
mod.lda.cod <- lda(train$enfermedad~., data = train.t)
mod.lda.cod
```
```{r}
# Matriz de confusión:
# matriz de confusión

confusionMatrix(predict(mod.lda.cod, test.t)$class, as.factor(test$enfermedad), positive = "1")
```
- Existe una mejora notable en el desempeño del modelo, lo cual puede observarse desde distintas métricas. La primera es que la TNI ahora es del 50%; es decir, las clases están balanceadas. La segunda es que la p[Acc>NIR] << 0.001, lo cual sugiere que las clasificaciones difieren significativamente de un modelo que solo prediga la clase mayoritaria. Es importante notar que la evaluación se realizó a partir de los datos de prueba. Las razones de esta mejoría, desde el punto de vista multivariado, posiblemente se deban a que las 4 categorías positivas de enfermedad se encuentran fuertemente traslapadas unas con otras, mientras que tienden a segregarse de la categoría negativa.

```{r}
confusionMatrix(predict(mod.lda.cod, train.t)$class, as.factor(train$enfermedad), positive = "1")
```

- Es posible ver también que el modelo no se encuentra sobreajustado, ya que la precisión (tanto nominal como con la Kappa de Cohen) con los datos de prueba es ligeramente superior a la de los datos de entrenamiento.

## Sección 6: BONUS: Clasificación utilizando una regresión logística
Resuelve este ejercicio por 3 (TRES) puntos extra en el examen; es decir, si realizas esta sección correctamente, la libreta no presenta errores de ejecución y el html está renderizado adecuadamente, estás aprobado. De estos 3 puntos, cada pregunta conceptual tiene un valor del 10% y cada pregunta con código tiene un valor del 20%.

1. Explica, en tus propias palabras, en qué consiste la regresión logística. Agrega dos fuentes bibliográficas.

2. ¿Qué similitudes/diferencias tiene frente al análisis de funciones discriminantes? ¿Tiene algún supuesto sobre la distribución/naturaleza de los datos? (De no haber citado fuentes en la pregunta anterior incluye dos)

3. ¿Podemos utilizar algún tipo de regularización (L1 o L2)? (De no haber citado fuentes en las preguntas anteriores incluye dos)

4. ¿Cuáles son los parámetros a modificar si queremos optimizar el modelo (de haberlos)? (De no haber citado fuentes en las preguntas anteriores incluye dos)

5. Realiza una regresión logística para predecir la presencia (1) o ausencia (0) de enfermedades cardiacas. ¿Cuál es la precisión alcanzada por el modelo? (OJO con el sobreajuste).
```{r}
# Código
```


6. Realiza la regresión logística para predecir todos los niveles de la variable enfermedad (sin codificar). ¿Qué precisión alcanza el modelo? (OJO con el sobreajuste)

```{r}
# Código
```

7. Presenta los resultados de la clasificación binaria de manera gráfica. ¿Qué tan pronunciada es la separación entre las clases?
```{r}
# Código
```

