---
title: "Hipótesis Múltiples y Multivariadas"
author: "M. en C. Arturo Bell Enríquez García"
output: 
  distill::distill_article:
    toc: true
    toc_float: true
    code_download: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(R.options = list(width = 80))
```

**[VIDEO](https://youtu.be/qAIYfF1rxfo)**

## Funciones personalizadas

```{r}

# Tema personalizado
blank_theme <- function(aspect.ratio = 1/1.61){
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank(),
        axis.line = element_blank(),
        aspect.ratio = aspect.ratio,
        axis.ticks = element_blank(),
        text = element_text(colour = "gray50"), # Eliminar
        legend.position = "none"
        )
}

```


# Múltiples hipótesis: FWER
## Corrección de Bonferroni

La probabilidad de encontrarnos con al menos un error de tipo 1 al realizar múltiples comparaciones independientes incrementa a una tasa de $1-(1-\alpha)^m$, donde m es el número de comparaciones. Grafiquemos este cambio:


```{r}
library(ggplot2)

error <- data.frame(m = 1:20)
error["P_alpha"] <- 1 - (1-0.05)^error$m

error.rate <- ggplot(data = error, aes(m, P_alpha)) + 
              geom_line(color = rgb(118,78,144, maxColorValue = 255)) +
              scale_y_continuous(breaks = NULL) +
              scale_x_continuous(breaks = c(1, 2, 5, 10, 20)) +
              expand_limits(y = c(0,1)) +
              blank_theme() +
              geom_hline(yintercept = 0.05,
                         colour = "deepskyblue4", linetype = "dashed") +
              geom_hline(yintercept = 0.5,
                         colour = "firebrick", linetype = "dashed",
                         alpha = 0.5) +
              geom_hline(yintercept = 1,
                         colour = "firebrick", linetype = "dashed",
                         alpha = 0.5) +
              annotate("text", x = 0, y = 0.08,
                       label = "0.05", colour = "deepskyblue4", 
                       alpha = 0.5) + 
              annotate("text", x = 0, y = 0.53,
                       label = "0.5", colour = "firebrick",
                       alpha = 0.5) +
              annotate("text", x = 0, y = 0.97,
                       label = "1", colour = "firebrick",
                       alpha = 0.5) +
              labs(title = "P(error) al incrementar el número de pruebas (m)",
                   subtitle = bquote({1 - (1- alpha)^m}),
                   x = element_blank(),
                   y = element_blank(),
                   caption = "King & Eckersley (2019)"
                   )

error.rate
```

Ahora apliquemos la corrección de Bonferroni, dada por $\alpha/m$, de modo que la ecuación anterior queda formulada como: $1-(1-\alpha/m)^m$

```{r}
error["P_bonf"] <- 1 - (1-(0.05/error$m))^error$m

error.corr <- ggplot(data = error, aes(m, P_bonf)) + 
              geom_line(color = rgb(118,78,144, maxColorValue = 255)) +
              scale_y_continuous(breaks = NULL) +
              scale_x_continuous(breaks = c(1, 2, 5, 10, 20)) +
              expand_limits(y = c(0.04, 0.06)) +
              blank_theme() +
              geom_hline(yintercept = 0.05,
                         colour = "deepskyblue4", linetype = "dashed") +
              geom_hline(yintercept = 0.04,
                         colour = "lightslategray", linetype = "dashed",
                         alpha = 0.5) +
              geom_hline(yintercept = 0.06,
                         colour = "lightslategray", linetype = "dashed",
                         alpha = 0.5) +
              annotate("text", x = 0, y = 0.0505,
                       label = "0.05", colour = "deepskyblue4",
                       alpha = 0.5) + 
              annotate("text", x = 0, y = 0.0405,
                       label = "0.04", colour = "lightslategray",
                       alpha = 0.5) +
              annotate("text", x = 0, y = 0.0595,
                       label = "0.06",colour = "lightslategray",
                       alpha = 0.5) +
              labs(title = "P(error) al corregir según el número de pruebas (m)",
                   subtitle = bquote({1 - (1- (alpha/m))^m}),
                   x = element_blank(),
                   y = element_blank(),
                   caption = "King & Eckersley (2019)"
                   )

error.corr
```

```{r}
set.seed(45)
n <- 1000
robs <- data.frame(z = rnorm(n))
robs["color"] <- ifelse(robs$z < -1.96 | robs$z > 1.96, 
                        "firebrick", "deepskyblue4")

robs.plot <- ggplot(data = robs, aes(z)) + 
             geom_density(color = "deepskyblue4") + 
             blank_theme() + 
             labs(title = 
                    "Observaciones aleatorias a un alpha de 0.05",
                  subtitle = "Bandas indican límites del LS   ",
                  caption = paste(n, " datos simulados"),
                  x = "Z",
                  y = element_blank()
                  ) +
             geom_vline(xintercept = -1.96, 
                        colour = rgb(118,78,144, maxColorValue = 255), 
                        linetype = "dashed"
                        ) +
             geom_vline(xintercept = 1.96, 
                        colour = rgb(118,78,144, maxColorValue = 255), 
                        linetype = "dashed"
                        ) +
             geom_point(aes(x = z, y = 0), 
                        color = robs$color, alpha = 0.3) +
             scale_y_continuous(breaks = NULL) +
             scale_x_continuous(breaks = c(-3, -1.96, -1, 0, 1, 1.96, 3), 
                                labels = 
                                  as.character(c(-3, -1.96, -1, 0, 1, 1.96, 3))
                                ) +
             annotate("text", x = 3, y = 0.5, 
                      label = paste("# sign = ", 
                                    length(robs$color[robs$color ==
                                                        "firebrick"]),
                                    "/", n),
                      colour = "firebrick"
                      )

robs.plot
```

```{r}
set.seed(45)
n <- 1000
a.corr <- (0.05/n)/2
sig.lev <- abs(qnorm(a.corr))
robs <- data.frame(z = rnorm(n))
robs["color"] <- ifelse(robs$z < -sig.lev | robs$z > sig.lev,
                        "firebrick", "deepskyblue4")

rcor.plot <- ggplot(data = robs, aes(z)) + 
             geom_density(color = "deepskyblue4") + 
             blank_theme() + 
             labs(title = "Observaciones aleatorias a un alpha de 0.05",
                  subtitle = "Bandas indican límites del LS corregido",
                  caption = paste(n, " datos simulados"),
                  x = "Z",
                  y = element_blank()
                  ) +
             geom_vline(xintercept = -sig.lev, 
                        colour = rgb(118,78,144, maxColorValue = 255), 
                        linetype = "dashed"
                        ) +
             geom_vline(xintercept = sig.lev, 
                        colour = rgb(118,78,144, maxColorValue = 255), 
                        linetype = "dashed"
                        ) +
             geom_point(aes(x = z, y = 0), 
                        color = robs$color, alpha = 0.3) +
             scale_y_continuous(breaks = NULL) +
             scale_x_continuous(breaks = c(-3, -1.96, -1, 0, 1, 1.96, 3), 
                                labels =
                                  as.character(c(-3, -1.96, -1, 0, 1, 1.96, 3))
                                ) +
             annotate("text", x = 2.5, y = 0.5, 
                      label = paste("# sign = ", 
                                    length(robs$color[robs$color ==
                                                        "firebrick"]),
                                    "/", n),
                      colour = "firebrick"
                      )

rcor.plot
```

## ANOVA Sheirer-Ray-Hare

Carguemos los datos:

```{r}
mili <- read.csv("data/milipedos.csv")
colnames(mili) <- c("Especie", "Sexo", "Ala")
str(mili)
```

Realicemos la prueba de normalidad para cada nivel de cada variable:

```{r}
norm.mili <- data.frame(grupo = NA, n = NA, W = NA, p = NA)
cols <- colnames(mili)[1:2]
especies <- as.character(unique(mili$Especie))
sexos <- as.character(unique(mili$Sexo))

for (i in seq_along(cols)) {# Cicla entre las columnas indicadas
  if (i == 1) { # Si es la primera columna:
    # Cicla entre los valores de la columa Especies
    for (j in seq_along(especies)) {
      shap <- shapiro.test(mili$Ala[mili[cols[i]] == especies[j]])
      norm.mili[j,] <- c(especies[j],
                         # Tamaño de muestra para esa iteración
                         length(mili$Ala[mili[cols[i]] == especies[j]]), 
                         round(shap$statistic, 2), 
                         round(shap$p.value, 2)
                         )
    }
  }
  if (i == 2) { # Si es la segunda columna
    # Cicla entre los valores de la columna Sexo
    for (k in 1:length(sexos)) {
      shap <- shapiro.test(mili$Ala[mili[cols[i]] == sexos[k]])
      norm.mili[j+k,] <- c(sexos[k], # Sexo de la iteración
                           # Tamaño de muestra para esa iteración
                           length(mili$Ala[mili[cols[i]] == sexos[k]]), 
                           round(shap$statistic, 2), # 
                           round(shap$p.value, 2)
                           )
    }
  }
}

norm.mili
```

Comprobemos la homogeneidad de varianzas. Dado que los datos se ajustaron a una distribución normal, podemos utilizar una prueba de Bartlett:

```{r}
bartlett.test(Ala~Sexo, data = mili)
bartlett.test(Ala~Especie, data = mili)
```

Con la prueba de Levene:

```{r}
library(car)
leveneTest(Ala~Sexo, data = mili)
leveneTest(Ala~Especie, data = mili)
```

Realicemos la prueba Scheirer-Ray-Hare:

```{r}
library(rcompanion)
library(FSA)

scheirerRayHare(Ala ~ Especie + Sexo, data = mili)
```


```{r}
dunnTest(Ala~Especie, data = mili, method = "bonferroni")
```

Bajo este criterio, las diferencias parecieran no ser significativas. Apliquemos entonces el ANOVA de dos vías paramétrico y veamos qué encontramos:

```{r}
res.mili <- aov(Ala~Especie * Sexo, data = mili)
summary(res.mili)
```

¡SORPRESA! Ahora encontramos diferencias en ambos niveles, aunque no se encontró una interacción entre los factores. Realicemos la prueba HSD de Tukey para analizar las diferencias a cada nivel.

```{r}
TukeyHSD(res.mili)$Especie
```

Veamos ahora estos resultados de manera gráfica utilizando un gráfico de interacción:

```{r}
inter.plot <- ggplot(data = mili, aes(x = Sexo, y = Ala, color = Sexo)) + 
              geom_violin() + geom_boxplot(width = 0.1) + 
              facet_wrap(~Especie) + 
              blank_theme(1.61) +
              labs(title = "Interacción de la [Ala] (mg/100 ml) en milípedos",
                   subtitle = "Especie + Sexo",
                   x = element_blank(),
                   y = element_blank(),
                   caption = "Datos: milipedos.csv")
inter.plot
```

La variable Especie sola

```{r}
espec.plot <- ggplot(data = mili, aes(x = Especie, y = Ala, color = Especie)) + 
              geom_violin() + geom_boxplot(width = 0.1) + 
              blank_theme() +
              labs(title = "Interacción de la [Ala] (mg/100 ml) en milípedos",
                   subtitle = "Especie",
                   x = element_blank(),
                   y = element_blank(),
                   caption = "Datos: milipedos.csv")
espec.plot
```

La variable sexo sola

```{r}
sexos.plot <- ggplot(data = mili, aes(x = Sexo, y = Ala, color = Sexo)) + 
              geom_violin() + geom_boxplot(width = 0.1) + 
              blank_theme() +
              labs(title = "[Ala] (mg/100 ml) en milípedos",
                   subtitle = "Especie",
                   x = element_blank(),
                   y = element_blank(),
                   caption = "Datos: milipedos.csv")
sexos.plot
```

### Ejercicio

Realizar un ANOVA Scheirer-Ray-Hare con la base de datos strawberry ([Horst *et al.* 2005](https://doi.org/10.1094/pd-89-1195)). Una base de datos multivariada con medidas de peso, % de Botrytis, % de otras epecies fúngicas y una evaluación de Phomopsis en las hojas para 4 tratamientos con 3 réplicas cada uno.

```{r}
straw <- read.csv("data/strawberry.csv")
rmarkdown::paged_table(head(straw))
str(straw)
summary(straw)
```

Hay un par de elementos con los cuales hay que tener cuidado: 1) las variables tratamiento y réplica son variables categóricas y fueron detectadas como variables de enteros, 2) la variable Eval está en escala *ordinal* no en escala de intervalo o de razón, por lo cual queda automáticamente descartada para pruebas paramétricas. Corrijamos entonces el punto 1:

```{r, results='hide'}
straw$Tratamiento <- factor(LETTERS[straw$Tratamiento])
straw$Rep <- factor(letters[straw$Rep])
head(straw)
```
```{r, echo = FALSE}
rmarkdown::paged_table(head(straw))
```


# Comparaciones Multivariadas
## Datos para comparaciones Mv
1. Base de datos iris. Medidas de 4 variables cuantitativas para 50 flores de cada especie de *Iris*: *setosa*, *versicolor* y *virginica*. Al explorarla vemos que todo está en orden, las cuatro variables cuantitativas fueron detectadas como tal y la única variable categórica fue asignada correctamente:

```{r}
rmarkdown::paged_table(head(iris))
str(iris)
summary(iris)
```


## Prueba $T^2$ de Hotelling
Es una extensión multivariada de la prueba T de Student; por lo tanto, es una prueba paramétrica. Comparemos si las especies *versicolor* y *virginica* son iguales. Para ello es importante revisar los supuestos del análisis:

### Normalidad
```{r}
library(MVN)
mvn(iris, subset = "Species", mvnTest = "mardia",
    desc = F)$multivariateNormality
```

```{r}
mvn(iris, subset = "Species", mvnTest = "hz",
    desc = F)$multivariateNormality
```

```{r}
mvn(iris, subset = "Species", mvnTest = "royston",
    desc = F)$multivariateNormality
```

### Igualdad de dispersión multivariada
Al aplicar la prueba global vemos que al parecer no hay diferencias importantes en las dispersiones multivariadas:

```{r}
library(vegan)
dist.mat <- vegdist(iris[,1:4], method = "euclidean", type = c("median"))
groups <- as.character(iris$Species)
# Realizar el procedimiento
disp.mv <- betadisper(dist.mat, group = groups, type = "median") 
disp.mv
anova(disp.mv) # Prueba de hipótesis
```

La prueba post-hoc confirma los resultados:

```{r}
mod.HSD <- TukeyHSD(disp.mv)
mod.HSD <- data.frame(mod.HSD$group, comp = dimnames(mod.HSD$group)[[1]])
mod.HSD
```

### Comparación Multivariada:
Extraemos dos grupos a comparar:

```{r}
versicolor <- subset(iris, (Species == "versicolor"))[,1:4]
virginica <- subset(iris, (Species == "virginica"))[,1:4]

versi.virg <- subset(iris,
                     (Species == "versicolor") | (Species == "virginica"))
```

Aplicamos la prueba:

```{r}
library(Hotelling)
hot.t2 <- hotelling.test(x = virginica, y = versicolor)
hot.t2
```

Al parecer, los promedios de las mediciones multivariadas son diferentes.

### Comparaciones univariadas
Realizaremos 4 comparaciones univariadas ¿tiene sentido aplicar una corrección de Bonferroni? Algo a notar es que la prueba aplicada en este caso es la prueba de Welch; es decir, una prueba bajo el supuesto de desigualdad de varianzas (muestras heterocedásticas). Para aplicar la prueba T de Student solo hay que agregar el argumento `equal.var = TRUE` a la función.

```{r}
t.test(Sepal.Length~Species, versi.virg)
```

```{r}
t.test(Sepal.Width~Species, versi.virg)
```

```{r}
t.test(Petal.Length~Species, versi.virg)
```

```{r}
t.test(Petal.Width~Species, versi.virg)
```

## Análisis Multivariado de la Varianza
Extensión Multivariada del Análisis de la Varianza; por lo tanto es el equivalente a una prueba $T^2$ de Hotelling con más de dos grupos (al igual que el ANOVA con respecto a la prueba t de Student)

Ahora apliquemos la prueba utilizando la función `Manova()` de la librería `car`

```{r}
model <- lm(cbind(Sepal.Length,
                  Petal.Length,
                  Sepal.Width,
                  Petal.Width)~Species, data = iris)
Manova(model, test.statistic = "Wilks")
```

```{r}
# La forma por defecto de R, con la traza de Pillai
res.man <- manova(cbind(Sepal.Length, Petal.Length, Sepal.Width, Petal.Width)~Species, data = iris)
summary(res.man)
```
```{r}
summary.aov(res.man)
```

La prueba post-hoc es una prueba HSD de Tukey por cada variable. 

```{r}
TukeyHSD(aov(Sepal.Width~Species, data = iris))
```

Veamos un gráfico de violín para cada variable de cada especie:

```{r}
library(gridExtra)

sepall.plot <- ggplot(data = iris, aes(x = Species, y = Sepal.Length, colour = Species)) + 
               geom_violin() + 
               geom_boxplot(width = 0.1) + 
               blank_theme(1/1.61) +
               labs(title = "Sepal length",
                    x = element_blank(),
                    y = element_blank())
sepalw.plot <- ggplot(data = iris, aes(x = Species, y = Sepal.Width, colour = Species)) + 
               geom_violin() + 
               geom_boxplot(width = 0.1) + 
               blank_theme(1/1.61) +
               labs(title = "Sepal width",
                    x = element_blank(),
                    y = element_blank())
petall.plot <- ggplot(data = iris, aes(x = Species, y = Petal.Length, colour = Species)) + 
               geom_violin() + 
               geom_boxplot(width = 0.1) + 
               blank_theme(1/1.61)+
               labs(title = "Petal length",
                    x = element_blank(),
                    y = element_blank())
petalw.plot <- ggplot(data = iris, aes(x = Species, y = Petal.Width, colour = Species)) + 
               geom_violin() + 
               geom_boxplot(width = 0.1) + 
               blank_theme(1/1.61)+
               labs(title = "Sepal width",
                    x = element_blank(),
                    y = element_blank())

grid.arrange(sepall.plot, sepalw.plot, petall.plot, petalw.plot)
```

O veamos un gráfico de coordenadas paralelas, el cual nos permite analizar las mediciones de cada variable de cada individuo en un mismo gráfico:

```{r}
library(GGally)
coord.plot <- ggparcoord(iris, 
                         columns = 1:4, 
                         groupColumn = 5, 
                         showPoints = T, 
                         scale = "std", 
                         order = "anyClass", 
                         alphaLines = 0.5) + 
               blank_theme(1/1.61) +
               labs(title = "Gráfico de coordenadas paralelas",
                    subtitle = "Valores escalados",
                    y = element_blank(),
                    x = element_blank(),
                    caption = "Datos: Iris")
coord.plot
```

## Análisis Permutacional Multivariado de la Varianza:
Los pasos a seguir son básicamente los mismos que los que seguimos para realizar la prueba de homogeneidad de matrices de dispersión. Este supuesto es, debido a la aproximación permutacional, (posiblemente) el supuesto más importante para esta prueba. Es importante notar que existe una corrección para grupos con varianzas no homogéneas.

```{r}
set.seed(1)
n <- 100 # Tamaño de muestra

# Valores observados
tr <- rbinom(100, 1, 0.5) # Distribución binomial con p(éxito) = 50%
y <- 1 + tr + rnorm(n, 0, 3) #Valores de respuesta

s <- sample(tr, length(tr), FALSE) # Muestreo aleatorio sin remplazo 
diff(by(y, s, mean)) # Promedio de las diferencias

# Permutaciones
dist <- data.frame(f = unname(replicate(2000, diff(by(y, sample(tr, length(tr), FALSE), mean)))))
```

```{r}
permut.plot <- ggplot(data = dist, aes(f)) + 
               geom_density(color = "deepskyblue4",
                            fill = "deepskyblue3", alpha = 0.5) + 
               geom_vline(xintercept = 1.3,
                          colour = rgb(118,78,144, maxColorValue = 255)) + 
               blank_theme() +
               labs(title = "Resultados de un experimento permutacional",
                    subtitle = "Distribución de diferencias entre grupos",
                    caption = "Datos simulados",
                    x = element_blank(),
                    y = element_blank())
permut.plot
```

Apliquemos entonces la prueba. Para ello lo primero será calcular la matriz de distancias (de no pasar una matriz de distancias a la prueba hará por default la disimilaridad de Bray-Curtis)

```{r}
# Matriz de distancias
dist.mat <- vegdist(iris[,1:4], method = "euclidean")
# Objeto que contiene los distintos niveles de agrupamiento, anidados o no
grps <- iris[,5]
```

Ahora podemos aplicar el PERMANOVA. De los resultados podemos observar que la principal división entre especies está dada por la longitud del sépalo, seguida por el ancho. Las cuatro variables explican el 100% del espacio multivariado ($R^2$ de los residuales = 0). Una forma compacta de reportar estos resultados sería: "[...] diferencias significativas en la longitud del sépalo ($F_{1, 143}$ = $5.1*10^18$; p < 0.001)"

```{r}
adonis2(dist.mat~iris$Sepal.Length*iris$Sepal.Width+
          iris$Petal.Length*iris$Petal.Width, 
        data = grps, permutations = 999)
```

Veamos la dispersión multivariada:

```{r}
plot(betadisper(dist.mat, grps), hull = F, ellipse = T)
```

Podemos utilizar también un Escalamiento Multi-Dimensional No Paramétrico. Esta técnica es similar al PCA en el sentido de que proyecta un espacio altamente dimensional a un espacio con menos dimensiones (k), tratando de preservar las distancias entre cada punto. En pocas palabras, es una "hoja" o "lámina" de pocas dimensiones dentro de un espacio altamente dimensional.

```{r}
iris.mds <- metaMDS(dist.mat, distance = "euclidean", k = 2, trace = F)
mds.dims <- data.frame(NMDS1 = iris.mds$points[,1],
                       NMDS2 = iris.mds$points[,2])

mds.plot.data <- cbind(mds.dims, iris)

# Correlaciones de cada factor con cada dimensión reducida (flechas)
fit <- envfit(iris.mds, iris)
arrow <- data.frame(fit$vectors$arrows,
                    R = fit$vectors$r, P = fit$vectors$pvals)
arrow["Variable"] <- rownames(arrow)

arrow.p <-subset(arrow, P <= 0.05)
```

Posteriormente podemos graficarlo. El "estrés" representa la fidelidad con respecto al espacio original; entre más alto sea, mayores serán las deformaciones (menor fue el éxito de preservar las distancias). En general, valores de estrés menores a 0.1 se consideran aceptables, menores a 0.05 como una buena representación y por encima de 0.3 indican una "ordenación" arbitraria. En nuestro gráfico, el estrés de 0.02 indica que la representación es fidedigna, que la mayor división entre especies se da en el eje x (usualmente) y que las variables más relacionadas con esa separación son la longitud y el ancho del pétalo, lo cual corresponde perfectamente con lo encontrado por el PERMANOVA.

```{r}
mds.plot <- ggplot(mds.plot.data, aes(NMDS1, NMDS2)) +
            geom_point(aes(color = Species), alpha = 0.7) +
            stat_ellipse(aes(fill = Species),
                         type = "t", size = 1,
                         geom = "polygon", alpha = 0.2) + 
            labs(title = "Escalamiento Multidimensional no métrico (NMDS)",
                 subtitle = paste('Estrés =',round(iris.mds$stress,3)),
                 caption = "Datos: Iris") +
            blank_theme() + theme(legend.position = "right") # +
            # geom_segment(data = arrow.p, 
            #              aes(x=0, y=0, xend = NMDS1, yend = NMDS2,
            #                  lty = Variable),
            #              #Flechas escaladas según su R^2
            #              arrow = arrow(length = unit(.2, "cm")*arrow.p$R)
            #              )

mds.plot
```
